{
  "article_text": [
    "the deflection of light from a distant source by the gravitational influence of an intermediate object gives rise to so - called gravitational lensing systems .",
    "images of a source not only provide information about said source , but also encode properties about the mass of the object responsible for the deflection : the gravitational lens .    gravitational lens inversion , i.e. the determination of the mass density of the lens based on observed image properties , is the focus of this article .",
    "lens inversion procedures are often divided into two categories : parametric and non - parametric methods .",
    "parametric techniques approximate the mass distribution of the lens by a function that is characterized by a small number of parameters .",
    "they then optimize these parameters to provide the best possible fit to the observed data .",
    "several such algorithms have been proposed ( e.g. lensclean @xcite ) , and several software packages are publicly available ( e.g. gravlens @xcite and lenstool @xcite ) .",
    "non - parametric inversion methods try to avoid this restriction , for example by pixellizing the mass distribution ( e.g. @xcite ) , pixellizing the lens potential ( e.g. @xcite , @xcite ) or by dynamically adjusting the number of basis functions used ( e.g. @xcite ) .    in a previous article @xcite , we described a non - parametric inversion routine , intended for strong lensing systems containing many multiply imaged sources . using a genetic algorithm",
    ", we showed through simulations that the mass density of the lens can be reliably retrieved and that the reconstructed sources closely resemble their original counterparts .",
    "while such data is currently available @xcite and more of these systems are likely to be discovered in the future , they are currently far outnumbered by systems containing a handful of images of only one or a few sources .    for this reason , we felt the need to investigate the performance of the original procedure and the required modifications when confronted with a few - sources situation .",
    "as in the previous work , simulations are used to determine what can be inferred about the mass density when all the necessary information is available with great accuracy , thereby placing fundamental limits on the amount of information which can be extracted from such a lensing scenario .",
    "again , we will try to avoid imposing any prior on the mass density of the lens : only the information contained in the observed images is used .",
    "the situation being studied here , bears resemblance to the work of @xcite : there , based on the image locations of a few sources , a pixellized mass distribution of a cluster lens was reconstructed . however , while their algorithm uses one position per image , the method presented here makes use of the complete images .",
    "another important difference is that the method described in that article searches for the mass distribution which follows the light map as closely as possible .",
    "below , no information about the light map of the gravitational lens will be used .",
    "the following section contains a brief review of the lensing formalism , genetic algorithms and the original inversion technique .",
    "section [ sec : ext ] illustrates the difficulties encountered with the procedure and describes which measures can be taken to overcome them . after illustrating the effect of these modifications in sections [ sec : sim ] and [ sec : sim2 ] , our conclusions are summarized in section [ sec : conc ] .",
    "to first post - newtonian order , the gravitational lens effect can be well described by the so - called lens equation , describing a mapping @xmath0 from the image plane onto the source plane .",
    "our focus is on the strong lensing effect , in which multiple images of a source are generated .",
    "it is important to note that when these images are projected back onto the source plane using the lens equation , they must coincide since they are images of the same source . a thorough review of the gravitational lensing formalism can be found in @xcite .",
    "genetic algorithms implement a problem - solving strategy based on the principle of natural selection , present in biological systems .",
    "the procedure starts with a ` population ' of trial solutions , stored in an encoded form which is often referred to as the genome .",
    "each member of the population is then evaluated and a fitness measure is assigned . using the current population ,",
    "a new one is created by combining genomes  mimicking sexual reproduction  or by copying them  mimicking asexual reproduction .",
    "when selecting genomes in this process , a key ingredient of the genetic algorithm is to apply some form of selection pressure : genomes which are deemed more fit , should have a higher probability of creating offspring .",
    "this can be achieved by ranking the genomes according to their fitness measures and by assigning a higher selection probability to the genomes with a more favorable rank . after introducing some random mutations to ensure genetic diversity",
    ", the newly created population replaces the old one and the procedure is repeated until a stopping criterion is fulfilled . in some cases one can choose to apply ` elitism ' and copy the best genome in a generation directly to the next generation .",
    "research into this kind of evolutionary optimization was pioneered by @xcite and the type of genetic algorithm introduced there is now referred to as the canonical genetic algorithm .",
    "currently , genetic algorithms are available in many forms and are used to solve a wide variety of ( often high - dimensional ) problems , including the automatic generation of computer algorithms ( e.g. @xcite ) . for an excellent introduction to the use of genetic algorithms in an astrophysical context , the interested reader is referred to @xcite .",
    "the inversion procedure requires the user to define a square region in which the strong lensing mass will be reconstructed .",
    "this region is subdivided in a uniform grid of cells .",
    "each of the grid cells is assigned a basis function , more specifically a projected plummer sphere @xcite .",
    "writing the mass density distribution of the gravitational lens as a weighted sum of these basis functions , the gravitational lens effect is described by the following lens equation : @xmath1 here , @xmath2 is the center of a basis function , @xmath3 is its total mass and @xmath4 a measure of its width .",
    "a genetic algorithm is then applied to determine the weights @xmath3 of each basis function and the resulting mass distribution is used to create a new grid , in which regions containing a larger fraction of the mass will be subdivided further .",
    "a plummer basis function is assigned to each new grid cell and the genetic algorithm again determines the appropriate weights .",
    "this procedure can be repeated a number of times , depending on the desired level of detail .",
    "the genetic algorithm is clearly at the heart of this inversion method . for details about genome encoding , reproduction and mutation ,",
    "the reader is referred to @xcite . here",
    ", we will focus on the fitness evaluation since this determines the evolution of the algorithm towards a solution .",
    "the input of the entire procedure consists of the images associated with each source . using the plummer weights @xmath3 stored in a genome , equation ( [ eq : lenseqnmplum ] ) is used to project these images back onto their source planes .",
    "as was stated earlier , the correct lens equation generates overlapping images for each source , and it is precisely this criterion that is applied to determine the fitness of a genome .",
    "the left panel of fig .",
    "[ fig : backproj ] illustrates how the degree of overlap is measured .",
    "each back - projected image is surrounded by a rectangle of which the sides are parallel to the coordinate axes . if the back - projected images of a source overlap perfectly , so will the rectangles that surround each image .",
    "for this reason , the degree to which the images overlap will be approximated by the overlap of the associated rectangles .",
    "this can easily be calculated : two rectangles will coincide if their corners coincide , which suggests that the separation between corresponding corners can be used to measure the amount of overlap . to assign a fitness value , corresponding corners of the rectangles",
    "are connected with imaginary springs and the potential energy of the situation is calculated .",
    "note that in calculating distances between corners , the average size of the rectangles is used as the length scale .",
    "this makes sure that the overlap is measured relative to the size of the source . the same procedure is repeated for the other sources and the sum of all these potential energies is used as the fitness measure of the genome .",
    "lower values indicate a better overlap of the back - projected images and therefore correspond to genomes which are deemed more fit .",
    "several runs of this inversion routine typically generate solutions which differ somewhat .",
    "this is a result of the inherent randomness present in genetic algorithms which will manifest itself especially when the grid is refined further . averaging a number of individual solutions yields a final mass density which is far more smooth than any individual solution and inspecting the standard deviation provides information about the amount of disagreement between the generated solutions .",
    "this way , the standard deviation of individual solutions yields an indication of the uncertainty in the reconstructed mass density .",
    "note that this is only an indication , as it does not include systematic effects .",
    "tests with simulations indicate that when many multiply imaged sources are available , this procedure not only creates an excellent map of the lensing mass , but also retrieves the sizes and positions of the sources remarkably well .",
    "no prior assumptions are made regarding the mass density or the sources , and by construction , no negative mass densities will arise .",
    "the radial images are used in an effective way , i.e. the relative weight of a given image in the fitness value does not depend on its surface area , as in image fitting methods .",
    "this is an important feature if one is interested in obtaining the best possible estimate of the central mass density of the lens .    like other non - parametric inversion algorithms , in reality",
    "there are simply a very large number of parameters : the weights of a large amount of basis functions .",
    "plummer basis functions were chosen mainly for simplicity , but also because earlier tests indicated that a wide variety of mass distributions can be approximated by a sum of plummer basis functions .",
    "similar inversion results can be obtained using gaussian basis functions ; square basis functions appear to be less suitable as they quickly cause complex caustic structures .",
    "the inversion technique described above is intended to be used when many multiply imaged sources are available to constrain the mass distribution of the lens . to illustrate the problems one encounters in a situation where the lensing mass is poorly sampled",
    ", we use the sources and the lens mass density shown in fig .",
    "[ fig : reallens ] .",
    "the sources have an elliptical shape and are positioned at @xmath5 and @xmath6 respectively ; the lensing mass is located at @xmath7 . in this article , we use a standard cdm cosmology with a matter density @xmath8 and a hubble parameter @xmath9  km  s@xmath10  mpc@xmath10 for simplicity . as can be derived from the caustic structures , each source produces five images ,",
    "the positions of which are displayed in the left panel of fig .",
    "[ fig : realimages ] .",
    "the critical lines corresponding to both redshifts are also indicated in this figure .      when the procedure outlined above is applied to the images of fig .",
    "[ fig : realimages ] ( left panel ) , some undesired effects can be observed .",
    "the first one is demonstrated in the right panel of fig .",
    "[ fig : backproj ] . because the rectangles used to determine the degree of overlap in the back - projected images",
    "are aligned with the coordinate axes , crossing elliptical shapes will be interpreted as overlapping images . due to the large number of",
    "multiply imaged sources in the original study , and hence the large number of independent constraints , this problem did not manifest itself before .",
    "the solution to the problem is clear : the rectangles which are placed around the back - projected images should be rotated until they are aligned with their respective images .",
    "this can be done in an efficient way using the ` rotating calipers ' algorithm @xcite .",
    "another problem that surfaced due to the limited number of constraints , is non - overlapping brightness distributions of back - projected images .",
    "however , the fitness measure can easily be modified to correct this behavior : each rectangle is placed at a height corresponding to the maximal brightness value of the corresponding image . the average height is used as length scale in this direction and the fitness value is calculated as before , now using three - dimensional virtual springs instead of two - dimensional ones .",
    "the situation is illustrated in fig .",
    "[ fig : heights ] .",
    "more elaborate schemes can easily be implemented to ensure a suitable overlap of the back - projected images , at the cost of increasing the computer work load , but this will suffice for our goals . when these extensions are added to the original genetic algorithm , it is able to create solutions which produce overlapping images when projected back onto the source plane , both in the position and brightness domains .    unfortunately , when comparing the images predicted by the best lens solution with the observed ones , a more serious problem presented itself .",
    "because of the non - parametric nature of the reconstruction and the lack of firm constraints , the reconstructed lens mass distribution can contain many small - scale fluctuations that generate a host of images other than the observed ones .",
    "the right panel of fig .",
    "[ fig : realimages ] illustrates this undesired behavior .",
    "one possible solution to avoid this multitude of spurious images , is to impose some kind of prior on the lensing mass .",
    "for example , one could modify the fitness criterion to favor smoother mass distributions .",
    "undoubtedly , this would reduce the number of extra images since smoother mass distributions have less complex caustic structures .",
    "however , this goes against the spirit of our endeavor , which is to find out how much information can be retrieved non - parametrically from a few - image lens system .",
    "in order to avoid introducing this kind of bias in the generated solutions , a different approach is used . note that there is still much information available that has not yet been used .",
    "points in the image plane which are not part of an image of the source , i.e. the null space , provide additional constraints : if they are projected back onto the source plane using the correct lens equation , none of these points will lie inside the source area .",
    "otherwise , an image would be visible at that specific location . using the null space",
    "was already suggested in @xcite , but there , only null space points adjacent to the images were used .",
    "this can avoid the acceptance of solutions that produce images larger than the observed ones , but it obviously fails to avoid the extra images .    to incorporate the information in the null space , two schemes have been explored . in the first one , a regular grid of null space points is generated and the points which fall inside an input image are removed . to avoid generating images which lie relatively far from the other images , and thereby generating more mass than is necessary",
    ", the area in which the null space points are generated should be chosen large enough , i.e. somewhat larger than the area of the images themselves . an appropriate size can easily be discovered after a few attempts , but 10 - 20% larger is usually adequate .",
    "after projecting the images back onto the source plane , their envelope is calculated .",
    "this is the smallest convex polygon enclosing all the back - projected points , and is used as the current estimate of the source shape .",
    "next , each point in the null space is projected back onto the source plane and the number of points which lie inside the reconstructed source are counted .",
    "clearly , one would like this count to be as low as possible , since our objective is to remove the extra images .",
    "note that by only considering a discrete number of points in the null space , it is possible that small images are generated which lie in between null space points .    instead of simply using points",
    ", one can also divide the null space into a number of small triangles , similar to the approach in @xcite .",
    "when these are projected back onto the source plane , for each triangle the amount of overlap with the reconstructed source is calculated .",
    "the corresponding area of the triangle in the image plane is then used as this triangle s contribution to the null space fitness measure .",
    "again , this number should be as low as possible to avoid generating extra images .",
    "the advantage of this method is that it becomes easier to avoid small undesired images , at the cost of increased computational complexity .    in any case , at this point two numbers describe the fitness of a genome under study : one describes the overlap of the back - projected images , the other takes the null space into account . at first",
    ", one might try summing the two fitness values , multiplying each term with a specific weight .",
    "indeed , our first successful lens reconstructions used such a technique .",
    "however , using a weighted scheme requires the end - user to find and specify acceptable weight values .",
    "furthermore , using specific weight values will automatically bias the path followed in the search space as the optimization routine progresses .",
    "fortunately , there is no need to specify a weight factor .",
    "genetic algorithms are excellent solvers of multi - objective or multi - criterion optimization problems .",
    "below , some key concepts are introduced .",
    "the interested reader is referred to @xcite for an in - depth treatment of this subject .    in a multi - objective genetic algorithm",
    "a genome has several fitness measures , each one related to a specific aspect of the optimization problem .",
    "a genome is said to dominate another genome if two criteria are met : _",
    "( i ) _ it is not worse in all fitness measures , and _",
    "( ii ) _ it is strictly better in at least one fitness measure . using this concept of dominance , one can identify in a population the members which are not dominated by any other genome , resulting in the so - called non - dominated set .",
    "the concept of a non - dominated set is used to devise a new ranking scheme , as there is no longer a single fitness criterion to base the ranking procedure on .",
    "first , the non - dominated set of the entire population is calculated .",
    "the genomes in this set will receive the highest rank . after removing this set from the population , a new non - dominated set is identified and these genomes receive the next - to - highest rank .",
    "the procedure is repeated until all genomes of the population are processed .",
    "afterwards , the genetic algorithm can proceed as before .",
    "when there are conflicting objectives , there is a whole range of optimal solutions : the pareto - optimal front . there",
    "exist procedures to preserve a certain amount of diversity in the population , allowing the pareto - optimal front to be well sampled by the genetic algorithm . in our specific case however , the objectives are not conflicting and no further modifications are required .",
    "using the procedure outlined above , it is now straightforward to generate solutions which indeed only produce the input images . averaging twenty such solutions yields the mass density and reconstructed sources shown in fig .",
    "[ fig : avglens ] . comparing this figure with fig .",
    "[ fig : reallens ] , one immediately notices the striking resemblance .",
    "this proves that our method is capable of reproducing , at least qualitatively , the mass density distribution of a gravitational lens based on the positions , redshifts , and shapes of very few images and on null space information . the peaks in the reconstructed mass density appear to be somewhat stronger than those of the input lens .",
    "the reconstructed sources are very similar in shape to the true sources and their positions lie very close to those of the input sources .",
    "the reconstructed sources are , however , more extended than the input sources .",
    "the caustic structure presented in the middle and right panels of fig .",
    "[ fig : avglens ] are strikingly similar to but more extended than those of the input lens , presented in the middle and right panels of fig .",
    "[ fig : reallens ] . in this example",
    "the method using null space triangles was used , based on a regular @xmath11 grid , covering an area of @xmath12 arcmin@xmath13 .",
    "it is interesting to take a look at the difference in mass densities between original and reconstructed lens .",
    "the left panel of fig .",
    "[ fig : diff3d ] shows that the mass density around the peak positions is not reconstructed very well . inspecting the right panel of the same figure , which displays the standard deviation of the individual solutions , it is clear that precisely these regions differ strongly among the solutions . when the reconstructed source and lens are used to reproduce the images , the result shown in the left panel of fig .",
    "[ fig : avgimages ] is obtained .",
    "the ten input images are indeed reproduced and the critical lines closely resemble those of fig .",
    "[ fig : realimages ] ( left panel ) .",
    "one can not ask more from any lens inversion algorithm .",
    "the right panel of fig .",
    "[ fig : avgimages ] shows the circularly averaged mass density , centered on the mass density peak at @xmath14 .",
    "this plot visualizes once more the overestimated mass density in that region , although the same general features are clearly present in both original and reconstructed profile .",
    "when the total mass of the lens is calculated , the agreement is excellent within a radius of 1 , differing by only a few percent from the true mass , as is shown in fig .",
    "[ fig : profile ] . beyond that radius ,",
    "the difference starts to increase , indicating that using only the strong lens effect , one can not obtain a firm handle on the mass density outside the radius of the outer images .",
    "it was mentioned before that the reconstructed sources are somewhat larger ( and brighter ) than the true sources . since",
    "two sources are used in this simulation , this can not be the result of the mass sheet degeneracy ( e.g. @xcite ) and some other type of degeneracy must be at work here . in a single - source scenario , the mass - sheet degeneracy",
    "is artificially broken : the mass density of the reconstructions quickly drops to zero outside of the grid and it is unlikely that the procedure will construct a circular area of constant density using ( randomly initialized ) basis functions arranged on a grid .",
    "one might argue that a system with two sources and ten images still provides a relatively large number of constraints .",
    "for this reason , let us now turn to a simple five - image system , created by an elliptical mass distribution .",
    "the source and its corresponding images are depicted in the left panel of fig .",
    "[ fig : ell ] .",
    "the redshifts of the source and the lens are @xmath15 and @xmath16 respectively .",
    "note that in this situation the mass - sheet degeneracy is artificially broken , as explained above .",
    "in this case , the inversion algorithm seems to easily produce solutions causing a critical line to intersect the two rightmost images . to avoid this ,",
    "the brightness overlap and positional overlap were used as two separate fitness measures . since their combination",
    "can be seen as a weighting scheme , decoupling them allows a broader search in the model space .",
    "afterwards , the genetic algorithm was indeed able to consistently find solutions which reproduce the input images .",
    "after averaging ten solutions obtained using a moderately subdivided grid , the results shown in the center panel of fig .",
    "[ fig : ell ] were obtained .",
    "this clearly resembles the true situation , although the source is again larger and brighter . if the grid is subdivided further , this results in the situation depicted in the right panel of fig .  [ fig : ell ] , showing more complex critical lines and corresponding caustic structure .",
    "it is important to note that the resulting genome fitness did not improve significantly by using a finer grid . in practice ,",
    "due to a lack of constraints , one may simply opt for the least complex reconstruction .",
    "however , as is shown in the right panel of fig .",
    "[ fig : ell ] , the algorithm is indeed able to produce viable solutions containing small - scale variability introduced by using approximately one thousand basis functions .",
    "this ability to handle different scales well is , of course , required to qualify as a truly non - parametric technique .",
    "in this article we have presented an extension of our previously proposed inversion algorithm , which was intended to be used on a strong lensing system with many multiply imaged sources . since currently the number of known strong lensing systems with few sources far exceed those with many , we felt it was appropriate to study the necessary extensions of the original procedure to allow such systems to be inverted non - parametrically .",
    "the modifications presented above still use only physically motivated arguments and do not impose any prior on the reconstructed mass density .",
    "the inclusion of the null space led to an additional fitness measure , which can be handled efficiently and without the need of a weight parameter using a multi - objective genetic algorithm . in a similar way one could incorporate even more constraints , e.g. from the weak lensing regime or from time delay measurements , without the need for weights .",
    "this generic way of handling various types of constraints is clearly a great advantage of the proposed inversion method .",
    "we found that including brightness information is in this case necessary to ascertain acceptable source reconstructions .",
    "it is interesting to note that even without this extra information , the inclusion of the null space already brings out most of the general structure of the mass distribution .",
    "this suggests that uncertainty in measured image intensities will not prevent a good reconstruction of the mass density , which is important from a practical point of view .",
    "although the examples shown above seem to suggest a bias towards larger and brighter reconstructed sources , it is easy to create a scenario in which the genetic algorithm will cause the reconstructed sources to be smaller and dimmer .",
    "this kind of degeneracy can only be resolved if more data are available or some prior is imposed on the source . the fact that the true source features can not be obtained with certainty even when",
    "all the information is available with the greatest accuracy , indicates that care should be taken when interpreting source data obtained by strong lens inversion in general .",
    "deviations from the true mass density are to be expected , not only because of the sparse sampling of the lens equation , but also because of the inherent degenerate nature of the lens inversion problem . nevertheless , the similarities between the original lens systems and the reconstructions are remarkable , especially when taking into consideration that no prior information about the lens was needed .",
    "this indicates that much information is present in a strong lensing system and that it can be extracted non - parametrically using only information about the observed images .",
    "above , we have investigated only the ideal situation , when all image positions and fluxes are known accurately .",
    "practical difficulties like incomplete null space information , obscured images , measurement errors or the effect of a point spread function will further reduce the information content of a strong lensing system .",
    "the precise impact of these factors will require further research .",
    "furthermore , if relatively large images are present , it is likely that the simple technique to determine the overlap between images will fail .",
    "we are currently exploring methods to take image substructure into account to be able to handle such cases effectively .",
    "we would like to thank the anonymous referee for thoroughly reviewing the manuscript and supplying many valuable suggestions ."
  ],
  "abstract_text": [
    "<S> galaxies acting as gravitational lenses are surrounded by , at most , a handful of images . </S>",
    "<S> this apparent paucity of information forces one to make the best possible use of what information is available to invert the lens system . in this paper </S>",
    "<S> , we explore the use of a genetic algorithm to invert in a non - parametric way strong lensing systems containing only a small number of images . </S>",
    "<S> perhaps the most important conclusion of this paper is that it is possible to infer the mass distribution of such gravitational lens systems using a non - parametric technique . </S>",
    "<S> we show that including information about the null space ( i.e. the region where no images are found ) is prerequisite to avoid the prediction of a large number of spurious images , and to reliably reconstruct the lens mass density . while the total mass of the lens is usually constrained within a few percent , the fidelity of the reconstruction of the lens mass distribution depends on the number and position of the images . </S>",
    "<S> the technique employed to include null space information can be extended in a straightforward way to add additional constraints , such as weak lensing data or time delay information .    </S>",
    "<S> [ firstpage ]    gravitational lensing  </S>",
    "<S> methods :  data analysis  dark matter  galaxies :  clusters :  general </S>"
  ]
}