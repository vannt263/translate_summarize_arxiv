{
  "article_text": [
    "in the study of networked systems such as social , biological , and technological networks , centrality is one of the most fundamental of metrics .",
    "centrality quantifies how important or influential a node is within a network .",
    "the simplest of centrality measures , the _ degree centrality _ , or simply degree , is the number of connections a node has to other nodes . in a social network of acquaintances , for example , someone who knows many people is likely to be more influential than someone who knows few or none .",
    "eigenvector centrality  @xcite is a more sophisticated variant of the same idea , which recognizes that not all acquaintances are equal .",
    "you are more influential if the people you know are themselves influential .",
    "eigenvector centrality defines a centrality score  @xmath0 for each node  @xmath1 in an undirected network , which is proportional to the sum of the scores of the node s network neighbors @xmath2 , where @xmath3 is a constant and the sum is over all nodes . here",
    "@xmath4 is an element of the adjacency matrix  @xmath5 of the network having value one if there is an edge between nodes @xmath1 and  @xmath6 and zero otherwise . defining a vector  @xmath7 whose elements are the @xmath0",
    ", we then have @xmath8 , meaning that the vector of centralities is an eigenvector of the adjacency matrix . if we further stipulate that the centralities should all be nonnegative , it follows by the perron ",
    "frobenius theorem  @xcite that @xmath7 must be the leading eigenvector ( the vector corresponding to the most positive eigenvalue  @xmath3 ) .",
    "eigenvector centrality and its variants are some of the most widely used of all centrality measures .",
    "they are commonly used in social network analysis  @xcite and form the basis for ranking algorithms such as the hits algorithm  @xcite and the eigenfactor metric  @xcite .    as we argue in this paper",
    ", however , eigenvector centrality also has serious flaws .",
    "in particular , we show that , depending on the details of the network structure , the leading eigenvector of the adjacency matrix can undergo a localization transition in which most of the weight of the vector concentrates around one or a few nodes in the network . while there may be situations , such as the solution of certain physical models on networks , in which localization of this kind is useful or at least has some scientific interest , in the present case it is undesirable , significantly diminishing the effectiveness of the centrality as a tool for quantifying the importance of nodes . moreover , as we will show , localization can happen under common real - world conditions , for instance in networks with power - law degree distributions .    as a solution to these problems ,",
    "we propose a new centrality measure based on the leading eigenvector of the hashimoto or nonbacktracking matrix  @xcite .",
    "this measure has the desirable properties of ( 1 )  being closely equal to the standard eigenvector centrality in dense networks , where the latter is well behaved , while also ( 2 )  avoiding localization , and hence giving useful results , in cases where the standard centrality fails .",
    "a number of numerical studies of real - world networks have shown evidence of localization phenomena in the past  @xcite . in this paper",
    "we formally demonstrate the existence of a localization phase transition in the eigenvector centrality and calculate its properties using techniques of random matrix theory .",
    "the fundamental cause of the localization phenomenon we study is the presence of `` hubs '' within networks , nodes of unusually high degree , which are a common occurrence in many real - world networks  @xcite .",
    "consider the following simple undirected network model consisting of a random graph plus a single hub node , which is a special case of a model introduced previously in  @xcite . in a network of @xmath9 nodes ,",
    "@xmath10  of them form a random graph in which every distinct pair of nodes is connected by an undirected edge with independent probability  @xmath11 , where @xmath12 is the mean degree .",
    "the @xmath9th node is the hub and is connected to every other node with independent probability @xmath13 , so that the expected degree of the hub is  @xmath14 . in the regime where @xmath15 it is known that ( with high probability ) the spectrum of the random graph alone has the classic wigner semicircle form , centered around zero , plus a single leading eigenvalue with value @xmath16 and corresponding leading eigenvector equal to the uniform vector @xmath17 plus random gaussian noise of width  @xmath18  @xcite .",
    "thus the eigenvector centralities of all vertices are @xmath18 with only modest fluctuations .",
    "no single node dominates the picture and the eigenvector centrality is well behaved .",
    "if we add the hub to the picture , however , things change .",
    "the addition of an extra vertex naturally adds one more eigenvalue and eigenvector to the spectrum , whose values we can calculate as follows . let @xmath19 denote the @xmath20 adjacency matrix of the random graph alone and let the vector  @xmath21 be the first @xmath10 elements of the final row and column , representing the hub .",
    "( the last element is zero . )",
    "thus the full adjacency matrix has the form @xmath22    let @xmath23 be an eigenvalue of  @xmath5 and let @xmath24 be the corresponding eigenvector , where @xmath25 represents the first @xmath10 elements and @xmath26 is the last element . then , multiplying out the eigenvector equation @xmath27 , we find @xmath28 rearranging the first of these , we get @xmath29 and substituting into the second we get @xmath30 where @xmath31 is the identity . writing the matrix inverse in terms of its eigendecomposition @xmath32 , where @xmath33 is the @xmath1th eigenvector of  @xmath19 and @xmath34 is the corresponding eigenvalue , eq .   becomes @xmath35 where we have explicitly separated the largest eigenvalue  @xmath36 and the remaining @xmath37 eigenvalues , which follow the semicircle law .",
    "although we do nt know the values of the quantities @xmath38 appearing in eq .  , the left - hand side as a function of  @xmath23 clearly has poles at each of the eigenvalues  @xmath34 and a tail that goes as @xmath39 for large  @xmath23 .",
    "moreover , for properly normalized  @xmath40 the numerator of the first term in the equation is @xmath41 and hence this term diverges significantly only when @xmath42 is also  @xmath41 , i.e. ,  when @xmath23 is very close to the leading eigenvalue  @xmath16 .",
    "hence the qualitative form of the function must be as depicted in fig .",
    "[ fig : solution ] and solutions to the full equation correspond to the points where this form crosses the diagonal line representing the right - hand side of the equation .",
    "these points are marked with dots in the figure .    as the geometry of the figure makes clear",
    ", the solutions for  @xmath23 , which are the eigenvalues of the full adjacency matrix of our model including the hub vertex , must fall in between the eigenvalues  @xmath34 of the matrix  @xmath19 , and hence satisfy an interlacing condition of the form @xmath43 , where we have numbered both sets of eigenvalues in order from largest to smallest . in the limit where the network becomes large and the eigenvalues @xmath44 form a continuous semicircular band , this interlacing imposes tight bounds on the solutions @xmath45 to  @xmath46 , such that they must follow the same semicircle distribution .",
    "moreover , the leading eigenvalue  @xmath47 has to fall within @xmath41 of @xmath36 , and hence @xmath48 in the large size limit .",
    "( marked by the vertical dashed lines ) .",
    "the diagonal line represents the right - hand side and the points where the two cross , marked by dots , are the solutions of the equation for  @xmath23.,width=321 ]    this leaves just two unknown eigenvalues , @xmath49  lying above the semicircular band and @xmath50 lying below it . in the context of the eigenvector centrality it is the one at the top that we care about . in fig .",
    "[ fig : solution ] this eigenvalue is depicted as lying below the leading eigenvalue  @xmath47 , but it turns out that this is not always the case , as we now show .",
    "consider eq .",
    "for any value of  @xmath23 well away from  @xmath16 , so that the first term on the left can be neglected ( meaning that @xmath23 is not within @xmath41 of @xmath16 ) .",
    "the vector  @xmath33 for @xmath51 is uncorrelated with @xmath21 and hence the product @xmath38 is a gaussian random variable with variance  @xmath52 and , averaging over the randomness , the equation then simplifies to @xmath53 the quantity @xmath54 is a standard one in the theory of random matrices  it is the so - called stieltjes transform of  @xmath19 , whose value for a symmetric matrix with iid elements such as this one is known to be  @xcite @xmath55 combining eqs .   and   and solving for @xmath23 we find the eigenvalue we are looking for : @xmath56    depending on the degree  @xmath14 of the hub , this eigenvalue may be either smaller or larger than the other high - lying eigenvalue  @xmath57 . writing @xmath58 and rearranging , we see that the hub eigenvalue becomes the leading eigenvalue when @xmath59 i.e. ,  when the hub degree is roughly the square of the mean degree . below this point ,",
    "the leading eigenvalue is the same as that of the random graph without the hub and the eigenvector centrality is given by the corresponding eigenvector , which is well behaved , so the centrality has no problems . above this point",
    ", however , the leading eigenvector is the one introduced by the hub , and this eigenvector , as we now show , has severe problems .",
    "if the eigenvector  @xmath24 is normalized to unity then eq",
    ".   implies that @xmath60,\\ ] ] and hence @xmath61 where @xmath62 is again the stieltjes transform , eq .  ,",
    "and @xmath63 is its derivative . performing the derivative and setting @xmath64",
    ", we find that @xmath65 which is constant and does not vanish as @xmath66 .",
    "in other words , a finite fraction of the weight of the vector is concentrated on the hub vertex .",
    "the neighbors of the hub also receive significant weight : the average of their values is given by @xmath67 thus they are smaller than the hub centrality  @xmath26 , but still constant for large  @xmath9 . finally , defining the @xmath68-element uniform vector @xmath69 , the average of all @xmath10 non - hub vector elements is @xmath70 where we have used eq .   again .",
    "averaging over the randomness and noting that @xmath19 and @xmath21 are independent and that the average of  @xmath21 is @xmath71 , we then get @xmath72 which falls off as @xmath73 for large  @xmath9 .    thus , in the regime above the transition defined by  , where the eigenvector generated by adding the hub is the leading eigenvector , a non - vanishing fraction of the eigenvector centrality falls on the hub vertex and its neighbors , while the average vertex in the network gets only an @xmath41 vanishing fraction in the limit of large  @xmath9 , much less than the @xmath18 fraction received by the average vertex below the transition .",
    "this is the phenomenon we refer to as localization : the abrupt focusing of essentially all of the centrality on just a few vertices as the degree of the hub passes above the critical value  @xmath74 . in the localized regime",
    "the eigenvector centrality picks out the hub and its neighbors clearly , but assigns vanishing weight to the average node .",
    "if our goal is to determine the relative importance of non - hub nodes , the eigenvector centrality will fail in the localized regime .      as a demonstration of the localization phenomenon",
    ", we show in fig .",
    "[ fig : hub ] plots of the centralities of nodes in networks generated using our model .",
    "each plot shows the average centrality of the hub , its neighbors , and all other nodes for a one - million - node network with @xmath75 .",
    "the top two plots show the situation for the standard eigenvector centrality for two different values of the hub degree@xmath76 and @xmath77 .",
    "the former lies well within the regime where there is no localization , while the latter is in the localized regime . the difference between the two is striking  in the first the hub and",
    "its neighbors get higher centrality , as they should , but only modestly so , while in the second the centrality of the hub vertex becomes so large as to dominate the figure .        the extent of the localization can be quantified by calculating an inverse participation ratio @xmath78 . in the regime below the transition where there is no localization and all elements  @xmath0",
    "are @xmath18 we have @xmath79 .",
    "but if one or more elements are @xmath80 , then @xmath81 also .",
    "hence if there is a localization transition in the network then , in the limit of large  @xmath9 , @xmath82  will go from being zero to nonzero at the transition in the classic manner of an order parameter .",
    "[ fig : transition ] shows a set of such transitions in our model , each falling precisely at the expected position of the localization transition .",
    "so far we have looked only at the localization process in a simple model network , but localization occurs in more realistic networks as well .",
    "in general , we expect it to be a problem in networks with high - degree hubs or in very sparse networks , those with low average degree  @xmath12 , where it is relatively easy for the degree of a typical vertex to exceed the localization threshold .",
    "many real - world networks fall into these categories .",
    "consider , for example , the common case of a network with a power - law degree distribution , such that the fraction  @xmath83 of nodes with degree  @xmath84 goes as @xmath85 for some constant exponent  @xmath86  @xcite .",
    "we can mimic such a network using the so - called configuration model  @xcite , a random graph with specified degree distribution .",
    "there are again two different ways a leading eigenvalue can be generated , one due to the average behavior of the entire network and one due to hub vertices of particularly high degree . in the first case the highest eigenvalue for the configuration model is known to be equal to the ratio of the second and first moments of the degree distribution  @xmath87 in the limit of large network size and large average degree  @xcite . at the same time , the leading eigenvalue must satisfy the rayleigh bound @xmath88 for any real vector  @xmath89 , with better bounds achieved when  @xmath89 better approximates the true leading eigenvector .",
    "if @xmath14 denotes the highest degree of any hub in the network and we choose an approximate eigenvector of form similar to the one in our earlier model network , having elements @xmath90 for the hub , @xmath91  for neighbors of the hub , and zero otherwise , then the rayleigh bound implies @xmath92 .",
    "thus the eigenvector generated by the hub will be the leading eigenvector whenever @xmath93 ( possibly sooner , but not later ) .",
    "as a function of hub degree  @xmath14 for networks generated using the model described in the text with @xmath94 vertices and average degree @xmath12 ranging from 4 to  11 .",
    "the solid curves are eigenvector centrality ; the horizontal dashed curves are the nonbacktracking centrality .",
    "the vertical dashed lines are the expected positions of the localization transition for each curve , from eq .",
    ".,width=321 ]    in a power - law network with @xmath9 vertices and exponent  @xmath86 , the highest degree goes as @xmath95  @xcite and hence increases with increasing  @xmath9 , while @xmath96 and @xmath97 for the common case of @xmath98 .",
    "thus we will have @xmath93 for large  @xmath9 provided @xmath99 .",
    "so we expect the hub eigenvector to dominate and the eigenvector centrality to fail due to localization when @xmath100 , something that happens in many real - world networks .",
    "( similar arguments have also been made by chung  _ et  al . _  @xcite and by goltsev  _ et  al . _",
    "we give empirical measurements of localization in a number of real - world networks in table  [ tab : power ] below .",
    "so if eigenvector centrality fails to do its job , what can we do to fix it ?",
    "qualitatively , the localization effect arises because a hub with high eigenvector centrality gives high centrality to its neighbors , which in turn reflect it back again and inflate the hub s centrality .",
    "we can make the centrality well behaved again by preventing this reflection . to achieve this",
    "we propose a modified eigenvector centrality , similar in many ways to the standard one , but with an important change .",
    "we define the centrality of node  @xmath6 to be the sum of the centralities of its neighbors as before , but the neighbor centralities are now calculated _ in the absence of node  @xmath6_. this is a natural definition in many ways ",
    "when i ask my neighbors what their centralities are in order to calculate my own , i want to know their centrality due to their other neighbors , not myself .",
    "this modified eigenvector centrality has the desirable property that when typical degrees are large , so that the exclusion or not of any one node makes little difference , its value will tend to that of the standard eigenvector centrality .",
    "but in sparser networks of the kind that can give problems , it will be different from the standard measure and , as we will see , better behaved .",
    "our centrality measure can be calculated using the hashimoto or nonbacktracking matrix  @xcite , which is defined as follows .",
    "starting with an undirected network with @xmath101  edges , one first converts it to a directed one with @xmath102 edges by replacing each undirected edge with two directed ones pointing in opposite directions .",
    "the nonbacktracking matrix  @xmath103 is then the @xmath104 non - symmetric matrix with one row and one column for each directed edge  @xmath105 and elements @xmath106 where @xmath107 is the kronecker delta .",
    "thus a matrix element is equal to one if edge  @xmath105 points into the same vertex that edge  @xmath108 points out of and edges  @xmath105 and @xmath108 are not pointing in opposite directions between the same pair of vertices , and zero otherwise .",
    "note that , since the nonbacktracking matrix is not symmetric , its eigenvalues are in general complex , but the largest eigenvalue is always real , as is the corresponding eigenvector .",
    "the element  @xmath109 of the leading eigenvector of the nonbacktracking matrix now gives us the centrality of vertex  @xmath1 ignoring any contribution from  @xmath6 , and the full nonbacktracking centrality  @xmath110 of vertex  @xmath6 is defined to be the sum of these centralities over the neighbors of  @xmath6 : @xmath111 in principle one can calculate this centrality directly by calculating the leading eigenvector of  @xmath103 and then applying eq .  .",
    "in practice , however , one can perform the calculation faster by making use of the so - called ihara ( or ihara  bass ) determinant formula , from which it can be shown  @xcite that the vector  @xmath89 of centralities is equal to the first @xmath9 elements of the leading eigenvector of the @xmath112 matrix @xmath113 where @xmath5 is the adjacency matrix as previously , @xmath31 is the @xmath114 identity matrix , and @xmath115 is the diagonal matrix with the degrees of the vertices along the diagonal . since @xmath116 only has marginally more nonzero elements than the adjacency matrix itself ( @xmath117 for a network with @xmath101 edges and @xmath9 vertices , versus @xmath102 for the adjacency matrix ) , finding its leading eigenvector takes only slightly longer than the calculation of the ordinary eigenvector centrality .    to see that the nonbacktracking centrality can indeed eliminate the localization transition ,",
    "consider again our random - graph - plus - hub model and , as before , let us first consider the random graph on its own , without the hub",
    ". our goal will be to calculate the leading eigenvalue of the nonbacktracking matrix for this random graph and then demonstrate that no other eigenvalue ever surpasses it even when the hub is added into the picture , and hence that there is no transition of the kind that occurs with the standard eigenvector centrality .",
    "since all elements of the nonbacktracking matrix are real and nonnegative , the leading eigenvalue and eigenvector satisfy the perron ",
    "frobenius theorem , meaning the eigenvalue is itself real and nonnegative as are all elements of the eigenvector for appropriate choice of normalization .",
    "note moreover that at least one element of the eigenvector must be nonzero , so the average of the elements is strictly positive .    making use of the definition of the nonbacktracking matrix in eq .",
    ", the eigenvector equation @xmath118 takes the form @xmath119 or @xmath120 where we have changed variables from  @xmath84 to @xmath6 for future convenience .",
    "expressed in words , this equation says that @xmath23  times the centrality of an edge emerging from vertex  @xmath6 is equal to the sum of the centralities of the other edges feeding into  @xmath6 . for an uncorrelated , locally",
    "tree - like random graph of the kind we are considering here , i.e. ,  a network where the source and target of a directed edge are chosen independently and there is a vanishing density of short loops , the centralities on the incoming edges are drawn at random from the distribution over all edges  the fact that they all point to vertex  @xmath6 has no influence on their values in the limit of large graph size . bearing this in mind ,",
    "let us calculate the average  @xmath121 of the centralities  @xmath122 over all edges in the network , which we do in two stages .",
    "first , making use of eq .",
    ", we calculate the sum over all edges originating at vertices  @xmath6 whose degree  @xmath123 takes a particular value  @xmath84 : @xmath124 where @xmath125 is the number of vertices with degree  @xmath84 and we have in the third line made use of the fact that @xmath109 has the same distribution as values in the graph as whole to make the replacement @xmath126 in the limit of large graph size .",
    "now we sum this expression over all values of  @xmath84 and divide by the total number of edges  @xmath102 to get the value of the average vector element  @xmath121 : @xmath127 thus for any vector  @xmath7 we must either have @xmath128 , which as we have said can not happen for the leading eigenvector , or @xmath129 for the particular case of the poisson random graph under consideration here , this gives a leading eigenvalue of @xmath130 , the average degree .",
    "this result has been derived previously by other means  @xcite but the derivation given here has the advantage that it is easy to adapt to the case where we add a hub vertex to the network .",
    "doing so adds just a single term to eq .",
    "thus : @xmath131,\\ ] ] where @xmath14 is the degree of the hub , as previously .",
    "hence the leading eigenvalue is @xmath132 for constant  @xmath14 and constant ( or growing ) average degree , however , the term in  @xmath14 becomes negligible in the limit of large  @xmath9 and we recover the same result as before @xmath130 .",
    "thus no new leading eigenvalue is introduced by the hub in the case of the nonbacktracking matrix , and there is no phase transition as eigenvalues cross for any value of  @xmath14 .",
    "it is worth noting , however , that there are other mechanisms by which high - lying eigenvalues can be generated .",
    "for instance , if a network contains a large clique ( a complete subgraph in which every node is connected to every other ) it can generate an outlying eigenvalue of arbitrary size , as we can see by making use of the so - called collatz ",
    "wielandt formula , a corollary of the perron ",
    "frobenius theorem that says that for any vector  @xmath7 the leading eigenvalue satisfies @xmath133_i}{v_i}.\\ ] ] choosing a @xmath7 whose elements are one for edges within the clique and zero elsewhere , we find that a clique of size  @xmath84 implies @xmath134 , which can supersede any other leading eigenvalue for sufficiently large  @xmath84 .",
    "the corresponding eigenvector is localized on the clique vertices , potentially causing trouble once again for the eigenvector centrality .",
    "this localization on cliques would be an interesting topic for further investigation .      as a test of our nonbacktracking centrality ,",
    "we show in the lower two panels of fig .",
    "[ fig : hub ] results for the same networks as the top two panels .",
    "as the figure makes clear , the measure now remains well behaved in the regime beyond the former position of the localization transition  there is no longer a large jump in the value of the centrality on the hub or its neighbors as we pass the transition .",
    "similarly , the dashed curves in fig .  [ fig : transition ] show the inverse participation ratio for the nonbacktracking centrality and again all evidence of localization has vanished .",
    "llrcc & & & & non- + & network & & eigenvector & backtracking +    90    & planted hub , @xmath76 & 1000001 & @xmath135 & @xmath136 + & planted hub , @xmath77 & 1000001 & 0.2567 & @xmath136 + & power law , @xmath137 & 1000000 & 0.0089 & 0.0040 + & power law , @xmath138 & 1000000 & 0.2548 & 0.0011 +    90    & physics collaboration & 12008 & 0.0039 & 0.0039 + & word associations & 13356 & 0.0305 & 0.0075 + & youtube friendships & 1138499 & 0.0479 & 0.0047 + & company ownership & 7253 & 0.2504 & 0.0161 + & ph.d . advising & 1882 & 0.2511 & 0.0386 + & electronic circuit & 512 & 0.1792 & 0.0056 + & amazon & 334863 & 0.0510 & 0.0339    the inverse participation ratio also provides a convenient way to test for localization in other networks , both synthetic and real .",
    "table  [ tab : power ] summarizes results for eleven networks , for both the traditional eigenvector centrality and the nonbacktracking version .",
    "the synthetic networks are generated using the random - graph - plus - hub model of this paper and the configuration model with power - law degree distribution , and in each case there is evidence of localization in the eigenvector centrality in the regimes where it is expected and not otherwise , but no localization at all , in any case , for the nonbacktracking centrality . a similar picture is seen in the real - world networks  typically either localization in the eigenvector centrality but not the nonbacktracking version , or localization in neither case .",
    "figure  [ fig : circuit ] illustrates the situation for one of the smaller real - world networks , where the values on the highest - degree vertex and its neighbors are overwhelmingly large for the eigenvector centrality ( left panel ) but not for the nonbacktracking centrality ( right panel ) .",
    "in this paper we have shown that the widely used network measure known as eigenvector centrality fails under commonly occurring conditions because of a localization transition in which most of the weight of the centrality concentrates on a small number of vertices .",
    "the phenomenon is particularly visible in networks with high - degree hubs or power - law degree distributions , which includes many important real - world examples .",
    "we propose a new spectral centrality measure based on the nonbacktracking matrix which rectifies the problem , giving values similar to the standard eigenvector centrality in cases where the latter is well behaved , but avoiding localization in cases where the standard measure fails .",
    "the new measure is found to give significant decreases in localization on both synthetic and real - world networks .",
    "moreover , the new measure can be calculated almost as quickly as the standard one , and hence is practical for the analysis of very large networks of the kind common in recent studies .",
    "the nonbacktracking centrality is not the only possible solution to the problem of localization .",
    "for example , in studies of other forms of localization in networks it has been found effective to introduce a regularizing `` teleportation '' term into the adjacency and similar matrices , i.e. ,  to add a small amount to every matrix element as if there were a weak edge between every pair of vertices  @xcite .",
    "this strategy is reminiscent of google s pagerank centrality measure  @xcite , a popular variant of eigenvector centrality that includes such a teleportation term , and recent empirical studies suggest that pagerank may be relatively immune to localization  @xcite .",
    "it would be a worthwhile topic for future research to develop theory similar to that presented here to describe localization ( or lack of it ) in pagerank and related measures .",
    "the authors thank cris moore , elchanan mossel , raj rao nadakuditi , romualdo pastor - satorras , lenka zdeborov , and pan zhang for useful conversations .",
    "this work was funded in part by the national science foundation under grants dms1107796 and dms1407207 and by the air force office of scientific research ( afosr ) and the defense advanced research projects agency ( darpa ) under grant fa95501210432 ."
  ],
  "abstract_text": [
    "<S> eigenvector centrality is a common measure of the importance of nodes in a network . here </S>",
    "<S> we show that under common conditions the eigenvector centrality displays a localization transition that causes most of the weight of the centrality to concentrate on a small number of nodes in the network . in this regime </S>",
    "<S> the measure is no longer useful for distinguishing among the remaining nodes and its efficacy as a network metric is impaired . as a remedy </S>",
    "<S> , we propose an alternative centrality measure based on the nonbacktracking matrix , which gives results closely similar to the standard eigenvector centrality in dense networks where the latter is well behaved , but avoids localization and gives useful results in regimes where the standard centrality fails . </S>"
  ]
}