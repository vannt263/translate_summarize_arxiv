{
  "article_text": [
    "the advent of popular manycore systems has made concurrent programming for shared memory systems an important topic . with increasing parallelism available in a single shared - memory system , performance of techniques used to communicate between concurrently executing threads , or to access memory common to many such threads , is becoming one of the most significant components of the performance of an application running on such a system . in many cases of communication - heavy tasks , simple",
    "coarse - grained locking is not enough to yield good performance , so programmers need to resort to lock - less communication and concurrent data structures .",
    "this work provides a new data structure with an implementation that can be used concurrently and does nt use locks , and uses it to create an implementation of the fetch - and - add object ( a kind of counter ) with improved memory usage .      a useful abstraction in a single - threaded system is an object : an entity with a set of methods one can invoke , and a specification of semantics of these methods .",
    "naturally , a program can use multiple objects and invoke their methods in any order .",
    "we want to use a similar abstraction to model interaction between threads in a multi - threaded system .",
    "consider a set of independent , concurrently running threads ( running possibly distinct code ) that can only communicate by calling methods on some objects .",
    "we place no assumptions on the speed of execution and delays of the threads ",
    "they may wait arbitrarily long before a method call .",
    "we also assume that method calls on the objects complete instanteously , and that no two of them happen at the same time .",
    "this allows us to define semantics of the objects in the same fashion we define them in the single - threaded case : methods of every object are invoked in a known order , so single - threaded semantics suffice to determine the object s behaviour .",
    "we will call such objects _ concurrent objects _ to emphasize that they may be accessed concurrently .",
    "an object we will predominantly use in this work is a cas ( compare - and - swap ) register .",
    "we will specify its semantics by providing pseudocode which correctly implements this object in a single - threaded program ( this will be our method of choice of providing object s semantics ) :    * var * @xmath12 :    @xmath12    @xmath13 @xmath14 true false    intuitively , such a register holds a value that can be read ( by rd ) , modified unconditionally ( by wr ) and modified conditionally ( by cas ) .",
    "it s interesting due to its universality properties@xcite and because it is commonly seen in real - world hardware .",
    "[ ex - simple ] let s consider two threads , executing following pseudocodes ( x and y are two cas objects , with initial value 0 ) :    1 .",
    "x.wr(1 ) y.rd ( ) 2 .",
    "y.wr(1 ) x.rd ( )    figure  [ fig - ex - simple ] presents a possible execution of such two threads .",
    "note that in any correct execution , at least one of the rd ( ) calls returns 1 .",
    "( labx_wr_1 ) at ( 0.5,-0 + 0.5 ) x.wr(1);(0.5,-0-0.1 ) to ( labx_wr_1);(x_wr_1 ) at ( 0.5,-0 ) ; ( laby_rd_1 ) at ( 2.5,-0 + 0.5 ) y.rd()=0;(2.5,-0-0.1 ) to ( laby_rd_1);(y_rd_1 ) at ( 2.5,-0 ) ; ( laby_wr_1 ) at ( 3.5,-1 + 0.5 ) y.wr(1);(3.5,-1-0.1 ) to ( laby_wr_1);(y_wr_1 ) at ( 3.5,-1 ) ; ( labx_rd_1 ) at ( 5.5,-1 + 0.5 ) x.rd()=1;(5.5,-1-0.1 ) to ( labx_rd_1);(x_rd_1 ) at ( 5.5,-1 ) ; ( 0,0 ) to ( 6,0 ) ; ( 0,-1 ) to ( 6,-1 ) ;    ( labx_wr_2 ) at ( 8.0,-0 + 0.5 ) x.wr(1);(8.0,-0-0.1 ) to ( labx_wr_2);(x_wr_2 ) at ( 8.0,-0 ) ; ( laby_rd_2 ) at ( 10.0,-0 + 0.5 ) y.rd()=1;(10.0,-0-0.1 ) to ( laby_rd_2);(y_rd_2 ) at ( 10.0,-0 ) ; ( laby_wr_2 ) at ( 8.5,-1 + 0.5 ) y.wr(1);(8.5,-1-0.1 ) to ( laby_wr_2);(y_wr_2 ) at ( 8.5,-1 ) ; ( labx_rd_2 ) at ( 10.5,-1 + 0.5 ) x.rd()=1;(10.5,-1-0.1 ) to ( labx_rd_2);(x_rd_2 ) at ( 10.5,-1 ) ; ( 7.5,0 ) to ( 11,0 ) ; ( 7.5,-1 ) to ( 11,-1 ) ;      in many situations it would be convenient to have more complicated concurrent objects : counters that can be incremented , queues that can be pushed to and popped from , etc .",
    "alas , real - world hardware usually does nt implement such objects directly .",
    "we will thus implement them using cas registers or other simpler objects : we will substitute a set of simpler objects for every such object and for every method call on this object , execute a procedure that implements it instead .",
    "however , these prodecures might run concurrently , so we ca nt blindly use a single - threaded implementation of the object .",
    "obviously , we will want such substitution to preserve semantics of the program in which it was substituted .",
    "the following condition immediately implies this :    an implementation of a concurrent object _ serializes _",
    "iff for every execution of a program with the implementation substituted for the object : for every call to object s method that completes , we can define a _",
    "serialization point _ in its execution interval ( between its first and last constituent operation ) , such that all these calls would return the same values if they happened instaneously at their serialization points .",
    "an observant reader might note that if all procedures in an implementation never terminate , the definition is vacously true .",
    "indeed , we will present some terminations guarantees separately , but first let us consider an example implementation of a simple structure .",
    "let s consider an increase - only counter : a shared object with the following semantics :    * var * @xmath12 :    @xmath15 @xmath12    we will see that the following implementation serializes to this shared object :    * var * @xmath16 :    @xmath17 [ trivial - faa - rd ]    @xmath18    note that every call to inc executes exactly one successful call to @xmath19 .",
    "let us claim that the serialization point of inc is that successful call to cas , and that the serialization point of read is the call to @xmath20 .",
    "we can easily see that the number returned by rd is exactly the number of incs that serialized before that read .",
    "we can also see that this implementation satisfies some global progress property ",
    "when the cas in inc fails , another inc must have suceeded very recently .",
    "in fact , it must have succeeded between the most recent execution of line  [ trivial - faa - rd ] and the failed cas .",
    "still , a single inc operation can fail to terminate .",
    "consider an alternative implementation of an increment - only counter . in the following pseudocode",
    ", @xmath9 denotes the number of threads in the system .    * var * @xmath21 : [ p]@xmath22 @xmath23.{\\textsc{rd}}()$ ] @xmath24.{\\textsc{wr}}(x + 1)$ ] @xmath25 @xmath26.{\\textsc{rd}}$ ] @xmath27    here we differentiate between threads : the index @xmath28 in inc corresponds to the current thread s i d from range @xmath29 .",
    "let us first see that this implementation actually serializes to the increment - only counter . obviously , we need to choose the call to write as the serialization point of inc . from the monotonicity of entries of t",
    "we can infer that read returns a value between ( inclusive ) the number of calls to inc that have serialized before read has started and the number of calls serialized before it has finished . thus if a call to read returns @xmath12 , there is a point during its execution when exactly @xmath12 incs had been serialized .",
    "we can choose this point to be the serialization point of read .",
    "note that it need not correspond to an action executed by the implementation of read .",
    "we can see that this implementation satisfies a very strong termination condition  the number of steps every procedure takes is bounded and the bound depends only on the number of threads ( and not on the behaviour of the scheduler ) .",
    "we will call such implementations _ wait - free_. for a discussion of weaker termination guarantees , see chapter 3.7 of @xcite .",
    "every object that has a single - threaded specification has a wait - free implementation@xcite using only cas registers .",
    "however , all currently - known such constructions yield objects with step complexities inflated at least by a factor of the number of threads .",
    "thus , creating faster wait - free implementations of data structures is interesting , also from a practical point of view .",
    "the object implemented in this work is a generalization of a popular building block for multithreaded objects  an atomic snapshot object@xcite .",
    "its semantics can be defined by the following single - threaded pseudocode :    * var * @xmath21 : [ n]@xmath30 @xmath31 \\gets x$ ] @xmath32 \\gets t[i]$ ] @xmath27    intuitively , this object represents an array that can be modified piecewise and read all at once .",
    "there are known wait - free implementations of an @xmath1-element atomic snapshot with @xmath4 update and @xmath33 scan step complexities@xcite .",
    "these complexities are obviously optimal .",
    "one can try to extend this structure in many ways .",
    "two of them are particularly interesting for us .",
    "first , we can merge the update and scan operations into an operation that does an update and a scan .",
    "this object , which we will call write - and - snapshot@xcite , can be defined by the following single - threaded specification :    * var * @xmath21 : [ n]@xmath30 @xmath31 \\gets x$ ] @xmath32 \\gets t[i]$ ] @xmath27    for the second extension , let us note that in many cases one does nt need the scan operation to return the whole array , but rather some sort of its digest .",
    "the f - arrays@xcite allow one to do precisely that for digests expressible as a result of applying an associative operation to all the array s elements ( for example , if we need to retrieve the sum of them ) .",
    "if we call the operator @xmath0 , the following is a specification of an f - array :    * var * @xmath21 : [ n]@xmath30 @xmath31 \\gets x$ ] @xmath34 , t[1 ] , \\ldots , t[n-1])$ ]    there is an implementation of f - array with step complexities of update and scan being respectively @xmath35 and @xmath4 and the memory complexity being linear in @xmath1 .    this work introduces a write - and - f - array : an object that combines these two modifications .",
    "its semantics are defined by the single - threaded specification below :    * var * @xmath21 : [ n]@xmath30 @xmath31 \\gets x$ ] @xmath34 , t[1 ] , \\ldots , t[n-1])$ ]    the main result of this work is an implementation of a single - writer write - and - f - array : that is , one that disallows concurrent modifications to the same array element . the implementation uses @xmath36 memory and the step complexity of the operation is @xmath37 .",
    "we then use this object to implement a fetch - and - add object .",
    "fetch - and - add is a generalization of the increment - only counter from previous chapters .",
    "its semantics are specified by the listing below :    * var * v : @xmath38 @xmath39 @xmath40    fetch - and - add object can be used to produce unique identifiers , implement mutual exclusion , barrier synchronization@xcite , or work queues@xcite .",
    "its known wait - free shared memory implementations for @xmath9 processes have @xmath41 memory complexity and @xmath42 step complexity @xcite@xcite .",
    "they also need to employ complicated memory management techniques to bound their memory use .",
    "our implementation reduces the memory complexity to @xmath43 while maintaining polylogarithmic step complexity .",
    "we will first implement a helper object  the history object .",
    "intuitively , it contains a versioned memory cell and allows retrieval of past @xmath1 values of the cell .",
    "the cell holds objects of type .",
    "the semantics of this object are precisely specified by the following single - threaded implementation :    * var * @xmath44 : [  ] @xmath30 * var * @xmath16 : @xmath16 , @xmath45 $ ] @xmath46 $ ] @xmath46 \\gets t$ ] @xmath47 true false    our wait - free implementation will impose an additional constraint on its use : every call to publish is parameterized by an integer in range @xmath48 and executions of publish@xmath49 for the same @xmath28 can not run simultaneously . both @xmath1 and @xmath9 must be known when the object is created .",
    "our implementation is presented below :    * var * @xmath50 : @xmath51 * var * @xmath44 : [ n]@xmath52 * var * @xmath53 : [ p]@xmath52 @xmath54 help ( ) @xmath55.{\\textsc{rd}}()$ ] @xmath54 @xmath56.{\\textsc{rd}}()$ ] @xmath57.{\\textsc{rd}}()$ ] @xmath55.{\\textsc{cas}}(h , l)$ ] [ hist - help - cas ] @xmath54 [ hist - get - notyet - sp ] [ hist - get - notyet ] help ( ) @xmath58.{\\textsc{rd}}()$ ] @xmath59 [ hist - get - tooold ] @xmath54 [ hist - pub - earlier - sp ] * false * [ hist - pub - earlier - exit ] help ( ) @xmath60.{\\textsc{wr}}((v , t))$ ] [ hist - pub - latest ] [ hist - pub - later - sp ] * false * * true *    as the comments indicate , @xmath60 $ ] is used to temporarily hold the value being published by publish@xmath49 .",
    "the array @xmath44 is used to hold , roughly , the @xmath1 most recently published values ( the most recently published value might be absent ; exact semantics will be given by the lemmas below ) together with their version numbers .",
    "the field @xmath50 holds the particulars of the most recently published value ; the successful publish calls will serialize at the moment @xmath50 changes .",
    "our implementation contains an additional function help .",
    "it is used internally to write the most recently published value to the array @xmath44 , if it is nt stored there already .",
    "we will now prove some properties related to exact semantics of @xmath44 and @xmath53 and then use them to prove that our implementation serializes to the specification .",
    "we posit that the serialization point of publish is in  line  [ hist - pub - later - sp ] , unless that line is nt reached . in that case",
    "when the call returns false in  line  [ hist - pub - earlier - exit ] ) the serialization point is in  line  [ hist - pub - earlier - sp ] .",
    "[ hist - cv - latest ] if @xmath61 at time @xmath62 , and at some later point in time @xmath60 = ( v , t)$ ] , then there was a successful call to publish@xmath49@xmath63 with serialization point before time @xmath62 .",
    "s must have been modified by a successful cas in line  [ hist - pub - later - sp ] .",
    "obviously , a successful invocation of publish@xmath49@xmath63 must have executed that cas .",
    "let s denote it by @xmath64 .",
    "this invocation sets @xmath60 $ ] to @xmath63 .",
    "what remains to be proven is that no later invocation of publish@xmath65 will set @xmath60 $ ] to @xmath66 for any x. only invocations of publish@xmath49 modify @xmath60 $ ] and they can start only after @xmath64 has finished . together with a simple observation that @xmath67 is nondecreasing in time this implies that any later invocation of publish that sets @xmath60 $ ] must have been called with a strictly greater @xmath68 .",
    "[ obs - hist - is - correct ] if @xmath69 = ( v , t)$ ] at some point then a successful call to publish@xmath65@xmath63 has had its serialization point earlier .",
    "[ lem - hist - help - comes ] let @xmath64 be a call to publish@xmath49 .",
    "let @xmath70 be a successful call to publish@xmath71 and @xmath72 a call to publish@xmath49 , both with serialization points after serialization point of @xmath64 .",
    "then there is a call to help that starts after the serialization point of @xmath64 and ends before the one of @xmath70 and before the execution of line  [ hist - pub - latest ] in @xmath72 .",
    "the serialization point of @xmath64 must happen before @xmath70 executes line  [ hist - pub - earlier - sp ] ",
    "if s has changed between line  [ hist - pub - earlier - sp ] and line  [ hist - pub - later - sp ] of @xmath70 , @xmath70 would fail .",
    "thus the call to help from @xmath70 will start after the serialization point of @xmath64 and will finish before the serialization point of @xmath70 .",
    "the call to help from @xmath72 will start after serialization point of @xmath64 ( @xmath72 may only start after @xmath64 has finished ) and will finish before line  [ hist - pub - latest ] of @xmath72 . of these two calls to help , the one that finishes earlier satisfies both conditions .",
    "[ lem - hist - is - complete ] if a call to help ( ) has executed fully ( ie . started and finished ) after the serialization point of a successful publish@xmath65@xmath73 , then @xmath74.v \\geq v$ ] .",
    "let us first note that @xmath74.v$ ] is nondecreasing .",
    "it thus suffices to prove that the condition is met at some point before the end of the call to help .",
    "we will do so by induction on the time at which the invocation of publish serializes . consider a call to publish@xmath49@xmath73 that serializes at time @xmath62 , and a call to help that starts after @xmath62 . by lemma  [ lem - hist - help - comes ]",
    "there is a call to help that finishes before the next serialization point of a successful publish@xmath65 ( thus before @xmath50 is modified ) and before @xmath60 $ ] is modified . without loss of generality",
    "we can assume that the call to help we are considering satisfies these conditions . by inductive hypothesis and lemma  [ lem - hist - help - comes ] , since a successful call to publish@xmath65@xmath75 has occured before time @xmath62 , @xmath76.first \\geq v - n$ ] at time @xmath62 .",
    "taking into account that @xmath69.v \\mod n = i$ ] , at any later point in time one of @xmath76.v = v - n$ ] and @xmath76 \\geq v$ ] will hold .",
    "thus the cas in line  [ hist - help - cas ] either succeeds , which causes the lemma s conclusion to start being satisfied , or fails , which means that the conclusion was already satisfied .    the operations in the implementation of the history object serialize to the single - process object with serialization points of publish@xmath65 as posited earlier .",
    "note that @xmath67 is at all times equal to the first argument of the latest successful publish .",
    "let us first consider a call to get - current that returns @xmath40 . from lemma  [ lem - hist - is - complete ] we know that @xmath77 . by observation  [ obs - hist - is - correct ] ,",
    "the successful publish@xmath65@xmath78 happened before the read from @xmath79 $ ] .",
    "if @xmath80 , then this call to publish was the most recent successful publish at the time when @xmath50 was read , so we can serialize the operation there .",
    "otherwise , it has happened ( had its serialization point ) after that read , so we can serialize the operation just after it .",
    "let us consider a calls to publish@xmath65 :    * if a call to publish@xmath65@xmath73 fails in line  [ hist - pub - earlier - exit ] , then we can see that the most recently serialized ( from the point of view of line  [ hist - pub - earlier - sp ] ) successful publish published a version different than @xmath81 . *",
    "if a call to publish@xmath65@xmath73 fails by failing the cas in line  [ hist - pub - later - sp ] , then a successful publish@xmath65 has occured after line  [ hist - pub - earlier - sp ] had been executed , so the most recent successful publish@xmath65 at the time of cas has published a version greater than @xmath81 . *",
    "if a call to publish@xmath65@xmath73 succeeds , then at the time of cas in line  [ hist - pub - later - sp ] the most recently published version is @xmath81 .",
    "this suffices to prove that the value returned by publish is always correct with respect to the posited serialization order . what remains to consider are the calls to get :    *",
    "if a call to get@xmath82 fails in line  [ hist - get - notyet ] , then the most recent successful publish@xmath65 when line  [ hist - get - notyet - sp ] executed had a smaller version number than requested , so we can serialize the call to get at line  [ hist - get - notyet - sp ] . *",
    "if a call to get@xmath82 fails in line  [ hist - get - tooold ] because @xmath83 , then ( by observation  [ obs - hist - is - correct ] ) a successful call to publish@xmath65@xmath84 has occured by that time and @xmath85 , so if we serialize get at that point , it should fail .",
    "* if a call to get@xmath82 fails in line  [ hist - get - tooold ] because @xmath86 , then ( by lemma  [ lem - hist - is - complete ] ) a call to publish@xmath65@xmath73 has not occured before the call to help in line  x. we can thus serialize this get just before the call to help has started . *",
    "if a call to get@xmath82 succeeds , then by observation  [ obs - hist - is - correct ] it returns a value that was published by a successful call to publish@xmath65@xmath73 . by lemma  [ lem - hist - is - complete ] ,",
    "version @xmath87 was not published before the call to help has started .",
    "thus we can serialize this get just after the successfull call to publish@xmath65@xmath73 has occured , or , if it has occured before get started , just before the call to help started .",
    "obviously all operations run in @xmath4 time .",
    "memory complexity is @xmath88 , where @xmath1 and @xmath9 are the parameters defined at the beginning of this section .",
    "we will now use this object in the main result of this work , an implementation of a write - and-@xmath0-array .",
    "we will now present our main result  an implementation of a write - and - f - array .",
    "we will actually present a wait - free implementation of a slightly richer object  the additional operations and return values are required for the recursive construction of the concurrent implementation .    a single - threaded specification of the structure is shown below .",
    "it uses a version function , which is a black - box integer - valued function , subject to following conditions :    1 .",
    "subsequent return values of version are nondecreasing .",
    "2 .   if a call to version(*false * ) is followed by a call to version(*true * )",
    ", the second call must return a strictly greater integer than the first one .    * var * @xmath89 $ ] : [ n]@xmath30 * var * @xmath90 : [ n ] * var * @xmath91 : [ n ] * var * @xmath92 : [ n ]    @xmath93 \\gets t$ ] @xmath94 , v[1],\\ldots , v[n-1])$ ] @xmath95 \\gets \\text{last\\_update}[i ] + 1 $ ] @xmath96 \\gets { \\textsc{version}}(\\textbf{true})$ ] @xmath97 \\gets r$ ] @xmath95 , \\text{last\\_version}[i ] , \\text{last\\_value}[i]$ ] @xmath95 , \\text{last\\_version}[i ] , \\text{last\\_value}[i]$ ] @xmath98 , v[1],\\ldots , v[n-1])$ ]    one can observe that the version numbers group the calls to write - and - f into groups of consecutive calls with no intervening calls to read .    the concurrent implementation will be restricted by disallowing concurrent calls to write - and - f@xmath99 for the same @xmath100 .",
    "it is conceptually very similar to jayanti s tree - based f - array implementation .",
    "it uses a binary tree structure , with each array element assigned to a leaf and intervals of array elements assigned to internal nodes",
    ". we will construct it recursively .",
    "the implementation for @xmath101 is presented below .",
    "if we note that no concurrent calls to write - and - f may be made in it , we can easily see that it is indeed correct and that all operations take constant time .",
    "* var * @xmath50 : @xmath102 @xmath103 @xmath104 @xmath105 @xmath103 @xmath106 @xmath107    the implementation for @xmath108 is presented below ( interspersed with comments ) :    * var * @xmath21 : [ 2 ] * var * @xmath68 : [ 2 ] * var * @xmath109 : * var * @xmath68 : * var * @xmath21 : * var * @xmath110 : [ 2]write - and - f - array * var * @xmath44 : * * history object**<node - value > * var * @xmath53 : [ n]last - value    c[0 ] and c[1 ] are the subobjects from the recursive construction  they are of size @xmath111 and @xmath112 , respectively .",
    "array elements of the enclosing structure are mapped bijectively to consecutive array elements of these two subobjects .",
    "the mapping is defined by following functions ( the element @xmath100 is mapped to element @xmath113 in c[@xmath114 ) : @xmath115 @xmath116 history object h is used to store the object s current value ( the value that would be returned by read ) and past values .",
    "the version numbers exported by the history object correspond to the values returned by version in the specification .",
    "the elements of h are nt just values ; they instead contain the values of both children together with their versions .",
    "the array l is used to store the values get - last should return , but the values there might be stale ( we will prove bounds on their staleness later on ) .",
    "@xmath117 [ get - getownver ] @xmath118 , h.t[1])$ ] @xmath117 [ upd - getown ] @xmath119 , h'.t[0 ] \\gets c[0].{\\textsc{read}}()$ ] [ upd - getch-0 ] @xmath120 , h'.t[1 ] \\gets c[1].{\\textsc{read}}()$ ] [ upd - getch-1 ] @xmath121 @xmath122 [ upd - publish ] @xmath123.{\\textsc{write - and - f$_{child\\_id(i)}$}}(t)$ ] [ upd - chupd ] [ updcall1 ] update@xmath99 ( ) [ updcall2 ] @xmath124    the implementation of read and write - and - f strongly resemble the f - array .",
    "write - and - f uses a helper function update .",
    "the intuition behind update is that it `` pushes '' new values from @xmath125 $ ] and @xmath126 $ ] to @xmath44 .",
    "we will show that it suffices to attempt to call update twice to accomplish that .",
    "@xmath127.{\\textsc{get - last}}(child\\_id(x))$ ] [ get - last - recurse ] @xmath128    binary search @xmath129 for first @xmath68 such that : [ help - binsch ]    @xmath130 \\geq l_c.v$ ]    @xmath131 [ help - getprev ] @xmath132 @xmath133)$ ] @xmath134 , l_c.t)$ ] @xmath135.{\\textsc{rd}}$ ] [ upd - last - alreadydone ] @xmath136.\\text{cas}(l , ( l_c.n , v , t))$ ] @xmath137 @xmath136.{\\textsc{rd}}()$ ]    the use of binary search in line  [ help - binsch ] warrants explanation .",
    "the predicate employed can obviously change its value in time .",
    "thus , the binary search will return a @xmath68 such that the predicate held at one point in time for @xmath68 and did nt at another point for @xmath81 .",
    "we will see that this is sufficient .",
    "indeed , the result of the binary search will be important only in the cases when the value of the predicate does nt change during the search .",
    "we will first prove two simple facts about update :    [ lem - versions - increase ] for any two subsequent successful calls to @xmath138 with values @xmath139 and @xmath140 , @xmath141 \\leq h_2.v[i]$ ] for both @xmath100 .",
    "( labprev_getch ) at ( 1,-1 + 0.5 ) read children;(1,-1 - 0.1 ) to ( labprev_getch);(prev_getch ) at ( 1,-1 ) ; ( labprev_pub ) at ( 3,-1 + 0.5 ) @xmath142;(3,-1 - 0.1 ) to ( labprev_pub);(prev_pub ) at ( 3,-1 ) ;    ( labget_ver ) at ( 5,-0 + 0.5 ) @xmath143;(5,-0 - 0.1 ) to ( labget_ver);(get_ver ) at ( 5,-0 ) ; ( labgetch ) at ( 7,-0 + 0.5 ) read children;(7,-0 - 0.1 ) to ( labgetch);(getch ) at ( 7,-0 ) ; ( labpublish ) at ( 9,-0 + 0.5 ) @xmath144;(9,-0 - 0.1 ) to ( labpublish);(publish ) at ( 9,-0 ) ;    ( 0,-1 ) to ( 10,-1 ) ; ( 0,0 ) to ( 10,0 ) ; ( 0.5,-1 ) to ( 3.5,-1 ) ; ( 4.5,0 ) to ( 9.5,0 ) ;    ( prev_pub ) to ( get_ver ) ;    assume otherwise .",
    "consider the first pair @xmath145 of consecutive calls to publish that contradicts the lemma ( see figure  [ fig - versions - increase ] ) .",
    "the only place publish is called is line [ upd - publish ] in update .",
    "@xmath144 had its most recent call to get - current ( denoted by @xmath143 ) in line  [ upd - getown ] sometime earlier .",
    "no successful publish could have occured between @xmath143 and @xmath144 ; otherwise @xmath144 would have failed .",
    "thus , @xmath142 must have occured before @xmath143 and so its execution of lines [ upd - getch-0 ] and [ upd - getch-1 ] ( denoted by `` read children '' on the diagram ) must have occured strictly earlier than the same for the second call .",
    "this together with monotonicity of versions in children delivers the contradiction .    for every execution of write - and - f : during execution of lines [ updcall1 ] and [ updcall2 ] at least one successful call to update occurs .",
    "( labour_gv1 ) at ( 5.5,-0 + 0.5 ) @xmath146;(5.5,-0 - 0.1 ) to ( labour_gv1);(our_gv1 ) at ( 5.5,-0 ) ; ( labbad_pub1 ) at ( 6.5,-1 + 0.5 ) @xmath147;(6.5,-1 - 0.1 ) to ( labbad_pub1);(bad_pub1 ) at ( 6.5,-1 ) ; ( labour_pub1 ) at ( 7.5,-0 + 0.5 ) @xmath148;(7.5,-0 - 0.1 ) to ( labour_pub1);(our_pub1 ) at ( 7.5,-0 ) ; ( our_gv1 )  ( bad_pub1 ) ; ( bad_pub1 )  ( our_pub1 ) ; ( labbad_gv2 ) at ( 7,-2 + 0.5 ) @xmath149;(7,-2 - 0.1 ) to ( labbad_gv2);(bad_gv2 ) at ( 7,-2 ) ; ( bad_pub1 )  ( bad_gv2 ) ; ( labour_gv2 ) at ( 9.5,-0 + 0.5 ) @xmath143;(9.5,-0 - 0.1 ) to ( labour_gv2);(our_gv2 ) at ( 9.5,-0 ) ; ( labbad_pub2 ) at ( 11,-2 + 0.5 ) @xmath150;(11,-2 - 0.1 ) to ( labbad_pub2);(bad_pub2 ) at ( 11,-2 ) ; ( labour_pub2 ) at ( 12,-0 + 0.5 ) @xmath151;(12,-0 - 0.1 ) to ( labour_pub2);(our_pub2 ) at ( 12,-0 ) ; ( our_gv2 )  ( bad_pub2 ) ; ( bad_pub2 )  ( our_pub2 ) ;    ( 2.5,0 )  ( 13,0 ) ; ( 3,0 ) ",
    "( 12.5,0 ) ;    ( 5.5,-1 ) ",
    "( 7.5,-1 ) ; ( 6,-1 ) ",
    "( 7,-1 ) ;    ( 6,-2 )  ( 12,-2 ) ; ( 6.5,-2 ) ",
    "( 11.5,-2 ) ;    if one of the calls to update from the lines in question suceeds , then the lemma trivially holds .",
    "thus we assume that they have both failed .",
    "the situation is depicted in figure  [ fig - only - two - pubs ] . @xmath152",
    "correspond to these two failed calls to update . in order for @xmath148 to fail , a publish must have succeeded between @xmath146 and @xmath148  let s call it @xmath147 . similarly , a publish must have suceeded between @xmath143 and @xmath151 . alas ,",
    "this publish ( denoted @xmath150 ) must have had its corresponding call to get - current ( denoted @xmath149 ) after @xmath147 .",
    "the call to update that called @xmath149 and @xmath150 satisfies the lemma s conclusion .",
    "let us consider an execution of write - and - f@xmath99 .",
    "let @xmath153 be the return value of the corresponding call to @xmath123.{\\textsc{write - and - f$_{child\\_id(i)}$}}$ ] .",
    "then by the time the call to write - and - f@xmath99 finishes , the value of the most recently published node has @xmath154 \\geq v_c$ ] .",
    "we will consider the first call to publish that publishes such a node value as the serialization point of the write - and - f . obviously , many calls to write - and - f can then serialize at the same instant in time .",
    "we will order them by taking first these with @xmath155 in the order in which their corresponding calls to write - and - f happened in @xmath125 $ ] and then those with @xmath156 in the corresponding order .",
    "the choice of order on elements of @xmath110 is arbitrary , albeit it is reflected in the computation of @xmath21 in help .",
    "before we prove that the implementation is correct , we need the following two lemmas about the array @xmath53 .    if help is called after the serialization point of the @xmath157 call to write - and - f@xmath99 , then @xmath158.n \\geq n$ ] after the call to help completes .",
    "[ last - is - complete ]    we will prove this lemma by induction on @xmath109 .",
    "the proof for the base case will be very similar to the induction step , so we present both of them simultaneously .",
    "let @xmath159 be the time the successfull call to publish@xmath73 occured .",
    "consider an update@xmath99 that was serialized at @xmath159 .",
    "for every @xmath160 , a call to @xmath161 starts and finishes between @xmath162 and @xmath163 .",
    "thus , there is such a call that starts and finishes between @xmath159 and @xmath164 .",
    "without loss of generality we can assume that the call to help from the lemma s hypothesis executes in this time interval .",
    "in that case , the binary search from line  [ help - binsch ] will not see any @xmath165 for @xmath166 returning and will return version @xmath68 . for the same reason , both gets will succeed .",
    "we want to prove that @xmath158.n \\geq n-1 $ ] from @xmath159 on . for the base case this holds , because the initial values satisfy this requirement . for the inductive step",
    ", we have to use the hypothesis : at @xmath159 , the @xmath167 call to write - and - f@xmath99 has completed , so a call to @xmath161 has completed between the serialization point of that call to write - and - f@xmath99 and @xmath159 .",
    "thus @xmath158.n \\geq n-1 $ ] from @xmath159 on .",
    "if the condition in line  [ upd - last - alreadydone ] is not satisfied or the cas in the next line fails , the lemma hold .",
    "otherwise , by the time the cas succeeds the lemma will obviously hold .    if a call to @xmath161 sets @xmath158 $ ] to @xmath168 , then by the time the call has finished : [",
    "last - is - correct ]    1 .",
    "write - and - f@xmath99 has been called at least @xmath109 times .",
    "2 .   let @xmath153 be the return value of the @xmath157 call to @xmath123.{\\textsc{write - and - f}}_{child\\_id(p)}$ ] .",
    "let @xmath169 and @xmath170 be the version and node value published at the serialization point of the @xmath157 write - and - f@xmath99 and @xmath171 be the node value published with version @xmath172 .",
    "then @xmath173 and : * if @xmath174 then @xmath175)$ ] , * if @xmath176 then @xmath177 , t_c)$ ] .",
    "for the first part , we need to note that by the time line  [ get - last - recurse ] executes , the @xmath157 write - and - f@xmath178 has already executed in the appropriate child . if the binary search fails or returns version different from @xmath169 , help will exit early . indeed ,",
    "if the binary search returns a different @xmath68 , @xmath179 will fail .",
    "this immediately proves the first part of the lemma and shows that @xmath171 and @xmath170 in the code have the same values as @xmath171 and @xmath170 in the lemma , which proves the second part .    the operations in multi - process write - and - f - array serialize to the single - process specification with serialization point of write - and - f as posited earlier .",
    "let us choose the call to get - current as the serialization point of read .",
    "we will first prove that these are correct serialization points for write - and - f and read .",
    "consider the @xmath157 call to write - and - f@xmath99 and let @xmath180 be its return value .",
    "as this triple was read from @xmath158 $ ] , we can use lemmas  [ last - is - complete ] and  [ last - is - correct ] to show that @xmath181 ( note that executions of write - and - f@xmath99 for the same @xmath100 are disjoint in time ) . from lemma",
    "[ last - is - correct ] we get that @xmath169 is equal to the version published at the serialization point of the call to write - and - f .",
    "this obviously implies that version is nondecreasing for subsequent calls to write - and - f and read . as only the calls to write - and - f that serialize on a single publish return equal @xmath68",
    ", no read call can serialize in between .",
    "this proves both properties required from version .",
    "we still need to prove that @xmath182 and the values returned by read are consistent with the posited serialization order .",
    "consider a set of write - and - f calls that are serialized together .",
    "let @xmath170 and @xmath171 be the history elements published , respectively , at the serialization point and most recently before it .",
    "let @xmath183 be the sequence of return values of @xmath125.{\\textsc{write - and - f}}$ ] calls corresponding to write - and - f calls in question , in serialization order .",
    "let @xmath184 be a similar sequence for @xmath126 $ ] .",
    "by lemma  [ lem - versions - increase ] these are exactly the calls to @xmath185.{\\textsc{write - and - f}}$ ] serialized with versions in @xmath186 , h_{new}.v[j]\\right]$ ] for @xmath187 . by lemma",
    "[ last - is - correct ] the sequence returned by the write - and - f calls is @xmath188 @xmath189 @xmath190 @xmath191 , b_0 ) , $ ] @xmath191 , b_1 ) , \\ldots$ ] in the order of serialization .",
    "additionally , @xmath191 , h_{new}.t[1])$ ] is the value that would be returned by any read calls until the next serialization point of write - and - f .",
    "this suffices to show that the return values of consecutive calls to write - and - f are actually the results of applying the updates .",
    "this proves that values returned by get and update are correct wrt .",
    "posited serialization order .",
    "we still need to show that we can correctly serialize the calls to get - last .",
    "lemma  [ last - is - correct ] implies that two calls to @xmath124 will never return different triples with equal @xmath109 .",
    "as write - and - f returns the result of a call to get - last , we just need to show that get - last@xmath192 can be serialized so that the @xmath109 in its return value is the number of previously serialized calls to write - and - f@xmath99 . from lemma  [ last - is - complete ]",
    "we get that @xmath109 is at least the number of calls to write - and - f@xmath99 that serialized before get - last started . from lemma",
    "[ last - is - correct ] we know that @xmath109 was at most the number of such calls that serialized before get - last finished .",
    "thus , there is a point in the execution interval of get - last when @xmath109 is equal to the number of such calls that have already serialized .",
    "we choose any such point in time to be the serialization point of the call to get - last .",
    "the structure uses @xmath36 memory .",
    "a get - last operation takes @xmath7 time , a read operation takes @xmath4 time and a write - and - f operation takes @xmath3 time .",
    "we can construct a fetch - and - add object for @xmath9 threads by using a write - and - f - array of size @xmath9 with addition as the operation @xmath0 .",
    "every thread is assigned an element in the array , and modifies only that element .",
    "this gives us a fetch - and - add object for @xmath9 threads with @xmath11 step complexity and @xmath43 memory complexity .",
    "additionally , the object implements a method that retrieves the current value in @xmath4 time .",
    "a fetch - and - add object was implemented using the above - mentioned construction from the write - and - f object .",
    "the implementation is written in c++ and uses the c++11 standard library support for atomic operations .",
    "it is published on github .",
    "direct implementation of previously described algorithm would require cas objects of size larger than the 64-bit intel processors support .",
    "however , the way most of these objects are accessed in the implementation makes it possible to split them into multiple cas objects .",
    "the only cas objects that do nt afford this transformation are the version number holders from the history object .",
    "we use 64-bit versions and thus even these objects are no larger than 128 bits . thus , our implementation can run on 64-bit intel architecture processors , but not on 32-bit ones .",
    "unfortunately , the c++ standard library support for atomic operations does nt allow atomic reads of a part of a larger atomic variable ( specifically , reads of 64-bit halves of a 128-bit variable ) .",
    "as 128-bit atomic reads on amd64 are very costly ( they use a 128-bit wide cas ) , limiting their number was very important for the efficiency s sake .",
    "thus , the implementation makes an unwarranted assumption that an atomic variable has the same memory layout as a normal , non - atomic variable of the same size .",
    "this assumption holds for gcc 4.6 on amd64 .",
    "the correctness of the implementation was tested experimentally both on real hardware and by using the relacy race detector@xcite .",
    "relacy race detector is a framework for testing multi - threaded programs in c++11 .",
    "it substitues its own implementation of synchronization primitives and atomic variables and runs user - supplied tests multiple times , with various interleavings of threads",
    ". it can detect data races on non - atomic variables , deadlock conditions , and failed user - supplied invariant and assertion checks .",
    "one notable feature is the support for atomic operations with reduced consistency  relacy can simulate acquire / release semantics , as specified in the c++11 atomic variables library . our fetch - and - add implementation can be compiled both to run on bare hardware and to run in relacy .",
    "the use of relacy not only provided confidence about correctness of the implementation , but also allowed us to downgrade consistency guarantees of some writes .",
    "the implementation was benchmarked on a machine with 4 12-core amd opteron 6174 processors .",
    "the benchmark created a fetch - and - add object and started a preset number of threads .",
    "each thread incremented the counter in a loop , counting its operations locally .",
    "after 20 seconds elapsed , all threads were signalled to stop and their operation counters were summed . for comparison ,",
    "the same benchmark was run with the fetch - and - add object implemented by a simple read - modify - write loop .",
    "all benchmarks were run when the machine was minimally loaded ( had 5 minute load average smaller than 0.5 at the start of the benchmark ) .",
    "the results of the benchmark are shown in figure  [ fig - meas ] .",
    "the figure contains a plot of average time it takes to complete one operation as a function of the number of concurrently executing threads .",
    "the horizontal scale of the figure is proportional to the square of the logarithm of the number of threads .",
    "the reason for this is that the optimistic time complexity of our fetch - and - add object is @xmath193 .",
    "we can see that the graph for our implementation approximates a straight line up to about 30 threads , where it starts to diverge upward .",
    "this peculiar divergence disappears if we assign one core to each thread and force it to run only there ( by setting cpu affinity ) .",
    "other affinity settings yielded graphs similar to one of these two .",
    "we were unable to explain this behaviour",
    ". it might be worth noting that the anomaly in the no - affinity case happens when we start using all 4 physical cpus .",
    "it can be easily seen from the graph that our fetch - and - add object is far from practical .",
    "it is about 100 times slower than the naive lock - free implementation for small numbers of threads and about 10 times slower for larger numbers of threads .",
    "we believe that this implementation is suboptimal , although achieving similar performance as the naive implementation seems impossible .",
    "one change that could improve the performance of this implementation is changing the arity of the tree .",
    "the construction can easily be adapted to trees with larger arity and this might decrease the number of expensive cas operations at the expense of the number of atomic reads , which are comparatively cheap on intel processors .",
    "our implementation of write - and - f - array can be modified by splitting the work done by help into @xmath35 separate pieces ( updates on consecutive levels of the tree ) and running only a single such piece in update . if we then enlarge the history size to @xmath194 , lemma  [ last - is - complete ] still holds .",
    "this modification increases the memory complexity to @xmath195 and decreases the step complexity of write - and - f to @xmath196 .",
    "the structure can be straightforwardly modified to use ll / cs instead of cas , albeit it then requires the ability to have two outstanding lls at the same time .",
    "the modified version can be further modified to use bounded version numbers , from a range of size @xmath33 .",
    "unfortunately , popular architectures that implement ll / sc ( such as powerpc ) allow only one outstanding ll at a time .",
    "the effect of the arity of the tree on the performance seems to be worth investigating .",
    "we pose also two purely theoretical problems :    * our implementation of write - and - f - array is single - writer , so it is natural to consider the multi - writer write - and - f - array .",
    "can we construct a multi - writer write - and - f - array in subquadratic memory with similar step complexities of the operations ? * the memory consumption of write - and - f - array implemented with atomic registers and cas or ll / cs objects is bounded from below by a linear function of the number of processes that can execute write - and - f concurrently@xcite , so it must be @xmath197 .",
    "can we achieve lower memory and/or step complexities ?",
    "the author would like to thank his advisor , dr .",
    "grzegorz herman for many fruitful discussions and help while preparing this work .",
    "he would also like to thank szymon acedaski for his help in improving the presentation of this work .",
    "9 herlihy m. , shavit n. `` the art of multiprocessor programming '' , morgan kaufmann publishers inc .",
    ", 2008 herlihy m. `` wait - free synchronization '' , acm trans . program .",
    "13 , 1 , pp . 124149 ( 1991 ) riany y. , shavit n. , touitou d. `` towards a practical snapshot algorithm '' , theoretical computer science 269 , pp . 163201 ( 2001 ) afek y. , attiya h. , dolev d. , gafni e. , merritt m. , shavit n. `` atomic snapshots of shared memory '' , journal of the acm 40 , pp . 873890 ( 1993 )",
    "afek y. , weisberger e. `` the instancy of snapshots and commuting objects '' , journal of algorithms 30.1 , pp .",
    "68105 ( 1999 ) chandra t. d. , jayanti p. , tan k. `` a polylog time wait - free construction for closed objects '' , proceedings the 17th podc , pp . 287296 ( 1998 )",
    "`` f - arrays : implementation and applications '' , proceedings of the 21st podc , pp . 270279 ( 2002 ) ellen f. , ramachandran v. , woelfel p. `` efficient fetch - and - increment '' , lecture notes in computer science 7611 , pp .",
    "1630 ( 2012 ) fich f. e. , hendler d. , shavit n. `` linear lower bounds on real - world implementations of concurrent objects '' , foundations of computer science , pp . 165173 ( 2005 )",
    "freudenthal , e. , gottlieb , a. `` process coordination with fetch - and - increment '' , proceedings of asplos - iv , pp .",
    "260-268 ( 1991 ) goodman , j. , vernon , m. , woest , p. `` efficent synchronization primitives for large - scale cache - coherent multiprocessors '' , proceedings of asplos - iii , pp .",
    "64-75 ( 1989 ) vyukov d. , relacy race detector , ` http://www.1024cores.net/home/relacy-race-detector `"
  ],
  "abstract_text": [
    "<S> we introduce a new shared memory object : the write - and - f - array , provide its wait - free implementation and use it to construct an improved wait - free implementation of the fetch - and - add object . </S>",
    "<S> the write - and - f - array generalizes single - writer write - and - snapshot@xcite object in a similar way that the f - array@xcite generalizes the multi - writer snapshot object . </S>",
    "<S> more specifically , a write - and - f - array is parameterized by an associative operator @xmath0 and is conceptually an array with two atomic operations :    * write - and - f modifies a single array s element and returns the result of applying @xmath0 to all the elements , * read returns the result of applying @xmath0 to all the array s elements .    </S>",
    "<S> we provide a wait - free implementation of an @xmath1-element write - and - f - array with @xmath2 memory complexity , @xmath3 step complexity of the write - and - f operation and @xmath4 step complexity of the read operation . </S>",
    "<S> the implementation uses cas objects and requires their size to be @xmath5 , where @xmath6 is the total number of write - and - f operations executed . </S>",
    "<S> we also show , how it can be modified to achieve @xmath7 step complexity of write - and - f , while increasing the memory complexity to @xmath8 .    </S>",
    "<S> the write - and - f - array can be applied to create a fetch - and - add object for @xmath9 processes with @xmath10 memory complexity and @xmath11 step complexity of the fetch - and - add operation . </S>",
    "<S> this is the first implementation of fetch - and - add with polylogarithmic step complexity and subquadratic memory complexity that can be implemented without cas or ll / sc objects of unrealistic size@xcite .    </S>",
    "<S> keywords : concurrency , wait - free , snapshot , fetch - and - add </S>"
  ]
}