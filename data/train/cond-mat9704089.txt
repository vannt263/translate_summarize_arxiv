{
  "article_text": [
    "the parallel dynamics of extremely diluted asymmetric and layered feedforward @xmath3-ising neural networks have been solved exactly ( cfr .",
    "@xcite-@xcite and the references cited therein ) .",
    "this has been possible because in these types of networks one knows that there are no feedback loops as time progresses . in particular , this allows one to derive recursion relations for the relevant order parameters of these systems : the main overlap for the condensed pattern , the mean of the neuron activities and the variance of the residual overlap responsible for the intrinsic noise in the dynamics of the main overlap ( sometimes called the width - parameter ) .",
    "these results are in strong contrast to those for the parallel dynamics of networks with symmetric connections . for these systems",
    "it turns out that even in the diluted @xmath4 case , feedback correlations become essential from the second time step onwards , which already complicates the dynamics in a nontrivial way @xcite-@xcite . for fully connected @xmath4 systems ,",
    "an increasing complexity of such long - term temporal correlations makes the dynamics , in general , extremely complicated .",
    "therefore , either approximate treatments of the feedback influence on the network evolution or only the first few time steps of the main overlap evolution have been analyzed so far .",
    "nevertheless , this has led to some important insights into the dynamics of the little - hopfield model ( cfr .",
    "@xcite-@xcite and references therein ) .    in this paper",
    "we consider the zero - temperature parallel dynamics of fully connected @xmath0-ising neural networks for general @xmath0 . generalizing a @xmath4 result from the literature @xcite-@xcite we find that there exists a lyapunov function leading to the occurrence of fixed - points and two - cycles .",
    "since two - cycles in the @xmath4 little - hopfield model seem to appear far from the retrieval region @xcite and/or seem to involve only a tiny fraction of all spins @xcite , we only look at the fixed - point dynamics .    using a probabilistic approach",
    "@xcite we extend our analysis for extremely diluted @xcite,@xcite and layered @xmath0-ising networks @xcite to the non - trivial case of fully connected systems at zero temperature .",
    "in particular , we develop a recursive scheme to calculate the relevant order parameters of the system , i.e. , the main overlap , the activity and the variance of the residual overlap , for any time step .",
    "we write out these expressions in detail for the first three time steps of the dynamics . furthermore , under the condition",
    "that the local field becomes stationary we derive the fixed - point equations for these order parameters .",
    "they are found to be the same as those derived via thermodynamical methods @xcite .",
    "finally , extensive numerical simulations for the @xmath1 model are compared with the theoretical results .",
    "the rest of the paper is organized as follows . in section [ sec : mod ] we introduce the model , its dynamics and the hamming distance as a macroscopic measure for the retrieval quality . in section [ sec : gensch ] we use the probabilistic approach in order to derive a recursive scheme for the evolution of the distribution of the local field , leading to recursion relations for the order parameters of the model . using this general scheme , we explicitly calculate in section [ sec : ev.eq . ]",
    "the order parameters for the first three time steps of the dynamics . in section [ sec : fixp ] we show the existence of a lyapunov function at zero temperature and we discuss the evolution of the system to fixed - point attractors . a detailed discussion of the theoretical results obtained in section [ sec : ev.eq . ] and a comparison with extensive numerical simulations are presented in section [ sec : results ] .",
    "some concluding remarks are given in section [ sec : con ] .",
    "consider a neural network @xmath5 consisting of @xmath6 neurons which can take values @xmath7 from a discrete set @xmath8 . given the configuration @xmath9 , the local field in neuron @xmath10 equals @xmath11 with @xmath12 the synaptic couplings between neurons @xmath10 and @xmath13 . in the sequel we write the shorthand notation @xmath14 .",
    "the configuration @xmath15 is chosen as input . at zero temperature",
    "all neurons are updated in parallel according to the rule @xmath16",
    "= \\epsilon_i[s_k|{\\bsigma}_{\\lambda \\setminus\\{i\\}}(t ) ] \\,.\\ ] ] here the energy potential @xmath17 $ ] is defined by @xmath18=                  -\\frac{1}{2}[h_i({\\bsigma}_{\\lambda\\setminus\\{i\\}})s - bs^2 ]                                              \\,,\\ ] ] where @xmath19 is the gain parameter of the system .",
    "the updating rule ( [ eq : enpot ] ) is equivalent to using a gain function @xmath20 , @xmath21-                                \\theta\\left[b(s_k+s_{k-1})-x\\right ]                          \\right]\\end{aligned}\\ ] ] with @xmath22 and @xmath23 . for finite @xmath0 ,",
    "this gain function @xmath20 is a step function .",
    "the gain parameter @xmath24 controls the average slope of @xmath20 .    in this network",
    "we want to store @xmath25 patterns .",
    "these patterns are a collection of independent and identically distributed random variables ( i.i.d.r.v . ) , @xmath26 , @xmath27 and @xmath28 with zero mean and variance @xmath29 $ ] .",
    "the synaptic couplings between the neurons are chosen according to the hebb learning rule @xmath30    to measure the retrieval quality of the system one can use the hamming distance between a stored pattern and the microscopic state of the network @xmath31 ^ 2          \\,.\\ ] ] this naturally introduces the main overlap @xmath32 and the arithmetic mean of the neuron activities @xmath33 ^ 2     \\,.\\ ] ]",
    "it is known that contrary to the asymmetrically diluted and layered neural networks , the parallel dynamics of fully connected systems , even at zero temperature , is not exactly solvable because of the strong feedback correlations  @xcite .",
    "on the basis of the probabilistic approach used before ( see , e.g. , @xcite,@xcite ) we develop in this section a recursive dynamical scheme in order to calculate the distribution of the local field at a general time step , for @xmath34-ising neural networks .",
    "this results in recursion relations determining the evolution of the order parameters of these systems .",
    "suppose that the initial configuration of the network @xmath35 , is a collection of i.i.d.r.v .  with mean @xmath36=0 $ ] , variance @xmath37=a_0 $ ] , and correlated with only one stored pattern ,",
    "say the first one @xmath38 : @xmath39=\\delta_{\\mu,1}m^1_0 a                  \\quad m^1_0>0 \\ , .\\ ] ] this implies that by the law of large numbers ( lln ) one gets for the main overlap and the activity at @xmath40 @xmath41                  = m^1_0                                           \\\\",
    "a(0)&\\equiv&\\lim_{n \\rightarrow \\infty } a_\\lambda ( 0 )                  \\ustr{pr}{= } \\e[\\sigma_i^2(0)]=a_0\\end{aligned}\\ ] ] where the convergence is in probability @xcite .",
    "using standard signal - to - noise techniques ( see , e.g. , @xcite ) , we find the local field at @xmath40 @xmath42                          \\nonumber                                      \\\\           & \\ustr{{\\cal d}}{=}&\\xi_i^1 m^1(0)+{\\cal n}(0,\\alpha a_0 )   \\,,\\end{aligned}\\ ] ] where the convergence is in distribution ( see , e.g. , @xcite ) . the quantity @xmath43 represents a gaussian random variable with mean @xmath44 and variance @xmath45 .    for a general time step",
    "we find from eq .",
    "( [ eq : gain ] ) and the lln in the limit @xmath46 for the main overlap ( [ eq : mdef ] ) and the activity ( [ eq : adef ] ) @xmath47 with @xmath48 . in the above",
    "@xmath49 denotes the average both over the distribution of the embedded patterns @xmath50 and the initial configurations @xmath51 .",
    "the average over the initial configurations is hidden in an average over the local field through the updating rule ( [ eq : gain ] ) . from the study of layered networks(@xcite-@xcite )",
    "we know already that due to the correlations there will be a third important parameter in the description of the time evolution of the system : the influence of the non - condensed patterns which is expressed by the variance of the residual overlaps @xmath52 \\ , \\\\",
    "r^\\mu(t ) & \\equiv & \\lim_{n \\rightarrow \\infty }          r_\\lambda^\\mu(t ) = \\lim_{n \\rightarrow \\infty }                  \\frac{1}{a\\sqrt{n}}\\sum_{i\\in\\lambda }                  \\xi_i^\\mu\\sigma_i(t )                  \\quad \\mu \\in { \\cal p}\\setminus\\{1\\ }                   \\ , .",
    "\\label{eq : rdef}\\end{aligned}\\ ] ] clearly , @xmath53 .",
    "the distribution of the embedded patterns is given .",
    "it is the purpose of this section to calculate the distribution of the local field as a function of time .",
    "we start by rewriting the local field ( [ eq : h ] ) at time @xmath54 in the following way @xmath55 from a technical point of view the explicit addition and subtraction of the @xmath56 term in ( [ eq : hrecb ] ) is convenient in order to treat all indices in the sum over @xmath13 on an equal footing .",
    "this turns out to be important to take into account all possible feedback loops .",
    "we would like to remark that the set of @xmath57 variables @xmath58 appearing in the last term of ( [ eq : hreca ] ) are not independent because the @xmath59 are weakly dependent on the @xmath60 . on the contrary , in the case of layered or diluted networks all terms of this set of variables are independent such that their sum is a normal distribution .",
    "moreover , @xmath61 and @xmath59 are also independent implying that the mean and the variance of this distribution are known directly .",
    "the same is true for the fully connected model at time @xmath40 where the network states @xmath62 are randomly distributed and independent of the non - condensed ( @xmath63 ) embedded patterns .",
    "but after applying the dynamics the @xmath64 and the @xmath59 become dependent , leading to a weak dependence of @xmath65 and @xmath59 .",
    "this microscopic dependence gives rise to a macroscopic contribution after summing and taking the limit @xmath66 . in this respect",
    "we mention that in ref .",
    "@xcite an approximation has been put forward by neglecting precisely these correlations between the @xmath59 and the @xmath67 . for an overview of improvements of this approximation for @xmath4 and corresponding numerical simulations",
    "we refer to @xcite .    in order to determine the structure of the local field for fully connected networks , we first concentrate on the evolution of the residual overlap @xmath68 . as mentioned above the dynamics",
    "induces the dependence of @xmath69 and @xmath50 . to study its consequences",
    "we rewrite the residual overlap ( [ eq : rdef ] ) as @xmath70 with @xmath71 by subtracting the term @xmath72 the modified local field @xmath73 becomes only weakly dependent on @xmath59 , whereas @xmath74 depends strongly on @xmath59 .",
    "the gain function @xmath20 is a step function that changes its value by @xmath75 at @xmath76 .",
    "hence the term @xmath72 in ( [ eq : f1 ] ) becomes relevant if for some @xmath77 @xmath78 denoting by @xmath79 the set of indices satisfying condition ( [ eq : i_k ] ) , we split the residual overlap into two sums : @xmath80                                  ( s_{k+1}-s_k )                  \\right\\ }   \\ , .",
    "\\nonumber \\\\",
    "\\label{eq : f2}\\end{aligned}\\ ] ] in the argument of @xmath20 in the first term of ( [ eq : f2 ] ) the term @xmath72 is left out since it can not change the value of @xmath20 by definition of the sets @xmath79 . combining the first two terms , eq .",
    "( [ eq : f2 ] ) can be rewritten as @xmath81 ( s_{k+1}-s_k )   \\ , .",
    "\\nonumber \\\\",
    "\\label{eq : rreca}\\end{aligned}\\ ] ] we then consider the limit @xmath46 . in this limit",
    "the cardinal number of the set @xmath79 becomes deterministic @xmath82 with @xmath83 the probability density of the modified local field @xmath84 at time @xmath54 .",
    "we remark that in the thermodynamic limit the density distribution of the modified local field @xmath85 at time @xmath54 equals the density distribution of the local field @xmath86 itself .",
    "furthermore , we apply the clt on the first term of ( [ eq : rreca ] ) and the lln on the second term with the random variable @xmath87 fixed .",
    "this yields the following result @xmath88 where , recalling eqs .",
    "( [ eq : a ] ) and ( [ eq : f3 ] ) @xmath89 because of the weak dependence of @xmath90 and @xmath59 , and @xmath91    from the relation ( [ eq : rrec ] ) one finds a recursion relation for the variance of the residual overlap @xmath92 \\ , .",
    "\\label{eq : f4}\\ ] ] at this point it is interesting to remark that the last term on the r.h.s.of ( [ eq : f4 ] ) is entirely coming from the correlations caused by the fully connected structure of the network .",
    "it is absent for layered ( compare eq .",
    "( 30c ) of ref .",
    "@xcite ) and hence , of course , also for extremely diluted asymmetric architectures . in the latter case also",
    "the second term on the r.h.s . of ( [ eq : f4 ] ) disappears .    starting from the local field at time @xmath93 in the form of eq .",
    "( [ eq : hreca ] ) and using expressions ( [ eq : rrec ] ) , ( [ eq : w ] ) and ( [ eq : chi ] ) we obtain in the limit @xmath46 , after some straightforward manipulations @xmath94                  + { \\cal n}(0,\\alpha a(t+1 ) ) \\ , .",
    "\\label{eq : hrec}\\ ] ] from this it is clear that the local field at time @xmath93 consists out of a discrete part and a normally distributed part , viz .",
    "@xmath95 where @xmath96 satisfies the recursion relation @xmath97                           + \\xi_i^1m^1(t+1 )       \\label{eq : mrec}\\ ] ] and @xmath98 with @xmath99 given by the recursion relation ( [ eq : f4 ] ) .",
    "we still have to determine @xmath100 in eq .",
    "( [ eq : chi ] ) .",
    "we know that the quantity @xmath96 consists out of the signal term and a discrete noise term , viz .",
    "@xmath101 \\ , \\sigma _ i(t ' )   \\,.\\ ] ] the evolution equation tells us that @xmath102 can be replaced by @xmath103 such that the second term of @xmath96 is the sum of stepfunctions of correlated variables .",
    "these are also correlated through the dynamics with the normally distributed part of @xmath86 .",
    "therefore the local field can be considered as a transformation of a set of correlated normally distributed variables @xmath104 . defining the correlation matrix",
    "@xmath105 $ ] we arrive at the following expression for the probability density of the local field at time @xmath54 @xmath106 with @xmath107 .    together with the eqs .",
    "( [ eq : m])-([eq : a ] ) for @xmath108 and @xmath109 the equations ( [ eq : rrec])-([eq : f4 ] ) , ( [ eq : mrec ] ) and ( [ eq : fhdis ] ) form a recursive scheme in order to obtain the order parameters of the system .",
    "the practical difficulty which remains is the explicit calculation of the correlations in the network at different time steps as present in eq .",
    "( [ eq : f4 ] ) .",
    "following the general recursive scheme established in section [ sec : gensch ] evolution equations are derived for the order parameters of a fully connected @xmath0-ising network for the first three time steps , taking into account all correlations .",
    "this generalizes and extends the @xmath4 results in the literature mentioned in the introduction .      starting from eqs .",
    "( [ eq : init2]),([eq : m ] ) and ( [ eq : a ] ) one has immediately @xmath110 where @xmath111 now stands for the average taken with respect to the distribution of the first pattern and the initial configuration and @xmath112 denotes a gaussian measure @xmath113 .",
    "we recall that @xmath114 .",
    "next , from the initial conditions ( [ eq : init1])-([eq : init2 ] ) and the definition of the modified local field ( [ eq : f3 ] ) one also knows that @xmath115 and @xmath116 become a set of uncorrelated parameters for @xmath117 . here",
    "=          \\e[\\sigma_i(0 ) \\mbox{g}_b(\\hat h_i^\\mu(0 ) ) ]             \\,.\\ ] ] using the recursion relation ( [ eq : drec ] ) this leads to @xmath120 with @xmath121 these results generalize the corresponding @xmath4 results ( see , e.g. , @xcite and @xcite ) .",
    "first we need the distribution of the local field at time @xmath122 .",
    "this follows immediately from eqs .",
    "( [ eq : mrec ] ) and ( [ eq : vrec ] ) @xmath123                  + { \\cal n}(0,\\alpha a(1 ) )                          \\,.\\end{aligned}\\ ] ] recalling again eqs .",
    "( [ eq : m ] ) and ( [ eq : a ] ) , the main overlap and the activity read @xmath124 and @xmath125    these equations correspond to the equations for the @xmath4-network found in @xcite .",
    "the calculation of the third order parameter , i.e. , the variance of the residual overlap , needs some more work . from the recursion formula ( [ eq : rrec ] ) one finds @xmath126             & = & \\cov[{\\tilde r}^\\mu(1 ) , { \\tilde r}^\\mu(0 ) ]                         + \\chi(0)\\cov[{\\tilde r}^\\mu(1),r^\\mu(0 ) ] \\\\ & = & \\frac1a r(2,1 ) + \\chi(0 ) \\frac1a r(2,0)\\end{aligned}\\ ] ] with the correlation parameters , @xmath127 , defined as @xmath128 this is based on the fact that by definition of the modified local field ( [ eq : f3 ] ) @xmath115 and @xmath129 become a set of uncorrelated variables .",
    "these results lead to the recursion relation ( recall eq .",
    "( [ eq : drec ] ) ) @xmath130 we still have to determine the @xmath127 .",
    "the correlation @xmath131 can be written down immediately again by using the definition of the modified local field at @xmath122 @xmath132 to obtain @xmath133 , one remarks that due to the dependence of @xmath134 and @xmath135 the local fields @xmath136 and @xmath137 are correlated .",
    "the correlation coefficient of their normally distributed part in general defined as @xmath138 }                              { \\sqrt{v(t ) } \\sqrt{v(\\tilde t)}}\\ ] ] is found using the recursion formula ( [ eq : h(1 ) ] ) @xmath139 employing all this in eq .",
    "( [ eq : rt_ttilde ] ) we arrive at @xmath140 here the joint distribution @xmath141 equals @xmath142    we remark that , for @xmath4 , the result ( [ eq : d2 ] ) is slightly different from the corresponding result in @xcite ( see , e.g. , their eq.(39 ) ) . in more detail , in their approach",
    "these authors make an ansatz stating the independence of the normally distributed and discrete part in the noise arising from @xmath143 onwards .",
    "they explicitly state that they have no convincing arguments in favour of ( as well as against ) this ansatz for @xmath144 . in our approach",
    "we do not need this ansatz .",
    "this results in a more complicated expression for @xmath133 than the corresponding one found in @xcite , indicating that this ansatz really ignores some correlations .",
    "in fact both expressions coincide if we put @xmath145 equal to zero .",
    "we start by writing down the distribution of the local field at time @xmath146 . from eqs .",
    "( [ eq : mrec ] ) and ( [ eq : vrec ] ) we find @xmath147 + { \\cal n}(0,\\alpha a d(2 ) ) \\,.\\ ] ] this gives for the main overlap @xmath148                          + \\sqrt{\\alpha a d(2)}\\,y \\right )                  \\right\\rangle\\!\\right\\rangle\\ ] ] with @xmath149 the gaussian random variable @xmath150 .",
    "the average has to be taken over @xmath151 and @xmath135 .",
    "the average over @xmath134 causes no difficulties because this initial configuration is chosen randomly .",
    "the average over @xmath149 , the gaussian random variable appearing in @xmath152 , and @xmath135 is more tricky because @xmath152 and @xmath135 are correlated by the dynamics .",
    "however , the evolution equation ( [ eq : gain ] ) tells us that @xmath135 can be replaced by @xmath153 and , hence , the average taken over @xmath137 instead of @xmath135 .    from the recursion relation ( [ eq : hrec ] ) one finds for the correlation coefficient between @xmath137 and @xmath152 @xmath154                   \\right ] }                  { \\sqrt{\\alpha a d(0)}\\sqrt{\\alpha a d(2 ) } } \\ , .",
    "\\label{eq : for20}\\ ] ] using all this the main overlap at the third time step ( [ eq : m(3)a ] ) becomes @xmath155                 + \\sqrt{\\alpha a d(2)}\\,y                  \\right )                  \\right\\rangle\\!\\right\\rangle   \\nonumber \\\\\\end{aligned}\\ ] ] where the joint distribution of @xmath156 and @xmath149 equals @xmath157 in an analogous way one arrives at the expression for the activity at the third time step @xmath158                          + \\sqrt{\\alpha a d(2)}\\,y                  \\right )                \\right\\rangle\\!\\right\\rangle   \\ , .",
    "\\nonumber \\\\\\end{aligned}\\ ] ] in order to find the variance of the residual overlap at the third time step , @xmath159 , we start by rewriting eq .",
    "( [ eq : drec ] ) as @xmath160 with @xmath161 here we have used the recursion relation ( [ eq : rrec ] ) for @xmath162 and the fact that @xmath115 and @xmath129 become a collection of uncorrelated variables for @xmath163 .",
    "we then have to calculate the correlations @xmath164 , @xmath165 and @xmath166 . from the definition ( [ eq : rt_ttilde ] ) , the local field ( [ eq : h(2 ) ] ) and the joint distribution ( [ eq : dh20 ] ) one easily arrives at @xmath167                          + \\sqrt{\\alpha a d(2)}\\,y                  \\right )                 \\right\\rangle\\!\\right\\rangle       \\\\",
    "r(3,1)&=&\\left\\langle\\!\\left\\langle                  \\int { \\cal d } w^{2,0}(x , y)\\ ,                  \\mbox{g}_b\\left(\\xi^1m^1(0 ) + \\sqrt{\\alpha a d(0)}\\,x                    \\right ) \\mbox{g}_b\\left(\\xi^1m^1(2 ) +                  \\right .",
    "\\right .   \\nonumber\\\\                & & \\hspace{-1.8 cm } \\left.\\left.\\left .",
    "\\alpha\\chi(1 )                          \\left[\\mbox{g}_b(\\xi^1m^1(0)+                          \\sqrt{\\alpha a d(0)}\\,x ) + \\chi(0)\\sigma(0 )                          \\right ]                          + \\sqrt{\\alpha a d(2)}\\,y                  \\right )                 \\right\\rangle\\!\\right\\rangle \\,.\\end{aligned}\\ ] ] finding @xmath166 is more tricky since , after rewriting the network configurations @xmath69 at time @xmath122 and @xmath146 by means of the gain function ( [ eq : gain ] ) , the local fields at the three first time steps appear .",
    "so one has to calculate the elements of the correlation matrix of these local fields in general defined by @xmath168 the correlation coefficients @xmath145 and @xmath169 have been calculated already before ( recall eqs .",
    "( [ eq : for10 ] ) and ( [ eq : for20 ] ) ) .",
    "the correlation coefficient @xmath170 of @xmath171 and @xmath172 is found by using the recursion relation ( [ eq : hrec ] ) as @xmath173 }                  { \\sqrt{\\alpha a d(2)}\\sqrt{\\alpha a d(1 ) } }       \\,.\\ ] ] the distribution function @xmath174 of the three local fields equals @xmath175 where @xmath176 finally , using all this information one gets for the correlation parameter @xmath177                          + z                      \\right )                \\right\\rangle\\!\\right\\rangle \\,.\\end{aligned}\\ ] ] these results can be compared with those for extremely diluted systems . if the dilution is symmetric ( see refs .",
    "@xcite,@xcite for the case @xmath4 ) feedback loops over two time steps can exist , but the probability to have loops over a longer time period equals zero .",
    "therefore the @xmath134-term in ( [ eq : h(2 ) ] ) drops out .",
    "furthermore in the @xmath4 case the expression for the correlation coefficient ( [ eq : for20 ] ) simply reads @xmath178 . if the dilution is asymmetric @xcite , all feedback disappears and the local field is simply gaussian distributed .",
    "a second type of results can be obtained by requiring through the recursion relations ( [ eq : drec ] ) , ( [ eq : mrec ] ) and ( [ eq : vrec ] ) that the local field becomes stationary .",
    "we show that this leads to the same fixed - point equations as those found from thermodynamics in @xcite .    for the q - ising model at zero temperature",
    "one can show that @xmath179 with @xmath180 chosen such that @xmath181           = \\min_{s\\in{\\cal s } } \\epsilon_i[s|{\\bsigma}_{\\lambda                                    \\setminus\\{i\\}}(t)]\\ , , \\ ] ] is a lyapunov function . for finite @xmath6 , @xmath182 is bounded from below implying that @xmath183 after finitely many time steps .",
    "this can be realized for @xmath184 .",
    "the proof is straightforward and completely analogous to the argumentation used in @xcite,@xcite . both a fixed point and a two - cycle satisfy this condition . as stated in the introduction we only study fixed - points .    since the evolution equations for",
    "the order parameters in the extremely diluted and layered @xmath0-ising models do not change their form as time progresses , the fixed - point equations are obtained immediately by leaving out the time dependence ( see @xcite,@xcite ) .",
    "this still allows small fluctuations in the configurations @xmath185 .    since in the fully connected model treated here the form of the evolution equations for",
    "the order parameters do change by the explicit appearance of the @xmath186 , we can not use that procedure to obtain the fixed - point equations .",
    "instead we require that the distribution of the local field becomes independent of time .",
    "this is a stronger condition because fluctuations in the network configuration are no longer allowed .",
    "consequently , the main overlap and activity in the fixed - point are found from the definitions ( [ eq : mdef ] ) , ( [ eq : adef ] ) and not from leaving out the time dependence in the recursion relation ( [ eq : m ] ) and ( [ eq : a ] ) . the same line of reasoning is followed in , e.g. , @xcite,@xcite .",
    "we start by eliminating the time - dependence in the evolution equations for the local field ( [ eq : hrec ] ) .",
    "this leads to @xmath187 with @xmath188 .",
    "this expression consists out of two parts : a normally distributed part @xmath189 and some discrete noise part .",
    "we remark that this discrete noise coming from the correlation of the @xmath69 at different time steps is inherent in the fully connected dynamics . employing the expression eq .",
    "( [ eq : hfix ] ) in the updating rule ( [ eq : gain ] ) one finds @xmath190 this is a self - consistent equation in @xmath7 which in general admits more than one solution .",
    "this type of equation has been solved in the case of analog neural networks with continous time dynamics using a maxwell construction @xcite,@xcite .",
    "such a construction is standard in thermodynamics in order to maximize the exponent of the integrand appearing in free energy calculations .",
    "here we use a similar geometrical construction to treat eq .",
    "( [ eq : sfp ] ) .",
    "let @xmath191 be the straight line which connects the centers of the plateaus of the gain function @xmath20 .",
    "the equations for the functions @xmath20 and @xmath192 read @xmath193 the condition on the r.h.s . of ( [ eq : g ] ) is a condition on @xmath156 . using the definition of @xmath192",
    ", one can transform this into a condition on the image of @xmath192 , @xmath194 , viz .",
    "@xmath195 consider the transformation @xmath196 @xmath197    the function @xmath198 is not bijective while @xmath199 is not one - to - one . to obtain a unique solution for eq .",
    "( [ eq : sfp ] ) we modify the former function such that it becomes a step function with the same step height as the one in @xmath198 and the width of the steps such that @xmath200 connects the centers of the plateaus : @xmath201 or , using ( [ eq : gain ] ) @xmath202 this at first sight ad - hoc modification leads us to a unique solution of the self - consistent equation ( [ eq : sfp ] ) . indeed , from this modified transformation we know that @xmath203 such that @xmath204    at this point we remark that plugging this result into the local field equation ( [ eq : hfix ] ) tells us that the latter is the sum of two gaussians with shifted mean ( see also @xcite ) .",
    "using the definition of the main overlap and activity ( [ eq : mdef ] ) and ( [ eq : adef ] ) in the limit @xmath46 , one finds in the fixed point @xmath205 from ( [ eq : rrec ] ) , ( [ eq : drec ] ) and ( [ eq : chi ] ) it is clear that @xmath206 with @xmath207 these resulting equations ( [ eq : m1fix])-([eq : dfix ] ) are the same as the fixed - point equations derived from a replica - symmetric mean - field theory treatment in @xcite .",
    "their solution leads to the @xmath208 phase diagram fig .",
    "1b in @xcite .",
    "we end with the observation that for analog networks the construction ( [ eq : g])-([eq : tg ] ) is not necessary : the fixed - point equation ( [ eq : sfp ] ) has only one solution .",
    "as an illustrative example the equations derived in section [ sec : ev.eq . ] have been worked out explicitly in the case of the @xmath1 model with equidistant states and a uniform distribution of the patterns ( @xmath209 ) .    for this model a thermodynamic replica - symmetric mean - field theory approach leads to a capacity - gain phase diagram discussed already in @xcite ( fig .",
    "as explained in section [ sec : fixp ] the same phase diagram can be obtained through the dynamical approach presented here . for",
    "convenience and completeness this phase diagram is reproduced here as fig .  1 .",
    "at this point it is also useful to recall that there are two types of retrieval states . in region",
    "i the mean - square random overlap with the non - condensed patterns , @xmath210 , is of order @xmath211 while in region ii @xmath210 is of order @xmath212 @xcite .    for specific network parameters corresponding to different points in the retrieval region of this equilibrium phase diagram , indicated as @xmath213 to @xmath214 , we have compared the dynamics governed by the evolution equations found here with extensive simulations involving system - sizes up to @xmath215 ( each data point is averaged over 1600 runs ) .",
    "figures  2 - 5 present an overview of these results by plotting the overlap @xmath216 , the activity @xmath217 and the hamming distance @xmath218 versus the initial overlap @xmath219 with the condensed pattern .",
    "( we forget about the superscript 1 ) .",
    "the initial activity is taken to be @xmath220 .",
    "first we consider region i. for network parameters corresponding to point 1 below the thermodynamic transition line , i.e. , @xmath221 , we see in fig .  2 that for @xmath222 the dynamics quickly evolves to an overlap @xmath223 and that the hamming distance is zero for @xmath224 .",
    "the activity attains the value @xmath225 , meaning that the network configuration is uniformly distributed .",
    "the boundary between the @xmath223 attractor and the zero - attractor is rather sharply determined .    for a network corresponding to point 2 above the thermodynamic transition line , with @xmath226 ,",
    "we need a larger value of @xmath227 to reach the @xmath223 attractor and a hamming distance zero . as seen in fig .  3",
    ", @xmath227 has to be at least @xmath228 .",
    "also the boundary between the @xmath223 attractor and the zero - attractor is less sharply determined .",
    "figure  4 shows that this behavior is qualitatively the same for @xmath229 , corresponding to point 3 situated above the spin - glass transition in the phase diagram . in this case",
    "the value of @xmath227 has to be at least @xmath230 .",
    "for the other network parameters we have looked at , e.g. , @xmath231 the global behavior is similar .    for network parameters corresponding to points in region ii of the phase diagram , e.g. , point 4 with @xmath232",
    "it is shown in fig .  5 that the main overlap goes to its maximum value for almost all values of @xmath227 .",
    "the basin of attraction of the zero fixed - point is zero .",
    "the activity , however , goes to a value larger than @xmath225 .",
    "the network configuration is no longer uniformly distributed : the state @xmath233 has a smaller probability to appear than the states @xmath234 .",
    "hence , the hamming distance is never zero .",
    "this must be due to the fact that the influence of the non - condensed patterns is much larger here ( @xmath235 ) .",
    "the same qualitative behavior is found for network parameters corresponding to points in region ii below the thermodynamic transition line , e.g. , @xmath236 .",
    "in this paper we have derived the evolution equation for the distribution of the local field governing the parallel dynamics at zero temperature of fully connected @xmath0-ising networks , taking into account _ all _ feedback correlations .",
    "this leads to a general recursive scheme which allows us to calculate the relevant order parameters of the system , i.e. , the main overlap , the activity and the variance of the residual overlap , for any time step .",
    "we have worked out this scheme explicitly for the first three time steps of the dynamics .    under the condition that the local field becomes stationary we have also obtained the fixed - point equations for these order parameters .",
    "they are found to be the same as those derived via thermodynamic methods @xcite .    as an illustration",
    "we have presented a detailed discussion of these results for the @xmath1-model and we have made a comparison with extensive numerical simulations .",
    "it is seen that these numerical results provide excellent support for our theoretical predictions and that the first three time steps do give already a clear picture of the time evolution in the retrieval regime of the network .",
    "this work has been supported in part by the research fund of the k.u.leuven ( grant ot/94/9 ) and the korea science and engineering foundation through the src program .",
    "the authors are indebted to s.  amari , r.  khn a.  patrick and v.  zagrebnov for constructive discussions .",
    "one of us ( d.b . ) thanks the belgian national fund for scientific research for financial support .    99    b.  derrida , e.  gardner , and a.  zippelius , : 167 ( 1987 ) .",
    "d.  boll , g.m .",
    "shim , b.  vinck , and v.a .",
    "zagrebnov , : 565 ( 1994 ) .",
    "e.  domany , w.  kinzel , and r.  meir : 2081 ( 1989 ) .",
    "d.  boll d , g.m .",
    "shim , and b.  vinck , : 583 ( 1994 ) .",
    "watkin and d.  sherrington , : 5427 ( 1991 ) .",
    "patrick and v.a .",
    "zagrebnov , : l1323 ( 1990 ) ; : 1009 ( 1992 ) .",
    "w.  kinzel , _ z.  phys .  b _ * 60 * : 205 ( 1985 ) e.  gardner , b.  derrida and p.  mottishaw , : 741 ( 1987 ) . s.  amari and k.  maginu , _ neural networks _ * 1 * : 63 ( 1988 ) .",
    "w.  krauth , j.p .",
    "nadal and m.  mezard , : 2995 ( 1988 ) .",
    "h.  horner , d.  bormann , m.  frick , h.  kinzelbach and a.  schmidt , : 381 ( 1989 ) .",
    "henkel and m.  opper , : 403 ( 1990 ) ; : 2201 ( 1991 ) .",
    "patrick and v.a .",
    "zagrebnov , : 59 ( 1991 ) .",
    "patrick and v.a .",
    "zagrebnov , : 3413 ( 1991 ) .",
    "m.  okada , _ neural networks _ * 9 * : 1429 ( 1996 ) .",
    "p.  peretto , : 51 ( 1984 ) .",
    "van hemmen and r.  khn , in _ models of neural networks _ , eds .",
    "e.  domany , j.l .",
    "van hemmen j and k.  schulten,(springer , 1991 ) , p.1 .",
    "fontanari and kberle , : 13 ( 1988 ) .",
    "t.  stiefvater , k.r .",
    "mller and r.  khn , : 61 ( 1996 ) .",
    "d.  boll , b.  vinck , and v.a .",
    "zagrebnov , : 1099 ( 1993 ) .",
    "d.  boll , h.  rieger h and g.m .",
    "shim , : 3411 ( 1994 ) .",
    "e.  barkai , i.  kanter and h.  sompolinsky , : 590 ( 1990 ) .",
    "shiryayev , _ probability _ ( springer , new york , 1984 ) m.  shiino and t.  fukai , : l375 ( 1992 ) . m.  shiino and t.  fukai , : 867 ( 1993 ) ."
  ],
  "abstract_text": [
    "<S> using a probabilistic approach we study the parallel dynamics of fully connected @xmath0-ising neural networks for arbitrary @xmath0 . </S>",
    "<S> a lyapunov function is shown to exist at zero temperature . </S>",
    "<S> a recursive scheme is set up to determine the time evolution of the order parameters through the evolution of the distribution of the local field . </S>",
    "<S> as an illustrative example , an explicit analysis is carried out for the first three time steps . </S>",
    "<S> for the case of the @xmath1 model these theoretical results are compared with extensive numerical simulations . </S>",
    "<S> finally , equilibrium fixed - point equations are derived and compared with the thermodynamic approach based upon the replica - symmetric mean - field approximation .    </S>",
    "<S> parallel dynamics of fully connected @xmath2-ising neural networks +    * key words : * fully - connected networks ; @xmath0-ising neurons ; parallel dynamics ; probabilistic approach </S>"
  ]
}