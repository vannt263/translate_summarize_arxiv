{
  "article_text": [
    "a real random variable @xmath7 is _ normalized _ if it has mean 0 and variance 1 .",
    "a complex random variable @xmath7 is normalized if @xmath8 , where @xmath9 are iid copies of a real normalized random variable",
    ".    some popular normalized variables    * real standard gaussian @xmath10 , or real bernoulli @xmath11 which takes value @xmath12 with probability @xmath13 ; .1 in * complex standard gaussian @xmath14 , or complex bernoulli @xmath15 .    fixed a normalized random variable @xmath7 and consider the random vector @xmath16 , whose entries are iid copies of @xmath7 . sample @xmath1 iid copies @xmath17 of @xmath18 .",
    "we would like to study the normal vector of the hyperplane spanned by the @xmath5 .    in matrix term , we let @xmath19 be a random matrix of size @xmath1 by @xmath20 where the entries @xmath21 are iid copies of @xmath7 ; the @xmath5 are the row vectors of @xmath22 .",
    "let @xmath23 be a unit vector that is orthogonal to the @xmath5 ( here and later @xmath24 is either @xmath25 or @xmath26 , depending on the support of @xmath7 . )",
    "first note that recent studies in the singularity probability of random non - hermitian matrices ( see for instance @xcite ) show that under very general conditions on @xmath7 , with extremely high probability @xmath22 has rank @xmath1 . in this case",
    "@xmath4 is uniquely determined up to the sign @xmath12 when @xmath27 or by a uniformly chosen rotation @xmath28 when @xmath29 . throughout the paper ,",
    "we use asymptotic notation under the assumption that @xmath20 tends to infinity .",
    "in particular , @xmath30 , @xmath31 , or @xmath32 means that @xmath33 for some fixed @xmath34 .",
    "when the entries of @xmath22 are iid standard gaussian @xmath35 , it is not hard to see that @xmath4 is distributed as a random unit vector sampled according to the haar measure in @xmath36 of @xmath37 .",
    "one then deduces the following properties ( see for instance @xcite[section 2 ] )    [ thm : gaussian ] let @xmath4 be a random vector uniformly distributed on the unit sphere @xmath36 .",
    "then ,    * ( joint distribution of the coordinates ) @xmath4 can be represented as @xmath38 where @xmath39 are iid standard gaussian @xmath35 , and @xmath40 ; .05 in * ( inner product with a fixed vector ) for any fixed vector @xmath41 on the unit sphere , @xmath42 .05 in * ( the largest coordinate ) for any @xmath43 , with probability at least @xmath44 @xmath45 .05 in * ( the smallest coordinate ) for @xmath46 , any @xmath47 , and any @xmath48 , @xmath49 with probability at least @xmath50 .    motivated by the _ universality phenomenon _",
    "( see , for instance @xcite ) , it is natural to ask if these properties are universal , namely that they hold if @xmath7 is non - gaussian .",
    "our result confirms this prediction in a strong sense .",
    "they also have applications in the theory of random matrices , which we will discuss after stating the main result .",
    "let us introduce some notations .",
    "we say that @xmath7 is sub - gaussian if there exists a parameter @xmath51 such that for all @xmath52    @xmath53    let @xmath54 be an event depending on @xmath20 ( which is assumed to be sufficiently large ) .    * @xmath54 holds asymptotically almost surely if @xmath55 .",
    "* @xmath54 holds with high probability if there exists a positive constant @xmath56 such that @xmath57 .",
    "* @xmath54 holds with overwhelming probability , and write @xmath58 , if for any @xmath59 , with sufficiently large @xmath20 @xmath60 .",
    "[ thm : linear ] suppose that @xmath21 are iid copies of a normalized sub - gaussian random variable @xmath7 , then the followings hold .",
    "* ( the largest coordinate ) there are constants @xmath61 such that for any @xmath62 @xmath63 in particularly , with overwhelming probability + @xmath64 + .05 in * ( the smallest coordinate ) with high probability @xmath65 .05 in * ( joint distribution of the coordinates ) there exists a positive constant @xmath66 such that the following holds : for any @xmath67-tuple @xmath68 , with @xmath69 , the joint law of the tuple @xmath70 is asymptotically independent standard normal .",
    "more precisely , there exists a positive constant @xmath71 such that for any measurable set @xmath72 , + @xmath73 are iid standard gaussian . *",
    "( inner product with a fixed vector ) assume furthermore that @xmath7 is symmetric , then for any fixed vector @xmath41 on the unit sphere , @xmath74 .05 in    it also follows easily from and that with high probability @xmath75 .",
    "indeed , it is clear that with high probability , with @xmath76 for some sufficiently small @xmath66 , @xmath77 .",
    "thus by , with high probability @xmath78 .",
    "our approach can be extended to unit vectors orthogonal to the rows of an iid matrices @xmath22 of size @xmath79 , for any fixed @xmath80 or even @xmath80 grows slowly with @xmath20 ; the details will appear in a later paper .    as random hyperplanes appear frequently in various areas , including random matrix theory , high dimensional geometry , statistics , and theoretical computer science",
    ", we expect that theorem [ thm : linear ] will be useful .",
    "for the rest of this section , we discuss two applications .      given an @xmath81 random matrix @xmath82 with entries being iid copies of a normalized variable @xmath7 .",
    "let @xmath83 be its singular values .",
    "the two extremal @xmath84 and @xmath85 are of special interest , and was studied by goldstein and von neumann , as they tried to analyze the running time of solving a system of random equations @xmath86 .",
    "in @xcite , goldstein and von neumann speculated that @xmath85 is of order @xmath87 , which turned out to be correct .",
    "in particular , @xmath88 tends to a limiting distribution , which was computed explicitly by edelman in @xcite in the gaussian case .",
    "[ edelman ] for any @xmath89 we have    @xmath90    as well as    @xmath91    in other words , @xmath92 and @xmath93 .",
    "these distributions have been confirmed to be universal ( in the asymptotic sense ) by tao and the second author @xcite .    in applications ,",
    "one usually needs large deviation results , which show that the probability that @xmath85 is far from its mean is very small .",
    "for the lower bound , rudelson and vershyin @xcite proved that for any @xmath94    @xmath95    which is sharp up to the constant @xmath34 .",
    "for the upper bound , in a different paper @xcite , the same authors showed    @xmath96    using theorem [ thm : linear ] , we improve this result significantly by proving an exponential tail bound ,    [ cor : upper ] assume that the entries of @xmath97 are iid copies of a normalized subgaussian random variable @xmath7 in either @xmath25 or @xmath26 . then there exist absolute constants @xmath98 depending on @xmath99 such that @xmath100    our proof of theorem [ cor : upper ] is totally different from that of @xcite .",
    "as showed in the gaussian case , the exponential bound is sharp , up to the value of @xmath101 .",
    "our theorem is closely related to ( and in fact was motivated by ) recent results concerning delocalization and normality of eigenvectors of random matrices . for random hermitian matrices ,",
    "there have been many results achieving almost optimal delocalization of eigenvectors , starting with the work @xcite by erds et al . and and continued by tao et al . and by many others in @xcite .",
    "thanks to new universality techniques , one also proved normality of the eigenvectors ; see for instance the work @xcite by knowles and yin , @xcite by tao and vu , and @xcite by bourgade and yau .    for non - hermitian random matrix @xmath102 , much less is known .",
    "let @xmath103 be the eigenvalues with @xmath104 .",
    "let @xmath105 be the corresponding unit eigenvectors ( where @xmath5 are chosen according to the haar measure from the eigensphere if the corresponding roots are multiple ) .",
    "recently , rudelson and vershynin @xcite proved that with overwhelming probability all of the eigenvectors satisfy    @xmath106    by modifying the proof of theorem [ thm : linear ] , we are able sharpen this bound for eigenvectors of eigenvalues with small modulus .    [",
    "optimal delocalization for small eigenvectors][cor : eigenvectors ] assume that the entries of @xmath97 are iid copies of a normalized subgaussian random variable @xmath7 in either @xmath25 or @xmath26 .",
    "then for any fixed @xmath107 , with overwhelming probability the following holds for any unit eigenvector @xmath4 corresponding to an eigenvalue @xmath108 of @xmath22 with @xmath109    @xmath110    we believe that the individual eigenvector in theorem [ cor : eigenvectors ] satisfies the normality property , which would imply that the bound @xmath111 is optimal up to a multiplicative constant .",
    "figure [ fig:1 ] below shows that the first coordinate of the eigenvector corresponding to the smallest eigenvalue behaves like a gaussian random variable .    .",
    "the histograms represent the normalized real and imaginary parts @xmath112 and @xmath113 of the first coordinate of the unit eigenvector @xmath18 associated with the eigenvalue of smallest modulus.,title=\"fig:\",scaledwidth=60.0% ] .",
    "the histograms represent the normalized real and imaginary parts @xmath112 and @xmath113 of the first coordinate of the unit eigenvector @xmath18 associated with the eigenvalue of smallest modulus.,title=\"fig:\",scaledwidth=60.0% ]    finally , let us mention that all of our results holds ( with logarithmic correction ) under a weaker assumption that the variable @xmath7 is sub - exponential , namely there are positive constants @xmath114 and @xmath115 such that for all @xmath52 @xmath116 ; see remark [ remark : sub ] .",
    "the rest of the paper is organized as follows . after introducing supporting lemmas in section [ section : lemmas ]",
    ", we will prove and theorem [ cor : eigenvectors ] in section [ section : infty ] .",
    "section [ section : normality ] and section [ section : innerproduct ] are devoted to proving and correspondingly , while will be shown in section [ section : non - gap ] .",
    "finally , we prove theorem [ cor : upper ] in section [ section : singularvalue ] .",
    "we will use the following well - known concentration result of distances in random non - hermitian matrices ( see for instance ( * ? ? ?",
    "* lemma 43 ) , ( * ? ? ?",
    "* corollary 2.19 ) or @xcite ) .",
    "[ thm : distance ] let @xmath117 be a subspace of co - dimension @xmath118 in @xmath119 and let @xmath120 be the projection matrix onto the complement @xmath121 of @xmath117 .",
    "let @xmath122 and @xmath123 be independent random vectors where @xmath124 are iid copies of an @xmath24-normalized sub - gaussian random variable @xmath7",
    ". then the following holds .    1 .",
    "the distance from @xmath41 to @xmath117 is well concentrated around its mean , @xmath125 2 .",
    "the correlation @xmath126 is small , @xmath127    more generally , we have    [ lemma : hw ] there exists an absolute constant @xmath66 such that the following holds for any sub - gaussian @xmath24-normalized random variable @xmath7 .",
    "let @xmath22 be a fixed @xmath128 hermitian matrix .",
    "consider a random vector @xmath129 where the entries are iid copies of @xmath7 .",
    "then    @xmath130    in particularly , for any @xmath94    @xmath131    this lemma was first proved by hanson and wright in a special case @xcite .",
    "the above general version is due to rudelson and vershynin @xcite ; see also @xcite for related results which hold ( with logarithmic correction ) for sub - exponential variables .",
    "[ remark : sub ] as mentioned at the end of the introduction , the results of this paper hold ( with logarithmic correction ) for sub - exponential variables .",
    "one can achieve this by repeating the proofs , using the results from @xcite ( such as ( * ? ? ?",
    "* corollary 1.6 ) ) instead of lemmas [ thm : distance ] and [ lemma : hw ] .",
    "we leave the details as an exercise .",
    "the next tool is berry - essen theorem for frames , proved by tao and vu in @xcite . as the statement is technical ,",
    "let us first warm the reader up by the classical berry - essen theorem .",
    "[ lemma : be ] let @xmath132 be real numbers with @xmath133 and let @xmath7 be a @xmath24-normalized random variable with finite third moment @xmath134 .",
    "let @xmath135 denote the random sum    @xmath136    where @xmath39 are iid copies of @xmath7 .",
    "the for any @xmath137 we have    @xmath138    where the implied constant depends on the third moment of @xmath7 . in",
    "particularly ,    @xmath139    ( * ? ? ? * proposition d.2)[lemma : be ] let @xmath140 , and let @xmath7 be an @xmath24-normalized and have finite third moment .",
    "let @xmath141 be a normalized tight frame for @xmath142 , in other words    @xmath143    where @xmath144 is the identity matrix on @xmath142 .",
    "let @xmath145 denote the random variable    @xmath146    where @xmath147 are iid copies of @xmath7 .",
    "similarly , let @xmath148 be formed from @xmath80 iid copies of the standard gaussian random variable @xmath35 .",
    "then for any measurable @xmath149 and for any @xmath150 we have    @xmath151    where @xmath152 is the collection of @xmath153 such that @xmath154 .",
    "by a union bound , it suffices to show that for sufficiently large @xmath34    @xmath155    let @xmath156 , @xmath157 be the columns of @xmath22 . because @xmath158 , among the @xmath159 subset sums @xmath160 , there is a subset sum which is smaller than @xmath161 . with a loss of a factor @xmath162 in probability , without loss of generality we will assume that    @xmath163    let @xmath117 be the subspace generated by @xmath164 .",
    "let @xmath120 be the orthogonal projection from @xmath165 onto @xmath121 .",
    "we view @xmath120 as a hermitian matrix of size @xmath166 satisfying @xmath167 .",
    "it is known ( see for instance @xcite ) that with probability @xmath168 we have @xmath169 , which implies @xmath170 .",
    "recall that by definition ,    @xmath171    applying @xmath120 , we have    @xmath172    which implies    @xmath173    where @xmath174 and @xmath175 .",
    "we remark that the @xmath176 here are not deterministic but depend on the column vectors @xmath156 .    as @xmath177 is linear , and as @xmath178 , we have    @xmath179    thus    @xmath180    we are going to estimate the operator norm @xmath181 basing the randomness of @xmath182 .",
    "[ lemma : q : norm ] there exists a sufficiently large constant @xmath34 such that @xmath183    assume lemma [ lemma : q : norm ] for the moment , we can complete the proof of as follows .",
    "first , by lemma [ thm : distance ] , @xmath184 with probability at least @xmath185 .",
    "we then deduce from and from lemma [ lemma : q : norm ] that    @xmath186    completing the proof .",
    "to prove lemma [ lemma : q : norm ] , we first estimate @xmath187 for any fixed @xmath188",
    ". we will show    [ lemma : individual ] there exists a sufficiently large constant @xmath34 such that for any fixed @xmath189 with @xmath190 , @xmath191    the deduction of lemma [ lemma : q : norm ] from lemma [ lemma : individual ] is standard , we present it here for the sake of completeness .",
    "( of lemma [ lemma : q : norm ] ) let @xmath192 be a @xmath193-net for the set of unit vectors in @xmath194 .",
    "as is well known , one can assume that @xmath195 .",
    "applying lemma [ lemma : individual ] ,    @xmath196    now for any unit vector @xmath197 , there exists @xmath198 such that @xmath199 , and thus by the triangle inequality    @xmath200    this implies that @xmath201 , and hence    @xmath202    ( of lemma [ lemma : individual ] ) let @xmath203 be the concatenation of @xmath204 , then @xmath205 can be written as a bilinear form @xmath206 where @xmath207 is the tensor product of @xmath208 and @xmath120 , with @xmath209 . by construction",
    ", @xmath207 consists of @xmath210 blocks where the @xmath211-th block is the matrix @xmath212 .",
    "it thus follows that    @xmath213    applying lemma [ lemma : hw ] to @xmath214 , we have    @xmath215    it is easy to show that    @xmath216    taking @xmath217 , we obtain    @xmath218    to this end , by properties of a tensor product ,    @xmath219    which implies that    @xmath220    we now turn to the eigenvectors .",
    "we will be working with the perturbed matrix @xmath221 where @xmath222 and @xmath223 . by a standard net argument",
    ", it suffices to show the following    [ theorem : eiginfty ] for any fixed @xmath224 with @xmath225 , the following holds with overwhelming probability with respect to @xmath226 : if @xmath227 then @xmath4 satisfies .",
    "equivalently , we show that for any unit vector @xmath228 satisfying the condition of theorem [ theorem : eiginfty ] , then    @xmath229    we will proceed as in subsection [ subsection : zero ] by assuming that @xmath178 , where instead of @xmath230 we have    @xmath231    for some vector @xmath232 with norm @xmath233 , where @xmath156 is the @xmath234-th column of the matrix @xmath221 .    projecting onto @xmath121 , we obtain    @xmath235    note that here as @xmath236 , lemma [ thm : distance ] is still effective , which yields @xmath184 with probability at least @xmath185 .    to estimate the right hand side , set @xmath237 .",
    "similarly to lemma [ lemma : q : norm ] , we will establish    [ lemma : q : norm ] there exists a sufficiently large constant @xmath34 such that @xmath183    it is clear that follows from lemma [ lemma : q : norm ] .",
    "furthermore , similarly to our treatment in the previous subsection , for this lemma it suffices to show the following analog of lemma [ lemma : individual ] for any fixed @xmath238 .",
    "[ lemma : individual ] there exists a sufficiently large constant @xmath34 such that for any fixed @xmath189 with @xmath190 , @xmath191    it remains to prove lemma [ lemma : individual ] .",
    "write @xmath239 , where @xmath240 is a @xmath241-vector with at most one non - zero entry and @xmath242 is a random vector of iid entries .",
    "thus    @xmath243    for @xmath135 , argue similarly as in the proof of lemma [ lemma : individual ] , we obtain the following analog of    @xmath244    next , we have    @xmath245    additionally , as @xmath246 and @xmath190 , by the properties of @xmath247 the vector @xmath248 has norm at most @xmath249 . as such , the subgaussian random variable @xmath250 has variance at most one , and hence    @xmath251    we can argue similarly for @xmath252 to obtain the same bound .",
    "finally , notice that    @xmath253    putting all the estimates together , we obtain lemma [ lemma : individual ] as long as @xmath254 .",
    "let @xmath255 be the random matrix of size @xmath166 obtained from @xmath22 by deleting its first column .",
    "set @xmath256 , we have    @xmath257    as it is known that with probability at least @xmath168 the matrix @xmath255 is invertible ; in this case , we can write    @xmath258    since    @xmath259 we obtain    @xmath260 where @xmath261 are the singular values of @xmath255 with corresponding left - singular vectors @xmath262 .    we now condition on @xmath255 . by the sub - gaussian property of the entries , we can easily show that there is a constant @xmath34 such that with overwhelming probability ( with respect to @xmath263 )    @xmath264 with respect to @xmath255 we have    @xmath265    ( of claim [ claim : negative ] ) by    @xmath266    thus by the union bound    @xmath267    for the remaining sum @xmath268 , by the cauchy - interlacing law ,    @xmath269    where @xmath270 is obtained from @xmath255 by deleting its first @xmath271 columns .",
    "on the other hand , by the negative second moment identity ( see ( * ? ? ? * lemma a.4 ) )    @xmath272    where @xmath273 is the distance from the @xmath274th row of @xmath270 to the hyperplane @xmath275 spanned by the remaining rows of @xmath270 . using theorem [ thm : distance ] and the union bound , we obtain , for some constant @xmath66 and with overwhelming probability , that @xmath276 simultaneously for all @xmath277 .",
    "this implies that with overwhelming probability with respect to @xmath255    @xmath278    now by and claim [ claim : negative ] , we have    @xmath279    by the union by , we have with probability at least @xmath280 ,    @xmath281 proving the desired statement .",
    "using ( * ? ? ?",
    "* theorem 1.3 ) we can compare @xmath282 with @xmath283 , where @xmath284 is the least singular value of an @xmath24-normalized gaussian matrix .",
    "more precisely , it shows that there exists a positive constant @xmath66 such that    @xmath285    in the complex case , theorem [ edelman ] has @xmath286 .",
    "since @xmath287 , this implies the claim for @xmath288 for any fixed @xmath34 and properly chosen constants @xmath289 .    in the real case , one can not apply theorem [ edelman ] directly because of the error term is just plainly @xmath290 .",
    "however , in @xcite tao and the second author proved that this error term is at most @xmath291 for some constant @xmath292 .",
    "thus , one can conclude in the same manner as in the complex case .",
    "from here we assume @xmath293 , where @xmath34 is a sufficiently large constant . by the proof of of theorem [ thm : linear ] ( applied for matrices of size @xmath294 instead of @xmath295 )",
    "we have , for all @xmath296 that    @xmath297    equivalently , for all @xmath298 @xmath299    one the other hand , similarly to our treatment in section [ section : non - gap ]    @xmath300    where @xmath301 are the singular values of the random square matrix @xmath302 formed by the last @xmath20 columns , @xmath263 is the first column , and @xmath303 are the corresponding unit eigenvector of @xmath304 in @xmath305 .",
    "thus with probability at least @xmath306 we have    @xmath307    next , again by following the argument in section [ section : non - gap ] ( using the negative - moment identity , the cauchy - interlacing law , and theorem [ thm : distance ] ) , we can prove    [ claim : non - weight ] with probability at least @xmath308 one has    @xmath309 with @xmath99 from .    to handle the coefficients @xmath310 , we use the following concentration result from @xcite .",
    "* lemma 1.2 ) [ lemma : vw ] let @xmath311 be a random vector where @xmath176 are iid copies of @xmath7 .",
    "then there exists a constant @xmath312 such that the following holds .",
    "let @xmath117 be a subspace of dimension @xmath67 with an orthonormal basis @xmath313 .",
    "then for any @xmath314 and any @xmath315 @xmath316    there is a strong relation between this lemma and lemma [ lemma : hw ] .",
    "first , one can give a short proof of this lemma using lemma [ lemma : hw ] .",
    "second , one can also prove a generalization of lemma [ lemma : hw ] to sub - exponential variables ( with logarithmic correction ) using this lemma .",
    "see remark [ remark : sub ] .    in particular , by squaring",
    ", it follows that @xmath317    next , lemma [ lemma : vw ] , applied to @xmath318 ( with @xmath319 and @xmath320 ) , implies that    @xmath321    thus , with probability at least @xmath322 , we have    @xmath323    now we can conclude from , and claim [ claim : non - weight ] ( noting that @xmath324 ) that with probability at least @xmath325    @xmath326    this event guarantees that @xmath327 , or equivalently @xmath328 .",
    "our proof is complete .",
    "we will show that    latexmath:[\\[\\label{eqn : d=1 }     the general case with joint distribution of @xmath67 components , with @xmath67 chosen to be a small power of @xmath20 , can be treated similarly ; see also below .",
    "our method follows that of @xcite .",
    "first , by of theorem [ thm : linear ] , it suffices to work with the event @xmath54    @xmath330 assume that @xmath331 and @xmath332 for all @xmath234 .",
    "then there exists an absolute constant @xmath66 such that for a uniformly randomly chosen @xmath333-set @xmath334 from the index set @xmath335    @xmath336 where the probability is with respect to @xmath334 .    for convenience ,",
    "denote by @xmath337 the event    @xmath338    by theorem [ thm : concentration ] , with @xmath339 and @xmath340    @xmath341    we are conditioning on these two events for the rest of the argument .    with foresight ,",
    "we choose @xmath118 slightly larger than the value in section [ section : infty ] , in particularly @xmath118 will take the form @xmath342 for some sufficiently large constant @xmath343 to be chosen later .",
    "we next exploit once more by projecting onto the orthogonal complement @xmath121 of @xmath117 .",
    "this time we view the projection as @xmath344 ,    @xmath345    by a normalization @xmath346 , we rewrite as ( with @xmath347 )    @xmath348    for @xmath349 , let @xmath350 be the projection of the standard unit vector @xmath351 .",
    "then for @xmath352    @xmath353    where @xmath354 are the entries of our matrix @xmath22 .    in other words , one can view the @xmath355 matrix @xmath356 as    @xmath357    where @xmath358 is the @xmath359 matrix whose columns are zero except the @xmath360-th one , which is @xmath361 .",
    "next we record a useful lemma about the matrix @xmath255 , which can be proved by standard techniques from @xcite .",
    "[ lemma : m ] with high probability with respect to @xmath21 , the least singular value of @xmath362 is at least @xmath363 and the largest singular value of @xmath362 is at most @xmath364 .",
    "let @xmath365 be this event . by the property of projection @xmath366 ,    @xmath367    where we view @xmath358 as vectors in @xmath368 .",
    "now for any fixed @xmath369 , with @xmath370 , let @xmath371 be the set of matrices @xmath255 of size @xmath372 satisfying lemma [ lemma : m ] such that the normal vector @xmath373 satisfies @xmath374 . for convenience ,",
    "define    @xmath375    as with we are ready to apply lemma [ lemma : be ] .",
    "it is crucial to notice that conditioning on @xmath376 , the approximating matrix @xmath377 is a gaussian iid matrix of size @xmath355 , and hence theorem [ thm : gaussian ] applies to the normal vector @xmath378 of this matrix    @xmath379    for @xmath380 , we apply the following crucial lemma from ( * ? ? ?",
    "* proposition 3.5 ) .",
    "[ lemma : norm ] there exists a positive constant @xmath66 ( independently of @xmath343 ) such that the following holds with overwhelming probability with respect to @xmath376 : for any unit vector @xmath381 we have    @xmath382    for short we let @xmath383 be the event considered in lemma [ lemma : norm ] , thus    @xmath384    let us now consider the sets @xmath385 and @xmath386 .",
    "assume that @xmath387 with normal vectors @xmath388 and @xmath389 and such that @xmath390 .",
    "then as @xmath391 , we have ( rather generously ) @xmath392 . by definition of @xmath393 ( which satisfies lemma [ lemma : m ] )",
    ", it then follows that ( again very generously )    @xmath394    hence it follows from that    @xmath395    now choose @xmath396 ( with @xmath66 from lemma [ lemma : norm ] ) and @xmath397 .",
    "we have    @xmath398    by theorem [ thm : gaussian ] , we have , for some constant @xmath71 sufficiently small depending on @xmath66    @xmath399    now we pass from @xmath400 to @xmath401 conditioning on @xmath402 .",
    "on this event , by @xmath403    in other words ,    @xmath404    consequently ,    @xmath405    where we used the bound @xmath406 in the last estimate .    in summary",
    ", it follows from and that conditioning on @xmath407    @xmath408    for some absolute constant @xmath409 . in",
    "particularly , this immediately implies as all of the conditional events hold with high probability .",
    "the treatment here follows closely ( * ? ? ? * proposition 25 ) .",
    "let @xmath115 be a number growing slowly to infinity that will be specified later .",
    "for each component @xmath176 of @xmath4 we decompose                                          where the implied constant can depend on @xmath80 , and @xmath428 indicates over all @xmath80-tuples @xmath429 in which each index @xmath234 appears an even number of times . to complete the proof , we just note that                                      l. erds , a. knowles , h .-",
    "yau and j. yin , spectral statistics of erds - rnyi graphs ii : eigenvalue spacing and the extreme eigenvalues , _ communication in mathematical physics _ ,",
    "* 314 * ( 2012 ) , no . 3 , 587 - 640 . .05 in                    m. rudelson , r. vershynin , the littlewood - offord problem and invertibility of random matrices , _ advances in mathematics",
    ", * 218 * ( 2008 ) , no . 2 , 600 - 633 . .05 in m.",
    "rudelson and r.  vershynin , smallest singular value of a random rectangular matrix , _ communications on pure and applied mathematics _ ,",
    "* 62 * ( 2009 ) , 1707 - 1739 . .05 in"
  ],
  "abstract_text": [
    "<S> let @xmath0 be @xmath1 independent vectors in @xmath2 ( or @xmath3 ) . </S>",
    "<S> we study @xmath4 , the unit normal vector of the hyperplane spanned by the @xmath5 . </S>",
    "<S> our main finding is that @xmath4 resembles a random vector chosen uniformly from the unit sphere , under some randomness assumption on the @xmath5 .    </S>",
    "<S> our result has applications in random matrix theory . </S>",
    "<S> consider an @xmath6 random matrix with iid entries . </S>",
    "<S> we first prove an exponential bound on the upper tail for the least singular value , improving the earlier linear bound by rudelson and vershynin . </S>",
    "<S> next , we derive optimal delocalization for the eigenvectors corresponding to eigenvalues of small modulus . </S>"
  ]
}