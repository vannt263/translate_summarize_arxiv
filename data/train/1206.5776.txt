{
  "article_text": [
    "in 1981 hutchinson @xcite presented a theory of fractals and measures supported on fractals based on iterations of functions .",
    "let @xmath2 be an iterated function system with probabilities ( ifsp ) .",
    "that is , @xmath3 , @xmath4 , are functions and @xmath5 are associated non - negative numbers with @xmath6 .",
    "if the maps @xmath7 are contractions , i.e.   if there exists a constant @xmath8 such that @xmath9 , for all @xmath10 , then there exists a unique nonempty compact set @xmath11 satisfying @xmath12 for any @xmath13 , and a unique probability measure @xmath0 , supported on @xmath11 , satisfying the invariance equation @xmath14 see hutchinson @xcite .",
    "the set @xmath11 is sometimes called the set - attractor , and @xmath0 the measure - attractor of the ifsp .",
    "the set - attractor @xmath11 will have a self - repeating `` fractal '' appearance if all maps @xmath15 are similitudes , and the sets , @xmath16 , @xmath4 , do not overlap .",
    "this leads to the intuition to regard the set - attractor @xmath11 in as being built up by @xmath17 ( in general overlapping and heavily distorted ) `` copies '' of itself , and the measure - attractor as a `` greyscale colouring '' of the set - attractor .",
    "( note that the probabilities @xmath5 play no role in the definition of @xmath11 . )    in general we can not expect to have a unique set - attractor if the ifs - maps are not assumed to be contractions or more generally if the limits @xmath18 do not exist , with the limit being independent of @xmath19 , for _ all _ @xmath20 , but unique measure - attractors exist if the limits @xmath21 exist ( with the limit being independent of @xmath19 ) for _ almost all _ @xmath20 .",
    "( indeed , if the limit in exists a.s",
    ".  then @xmath22 may be regarded as a random variable , and its distribution @xmath23 , is then the unique solution to . )",
    "the theory of ifsp has a long pre - history within the theory of markov chains , starting already with papers in the 30th by dblin and others .",
    "let @xmath24 be the markov chain obtained by random ( independent ) iterations with the functions , @xmath15 , chosen with the corresponding probabilities , @xmath5 .",
    "that is , let @xmath25 be defined recursively by @xmath26 where @xmath27 is a sequence of independent random variables with @xmath28 , independent of @xmath29 , where @xmath29 is some given random variable .",
    "( it is well - know that any markov chain @xmath25 ( with values in @xmath30 ) can be expressed in the form @xmath31 where @xmath32 \\rightarrow   \\mathbb{r}^d$ ] is a measurable function and @xmath33 is a sequence of independent random variables uniformly distributed on the unit interval , see e.g.   kifer @xcite . )",
    "if an ifsp has a unique measure - attractor , @xmath0 , then @xmath0 is the unique stationary distribution of @xmath25 , i.e. @xmath0 is the unique probability measure with the property that if @xmath29 is @xmath0-distributed , then @xmath25 will be a ( strictly ) stationary ( and ergodic ) stochastic process , see e.g.  elton @xcite .",
    "therefore a unique measure - attractor can alternatively also be called a unique stationary distribution .    under standard average contraction conditions it follows that ( [ 0630 ] ) holds a.s . ,",
    "and the distribution of @xmath34 converges weakly to @xmath0 ( with exponential rate quantified e.g.  by the prokhorov metric for arbitrary distributions of the initial random variable @xmath29 ) .",
    "moreover the empirical distribution along trajectories of @xmath25 converges weakly to @xmath35 a.s . ,",
    "and @xmath25 obeys a central limit theorem .",
    "see e.g.  barnsley et al .",
    "@xcite , diaconis and freedman @xcite , and stenflo @xcite for details and further results .",
    "these papers also contains surveys of the literature .",
    "the inverse problem is to , given a probability measure @xmath0 , find an ifsp having @xmath0 as its unique measure - attractor .",
    "this problem is of importance in e.g.  image coding where the image , represented by a probability measure , can be encoded by the parameters in a corresponding ifsp in the affirmative cases , see e.g.  barnsley @xcite . for an encoding to be practically useful",
    "it needs to involve few parameters and the distribution of @xmath34 needs to converge quickly to equilibrium ( a property ensured by average contractivity properties of the functions in the ifsp ) for arbitrary initial distributions of @xmath29 .",
    "it is possible to construct solutions to the inverse problem in some very particular cases using barnsley s `` collage theorem '' , see @xcite containing exciting examples of e.g.  ferns and clouds ( interpreted as probability measures on @xmath36 ) and their ifsp encodings , but typically it is very hard to even find approximate solutions to the inverse problem for general probability measures on @xmath37 .    in this paper",
    "we present a ( strikingly simple ) solution to the inverse problem for continuous probability measures on @xmath1 .",
    "in order to present our solution to the inverse problem for continuous probability measures on @xmath1 , recall the following basic facts used in the theory of random number generation ;    let @xmath0 be a probability measure on @xmath1 , and let @xmath38)$ ] denote its distribution function .",
    "the generalised inverse distribution function is defined by @xmath39 and satisfies @xmath40 and @xmath41 and therefore @xmath42 from this it follows that if @xmath43 , i.e.  if @xmath44 is a random variable uniformly distributed on the unit interval , then @xmath45 is a @xmath0-distributed random variable .",
    "this basic property reduces the problem of simulating from an arbitrary distribution on @xmath1 , to the problem of simulating uniform random numbers on the unit interval .",
    "we say that @xmath0 is continuous if @xmath46 is continuous .",
    "note that @xmath47 for any @xmath48 for continuous probability measures in contrast with discrete probability measures where @xmath49 for some countable set @xmath50 .",
    "[ 110622 ] a continuous distribution , @xmath0 , on @xmath53 with distribution function , @xmath46 , is the measure - attractor of the ifs with monotone maps @xmath54 , for any @xmath19 with @xmath55 , and probabilities @xmath56 , where @xmath57 , @xmath58 , @xmath59 , for any @xmath60 .",
    "the markov chain generated by @xmath61 , @xmath59 , chosen with equal probabilities has the uniform distribution on the unit interval as its unique stationary distribution .",
    "that is , if @xmath62 is a sequence of independent random variables , uniformly distributed on @xmath63 , then @xmath64 is a markov chain starting at @xmath65 $ ] having the uniform distribution as its unique stationary distribution .",
    "this can be seen by observing that @xmath66 has the same distribution as the reversed iterates @xmath67 for any fixed @xmath68 , and the reversed iterates @xmath69 converges almost surely to the @xmath70-distributed random variable , @xmath71 , where the @xmath72 digit in the base @xmath17 expansion of @xmath71 is given by @xmath73 .",
    "if @xmath22 denotes the limit of the reversed iterates of the system with @xmath15 chosen with probability @xmath74 , then @xmath75 where the last equality holds since @xmath76 is non - decreasing , and since a monotone function can have at most a countable set of discontinuity points in its domain , it follows that @xmath76 is continuous for a.a .",
    "@xmath65 $ ] w.r.t . to the lebesgue measure .      if @xmath78 is a continuous @xmath0-distributed random variable , then @xmath51 , so @xmath79 .",
    "this contrasts the case when @xmath78 is discrete where @xmath80 will also be discrete , so we can not expect theorem [ 110622 ] to generalise to discrete distributions .",
    "if an ifs @xmath81 , has a continuous measure - attractor @xmath0 being the distribution of the a.s .",
    "limit of the reversed iterates , and the distribution function @xmath46 of @xmath0 satisfies @xmath82 , for any @xmath48 , with @xmath83 , then , similarly , the ifs @xmath84 } , u_i , p_i , i=1, ...",
    ",n \\}$ ] , with @xmath85 , @xmath86 , has the @xmath70-distribution as its unique stationary distribution .",
    "this is the case for absolutely continuous probability distributions @xmath0 if @xmath46 is strictly increasing .    from theorem [ 110622 ]",
    "it follows that any continuous probability distribution on @xmath1 can be approximated by the empirical distribution of a markov chain @xmath87 on @xmath1 generated by an ifsp with trivial `` randomness '' generated by e.g.  by a coin or a dice .",
    "theorem [ 110622 ] may be used to represent a continuous probability measure @xmath0 on @xmath1 by the functions suggested in the theorem .",
    "note that there exist many iterated function systems with probabilities generating the same markov chain , see e.g.  stenflo @xcite , so in particular it follows than an ifsp representation of a continuous probability measure on @xmath1 is not unique .",
    "the given ifsp representation suggested by theorem [ 110622 ] ( for a given @xmath60 ) is good in the sense that the generated markov chain converges quickly to the given equilibrium making it possible to quickly simulate it .",
    "if the suggested ifsp representation can not be described in terms of few parameters then it might make sense to consider an approximate representation by approximating the ifs functions with functions described by few parameters e.g.  by using taylor expansions .    from theorem [ 110622 ]",
    "it follows that if @xmath0 is a continuous probability measure on @xmath88 being the measure - attractor of @xmath89 , with @xmath90 for some @xmath17 , then there exists another ifsp with uniform probabilities having @xmath0 as its measure - attractor .",
    "let @xmath0 be the probability measure with triangular density function @xmath101 then @xmath0 is the unique stationary distribution of the markov chain generated by random iteration with the functions @xmath102 and @xmath103 chosen uniformly at random .",
    "the distribution function for the exponential distribution with expected value @xmath104 , @xmath105 , satisfies @xmath106 , @xmath107 .",
    "a markov chain generated by random iterations with the two maps @xmath108 and @xmath109 defined as in theorem [ 110622 ] has the exponential distribution with expected value @xmath0 as its stationary distribution .",
    "we can construct interesting `` new '' distributions by altering such markov chains in various ways , e.g.  by altering the application of two ifss corresponding to different parameter values .",
    "a result of such a construction is shown in the figure .",
    "the upper figures are histograms of the first 200000 points in simulations of a trajectory of a markov chain generated by random iterations with the two maps @xmath108 and @xmath109 defined as in theorem [ 110622 ] corresponding to the choices @xmath110 in the left hand figure and @xmath111 in the righthand figure respectively .",
    "the lower figures are histograms corresponding to trajectories of markov chains formed by random iterations with the maps @xmath112 , @xmath113 , @xmath114 , @xmath115 and @xmath116 , @xmath117 , @xmath118 , @xmath119 respectively , where in both cases the functions are chosen uniformly at random .",
    "the distributions constructed in the lower figures in the example above are @xmath120variable mixtures of the exponential distributions with expected values @xmath110 , and @xmath111 respectively .",
    "we can , more generally , for any integer @xmath121 , generate @xmath122variable mixtures between continuous distributions .",
    "see barnsley et al . @xcite and @xcite for more on the theory of @xmath122variable sets and measures ."
  ],
  "abstract_text": [
    "<S> for any continuous probability measure @xmath0 on @xmath1 we construct an ifs with probabilities having @xmath0 as its unique measure - attractor . </S>"
  ]
}