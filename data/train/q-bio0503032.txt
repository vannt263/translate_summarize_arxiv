{
  "article_text": [
    "predicting the three - dimensional structure of a protein from its amino acid sequence is an essential step toward the thorough bottom - up understanding of complex biological phenomena .",
    "recently , much progress has been made in developing so - called _ ab initio _ or _ de novo _ structure prediction methods@xcite . in the standard approach to such _",
    "de novo _ structure predictions , a protein is represented as a physical object in three - dimensional ( 3d ) space , and the global minimum of free energy surface is sought with a given force - field or a set of scoring functions . in the minimization process , structural features predicted from the amino acid sequence may be used as restraints to limit the conformational space to be sampled .",
    "such structural features include so - called one - dimensional ( 1d ) structures of proteins .",
    "protein 1d structures are 3d structural features projected onto strings of residue - wise structural assignments along the amino acid sequence@xcite . for example , a string of secondary structures is a 1d structure .",
    "other 1d structures include ( solvent ) accessibilities@xcite , contact numbers@xcite and recently introduced residue - wise contact orders@xcite .",
    "the contact number , also referred to as coordination number or ooi number@xcite , of a residue is the number of contacts that the residue makes with other residues in the native 3d structure , while the residue - wise contact order of a residue is the sum of sequence separations between that residue and contacting residues .",
    "we have recently shown that it is possible to reconstruct the native 3d structure of a protein from a set of three types of native 1d structures , namely secondary structures ( ss ) , contact numbers ( cn ) , and residue - wise contact orders ( rwco)@xcite . therefore , these 1d structures contain rich information regarding the corresponding 3d structure , and their accurate prediction may be very helpful for 3d structure prediction .",
    "in our previous study@xcite , we have developed a simple linear method to predict contact numbers from amino acid sequence . in that method ,",
    "the use of multiple sequence alignment was shown to improve the prediction accuracy , achieving an average correlation coefficient of 0.63 between predicted and observed contact numbers per protein . there , we used amino acid frequency table obtained from the hssp@xcite multiple sequence alignment .    in this paper , we extend the previous method by introducing a new framework called critical random networks ( crns ) , and apply it to the prediction of secondary structure and residue - wise contact order in addition to contact number prediction . in this framework ,",
    "a state vector of a large dimension is associated with each site of a target sequence .",
    "the state vectors are connected via random nearest - neighbor interactions .",
    "the value of the state vectors are determined by solving an equation of state .",
    "then a 1d quantity of each site is predicted as a linear function of the state vector of the site as well as the corresponding local pssm segment .",
    "this approach was inspired by the method of echo state networks ( esns ) which has been recently developed and successfully applied to complex time series analysis@xcite .",
    "unlike esns which treat infinite series of input signals in one direction ( from the past to the future ) , crns treat finite systems incorporating both up- and downstream information at the same time .",
    "also , the so - called echo state property is not imposed to a network , but the system is instead set at a critical point of the network . as the input to crns - based prediction , we employ position - specific scoring matrices ( pssms ) generated by psi - blast@xcite . by the combination of pssms and crns , accurate prediction of ss , cn and rwco",
    "have been achieved .",
    "currently , almost all the accurate methods for one - dimensional structure predictions combine some kind of sophisticated machine - learning approaches such as neural networks and support vector machines with pssms .",
    "the method presented here is no exception .",
    "this trend raises a question as to what extent the machine - learning approaches are effective . in this study , we address this question by comparing the crns - based method with a purely linear method based on pssms .",
    "although not so good as the crns - based method , the linear predictions are of surprisingly high quality .",
    "this result suggests that , although not insignificant , the effect of the machine - learning approaches is relatively of minor importance while the use of pssms is the most significant ingredient in one - dimensional structure prediction .",
    "the problem of how to effectively extract meaningful information from the amino acid sequence beyond that provided by pssms requires yet further studies .",
    "[ [ secondary - structures - ss ] ] secondary structures ( ss ) + + + + + + + + + + + + + + + + + + + + + + + + +    secondary structures were defined by the dssp program@xcite . for three - state ss prediction , the simple encoding scheme was employed .",
    "that is , @xmath2 helices ( @xmath3 ) , @xmath4 strands ( @xmath5 ) , and other structures ( `` coils '' ) defined by dssp were encoded as @xmath3 , @xmath5 , and @xmath6 , respectively . for ss prediction",
    ", we introduce feature variables @xmath7 to represent each type of secondary structures at the @xmath8-th residue position , so that @xmath3 is represented as @xmath9 , @xmath5 as @xmath10 , and @xmath6 as @xmath11 .    [",
    "[ contact - numbers - cn ] ] contact numbers ( cn ) + + + + + + + + + + + + + + + + + + + +    let @xmath12 represent the contact map of a protein .",
    "usually , the contact map is defined so that @xmath13 if the @xmath8-th and @xmath14-th residues are in contact by some definition , or @xmath15 , otherwise . as in our previous study ,",
    "we slightly modify the definition using a sigmoid function .",
    "that is , @xmath16\\}\\ ] ] where @xmath17 is the distance between @xmath18 ( @xmath19 for glycines ) atoms of the @xmath8-th and @xmath14-th residues , @xmath20 is a cutoff distance , and @xmath21 is a sharpness parameter of the sigmoid function which is set to 3@xcite .",
    "the rather generous cutoff length of 12 was shown to optimize the prediction accuracy@xcite .",
    "the use of the sigmoid function enables us to use the contact numbers in molecular dynamics simulations@xcite . using the above definition of the contact map",
    ", the contact number of the @xmath8-th residue of a protein is defined as @xmath22 the feature variable @xmath23 for cn is defined as @xmath24 where @xmath25 is the sequence length of a target protein .",
    "the normalization factor @xmath26 is introduced because we have observed that the contact number averaged over a protein chain is roughly proportional to @xmath26 , and thus division by this value removes the size - dependence of predicted contact numbers .    [ [ residue - wise - contact - orders - rwco ] ] residue - wise contact orders ( rwco ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    rwcos were first introduced in kinjo and nishikawa@xcite . using the same notation as contact numbers ( see above ) , the rwco of the @xmath8-th residue in a protein structure is defined by @xmath27 the feature variable @xmath23 for rwco is defined as @xmath28 where @xmath25 is the sequence length . due to the similar reason as cn , the normalization factor @xmath25 was introduced to remove the size - dependence of the predicted rwcos ( the rwco averaged over a protein chain is roughly proportional to the chain length ) .",
    "the input to the prediction scheme we develop in this paper is a position - specific scoring matrix ( pssm ) of the amino acid sequence of a target protein .",
    "let us denote the pssm by @xmath29 where @xmath25 is the sequence length of the target protein and @xmath30 is a 20-vector containing the scores of 20 types of amino acid residues at the @xmath8-th position : @xmath31 .",
    "when predicting a type of 1d structures , we first predict the feature variable(s ) for that type of 1d structures [ i.e. , @xmath32 , etc . for ss , @xmath33 for cn , and @xmath34 for rwco ] , and then the feature variable is converted to the target 1d structure .",
    "prediction of the feature variable @xmath23 can be considered as a mapping from a given pssm @xmath35 to @xmath23 .",
    "more formally , we are going to establish the functional form of the mapping @xmath36 in @xmath37 where @xmath38 is the predicted value of the feature variable @xmath23 . in our previous paper",
    ", we showed that cn can be predicted to a moderate accuracy by a simple linear regression scheme with a local sequence window@xcite .",
    "accordingly , we assume that the function @xmath36 can be decomposed into linear ( @xmath39 ) and nonlinear ( @xmath40 ) parts : @xmath41 .    the linear part is expressed as @xmath42 where @xmath43 is the half window size of the local pssm segment around the @xmath8-th residue , and @xmath44 are the weights to be trained . to treat n- and c - termini separately , we introduced the `` terminal residue '' as the 21st kind of amino acid residue .",
    "the value of @xmath45 is set to unity if @xmath46 or @xmath47 , or to zero otherwise .",
    "the `` terminal residue '' for the central residue ( @xmath48 ) serves as a bias term and is always set to unity .    to establish the nonlinear part",
    ", we first introduce an @xmath49-dimensional `` state vector '' @xmath50 for the @xmath8-th sequence position where the dimension @xmath49 is a free parameter .",
    "the value of @xmath51 is determined by solving the equation of state which is described in the next subsection . for the moment , let us assume that the equation of state has been solved , and denote the solution by @xmath52 .",
    "the state vector can be considered as a function of the whole pssm @xmath35 ( i.e. , @xmath53 ) , and implicitly incorporates nonlinear and long - range effects .",
    "now , the nonlinear part @xmath40 is expressed as a linear projection of the state vector : @xmath54 where @xmath55 are the weights to be trained .    in summary ,",
    "the prediction scheme is expressed as @xmath56 regarding @xmath57 and @xmath52 as independent variables , eq .",
    "[ eq : pred0 ] reduces to a simple linear regression problem for which the optimal weights @xmath44 and @xmath58 are readily determined by using a least squares method . for cn or rwco predictions , the predicted feature variable can be easily converted to the corresponding 1d quantities by multiplying by @xmath26 or @xmath25 , respectively . for ss prediction ,",
    "the secondary structure @xmath59 of the @xmath8-th residue is given by @xmath60 .",
    "we now describe the equation of state for the system of state vectors .",
    "we denote @xmath25 state vectors along the amino acid sequence by @xmath61 , and define a nonlinear mapping @xmath62 for @xmath63 by @xmath64\\ ] ] where @xmath4 and @xmath2 are positive constants , @xmath65 is an @xmath66 block - diagonal orthogonal random matrix , and @xmath67 is an @xmath68 random matrix ( a unit bias term is assumed in @xmath30 ) . the hyperbolic tangent function ( @xmath69 ) is applied element - wise .",
    "we impose the boundary conditions as @xmath70 . in this equation ,",
    "the term containing @xmath65 represents nearest - neighbor interactions along the sequence .",
    "the amino acid sequence information is taken into account as an external field in the form of @xmath71 .",
    "next we define a mapping @xmath72 by @xmath73 using this mapping @xmath74 , the equation of state is defined as @xmath75 that is , the state vectors are determined as a fixed point of the mapping @xmath74 . more explicitly , eq . [ eq : fixpoint ] can be expressed as @xmath76 , \\label{eq : eos}\\ ] ] for @xmath77 .",
    "that is , the state vector @xmath51 of the site @xmath8 is determined by the interaction with the state vectors of the neighboring sites @xmath78 and @xmath79 as well as with the ` external field ' @xmath30 of the site .",
    "the information of the external field at each site is propagated throughout the whole amino acid sequence via the nearest - neighbor interactions .",
    "therefore , solving eq .",
    "( [ eq : eos ] ) means finding the state vectors that are consistent with the external field as well as the nearest - neighbor interactions , and each state vector in the obtained solution @xmath80 self - consistently embodies the information of the whole amino acid sequence in a mean - field sense .    for @xmath81",
    ", it can be shown that @xmath74 is a contraction mapping in @xmath82 ( with an appropriate norm defined therein ) .",
    "and hence , by the contraction mapping principle@xcite , the mapping @xmath74 has a unique fixed point independently of the strength @xmath2 of the external field .",
    "when @xmath4 is sufficiently smaller than 0.5 , the correlation between two state vectors , say @xmath83 and @xmath84 , is expected to decay exponentially as a function of the sequential separation @xmath85 .",
    "on the other hand , for @xmath86 , the number of the fixed points varies depending on the strength of the external field @xmath2 . in this regime",
    ", we can not reliably solve the equation of state ( eq.[eq : fixpoint ] ) . in this sense ,",
    "@xmath87 can be considered as a critical point of the system @xmath88 . from an analogy with critical phenomena of physical systems@xcite (",
    "note the formal similarity of eq .",
    "[ eq : eos ] with the mean field equation of the ising model ) , the correlation length between state vectors is expected to diverge , or become long when the external field is finite but small .",
    "we call the system defined by eq .",
    "[ eq : eos ] with @xmath87 a critical random network ( crn ) .",
    "the equation of state ( eq . [ eq : eos ] ) is parameterized by two random matrices @xmath65 and @xmath67 , and consequently , so is the predicted feature variables @xmath38 . following a standard technique of statistical learning such as neural networks@xcite",
    ", we may improve the prediction accuracy by averaging @xmath38 obtained by multiple crns with different pairs of @xmath65 and @xmath67 .",
    "this averaging operation reduces the prediction errors due to the random fluctuations in the estimated parameters .",
    "we employ such an ensemble prediction with 10 sets of random matrices @xmath65 and @xmath67 in the following .",
    "the use of a larger number of random matrices for ensemble predictions improved the prediction accuracies slightly , but the difference was insignificant .      here",
    "we describe the value of the free parameters used , and a numerical procedure to solve the equation of state .",
    "the half window size @xmath43 in the linear part of eq .",
    "[ eq : pred0 ] is set to 9 for ss and cn predictions , and to 26 for rwco prediction .",
    "these values are found to be optimal in preliminary studies@xcite . regarding the dimension @xmath49 of the state vector ,",
    "we have found that @xmath89 gives the best result after some experimentation , and this value is used throughout . using the state vector of a large dimension as 2000",
    ", it is expected that various properties of amino acid sequences can be extracted and memorized .",
    "if the dimension is too large , overfitting may occur , but we did not find such a case up to @xmath89 .",
    "therefore , in principle , the state vector dimension could be even larger ( but the computational cost becomes a problem ) .",
    "each element in the @xmath68 random matrix @xmath67 in eq .",
    "[ eq : eos ] is obtained from a uniform distribution in the range [ -1 , 1 ] and the strength parameter @xmath2 is set to 0.01 .",
    "here and in the following , all random numbers were generated by the mersenne twister algorithm@xcite .",
    "the @xmath66 random matrix @xmath65 is obtained in the following manner .",
    "first we generate a random block diagonal matrix @xmath90 whose block sizes are drawn from a uniform distribution of integers 2 to 20 ( both inclusive ) , and the values of the block elements are drawn from the standard gaussian distribution ( zero mean and unit variance ) . by applying singular value decomposition , we have @xmath91 where @xmath35 and @xmath67 are orthogonal matrices and @xmath92 is a diagonal matrix of singular values .",
    "we set @xmath93 which is orthogonal as well as block diagonal .",
    "to solve the equation of state ( eq . [ eq : eos ] ) , we use a simple functional iteration with a gauss - seidel - like updating scheme .",
    "let @xmath94 denote the stage of iteration .",
    "we set the initial value of the state vectors ( with @xmath95 ) as @xmath96.\\label{eq : init_eos}\\ ] ] then , for @xmath63 ( in increasing order of @xmath8 ) , we update the state vectors by @xmath97 .",
    "\\label{eq : feos}\\ ] ] next , we update them in the reverse order .",
    "that is , for @xmath98 ( in decreasing order of @xmath8 ) , @xmath99 .",
    "\\label{eq : beos}\\ ] ] we then set @xmath100 , and iterate eqs .",
    "( [ eq : feos ] ) and ( [ eq : beos ] ) until @xmath101 converges .",
    "the convergence criterion is @xmath102 where @xmath103 denotes the euclidean norm .",
    "convergence is typically achieved within 100 to 200 iterations for one protein .",
    "we use the same set of proteins as used in our preliminary study@xcite . in this set , there are 680 protein domains selected from the astral database@xcite , each of which represents a superfamily from one of all-@xmath2 , all-@xmath4 , @xmath104 , @xmath105 or `` multi - domain '' classes of the scop database ( release 1.65 , december 2003)@xcite .",
    "conversely , each scop superfamily is represented by only one of the protein domains in the data set .",
    "thus , no pair of protein domains in the data set are expected to be homologous to each other . for training the parameters and testing the prediction accuracy , 15-fold cross - validation",
    "is employed .",
    "the set of 680 proteins is randomly divided into two groups : one consisting of 630 proteins ( training set ) , and the other consisting of 50 proteins ( test set ) . for each training",
    "set , the regression parameters @xmath44 and @xmath106 are determined , and using these parameters , the prediction accuracy is evaluated for the corresponding test set . this procedure was repeated for 15 times with different random divisions , leading to 15 pairs of training and test sets . in this way , there is some redundancy in the training and test sets although each pair of these sets share no proteins in common . but",
    "this raises no problem since our objective is to estimate the average accuracy of the predictions .",
    "a similar validation procedure was also employed by petersen et al.@xcite in total , 750 ( @xmath107 ) proteins were tested over which the averages of the measures of accuracy ( see below ) were calculated .",
    "to obtain the position - specific scoring matrix ( pssm ) of a protein , we conducted ten iterations of psi - blast@xcite search against a customized sequence database with the e - value cutoff of 0.0005@xcite .",
    "the sequence database was compiled from the dad database provided by dna data bank of japan@xcite , from which redundancy was removed by the program cd - hit@xcite with 95% identity cutoff .",
    "this database was subsequently filtered by the program pfilt used in the psipred program@xcite .",
    "we use the position - specific scoring matrices ( pssm ) rather than the frequency tables for the prediction .      for assessing the quality of ss predictions , we mainly use @xmath0 and @xmath108 ( the 1999 revision)@xcite .",
    "the @xmath0 measure quantifies the percentage of correctly predicted residues , while the @xmath108 measure evaluates the segment overlaps of secondary structural elements of predicted and native structures .",
    "optionally , we use @xmath109 and @xmath110 ( with @xmath111 being @xmath3 , @xmath5 , or @xmath6 ) and matthews correlation coefficient @xmath112 .",
    "the @xmath109 is defined by the percentage of correctly predicted ss type @xmath111 out of the native ss type @xmath111 , and @xmath110 is defined by the percentage of correctly predicted ss type @xmath111 out of the predicted ss type @xmath111 .    for cn and rwco predictions , we use two measures for evaluating the prediction accuracy .",
    "the first one is the correlation coefficient ( @xmath113 ) between the observed ( @xmath114 ) and predicted ( @xmath115 ) cn or rwco@xcite .",
    "the second is the rms error normalized by the standard deviation of the native cn or rwco ( @xmath116)@xcite . while @xmath113 measures the quality of relative values , @xmath116 measures that of absolute values of the predicted cn or rwco .",
    "note that the measures @xmath0 , @xmath108 , @xmath113 and @xmath116 are defined for a single protein chain . in practice , we average these quantities over the proteins in the test sets to estimate the average accuracy of prediction . on the other hand , per - residue measures , @xmath109 , @xmath110 and @xmath112 ,",
    "were calculated using all the residues in the test data sets , rather than on a per - protein basis .",
    "we examine the prediction accuracies for ss , cn , and rwco in turn .",
    "the main results are summarized in table [ tab : summ ] and figure [ fig : histo ] . finally , in order to examine the effect of nonlinear terms",
    ", we verify the prediction results obtained using only linear terms ( eq . [ eq : lin ] ) .",
    ".[tab : summ]summary of average prediction accuracies . [ cols=\"<,<\",options=\"header \" , ]      the condition of criticality ( @xmath87 in eq .",
    "[ eq : eos ] ) is expected to enhance the extraction of the long - range correlations of an amino acid sequence , thus improving the prediction accuracy . to confirm this point , we tested the method by setting @xmath117 so that the network of state vectors is not at the critical point any more ( otherwise the prediction and validation schemes were the same as above ) .",
    "the prediction accuracies obtained by these non - critical random networks were @xmath118% and @xmath119 for ss , @xmath120 and @xmath121 for cn , and @xmath122 and @xmath123 for rwco .",
    "these values are inferior to those obtained by the critical random networks ( table [ tab : summ ] ) , although slightly better than the purely linear predictions ( table [ tab : lin ] ) .",
    "therefore , compared to the non - critical random networks , the critical random networks can indeed extract more information from amino acid sequence and improve the prediction accuracies .",
    "regarding the framework of 1d structure prediction , the critical random networks are most closely related to bidirectional recurrent neural networks ( brnns)@xcite , in that both can treat a whole amino acid sequence rather than only a local window segment .",
    "the main differences are the following .",
    "first , network weights between input and hidden layers as well as those between hidden units are trained in brnns , whereas the corresponding weights in crns ( random matrices @xmath67 and @xmath65 , respectively , in eq .",
    "[ eq : eos ] ) are fixed .",
    "second , the output layer is nonlinear in brnns but linear in crns .",
    "third , the network components that propagate sequence information from n - terminus to c - terminus are decoupled from those in the opposite direction in brnns , but they are coupled in crns .    regarding the accuracy of ss prediction , brnns@xcite and crns exhibit comparable results of @xmath124 78% .",
    "however , a standard local window - based approach using feed - forward neural networks can also achieve this level of accuracy@xcite .",
    "thus , the crns - based method is not a single best predictor , but may serve as an addition to consensus predictions .",
    "although brnns have been also applied to cn prediction@xcite , contact numbers are predicted as 2-state categorical data ( buried or exposed ) so that the results can not be directly compared .",
    "nevertheless , we can convert crns - based real - value predictions into 2-state predictions . by using the same thresholds for the 2-state discretization as pollastri",
    "et al.@xcite ( i.e. , the average cn for each residue type ) , we obtained @xmath125 75.6% per chain ( 75.1% per residue ) , and matthews correlation coefficient @xmath126 0.503 whereas those obtained by brnns are @xmath125 73.9% ( per residue ) and @xmath126 0.478 . therefore , for 2-state cn prediction , the present method yields more accurate results .",
    "since the present study is the very first attempt to predict rwcos , there are no alternative methods to compare with .",
    "however , the comparison of crns - based methods for ss and cn predictions with other methods suggests that the accuracy of the rwco prediction presented here may be the best possible result using any of the statistical learning methods currently available for 1d structure predictions .      in the present study",
    ", we employed the simplest possible architecture for crns in which different sites are connected via nearest - neighbor interactions .",
    "a number of possibilities exist for the elaboration of the architecture .",
    "for example , we may introduce short - cuts between distant sites to treat non - local interactions more directly .",
    "since the prediction accuracies depend on the structural context of target proteins ( tables [ tab : cnhisto ] and [ tab : rwcohisto ] ) , it may be also useful to include more global features of amino acid sequences such as the bias of amino acid composition or the average of pssm components .",
    "these possibilities are to be pursued in future studies .",
    "we have developed a novel method , crns - based regression , for predicting 1d protein structures from amino acid sequence . when combined with position - specific scoring matrices produced by psi - blast ,",
    "this method yields ss predictions as accurate as the best current predictors , cn predictions far better than previous methods , and rwco predictions significantly correlated with observed values .",
    "we also examined the effect of pssms on prediction accuracy , and showed that most improvement is brought by the use of pssms although the further improvement due to the crns - based method is also significant . in order to achieve a qualitatively yet better predictions , however , it seems necessary to take into account other , more global , information than is provided by pssms .",
    "the authors thank motonori ota for critical comments on an early version of the manuscript , and kentaro tomii for the advice on the use of psi - blast .",
    "most of the computations were carried out at the supercomputing facility of national institute of genetics , japan .",
    "this work was supported in part by a grant - in - aid from the mext , japan .",
    "the source code of the programs for the crns - based prediction as well as the lists of protein domains used in this study are available at ` http://maccl01.genes.nig.ac.jp/~akinjo/crnpred_suppl/ ` .",
    "rost , b. prediction in 1d : secondary structure , membrane helices , and accessibility . in _ structural bioinformatics , _ bourne ,",
    "p.  e. and weissig , h. , editors , chapter  28 , 559587 .",
    "wiley - liss , inc . ,",
    "hoboken , u.s.a . , 2003 .",
    "altschul , s.  f. , madden , t.  l. , schaffer , a.  a. , zhang , j. , zhang , z. , miller , w. , and lipman , d.  l. gapped blast and psi - blast : a new generation of protein database search programs .",
    ", 33893402 , 1997 ."
  ],
  "abstract_text": [
    "<S> prediction of one - dimensional protein structures such as secondary structures and contact numbers is useful for the three - dimensional structure prediction and important for the understanding of sequence - structure relationship . here </S>",
    "<S> we present a new machine - learning method , critical random networks ( crns ) , for predicting one - dimensional structures , and apply it , with position - specific scoring matrices , to the prediction of secondary structures ( ss ) , contact numbers ( cn ) , and residue - wise contact orders ( rwco ) . </S>",
    "<S> the present method achieves , on average , @xmath0 accuracy of 77.8% for ss , correlation coefficients of 0.726 and 0.601 for cn and rwco , respectively . </S>",
    "<S> the accuracy of the ss prediction is comparable to other state - of - the - art methods , and that of the cn prediction is a significant improvement over previous methods . </S>",
    "<S> we give a detailed formulation of critical random networks - based prediction scheme , and examine the context - dependence of prediction accuracies . in order to study the nonlinear and multi - body effects , </S>",
    "<S> we compare the crns - based method with a purely linear method based on position - specific scoring matrices . </S>",
    "<S> although not superior to the crns - based method , the surprisingly good accuracy achieved by the linear method highlights the difficulty in extracting structural features of higher order from amino acid sequence beyond that provided by the position - specific scoring matrices .    * </S>",
    "<S> predicting secondary structures , contact numbers , and residue - wise contact orders of native protein structure from amino acid sequence by critical random networks *    akira r. kinjo@xmath1 and ken nishikawa    _ center for information biology and dna data bank of japan , + national institute of genetics , mishima , 411 - 8540 , japan ; + department of genetics , the graduate university for advanced studies + ( sokendai ) , mishima , 411 - 8540 , japan _    running title : protein structure prediction in 1d .    </S>",
    "<S> @xmath1correspondence to a. r. kinjo . + center for information biology and dna data bank of japan , + national institute of genetics , mishima , shizuoka , 411 - 8540 , japan + tel : + 81 - 55 - 981 - 6859 + fax : + 81 - 55 - 981 - 6889 + e - mail : akinjo@genes.nig.ac.jp    _ key words : _ protein structure prediction , one - dimensional structure , position - specific scoring matrix , critical random network </S>"
  ]
}