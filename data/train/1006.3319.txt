{
  "article_text": [
    "in this paper we consider quasi - linear elliptic partial differential equations over a polygonal / polyhedral domain @xmath0 ( @xmath1 ) of the form @xmath2&= f\\qquad & & \\text{in}\\,\\omega\\\\ u&= 0\\qquad & & \\text{on}\\,\\partial \\omega , \\end{aligned } \\right.\\ ] ] where @xmath3 is a function whose properties will be stated in section  [ s : setting ] below , and @xmath4 is given .",
    "these equations describe stationary conservation laws which frequently arise in problems of mathematical physics  @xcite . for example , in hydrodynamics and gas dynamics ( subsonic and supersonic flows ) , electrostatics , magnetostatics , heat conduction , elasticity and plasticity ( e.g. , plastic torsion of bars ) , etc .",
    "some of these examples are better modeled by variational inequalities ( see  @xcite and the references therein ) , but these fall beyond the scope of this article , which attempts to set a first step towards understanding the convergence and optimality of inexact kaanov - type iterations , in the context of adaptive finite element methods .    for a summary of convergence and optimality results of afem",
    "we refer the reader to the survey  @xcite , and the references therein . we restrict ourselves to those references strictly related to our work .",
    "_ inexact _ adaptive finite element methods have been considered for stokes problem in  @xcite using uzawa s algorithm .",
    "briefly , a richardson iteration is applied to the infinite - dimensional schur complement operator and in each iteration , the elliptic problem is solved up to a decreasing tolerance . in  @xcite linear convergence is proved and in  @xcite the optimality of the method in terms of degrees of freedom is proved , after adding some new refinement steps to the algorithm .    in  @xcite ,",
    "a contraction property is proved for an adaptive algorithm based on drfler s marking strategy  @xcite for nonlinear problems of the type  , using orlicz norms to cope with the very mild assumptions on the nonlinear term @xmath5 .    in this work",
    "we impose stronger assumptions on @xmath5 , which guarantee the convergence of kaanov s iteration  @xcite .",
    "more precisely , we assume that @xmath6 is decreasing with respect to its second variable ( cf .  ) , and fulfills condition   below ; which are the same assumptions stated in  @xcite , where they consider the iteration on a fixed space , either finite- or infinite - dimensional .",
    "our focus is the convergence analysis of the adaptive method that results from performing one mesh adaptation in each iteration of the non - linear solver .",
    "this turns out to be a very realistic and efficient method , based on the sole assumption that a _ linear _ system is exactly solved in each iteration step .",
    "this paper is organized as follows . in section  [",
    "s : setting ] we present the class of specific nonlinear problems that we study , and some of its properties . in section  [ s : adaptive loop ] , we present the inexact adaptive kaanov algorithm and in section  [ s : convergence ] we state and prove the main result of this article , namely the convergence of the discrete solutions produced by the algorithm to the exact solution of the nonlinear problem",
    ". finally , in section  [ s : numerical experiments ] , we present some numerical experiments which illustrate the theory , and explore the practical boundaries of applicability of the algorithm .",
    "let @xmath7 be a bounded polygonal ( @xmath8 ) or polyhedral ( @xmath9 ) domain with lipschitz boundary . a weak formulation of   consists in finding @xmath10 such that @xmath11 where @xmath12 and @xmath13 we require that @xmath5 is locally lipschitz in its first variable , uniformly with respect to its second variable ( cf .   below ) . on the other hand , we assume that @xmath5 is @xmath14 as a function of its second variable and there exist positive constants @xmath15 and @xmath16 such that @xmath17 where @xmath18 denotes the partial derivative of @xmath5 with respect to its second variable . the last condition is related to the well - posedness of problem   as we will show below . also , it is possible to prove that   implies that @xmath19 these same assumptions are stated in  @xcite , where several interesting applied problems are shown to satisfy them .",
    "additionally , it is easy to check that the form @xmath20 is linear and symmetric in its second and third variables .",
    "also , from   it follows that @xmath20 is bounded , @xmath21    if we define @xmath22 as the nonlinear operator given by @xmath23 then problem   is equivalent to the equation @xmath24 where @xmath25 is given .",
    "assumption   implies that @xmath26 is lipschitz and strongly monotone ( see  @xcite ) , i.e. , there exist positive constants @xmath27 and @xmath28 such that @xmath29 and @xmath30 as a consequence of   and  , problem   has a unique solution and is stable  @xcite .",
    "in order to define discrete adaptive approximations to problem   we will consider _ triangulations _ of the domain @xmath31 .",
    "let @xmath32 be an initial conforming triangulation of @xmath31 , that is , a partition of @xmath31 into @xmath33-simplices such that if two elements intersect , they do so at a full vertex / edge / face of both elements .",
    "let @xmath34 denote the set of all conforming triangulations of @xmath31 obtained from @xmath32 by refinement using the bisection procedures presented by stevenson  @xcite .",
    "these coincide ( after some re - labeling ) with the so - called _ newest vertex _",
    "bisection procedure in two dimensions and the bisection procedure of kossaczk in three dimensions  @xcite .    due to the processes of refinement",
    "used , the family @xmath34 is shape regular , i.e. , @xmath35 where @xmath36 is the diameter of @xmath37 , and @xmath38 is the radius of the largest ball contained in it . throughout this article",
    ", we only consider meshes @xmath39 that belong to the family @xmath34 , so the shape regularity of all of them is bounded by the uniform constant @xmath40 which only depends on the initial triangulation @xmath32  @xcite .",
    "also , the diameter of any element @xmath41 is equivalent to the local mesh - size @xmath42 , which in turn defines the global mesh - size @xmath43 .    for the discretization we consider the lagrange finite element spaces consisting of continuous functions vanishing on @xmath44 which are piecewise linear over a mesh @xmath45 , i.e. , @xmath46 we are now in position to state the adaptive loop to approximate the solution @xmath47 of the problem  .",
    "we now explain each module of the last algorithm in detail .    *",
    "the module . * : :    given the conforming triangulation @xmath48 of    @xmath31 , and the solution @xmath49 from the    previous iteration , the module outputs the solution    @xmath50 of    the _ linear _ problem    @xmath51    notice that while requires the solution of a linear system , the usual discretization of   in @xmath52 consists in finding @xmath53 such that @xmath54 which is nonlinear .",
    "we propose here to make only one step of a fixed point iterative method to solve the nonlinear problem , and proceed to the mesh adaptation , whereas the usual approach would be to approximate the discrete nonlinear problem up to a very fine accuracy ( pretending to have it exactly solved ) before proceeding to mesh adaptation  @xcite .",
    "each iteration of the adaptive loop is thus much cheaper in our approach .",
    "our theory guarantees convergence of this algorithm , and the numerical experiments of section  [ s : numerical experiments ] show that the convergence is quasi - optimal , although the latter is not yet rigorously proved .",
    "let us consider problem   ( resp .",
    "problem   with @xmath55 fixed ) .",
    "we denote the space @xmath56 ( resp .",
    "@xmath52 ) by @xmath57 , and the solution @xmath47 ( resp .",
    "@xmath58 ) by @xmath59 . given an initial approximation @xmath60 of the solution @xmath59 , we consider the sequence @xmath61 where @xmath62 is the solution of the _ linear _ problem @xmath63    this is known as kaanov s method , and it follows  @xcite that the sequence @xmath61 converges to the solution @xmath59 , provided @xmath64 for all @xmath65 and @xmath66 .",
    "notice that our algorithm consists in performing _ only one _ step of kaanov iteration in each step of the adaptive loop .",
    "* the module . * : :    given @xmath48 , @xmath49 and the    corresponding output @xmath58 of , the module computes and    outputs the local error estimators    @xmath67 given by    @xmath68    for all @xmath69 .",
    "here @xmath70    denotes the _ element residual _ given by    @xmath71-f,\\qquad\\forall\\,t\\in{\\mathcal t}_k,\\ ] ]    and @xmath72 denotes the _ jump residual _ given by    @xmath73,\\ ] ]    for each interior side @xmath74 , and    @xmath75 , if @xmath74 is a side lying    on the boundary of @xmath31 . here , @xmath37 and    @xmath76 denote the elements of @xmath48    sharing @xmath74 , and @xmath77 ,    @xmath78 are the outward unit normals of    @xmath37 , @xmath76 on @xmath74 , respectively .",
    "the squared sum of the a posteriori error estimators is an upper bound for the _ residual _ @xmath79 of @xmath58 which is defined as @xmath80 for @xmath81 .",
    "in fact , integrating by parts on each @xmath69 we have that @xmath82 and since @xmath83 for @xmath84 , using   and interpolation estimates , we arrive at the following upper bound : to indicate that @xmath85 with @xmath86 a constant depending on the data of the problem and possibly on shape regularity @xmath40 of the meshes .",
    "] @xmath87 is the union of @xmath37 and its neighbors in @xmath48 .",
    "the next result is some kind of _ stability _ result for the estimators , which is a property somewhat weaker than the usual _ efficiency _ , but sufficient to guarantee convergence of our adaptive algorithm ( see also  @xcite ) . in order to prove it , we assume that @xmath5 is locally lipschitz in its first variable , uniformly with respect to its second variable , as we mentioned before .",
    "more precisely , we assume that there exists a constant @xmath88 such that @xmath89 .",
    "[ p : estabilidad kakanov ] let @xmath90 be the sequence of discrete solutions computed with the adaptive algorithm . then , the local error estimators given by   are stable .",
    "more precisely , there holds @xmath91 for all @xmath55 .",
    "let @xmath90 be the sequence computed with the adaptive algorithm .",
    "let @xmath55 and @xmath69 be fixed . on the one hand , using that @xmath92 is linear , and thus @xmath93 inside @xmath37 , we have that @xmath94-f } \\right\\|_{t } }   \\\\ & \\le { \\left\\| { \\nabla \\big[\\alpha(\\cdot,|\\nabla u_{k-1}|^2)\\big]\\cdot\\nabla u_k } \\right\\|_{t}}+{\\left\\| { f } \\right\\|_{t}}.\\end{aligned}\\ ] ] since @xmath5 is locally lipschitz in its first variable ( cf .  )",
    ", it follows that if @xmath95 ( constant over @xmath37 ) , @xmath96 and thus , @xmath97    on the other hand , if @xmath74 is a side of @xmath48 shared by the elements @xmath98 , @xmath99 where we have used   and a scaled trace theorem .",
    "therefore , @xmath100 which completes the proof .    * the module . * : :    based on the local error indicators , the module selects a subset    @xmath101 of @xmath48 , using    any of the so - called _ reasonable _ marking strategies , such as the    _ maximum strategy _ , the _ equidistribution strategy _ , or _",
    "drfler s    strategy",
    "_  @xcite .",
    "more precisely , we only require that the set of    marked elements @xmath101 has at least one element    of @xmath48 holding the largest local estimator .",
    "that is , there exists an element    @xmath102 such that    @xmath103 this    is what practitioners usually do in order to maximize the error    reduction with a minimum computational effort . *",
    "the module . *",
    ": :    finally , the module takes the mesh @xmath48 and    the subset @xmath104 as    inputs . by using the bisection rule described by stevenson in  @xcite ,    this module refines ( bisects ) each element in    @xmath101 at least @xmath105 times ( where    @xmath106 is fixed ) , in order to obtain a new conforming    triangulation @xmath107 of    @xmath31 , which is a refinement of    @xmath48 and the output of this module . by    definition , @xmath108 for all    @xmath109 and the family of meshes obtained by    the adaptive algorithm is shape - regular .",
    "finally , it is worth    observing that the resulting spaces are nested , i.e. ,    @xmath110 ; this fact    will be used in the proof of lemma  [ l : sucesivas a cero ] below .",
    "[ r : uk acotada no lineal ] by the coercivity of @xmath20 given by  , and using the definition   of @xmath58 we have that @xmath111 for all @xmath55 , and then @xmath112 therefore , @xmath113 is bounded in @xmath56 .",
    "in this section we prove the convergence of the sequence computed with the adaptive algorithm described in the previous section .",
    "we combine the ideas of the proof of convergence of adaptive algorithms for linear problems given in  @xcite and  @xcite with new techniques needed to overcome the difficulties arisen by the nonlinear nature of the problem treated in this paper , adapting some ideas from  @xcite .    as a first step to prove the convergence of the @xmath113 to the exact solution @xmath47",
    ", we prove that @xmath114 , as @xmath115 tends to infinity , for which we need the following auxiliary lemma .    from now on",
    "we assume that @xmath116    [ l : key property ] let us assume that @xmath117 is a monotone decreasing function for all @xmath118 , i.e. ,   holds .",
    "then @xmath119 where @xmath120 .",
    "let @xmath121 .",
    "then , a change of variables in the integral defining @xmath122 yields @xmath123 since @xmath117 is a decreasing function for all @xmath118 , @xmath124 and the assertion of the lemma follows .",
    "[ l : sucesivas a cero ] let @xmath113 denote the sequence of discrete solutions computed with the adaptive algorithm .",
    "then , @xmath125    let @xmath113 be the sequence obtained with the adaptive algorithm . since @xmath20 is coercive ( cf .  ) , and linear and symmetric in its second and third variables , we have that @xmath126 from  , since @xmath127 , it follows that @xmath128 and thus @xmath129 replacing this equality in   and taking into account lemma  [ l : key property ] we obtain @xmath130 where @xmath131 , and therefore , @xmath132 is a monotone decreasing sequence .",
    "on the other hand , @xmath132 is bounded below since @xmath133    finally , from the last two assertions it follows that @xmath132 is convergent .",
    "considering  , we conclude the proof of this lemma .",
    "we show now that the sequence obtained with the adaptive algorithm is convergent , and more precisely , that it converges to a function in the limiting space @xmath134 .",
    "note that @xmath135 is a hilbert space with the inner product inherited from @xmath56 .",
    "[ t : convergencia a un limite ] let @xmath113 be the sequence obtained with the adaptive algorithm .",
    "let @xmath136 be the only solution to @xmath137 then @xmath138    notice that   always has a solution because   and   hold on @xmath135 , which is itself a hilbert space .",
    "let @xmath113 be the sequence obtained with the adaptive algorithm .",
    "let @xmath136 denote the solution of   and @xmath139 be the orthogonal projection onto @xmath140 . since @xmath26 is strongly monotone ( cf .  ) , using   and   we have that @xmath141 for all @xmath142 , where in the last inequality we have used  . from remark  [ r : uk acotada",
    "no lineal ] it follows that @xmath113 is bounded in @xmath56 , and using lemma  [ l : sucesivas a cero ] , together with the fact that the spaces @xmath143 are nested and @xmath144 is dense in @xmath135 , we conclude that @xmath145 in @xmath56 .    in order to show that the limiting function @xmath146 is , in fact , the solution of the problem   and thereby conclude that the adaptive sequence converges to the solution of this problem , we establish first two auxiliary results ( see lemma  [",
    "l : marcados tienden a cero ] and theorem  [ t : convergencia debil del residuo ] ) .",
    "we need the following    [ d : splitting ] given any sequence of meshes @xmath147 , with @xmath107 a refinement of @xmath48 , for each @xmath148 , we define @xmath149 and @xmath150 in words , @xmath151 is the subset of the elements of @xmath48 which are never refined in the adaptive process , and @xmath152 consists of the elements which are eventually refined .",
    "it can be proved  @xcite that if @xmath153 denotes the characteristic function of @xmath154 , then @xmath155 where @xmath156 denotes the piecewise constant mesh - size function satisfying @xmath157 , for all @xmath69 . since the error estimators are stable ( cf .",
    "proposition  [ p : estabilidad kakanov ] ) , using the convergence proved in the last theorem and   we can establish the following    [ l : marcados tienden a cero ] let @xmath158 be the sequence of local error estimators computed with the adaptive algorithm , and let @xmath159 be the sequence of subsets of marked elements over each mesh .",
    "then , @xmath160    let @xmath158 and @xmath159 be as in the assumptions . for each @xmath142 , we select @xmath161 such that @xmath162 . using proposition  [ p : estabilidad kakanov ]",
    "we have that @xmath163 where @xmath136 is the solution of  . on the one hand , the first term in the right hand side of   tends to zero due to theorem  [ t : convergencia a un limite ] . on the other hand ,",
    "since @xmath164 , from   it follows that @xmath165 and the last two terms in the right hand side of   also tend to zero .    using the upper bound  , the stability of the estimators ( proposition  [ p : estabilidad kakanov ] ) , the facts that @xmath113 is bounded ( cf .",
    "remark  [ r : uk acotada no lineal ] ) and the marking strategy is reasonable ( cf .  ) , and lemma  [ l : marcados tienden a cero ] , we now prove the following important result .    [",
    "t : convergencia debil del residuo ] if @xmath113 denotes the sequence of discrete solutions computed with the adaptive algorithm , then @xmath166    we prove first the result for @xmath167 , and then extend it to @xmath56 by density .",
    "let @xmath168 and @xmath169 . by definition",
    "[ d : splitting ] we have that @xmath170 .",
    "let @xmath171 be the lagrange s interpolant of @xmath172 .",
    "since @xmath173 , using  , and cauchy - schwartz s inequality we have that @xmath174 where , for any @xmath175 we hereafter denote @xmath176 by @xmath177 .",
    "taking into account proposition  [ p : estabilidad kakanov ] and the boundedness of the discrete solutions ( cf .",
    "remark  [ r : uk acotada no lineal ] ) we have that @xmath178 , and therefore , @xmath179 due to interpolation estimates .    in order to prove that @xmath180 as @xmath181 we now let @xmath182 be arbitrary .",
    "due to  , there exists @xmath168 such that @xmath183 on the other hand , since @xmath170 and the marking strategy is reasonable ( cf .  )",
    ", @xmath184 now , by lemma  [ l : marcados tienden a cero ] , we can select @xmath185 such that @xmath186 , for all @xmath187 .    summarizing",
    ", we have proved that @xmath188 finally , since @xmath189 is dense in @xmath56 , this limit is also zero for all @xmath81 .    as a consequence of theorem  [ t : convergencia debil del residuo ] we now prove that @xmath146 is the solution of problem  .",
    "[ t : u_infty es solucion inexacto ] if @xmath146 denotes the solution of  , then @xmath146 is the solution of problem  , i.e. , @xmath190    let @xmath146 be the solution of  .",
    "if @xmath81 , and @xmath113 denotes the sequence of discrete solutions computed with the adaptive algorithm , then @xmath191 where we have used that @xmath26 is lipschitz ( cf .  ) and @xmath20 is bounded ( cf .  ) . using theorem  [ t :",
    "convergencia a un limite ] , lemma  [ l : sucesivas a cero ] and theorem  [ t : convergencia debil del residuo ] it follows that the right - hand side in the last inequality tends to zero as @xmath115 tends to infinity .    as an immediate consequence of theorems  [ t : convergencia a un limite ] and  [ t : u_infty es solucion inexacto ] we finally obtain the main result of this article .",
    "[ t : main ] let @xmath113 denote the sequence of discrete solutions computed with the adaptive algorithm .",
    "if @xmath6 satisfies assumptions   and  , then @xmath113 converges to the solution @xmath47 of problem  .",
    "we conclude this section with a couple of remarks .",
    "the problem given by   is a particular case of the more general problem : @xmath192&= f\\qquad & & \\text{in}\\,\\omega\\\\ u&= 0\\qquad & & \\text{on}\\,\\partial \\omega , \\end{aligned } \\right.\\ ] ] where @xmath3 and @xmath4 satisfy the properties assumed in the previous sections , and @xmath193 is symmetric for all @xmath65 , and uniformly positive definite , i.e. , there exist constants @xmath194 such that @xmath195 if @xmath196 is piecewise lipschitz over an initial conforming mesh @xmath32 of @xmath31 , i.e. , there exists @xmath197 such that @xmath198 then the convergence results previously presented also hold for this problem .",
    "[ r : polynomial degree ] we have assumed the use of _ linear _ finite elements for the discretization ( see  ) .",
    "it is important to notice that the only place where we used this is in proposition  [ p : estabilidad kakanov ] .",
    "the rest of the steps of the proof hold regardless of the degree of the finite element space .",
    "the use of linear finite elements is customary in nonlinear problems , because they greatly simplify the analysis .",
    "the numerical experiments of the next section show a competitive performance of the adaptive method for any tested polynomial degree ( up to four ) .",
    "we conclude this article reporting on the behavior of the adaptive algorithm for some particular nonlinear problems . in the first subsection we study the convergence rate in terms of degrees of freedom for an exact solution and different functions @xmath6 . in the second subsection",
    "we show the performance of the algorithm when approximating an unknown solution of a prescribed curvature equation .",
    "let us consider the problem @xmath199&= f & & \\qquad \\text{in}\\,\\omega\\\\ u&= g & & \\qquad\\text{on}\\,\\partial \\omega , \\end{aligned } \\right.\\ ] ] where @xmath200 is the @xmath201-shaped domain given in figure  [ f : solucion ] .",
    "in the following examples , in order to study experimentally the behavior of the adaptive algorithm , we consider   with different choices of the function @xmath5 , defining @xmath202 and @xmath203 in each case so that the solution of the problem is the function @xmath47 depicted in figure  [ f : solucion ] , given in polar coordinates by @xmath204     where the problem   is posed and the function @xmath47 which is the solution of the problem in each example.,title=\"fig : \" ]   where the problem   is posed and the function @xmath47 which is the solution of the problem in each example.,title=\"fig : \" ]      we implemented the adaptive algorithm using the finite element toolbox alberta  @xcite .",
    "we iterated the algorithm until the global error estimator was below @xmath207 or the number of degrees of freedom exceeded @xmath208 .",
    "we tested the limits of our theory by trying with some functions @xmath5 which did not satisfy all the assumptions of the theoretical results above .",
    "[ ex : todo_ok ] as a first example , in order to study experimentally the rate of convergence of the adaptive algorithm , we consider @xmath209 which satisfies the hypotheses to guarantee the convergence ( see figure  [ f : todo_ok ] ) , i.e. , @xmath5 is a @xmath210-function , and there exist positive constant @xmath15 and @xmath16 such that @xmath211 and @xmath212    , of example  [ ex : todo_ok ] satisfies the properties we require to guarantee the convergence.,title=\"fig : \" ] , of example  [ ex : todo_ok ] satisfies the properties we require to guarantee the convergence.,title=\"fig : \" ]    in figure  [ f : todo_ok_error ] we plot the @xmath213-error versus the number of degrees of freedom ( dofs ) , for finite elements of degree @xmath214 . in this case , the rate of the convergence is optimal for adaptive strategies , that is , @xmath215 . for global refinement ,",
    "the observed order of convergence is @xmath216 for all tested polynomial degrees , due to the fact that the solution @xmath47 belongs to @xmath217 , for all @xmath218 , and does not belong to @xmath219 .",
    "note that , although the theory only guarantees the plain convergence for linear elements ( cf .",
    "theorem  [ t : main ] ) , the numerical results suggest that the method works for any polynomial degree ( see remark  [ r : polynomial degree ] ) , and the convergence rate is optimal .    .",
    "we present the @xmath213-error between the exact solution and discrete solutions , versus the number of degrees of freedom ( dofs ) used to represent each of them .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , but not for global refinement , due to the fact that the solution @xmath47 is not sufficiently smooth . in this case",
    ", @xmath220 satisfies all the properties established to guarantee the convergence with linear finite elements .",
    "the numerical experiments suggest that the method converges with optimal rate for any polynomial degree.,title=\"fig : \" ] .",
    "we present the @xmath213-error between the exact solution and discrete solutions , versus the number of degrees of freedom ( dofs ) used to represent each of them .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , but not for global refinement , due to the fact that the solution @xmath47 is not sufficiently smooth . in this case",
    ", @xmath220 satisfies all the properties established to guarantee the convergence with linear finite elements .",
    "the numerical experiments suggest that the method converges with optimal rate for any polynomial degree.,title=\"fig : \" ]    .",
    "we present the @xmath213-error between the exact solution and discrete solutions , versus the number of degrees of freedom ( dofs ) used to represent each of them .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , but not for global refinement , due to the fact that the solution @xmath47 is not sufficiently smooth . in this case",
    ", @xmath220 satisfies all the properties established to guarantee the convergence with linear finite elements .",
    "the numerical experiments suggest that the method converges with optimal rate for any polynomial degree.,title=\"fig : \" ] .",
    "we present the @xmath213-error between the exact solution and discrete solutions , versus the number of degrees of freedom ( dofs ) used to represent each of them .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , but not for global refinement , due to the fact that the solution @xmath47 is not sufficiently smooth . in this case",
    ", @xmath220 satisfies all the properties established to guarantee the convergence with linear finite elements .",
    "the numerical experiments suggest that the method converges with optimal rate for any polynomial degree.,title=\"fig : \" ]    [ ex : betasegundabad ] we consider the function @xmath221 which is monotone decreasing , i.e. , satisfies  , but not  , as it is shown in figure  [ f : betasegundabad ] .",
    "since   guarantees the well - posedness of problem   ( uniqueness and stability ) , we could be facing an example with multiple solutions .      in figure",
    "[ f : betasegundabad_error ] we plot the @xmath213-error versus the number degrees of freedom , for different polynomial degrees . for @xmath223 and @xmath224 the algorithm stopped with an estimator below the desired tolerance @xmath207 , although the error is around @xmath225 in all cases . on the other hand , as we can see in figure  [ f : betasegundabad_estimador ] , the global error estimator decreases with optimal rate for the adaptive strategies , indicating that the adaptive algorithm may be converging to another solution of the nonlinear problem , different from the one given by  .    .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we observe that the method does not converge , but the error stagnates around @xmath225 .",
    "since @xmath226 does not satisfy the condition which guarantees uniqueness of solutions , and based on the fact that the a posteriori error estimator does tend to zero ( see figure  [ f : betasegundabad_estimador ] ) we conclude that the method converges to _ another solution _ of the same problem , different from the one given by  .",
    ", title=\"fig : \" ] .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we observe that the method does not converge , but the error stagnates around @xmath225 .",
    "since @xmath226 does not satisfy the condition which guarantees uniqueness of solutions , and based on the fact that the a posteriori error estimator does tend to zero ( see figure  [ f : betasegundabad_estimador ] ) we conclude that the method converges to _ another solution _ of the same problem , different from the one given by  .",
    ", title=\"fig : \" ]    .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we observe that the method does not converge , but the error stagnates around @xmath225 .",
    "since @xmath226 does not satisfy the condition which guarantees uniqueness of solutions , and based on the fact that the a posteriori error estimator does tend to zero ( see figure  [ f : betasegundabad_estimador ] ) we conclude that the method converges to _ another solution _ of the same problem , different from the one given by  .",
    ", title=\"fig : \" ] .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we observe that the method does not converge , but the error stagnates around @xmath225 .",
    "since @xmath226 does not satisfy the condition which guarantees uniqueness of solutions , and based on the fact that the a posteriori error estimator does tend to zero ( see figure  [ f : betasegundabad_estimador ] ) we conclude that the method converges to _ another solution _ of the same problem , different from the one given by  .",
    ", title=\"fig : \" ]    based on this remark , it seems that the adaptive algorithm converges to a solution @xmath227 such that @xmath228 .",
    "we recall that @xmath5 does not satisfy the condition   which guarantees the uniqueness of solutions .    .",
    "we present the global error estimator @xmath229 versus dofs used to represent each discrete solution .",
    "we note that for the adaptive strategies the global error estimator decreases with the optimal rate for the @xmath230-error , although the error does not tend to zero ( see figure  [ f : betasegundabad_error ] ) . in this case , @xmath226 does not satisfy the condition which guarantees uniqueness of solutions .",
    "it seems that the method converges to _ another solution _ of the problem.,title=\"fig : \" ] .",
    "we present the global error estimator @xmath229 versus dofs used to represent each discrete solution .",
    "we note that for the adaptive strategies the global error estimator decreases with the optimal rate for the @xmath230-error , although the error does not tend to zero ( see figure  [ f : betasegundabad_error ] ) . in this case , @xmath226 does not satisfy the condition which guarantees uniqueness of solutions .",
    "it seems that the method converges to _ another solution _ of the problem.,title=\"fig : \" ]    .",
    "we present the global error estimator @xmath229 versus dofs used to represent each discrete solution .",
    "we note that for the adaptive strategies the global error estimator decreases with the optimal rate for the @xmath230-error , although the error does not tend to zero ( see figure  [ f : betasegundabad_error ] ) . in this case , @xmath226 does not satisfy the condition which guarantees uniqueness of solutions .",
    "it seems that the method converges to _ another solution _ of the problem.,title=\"fig : \" ] .",
    "we present the global error estimator @xmath229 versus dofs used to represent each discrete solution .",
    "we note that for the adaptive strategies the global error estimator decreases with the optimal rate for the @xmath230-error , although the error does not tend to zero ( see figure  [ f : betasegundabad_error ] ) . in this case , @xmath226 does not satisfy the condition which guarantees uniqueness of solutions .",
    "it seems that the method converges to _ another solution _ of the problem.,title=\"fig : \" ]        in figure  [ f : creciente_error ] we plot @xmath213-error versus the number of degrees of freedom , for finite elements of degrees @xmath232 . note that in this case the optimal convergence rate @xmath233 is still observed for the adaptive algorithm .",
    "this is an indication that the assumption   about @xmath5 being monotone decreasing can be superfluous , and only an artificial requirement for the presented proof ( see lemma  [ l : key property ] ) . a more detailed study about this hypothesis is subject of future research , and beyond the scope of this article .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , although the function @xmath234 is not monotone decreasing .",
    "this could mean that this hypothesis is not necessary for the convergence of the adaptive algorithm , which performs better than expected by our theory .",
    ", title=\"fig : \" ] .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , although the function @xmath234 is not monotone decreasing .",
    "this could mean that this hypothesis is not necessary for the convergence of the adaptive algorithm , which performs better than expected by our theory .",
    ", title=\"fig : \" ]    .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , although the function @xmath234 is not monotone decreasing .",
    "this could mean that this hypothesis is not necessary for the convergence of the adaptive algorithm , which performs better than expected by our theory .",
    ", title=\"fig : \" ] .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , although the function @xmath234 is not monotone decreasing .",
    "this could mean that this hypothesis is not necessary for the convergence of the adaptive algorithm , which performs better than expected by our theory .",
    ", title=\"fig : \" ]    [ ex : derivadainfinita ] finally , we consider an extreme case , with @xmath235 which satisfies   and  , but @xmath236 , as can be observed in figure  [ f : derivadainfinita ] .",
    "this means that @xmath5 is not lipschitz continuous . since we only require that @xmath237 is bounded ( cf .  )",
    ", it still satisfies the assumptions of the convergence theory , and optimality is observed regardless of the fact that @xmath236 .     of example",
    "[ ex : derivadainfinita ] satisfies our assumptions which do not require that @xmath5 is lipschitz continuous.,title=\"fig : \" ]   of example  [ ex : derivadainfinita ] satisfies our assumptions which do not require that @xmath5 is lipschitz continuous.,title=\"fig : \" ]    figure  [ f : derivadainfinita_error ] shows @xmath213-error versus dofs , for polynomial degrees @xmath232 .",
    "we obtain optimal convergence rate @xmath233 for the adaptive strategies .",
    "thus , even when @xmath5 is not lipschitz , the convergence rate is optimal . as a consequence",
    "we conclude that it should not be necessary to make additional assumptions in order to prove optimality .    .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , even though the function @xmath238 has an infinite derivative at @xmath239 .",
    "this example falls inside the theory , and the fact that @xmath5 is not lipschitz continuous does not destroy the optimality of the sequence of discrete solutions .",
    ", title=\"fig : \" ] .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , even though the function @xmath238 has an infinite derivative at @xmath239 .",
    "this example falls inside the theory , and the fact that @xmath5 is not lipschitz continuous does not destroy the optimality of the sequence of discrete solutions .",
    ", title=\"fig : \" ]    .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , even though the function @xmath238 has an infinite derivative at @xmath239 .",
    "this example falls inside the theory , and the fact that @xmath5 is not lipschitz continuous does not destroy the optimality of the sequence of discrete solutions .",
    ", title=\"fig : \" ] .",
    "we present the @xmath213-error between the exact and discrete solutions , versus dofs .",
    "we note that the convergence rate is optimal for the considered adaptive strategies , even though the function @xmath238 has an infinite derivative at @xmath239 .",
    "this example falls inside the theory , and the fact that @xmath5 is not lipschitz continuous does not destroy the optimality of the sequence of discrete solutions .",
    ", title=\"fig : \" ]      in this section we use the adaptive algorithm to approximate a solution to a prescribed mean curvature problem .",
    "we consider the problem @xmath240 & = f \\quad & & \\text{in } \\omega = ( -1,1)\\times(-1,1 )   \\\\ u & = 0 \\quad & & \\text{on } \\partial\\omega , \\end{aligned}\\right.\\ ] ] with @xmath241 the function @xmath242 corresponding to this equation does not fulfill   because @xmath243 as @xmath244 . nevertheless , for many right - hand side functions @xmath202 ,",
    "as the one stated above , the solution belongs to @xmath245 .",
    "this implies that @xmath246 is bounded and @xmath5 could be replaced by a function satisfying   without changing the solution .",
    "this is not needed in practice , but is rather a theoretical tool for proving that the assumptions hold in some sense .",
    "we experimented with several right - hand sides @xmath202 and observed that the method performs robustly whenever @xmath247 .",
    "when the solution has an unbounded gradient , the method produces a sequence with a maximum value increasing to infinity .",
    "this is a drawback of our method , since it can not be used to approximate singular solutions ( not belonging to @xmath245 ) , if @xmath5 does not satisfy  .",
    "it is worth recalling that adaptivity is still a good tool for approximating regular solutions , specially taking into account the fact that in this context _ regularity _ is a concept relative to the polynomial degree .",
    "using adaptivity with higher order finite elements can improve drastically the performance even when the solution is in @xmath248 .",
    "we present in figure  [ f : curvature ] a picture of the solution obtained with our method and several meshes at different iteration steps , for polynomial degrees 1 , 2 and 3 .",
    "it is worth observing the stronger grading obtained for higher polynomial degrees .",
    "this obeys the fact that we mention above , that the singularity of the solution is relative to the polynomial degree of the finite element space .",
    "recall that in practice adaptive methods with polynomials of degree @xmath249 on domains in @xmath250 converge with order dof@xmath251 . in order to obtain this rate with uniform meshes",
    ", we would need the solution to belong to @xmath252 .",
    "adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree . ]",
    "adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ] adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ] adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ]    adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ] adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ] adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ]    adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ] adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ] adaptive meshes obtained when solving the prescribed mean curvature equation   with polynomials of degree 1 ( top ) , 2 ( middle ) , 3 ( bottom ) .",
    "the meshes correspond to iteration count 10 ( left ) , 15 ( middle ) and 20 ( right ) .",
    "it is worth observing the higher grading presented by the meshes corresponding to higher polynomial degree.,title=\"fig : \" ]                      , _ theory of adaptive finite element methods : an introduction _ , in multiscale , nonlinear and adaptive approximation : dedicated to wolfgang dahmen on the occasion of his 60th birthday , r.  devore , a.  kunoth , eds . ,",
    "springer , 2009 .    , _ design of adaptive finite element software _ , lecture notes in computational science and engineering , vol .",
    "42 , springer - verlag , berlin , 2005 , the finite element toolbox alberta , with 1 cd - rom ( unix / linux ) .",
    "eduardo m.  garau : : :    consejo nacional de investigaciones cientficas y tcnicas and    universidad nacional del litoral , argentina ,    egarau@santafe-conicet.gov.ar .    +    partially supported by conicet ( argentina ) through grant pip    112 - 200801 - 02182 , and universidad nacional del litoral through grant    cai+d pi 062 - 312 .",
    "+    address : imal , gemes 3450 .",
    "s3000gln santa fe , argentina .",
    "pedro morin : : :    consejo nacional de investigaciones cientficas y tcnicas and    universidad nacional del litoral , argentina ,    pmorin@santafe-conicet.gov.ar .",
    "+    partially supported by conicet ( argentina ) through grant pip    112 - 200801 - 02182 , and universidad nacional del litoral through grant    cai+d pi 062 - 312 .",
    "+    address : imal , gemes 3450 .",
    "s3000gln santa fe , argentina .",
    "carlos zuppa : : :    universidad nacional de san luis , argentina , zuppa@unsl.edu.ar .    +    partially supported by universidad nacional de san luis through grant    22/f730-fcfmyn .",
    "+    address : departamento de matemtica , facultad de ciencias fsico    matemticas y naturales , universidad nacional de san luis , chacabuco    918 , d5700bwt san luis , argentina ."
  ],
  "abstract_text": [
    "<S> we design an adaptive finite element method to approximate the solutions of quasi - linear elliptic problems . </S>",
    "<S> the algorithm is based on a kaanov iteration and a mesh adaptation step is performed after each linear solve . </S>",
    "<S> the method is thus _ inexact _ because we do not solve the discrete nonlinear problems exactly , but rather perform one iteration of a fixed point method ( kaanov ) , using the approximation of the previous mesh as an initial guess . </S>",
    "<S> the convergence of the method is proved for any _ reasonable _ marking strategy and starting from any initial mesh . </S>",
    "<S> we conclude with some numerical experiments that illustrate the theory .    </S>",
    "<S> _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * keywords : * nonlinear stationary conservation laws ; adaptive finite element methods ; convergence . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ </S>"
  ]
}