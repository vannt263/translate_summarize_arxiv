{
  "article_text": [
    "in the mri , data acquisition is performed by scanning k - space data of objects according to sampling trajectory , and the image reconstruction is processed by conducting the fourier transform .",
    "thus , the quality and the property of reconstructed images depend on k - space sampling patterns such as cartesian , radial , and spiral sampling patterns @xcite .",
    "the radial k - space trajectory has many advantages over cartesian k - space trajectory , although the cartesian k - space trajectory is a conventional sampling pattern .",
    "more specifically , each line measured using the radial k - space trajectory contains both center and periphery frequency information .",
    "since the center frequencies are over - sampled for all the data lines , the center position is averaged when image reconstruction is conducted , so that the motion artifacts from the flow or respiration are reduced with the radial k - space trajectory @xcite .",
    "in addition , the radial k - space trajectory for sub - sampling experiments shows a visually better image quality than the under - sampled cartesian k - space trajectory . this is because the associated aliasing artifacts occur as less - coherent streaking patterns that are much less disturbing than the wrap - around artifact patterns due to the cartesian k - space under - sampling .",
    "since the increase in the scan times is a critical weak point in mr reconstruction , subsampling is required to reduce the scan time .",
    "based on the observation that streaking artiacts are less coherent , many researchers developed under - sampled radial k - space image reconstruction methods using compressed sensing ( cs ) algorithms @xcite . however , one of the main technical limitations of cs methods is the increase in computational complexity due to the iterative reconstruction process , thus necessitating a new method that oviates these limitations .",
    "recently , deep learning approaches have achieved tremendous success in various fields , such as classification @xcite , segmentation @xcite , denoising @xcite , super resolution @xcite , etc . in the field of medical imaging ,",
    "most of the works are focused on image - based diagnostics .",
    "recently , wang et al  @xcite applied deep learning to cs - mri .",
    "they trained the deep neural network from the downsampled reconstruction images to learn a fully sampled reconstruction .",
    "then , they used the deep learning result either as initialization or as a regularization term in classical cs approaches .",
    "deep network architecture using unfolded iterative cs algorithm has been also proposed @xcite . instead of using handcrafted regularizers , the authors in @xcite tried to learn a set of optimal regularzers using a reaction diffusion model .",
    "one of the main advantages of deep learning - based reconstruction is that , once the network is trained , the same network can be used for various images in the test phase so that the actual computation time is determined by the complexity in the test phase and not by the training phase .",
    "in fact , the computational time in the test phase is faster than the cs - based reconstruction by several order of magnitude .",
    "in the x - ray computed tomography ( ct ) area , only a few deep learning architectures attempted to reconstruct , not to diagnose .",
    "et al_@xcite provided the first systematic study of deep cnn for low - dose ct and showed that a deep cnn using directional wavelets is more efficient in removing low - dose related ct noises . unlike these low - dose artifacts from reduced tube currents , the streaking artifacts originated from sparse projection views show globalized artifacts that are difficult to remove using conventional denoising cnns @xcite . jin _",
    "et al_@xcite and han _",
    "et al_@xcite independently proposed multi - scale residual learning networks using u - net @xcite to remove the global streaking artifacts caused by sparse projection views .",
    "recall that the projection slice theorem can convert the radial k - space data into a sinogram data format corresponding to parallel beam x - ray ct @xcite .",
    "accordingly , the radial k - space sampling data can be reconstructed by ct reconstruction method , such as filtered back - projection ( fbp ) .",
    "this does not require re - gridding of k - space data to the cartesian grid , which makes the reconstruction more accurate .",
    "this method is often called as the projection reconstruction ( pr ) in mr literature .",
    "the similarity of the sparse view ct and accelerated radial acquisition in mr lead us to exploit the synergy from the deep learning - based ct reconstruction @xcite instead of mr works @xcite that were mainly developed for the cartesian trajectory .",
    "another important contribution of this paper is the _ domain adaptation _",
    "@xcite , which has never been exploited in @xcite .",
    "note that a large data set is usually required when training a deep neural network .",
    "in contrast to the x - ray ct , the radial trajectory is not widely used in mri , so that a large number of pr data sets are not easily obtained in most mr sites .",
    "although our deep network can be trained with only radial mr data , one of the most important innovations and the focuses of this work is to consider this common scenario using the domain adaptation , which is an active field of research in deep learning @xcite .",
    "specifically , we want to transfer an advanced deep network from ct data set and adapt the network parameter to suit mr reconstruction . in order to demonstrate a comparative advantage of this approach ,",
    "the proposed method is compared with cs algorithms , such as total variation ( tv ) @xcite - based cs @xcite and the pr - focuss @xcite .",
    "if @xmath2 denotes an mr image , then the radial k - space data obtained at the angle @xmath3 are written by @xmath4 where @xmath5 is the parallel - beam projection data at the angle @xmath3 .",
    "this is called the projection slice theorem @xcite .",
    "fig [ fig : ct_mr_relationship ] illustrates how mr radial k - space trajectory can be converted to the sinogram data in the parallel - beam x - ray ct geometry .",
    "this implies that the deep network trained from ct data can be used synergistically in the projection reconstruction mri .",
    "specifically , when the number of radial k - space scan lines in mr or the projection views in ct is not sufficient , similar streaking artifacts occur in the reconstructed image .",
    "for example , fig [ fig : streaking_artifact ] illustrates the fbp reconstruction results from sub - sampling data for ct and mr . figs .",
    "[ fig : streaking_artifact](a)(b ) show reconstruction results of ct and mr from 48 view projection and 45 radial k - space lines , respectively . in fig",
    "[ fig : streaking_artifact](a ) , the first and the second columns show very difference ct images , but similar streaking artifact patterns are observed from those images .",
    "interestingly , the similar phenomenon is also verified from mr images as shown in fig [ fig : streaking_artifact](b ) .",
    "note that the streaking artifacts show similar patterns despite objects difference .",
    "this suggests that the streaking artifacts from different objects may have similar distribution that can be used in designing a deep network .",
    "in particular , we expect that the data manifold of various streaking artifacts is topologically simpler , so learning the streaking artifacts using a neural network is easier than learning the original images .",
    "the complexity of the data manifold from streaking artifacts were thus analyzed in our earlier work @xcite with a topological tool called the _ persistent homology _",
    "@xcite . here",
    ", the betti numbers ( @xmath6 ) represent the number of @xmath7-dimensional holes of a manifold with @xmath8 and @xmath9 as the number of connected components and cycles .",
    "specifically , we can infer the topology of a data manifold by changing the similarity measure between the data points and tracking the changes of betti numbers .",
    "when allowable distance @xmath10 increases , point clouds get together and eventually become a single cluster",
    ". therefore , the point clouds with high diversity will merge slowly and this is presented as a slow decrease in the betti numbers . by tracking @xmath8 and @xmath9 , we have shown that the manifold of the streaking artifacts does not have holes , so the structure is relatively simple @xcite . for more information , see @xcite .",
    "as shown in fig [ fig : transfer_learning ] , the corrupted reconstruction from sub - sampled radial k - space data @xmath11 can be regarded of composition of two parts : an artifact - free image @xmath12 and a streaking artifact image @xmath13 . when the streaking artifact image is accurately estimated from the corrupted image ,",
    "the artifact - free image is extracted by subtracting the streaking artifact from the corrupted image .",
    "therefore , the proposed residual learning architecture is trained to learn streaking artifact patterns from the corrupted images from under - sampled radial k - space data .",
    "as shown in fig [ fig : streaking_artifact ] , the streaking artifacts are displayed as globally distributed artifacts . in order to capture the globally spread streaking artifacts ,",
    "the receptive field of the network should be sufficiently large and the network depth should be increased .",
    "thus , the multi - scale residual learning network is more effective in capturing globally distributed streaking artifacts .",
    "specifically , as illustrated in fig [ fig : transfer_learning ] , in the first half of the proposed network , each stage is followed by a max pooling layer , whereas in the latter half of the network an average unpooling layer is used . in our previous work @xcite , we showed that this results in a enlarged effective receptive field which is more advantageous in removing the streaking artifacts .",
    "scale - by - scale contracting paths are used to concatenate the results from the front part of the network to the latter part of network .",
    "the number of channels for each convolution layer is shown in fig [ fig : transfer_learning ] . note that the number of channels is doubled after each pooling layer .",
    "in addition , the proposed residual network consists of convolution layer , batch normalization @xcite , rectified linear unit ( relu ) @xcite , and the contracting path connection with concatenation @xcite .",
    "specifically , each stage contains four sequential layers composed of convolution with @xmath14 kernels , batch normalization , and relu layers .",
    "finally , the last stage has two sequential layers , and the last layer contains only convolution layer with @xmath15 kernel .      in a deep neural network",
    ", a large number of dataset is usually required .",
    "unfortunately , the cartesian k - space sampling pattern is much more widely used in mri than radial sampling pattern , so it is often hard to collect a numerous dataset for the radial sampling patterns . on the basis of the observation that the streaking artifact patterns are similar regardless of imaging modalities , we therefore perform domain adaptation technique to overcome insufficiency of mr dataset . here",
    ", we formalize the problem of domain adaptation , which is used in this paper to compensate for the insufficient projection reconstruction mr data set . considering that our network is trying to learn the streaking artifacts from the corrupted images",
    ", @xmath16 denotes the fbp reconstruction images from sparse views , and @xmath17 corresponds to the streaking artifact images .",
    "we define a _ domain _ as a pair consisting of a distribution @xmath18 over @xmath16 and a regression function @xmath19 that belongs to the function class @xmath20 .",
    "we consider two domains , a _ source _ domain and a _ target _ domain . in this paper ,",
    "the source domain is ct data , while the target domain is mr data .",
    "we denote by @xmath21 the source domain and @xmath22 the target domain distributions . in the domain adaption scenario ,",
    "we receive two samples : a labeled sample of @xmath7 points from the source domain @xmath23 with @xmath24 drawn i.i.d . according to @xmath21 , and unlabeled sampling drawn i.i.d .",
    "according to the target distribution @xmath22 .",
    "in addition , a small amount of label data from the target domain @xmath25 are available .",
    "this is based on the practical acquisition scenario in which there are ample projection data sets in the ct area , while a small amount of radial mr data set is available . for any distribution @xmath18 , a loss function is defined by a function that minimizes the risk in the target domain @xmath26 ^ 2,\\ ] ] where @xmath27 denotes the network parameters .",
    "then , our goal in domain adaptation is to minimize the loss in target ( i.e. mr ) domain .",
    "using triangular inequality , we have @xmath28 where the so - called @xmath29-discrepancy between two domains is defined by @xcite @xmath30 to minimize the risk in the target domain , we are therefore interested in minimizing the risk in the source domain @xmath31 and the @xmath29-discrepancy between the two domains .",
    "however , the first technical issue is that the associated probability distribution @xmath21 is unknown . to address this issue , the approaches from statistical learning theory @xcite offer the bound of the risk of a learning algorithm with regard to the complexity measure ( eg .",
    "vc dimension , shatter coefficients , etc ) and the empirical risk . specifically , with probability @xmath32 , for every function @xmath33 , we have @xcite @xmath34 where the empirical rademacher complexity @xmath35 is defined to be @xmath36,\\ ] ] where @xmath37 are independent random variables uniformly chosen from @xmath38 . thus , we can obtain the following generalization error bound for the domain adaptation : @xmath39    in general , the rademacher complexity term is determined by the structure of a network . in order to reduce the generalization error of domain adaptation for mr reconstruction",
    ", we should therefore minimize the empirical risk in the source domain and the discrepancy between the two domains .",
    "empirical risk minimization in the source domain is a standard neural network training process . in our case , we use the ct data so that the network can learn the ct streaking artifacts . for the discrepancy minimization , we use the small set of label data from the mr domain @xmath25 so that refined network output follows the target distribution .",
    "specifically , we use an incremental approach , in which the network parameter is iteratively adjusted to change the network outputs @xmath40 to reduce the discrepancy .    specifically , we denote the estimated network parameter at the @xmath41-th iteration of our algorithm @xmath42 : each iteration of our method takes a batch of random input @xmath43 and calculates its corresponding output @xmath44 based on @xmath42 . to make a better approximation of the target distribution @xmath22",
    ", we restrict the path of evolution such that @xmath45 therefore , we should update the network parameter such that @xmath46 where @xmath47 denotes the batch size . using the taylor series expansion",
    ", we have @xmath48 accordingly , we have @xmath49 one step stochastic gradient descent of is then given by @xmath50 where @xmath51 denotes the mr streaking artifacts , and @xmath52 is the @xmath41-th iteration network output for a given mr input data @xmath53 .",
    "this is then backpropagated across all network levels to update the network parameters .",
    "note that there are different approaches for domain adaptation like fine - tuning @xcite , adversary domain adaptation @xcite , etc .",
    "the difference in these approaches is essentially the definition of @xmath54 in and .",
    "the above - described approach using corresponds to the network fine - tuning using the target domain data , but the algorithm could be improved using more advanced domain adaptation techniques .",
    "the proposed network consists of two parts : empirical risk minimization using pre - training in the source domain ( ct ) , and minimization of discrepancy between ct and mr domains using fine - turning in the target domain ( mr ) . in the source domain ,",
    "rebinned fan - beam ct data were used .",
    "the data were acquired from somatom definifion as+ , and somatom definition flash operated in single - source mode , which was manufactured by siemens healthcare , germany .",
    "the x - ray tube potential and mas were 120 kvp and 200 mas , respectively .",
    "specifically , flying focal spot ( ffs ) technique @xcite was applied as data acquisition method . since a rebinning process",
    "is required to reconstruct image with the ffs data , the ffs data was rebinned into fanbeam ct data .    to minimize the discrepancy between ct and mr domains ,",
    "fine - tuning was performed using a few mr data .",
    "the mr data were acquired from the radial spin - echo sequence by 3.0 t mr system manufactured by isol technology in korea .",
    "repetition time ( tr ) and echo time ( te ) are 2000 ms and 90 ms , respectively .",
    "the total number of slices was 20 slices and each slice thickness was 4 mm .",
    "fig [ fig : mr_dataset ] shows the entire mr dataset for both training and test .",
    "as shown in fig [ fig : mr_dataset](a ) , 1 , 3 , 6 , 9 , and 15 slices from 15 slice images were used in the training dataset .",
    "the test was performed by using five distinct slices , as shown in fig [ fig : mr_dataset](b ) .    in order to see the effect of the number of mr data ,",
    "the network parameter was fine - tuned with various number of training dataset from 1 , 3 , 6 , 9 , and 15 .",
    "if only one mr data was used , the yellow box image in fig [ fig : mr_dataset](a ) was used . if 3 , 6 or 9 slices were used for domain adaptation , then the dataset in the @xmath55 , @xmath56 , or @xmath57 rows of fig [ fig : mr_dataset](a ) were used . when using 15 slices in the training dataset , all the dataset in fig [ fig : mr_dataset](a ) were used .",
    "the network training for the proposed deep residual network with domain adaptation consists of two parts .",
    "the first is a pre - training phase using a numerous ct dataset to learn different streaking patterns , and the second is a fine - tuning phase using a small mr dataset that matches a detailed mr structure .",
    "the proposed method performed the pre - training scheme using ct dataset to compensate a deficient feature components since we do not have enough radial k - space mr data .",
    "more specifically , we used a pre - trained deep residual learning network for sparse view ct data as developed by han _",
    "et al_@xcite .",
    "this was developed using 3602 slices of @xmath58 size real patient ct data provided by 2016 aapm low - dose ct grand challenge ( http://www.aapm.org/grandchallenge/lowdosect/ ) .",
    "specifically , the network learns streaking artifacts from 48 and 96 view fan beam projection data .",
    "the network was trained by stochastic gradient descent ( sgd ) .",
    "the regularization parameter was @xmath59 .",
    "the learning rate was set from @xmath60 to @xmath61 , which was gradually reduced at each epoch .",
    "the number of epoch was 150 .",
    "mini - batch data was used using image patch , and the size of image patch was @xmath62 .",
    "the fine - tuning was then performed using a small mr dataset to adjust the difference between the streaking artifact pattern and the detailed mr structure .",
    "the procedure of fine - tuning was exactly the same as ct pre - training with stochastic gradient algorithm using the same parameters .",
    "then , the other slices with very different structures were used as test set for validation .",
    "fig [ fig : fine_tuning](c ) shows a result from the pre - training network when an under - sampled mr image as shown in fig [ fig : fine_tuning](b ) is used as the network input . because the pre - training network is focused on removing ct streaking patterns",
    ", the network recognized the detailed mr structures as the ct streaking artifacts and erroneously removed the mr structures .",
    "moreover , the pre - trained network was trained using a fan - beam ct geometry instead of the parallel beam geometry as in projection reconstruction mr so that the resulting streaking artifacts are statistically different .",
    "therefore , the detail structures of mr were not fully recovered .    to compensate for this phenomenon ,",
    "a domain adaptation using fine - tuning technique was performed on the pre - trained network .",
    "fig [ fig : fine_tuning](d ) shows a reconstructed image from the fine - tuned network with only 1 mr data .",
    "the detailed structure was better conserved in the fine - tuned network than pre - trained network , as compared in fig [ fig : fine_tuning](c ) and fig [ fig : fine_tuning](d ) .",
    "fig [ fig : result_comp_cs1 ] shows reconstruction results from compressed sensing methods using tv and pr - focuss @xcite , and the proposed method fine - tuned with only 1 mr data . an input image ( @xmath16 )",
    "was reconstructed by 36 views projection data .",
    "the results in fig [ fig : result_comp_cs1 ] clearly showed that the proposed method eliminates the streaking artifact and preserves the detailed brain structure for all of the number of views .",
    "the improvement was clearly visible in the difference images in fig [ fig : result_comp_cs1 ] .",
    "the average nmse and computation complexity from five test slices are given in table [ tbl : err_table ] .",
    "the normalized mean square error ( nmse ) was significantly improved .",
    "in addition , a computation complexity is significantly reduced compared to other methods .",
    "the proposed method took only 0.05 seconds while the computational time for tv method was about 24 to 31 seconds , and about 25 to 45 seconds for the pr - focuss depending on the number of views .",
    "the proposed method exceeds the cs algorithms in both nmse and computational time .    in order to verify the importance of the pre - trained network , we conducted various comparative studies .",
    "first , we try to compare the proposed network with the residual network , which is trained only with mr data . for a fair comparison ,",
    "the network parameters for mr - only residual network were equated with those of the proposed network architecture , except for the number of epoch .",
    "the epoch was set at 300 , equal to our proposed domain adaptation network , which has 150 epoch for pre - traing and 150 epoch for fine - tuning .",
    "the convergence plot is shown in fig [ fig : err_plots ] .",
    "note the we only plot after the 150th epoch in the proposed network .",
    "this is because the pre - training with ct dataset was performed before the 150th epoch and the fine - tuning with mr dataset was performed after the 150th epoch .",
    "the mr - only residual networks showed inferior performance .",
    "reconstruction results from 45 view projection data are shown in fig [ fig : result_comp_cs2 ] .",
    "the domain adaptation results in an improved reconstruction , as confirmed in the difference images .",
    "in addition , as shown in table [ tbl : err_table](a ) , if the projection views were more and more sparse , the proposed network significantly outperforms than the mr - only residual network because a few mr dataset were not sufficient to learn the strong streaking artifact pattern caused by severely undersampled view .",
    "in order to check the performance of the fine - tuning based on the number of mr dataset , we have learned the network with a various number of mr dataset such as 1 , 3 , 6 , 9 , or 15 slices .",
    "since the pre - trained network is already optimized for the ct streaking artifact , it is necessary to use fine - tuning to minimize discrepancies between the source domain and the target domain .",
    "if the target domain dataset is sufficient , the discrepancy can be further minimized by the fine - tuning .",
    "fig [ fig : result_comp_cs3 ] shows results for the domain adaptation using 1 , 3 , 6 , and 15 slices .",
    "the more the mr slices were used for the domain adaptation , the better the reconstructed images appear . table [ tbl : err_table](a ) shows the average nmse values along the different number of mr dataset .",
    "as the number of mr dataset increases , the nmse values gradually decreases .",
    "we also had a comparative study for the performance of the mr - only residual network by increasing the number of training data set .",
    "as shown in table [ tbl : err_table](a ) , an increase in the number of mr dataset improves the performance and it is impressive to see that the mr - only residual network trained with more than 6 mr slices outperforms the cs - based approaches .",
    "this again shows the advantages of the the proposed residual learning architecture .",
    "although the mr - only residual network shows apparent improvement along the number of mr dataset , the domain adaptation method has a more stable reconstruction than the mr - only network across different size of training data set .",
    "we developed a novel deep learning approach with domain adaptation to remove streaking artifact patterns resulting from sub - sampled k - space data in mri .",
    "the proposed network was pre - trained using a large number of x - ray ct dataset to overcome the insufficiency of the radial k - space trajectory mr dataset . if there is sufficient number of radial mr data , the deep network with mr data alone showed good reconstruction results .",
    "however , for insufficient training data set , the proposed network showed the best performance when combined with pre - training and fine - tuning .",
    "moreover , the computation speed was extremely faster than the conventional compressed sensing methods because the proposed method does not use projection and back - projection which require heavy computational complexity .",
    "the proposed domain adaptation approach demonstrated the potential for mixing different medical systems when the image artifacts are similar and topologically simple .",
    "the principles of medical imaging systems such as computed tomography ( ct ) , magnetic resonance image ( mri ) , and optical diffraction tomography ( odt ) , are closely related in the fourier space as fourier slice theorem and fourier diffraction theorem . based on the relationship",
    ", the domain adaptation approach can be applied to various modalities to remove various artifacts . by extension",
    ", the proposed network may be universally used to overcome the lack of data set and removing the artifact patterns distributed either locally or globally .",
    "the authors would like to thanks dr .",
    "cynthia macollough , the mayo clinic , the american association of physicists in medicine ( aapm ) , and grant eb01705 and eb01785 from the national institute of biomedical imaging and bioengineering for providing the low - dose ct grand challenge data set .",
    "this work is supported by korea science and engineering foundation , grant number nrf2016r1a2b3008104 ."
  ],
  "abstract_text": [
    "<S> * purpose : * a radial k - space trajectory is one of well - established sampling trajectory in magnetic resonance imaging . </S>",
    "<S> however , the radial k - space trajectory requires a large number of radial lines for high - resolution reconstruction . increasing the number of lines causes longer sampling times , making it more difficult for routine clinical use . </S>",
    "<S> if we reduce the radial lines to reduce the sampling time , streaking artifact patterns are unavoidable . to solve this problem </S>",
    "<S> , we propose a novel deep learning approach to reconstruct high - resolution mr images from the under - sampled k - space data . </S>",
    "<S> + * methods : * the proposed deep network estimates the streaking artifacts . once the streaking artifacts are estimated , an artifact - free image is then obtained by subtracting the estimated streaking artifacts from the distorted image . in the case of the limited number of available radial acquisition data , we apply a domain adaptation scheme , which first pre - trains the network with a large number of x - ray computed tomography ( ct ) data sets and then fine - tunes it with only a few mr data sets . </S>",
    "<S> + * results : * the proposed deep learning method shows better performance than the existing compressed sensing algorithms , such as total variation and pr - focuss . </S>",
    "<S> in addition , the calculation time is several order of magnitude faster than total variation and pr - focuss methods . </S>",
    "<S> + * conclusion : * the proposed deep learning method surpasses the image quality as well as the computation times against the existing compressed sensing algorithms . </S>",
    "<S> in addition , we demonstrate the possibilities of domain - adaptation approach when a limited number of mr data is available .    </S>",
    "<S> keywords : deep learning , convolutional neural network , domain adaptation , projection reconstruction mri , compressed sensing    deep learning with domain adaptation for accelerated projection reconstruction mr    yo seob han@xmath0 , jaejun yoo@xmath0 and jong chul ye@xmath0 +    _ @xmath0dept . of bio and brain engineering + korea advanced institute of science & technology ( kaist ) + 373 - 1 guseong - dong yuseong - gu , daejon 305 - 701 , republic of korea + _     + running head : deep learning for cs mr + journal : magnetic resonance in medicine +    @xmath1 correspondence to : + jong chul ye , ph.d .   </S>",
    "<S> + professor + dept . of bio and brain engineering , kaist + 373 - 1 guseong - dong yuseong - gu , daejon 305 - 701 , korea + email : jong.ye@kaist.ac.kr + tel : 82 - 42 - 350 - 4320 + fax : 82 - 42 - 350 - 4310 +   +   + total word count : approximately 5000 words . </S>"
  ]
}