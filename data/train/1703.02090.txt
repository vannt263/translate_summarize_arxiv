{
  "article_text": [
    "one of the roles of a mobile application platform is to help users avoid unexpected or unwanted use of their personal data  @xcite .",
    "mobile platforms currently use permission systems to regulate access to sensitive resources , relying on user prompts to determine whether a third - party application should be granted or denied access to data and resources .",
    "one critical caveat in this approach , however , is that mobile platforms seek the consent of the user the first time a given application attempts to access a certain data type and then enforce the user s decision for all subsequent cases , regardless of the circumstances surrounding each access .",
    "for example , a user may grant an application access to location data because she is using location - based features , but by doing this , the application can subsequently access location data for behavioral advertising , which may violate the user s preferences .",
    "earlier versions of android ( 5.1 and below ) asked users to make privacy decisions during application installation as an all - or - nothing ultimatum ( ask - on - install ) : either all requested permissions are approved or the application is not installed .",
    "previous research showed that few people read the requested permissions at install - time and even fewer correctly understood them  @xcite .",
    "furthermore , install - time permissions do not present users with the context in which those permission will be exercised , which may cause users to make suboptimal decisions not aligned with their actual preferences . for example , egelman et al .  observed that when an application requests access to location data without providing context , users are just as likely to see this as a signal for desirable location - based features as they are an invasion of privacy  @xcite . asking users to make permission decisions at runtime  at the moment when the permission will actually be used by the application  provides more context ( i.e. , what they were doing at the time that data was requested )  @xcite .",
    "however , due to the high frequency of permission requests , it is not feasible to prompt the user every time data is accessed  @xcite .    in ios and android m ,",
    "the user is now prompted at runtime the first time an application attempts to access one of a set of `` dangerous '' permission types ( e.g. , location , contacts , etc . ) .",
    "this _ ask - on - first - use _ ( aofu ) model is an improvement over ask - on - install ( aoi ) . prompting users the first time an application uses one of the designated permissions gives users a better sense of context : their knowledge of what they were doing when the application first tried to access the data should help them determine whether the request is appropriate . however , wijesekera et al .",
    "showed that aofu fails to meet user expectations over half the time , because it does not account for the varying contexts of future requests  @xcite .",
    "the notion of _ contextual integrity _ suggests that many permission models fail to protect user privacy because they fail to account for the context surrounding data flows  @xcite .",
    "that is , privacy violations occur when sensitive resources are used in ways that defy users expectations .",
    "we posit that more effective permission models must focus on whether resource accesses are likely to defy users expectations in a given context  not simply whether the application was authorized to receive data the first time it asked for it .",
    "thus , the challenge for system designers is to correctly infer when the context surrounding a data request has changed , and whether the new context is likely to be deemed `` appropriate '' or `` inappropriate '' for the given user .",
    "dynamically regulating data access based on the context requires more user involvement to understand users contextual preferences .",
    "if users are asked to make privacy decisions too frequently , or under circumstances that are seen as low - risk , they may become habituated to future , more serious , privacy decisions . on the other hand ,",
    "if users are asked to make too few privacy decisions , they may find that the system has acted against their wishes .",
    "thus , our goal is to automatically determine _ when _ and under _ what _ circumstances to present users with runtime prompts .    to this end , we collected real - world android usage data in order to explore whether we could infer users future privacy decisions based on their past privacy decisions , contextual circumstances surrounding applications data requests , and users behavioral traits .",
    "we conducted a field study where 131 participants used android phones that were instrumented to gather data over an average of 32 days per participant .",
    "also , their phones periodically prompted them to make privacy decisions when applications used sensitive permissions , and we logged their decisions .",
    "overall , participants wanted to block 60% of these requests .",
    "we found that aofu yields 84% accuracy , i.e. , its policy agrees with participants prompted responses 84% of the time .",
    "aoi achieves only 25% accuracy .",
    "we designed new techniques that use machine learning to automatically predict how users would respond to prompts , so that we can avoid prompting them in most cases , thereby reducing user burden .",
    "our classifier uses the user s past decisions in related situations to predict their response to a particular permission prompt .",
    "the classifier outputs a prediction and a confidence score ; if the classifier is sufficiently confident , we use its prediction , otherwise we prompt the user for their decision .",
    "we also incorporate information about the user s behavior in other security and privacy situations to make inferences about their preferences : whether they have a screen lock activated , how often they visit https websites , and so on .",
    "we show that our scheme achieves 95% accuracy ( a @xmath0 reduction in error rate over aofu ) with significantly less user involvement than the _ status quo_.    the specific contributions of our work are the following :    we conducted the first known large - scale study on quantifying the effectiveness of ask - on - first - use permissions .    we show that a significant portion of the studied participants make contextual decisions on permissions using the foreground application and the visibility of the permission - requesting application .",
    "we show how a machine - learned model can incorporate context and better predict users privacy decisions .    to our knowledge",
    ", we are the first to use passively observed traits to infer future privacy decisions on a case - by - case basis at runtime .",
    "there is a large body of work demonstrating that install - time prompts fail because users do not understand or pay attention to them  @xcite .",
    "when using install - time prompts , users often do not understand which permission types correspond to which sensitive resources and are surprised by the ability of background applications to collect information  @xcite .",
    "applications also transmit a large amount of location or other sensitive data to third parties without user consent  @xcite .",
    "when possible risks associated with these requests are revealed to users , their concerns range from annoyance to wanting to seek retribution  @xcite .    to mitigate some of these problems , systems have been developed to track information flows across the android system  @xcite or introduce finer - grained permission control into android  @xcite , but many of these solutions increase user involvement significantly , which can lead to habituation .",
    "additionally , many of these proposals are useful only to the most - motivated or technically savvy users .",
    "for example , many such systems require users to configure complicated control panels , which many are unlikely to do  @xcite .",
    "other approaches involve static analysis in order to better understand how applications _ could _ request information  @xcite , but these say little about how applications _ actually _ use information .",
    "dynamic analysis improves upon this by allowing users to see how often this information is requested in real time  @xcite , but substantial work is likely needed to present that information to average users in a meaningful way .",
    "solutions that require runtime prompts ( or other user interruptions ) need to also minimize user intervention , in order to prevent habituation .",
    "other researchers have developed recommendation systems to recommend applications based on users privacy preferences  @xcite .",
    "systems have also been developed to predict what users would share on mobile social networks  @xcite , which suggests that future systems could potentially infer what information users would be willing to share with third - party applications . by requiring users to self - report privacy preferences ,",
    "clustering algorithms have been used to define user privacy profiles even in the face of diverse preferences  @xcite .",
    "however , researchers have found that the order in which information is requested has an impact on prediction accuracy  @xcite , which could mean that such systems are only likely to be accurate when they examine actual user behavior over time ( rather than relying on one - time self - reports ) .",
    "liu et al .",
    "clustered users by privacy preferences and used ml techniques to predict whether to allow or deny an application s request for sensitive user data  @xcite . however , their dataset was collected from a set of highly privacy - conscious individuals  those choosing to install a permission - control mechanism .",
    "furthermore , the researchers removed `` conflicting '' user decisions , in which a user chose to deny a permission for an application , and then later chose to allow it",
    ". however , these conflicting decisions happen nearly 50% of the time in the real world  @xcite , and accurately reflect the nuances of user privacy preferences ; they are not experimental mistakes , and therefore models need to account for them .",
    "in fact , previous work found that users commonly reassess privacy preferences after usage  @xcite .",
    "liu et al.also expect users to make 10% of permission decisions manually , which , based on field study results from wijesekera et al .",
    ", would result in being prompted every three minutes  @xcite .",
    "this is obviously impractical .",
    "our goal is to design a system that can automatically make decisions on behalf of users , that accurately models their preferences , while also not over - burdening them with repeated requests .",
    "closely related to this work , liu et al .",
    "@xcite performed a field study to measure the effectiveness of a privacy assistant that offers recommendations to users on privacy settings that they could adopt based on each user s privacy profile  the privacy assistant predicts what the user might want based on the inferred privacy profile and static analysis of the third - party application .",
    "while this approach increased user awareness on resource usage , the recommendations are static : they do not consider each application s access to sensitive data on a case - by - case basis .",
    "such a coarse - grained approach goes against previous work suggesting that people do want to vary their decisions based on contextual circumstances  @xcite . a blanket approval or denial of a permission to a given application carries a considerable risk of privacy violations or loss of desired functionality . in contrast",
    ", our work tries to infer the appropriateness of a given request by considering the surrounding contextual cues and how the user has behaved in similar situations in the past , in order to make decisions on a case - by - case basis using dynamic analysis .",
    "their dataset was collected from a set of highly privacy - conscious and considerably tech - savvy individuals , which might limit the generalization of their claims and findings , whereas we conducted a field study on a more representative sample .",
    "nissenbaum s theory of contextual integrity suggests that permission models should focus on information flows that are likely to defy user expectations  @xcite .",
    "there are three main components involved in deciding the appropriateness of a flow  @xcite : the context in which the resource request is made , the role played by the agent requesting the resource ( i.e. , the role played by the application under the current context ) , and the type of resource being accessed .",
    "neither previous nor currently deployed permission models take all three factors into account .",
    "this model could be used to improve permission models by automatically granting access to data when the system determines that it is appropriate , denying access when it is inappropriate , and prompting the user only when a decision can not be made automatically , thereby reducing user burden .    _",
    "access control gadgets _",
    "( acgs ) were proposed as a mechanism to tie sensitive resource access to certain ui elements  @xcite .",
    "authors posit that such an approach will increase user expectations since a significant portion of participants expected a ui interaction before a sensitive resource usage , giving users an implicit mechanism to control access and increasing the awareness on resource usage .",
    "the biggest caveat in this approach is tying a ui interaction to each sensitive resource access is practically impossible due to the high frequency at which these resources are accessed  @xcite , and due to the fact that many legitimate resource accesses occur without user initiation  @xcite .",
    "wijesekera et al .",
    "performed a field study  @xcite to operationalize the notion of `` context , '' so that an operating system can differentiate between appropriate and inappropriate data requests by a single application for a single data type .",
    "they found that users decisions to allow a permission request were significantly correlated with that application s visibility : in this case , the context is using or _ not _ using the requesting application .",
    "they posit visibility of the application could be a strong contextual cue that influences users responses to permission prompts .",
    "they also observed that privacy decisions were highly nuanced , and therefore a one - size - fits - all model is unlikely to be sufficient ; a given information flow may be deemed appropriate by one user and inappropriate by another user .",
    "they recommended applying machine learning in order to infer individual users privacy preferences .    to achieve this",
    ", research is needed to determine what factors affect user privacy decisions and how to use those factors to make privacy decisions on the user s behalf .",
    "while we can not automatically capture everything involved in nissenbaum s notion of context , we can try for the next - best thing : we can try to detect when context has likely changed ( insofar as to decide whether or not a different privacy decision should be made for the same application and data type ) , by seeing whether the circumstances surrounding a data request are similar to previous requests or not .",
    ".felt et al .  proposed granting a select set of 12 permissions at runtime so that users have contextual information to infer why the data might be needed  @xcite .",
    "our instrumentation omits the last two permission types ( internet & write_sync_settings ) and records information about the other 10 .",
    "[ cols= \" < \" , ]"
  ],
  "abstract_text": [
    "<S> current smartphone operating systems regulate application permissions by prompting users on an ask - on - first - use basis . </S>",
    "<S> prior research has shown that this method is ineffective because it fails to account for context : the circumstances under which an application first requests access to data may be vastly different than the circumstances under which it subsequently requests access . </S>",
    "<S> we performed a longitudinal 131-person field study to analyze the contextuality behind user privacy decisions to regulate access to sensitive resources . </S>",
    "<S> we built a classifier to make privacy decisions on the user s behalf by detecting when context has changed and , when necessary , inferring privacy preferences based on the user s past decisions and behavior . </S>",
    "<S> our goal is to automatically grant appropriate resource requests without further user intervention , deny inappropriate requests , and only prompt the user when the system is uncertain of the user s preferences . </S>",
    "<S> we show that our approach can accurately predict users privacy decisions 96.8% of the time , which is a four - fold reduction in error rate compared to current systems . </S>"
  ]
}