{
  "article_text": [
    "reproducible research has received an increasing level of attention throughout the scientific community [ 19 , 22 ] and the public at large [ 25 ] . all steps of the scientific process , from data collection and processing , to analyses , visualizations and conclusions depend ever more on computation and algorithms , _ computational reproducibility _ has received particular attention [ 18 ] .",
    "though in principle this algorithmic dependence should make such research easier to reproduce ",
    "computer codes being both more portable and potentially more precise to exchange and run than experimental methods  in practice this has led to an ever larger and more complex black box that stands between what was actually done and what is described in the literature .",
    "crucial scientific processes such as replicating the results , extending the approach or testing the conclusions in other contexts , or even merely installing the software used by the original researchers can become immensely time - consuming if not impossible .      systems research has long concerned itself with the issues of computational reproducibility and the technologies that can facilitate those objectives [ 6 ] .",
    "docker is a new but already very popular open source tool that combines many of these approaches in a user friendly implementation , including : ( 1 ) performing linux container ( lxc ) based operating system ( os ) level virtualization , ( 2 ) portable deployment of containers across platforms , ( 3 ) component reuse , ( 4 ) sharing , ( 5 ) archiving , and ( 6 ) versioning of container images .",
    "while docker s market success has largely focused on the needs of businesses in deploying web applications and the potential for a lightweight alternative to full virtualization , these features have potentially important implications for systems research in the area of scientific reproducibility . in this paper ,",
    "i seek to set these issues in the context of reproducibility throughout the various domain sciences where computation plays an ever - increasing role , but where researchers are largely unaware of the concerns or technologies involved in making these computations more reproducible , extensible , and portable to other researchers . in so doing , i highlight elements of the docker platform that should be of interest to both computer systems research and domain scientists .",
    "it is worth observing from the outset that the primary barrier to computational reproducibility in many domain sciences has nothing to do with the technological approaches discussed here , but stems rather from a reluctance to publish the code used in generating the results in the first place [ 2 ] . despite extensive evidence to the contrary",
    "[ 14 ] , many researchers and journals continue to assume that summary descriptions or pseudo - code provide a sufficient description of computational methods used in data gathering , processing , simulation , visualization , or analysis . until such code is available in the first place , one can not even begin to encounter the problems that the approaches discussed here set out to solve . as a result",
    ", few domain researchers may be fully aware of the challenges involved in effectively re - using published code .    a lack of requirements or incentives no doubt plays a crucial role in discouraging sharing [ 2 , 24 ] . nevertheless , it is easy to underestimate the significant barriers raised by a lack of familiar , intuitive , and widely adopted tools for addressing the challenges of computational reproducibility .",
    "surveys and case studies find that a lack of time , more than innate opposition to sharing , discourages researchers from providing code [ 7 , 23 ] .      by restricting ourselves to studies of where code has been made available",
    ", i will sidestep for the moment the cultural challenges to reproducibility so that i may focus on the technical ones ; in particular , those challenges for which improved tools and techniques rather than merely norms of behavior can contribute substantially to improved reproducibility .    studies focusing on code that has been made available with scientific publications regularly find the same common issues that pose substantial barriers to reproducing the original results or building on that code [ 4 , 8 , 10 , 16 , 27 ] , which i attempt to summarize as follows .",
    "a recent study by researchers at the university of arizona found that less than 50% of software could even be successfully built or installed [ 4 ] and similar results are seen in an ongoing effort by other researchers to replicate that study [ 27 ] . installing or building software necessary to run the code in question assumes the ability to recreate the computational environment of the original researchers .",
    "differences in numerical evaluation , such as arise in floating point arithmetic or even ambiguities in standardized programming languages ( `` order - of - evaluation '' problems ) can be responsible for differing results between or even within the same computational platform [ 14 ] .",
    "such issues make it difficult to restrict the true dependencies of the code to higher level environments such as that of a given scripting language , independent of the underlying os or even hardware itself .",
    "documentation on how to install and run code associated with published research is another frequent barrier to replication . a study by lapp [ 16 ] found this impairs a researcher s ability to install and build the software necessary , as even small holes in the documentation were found to be major barriers , particularly for `` novices '' [ 8 ]  where novices may be experts in nearby languages but unfamiliar with the package managers and other tools of the language involved .",
    "this same problem is discussed in [ 3 ] .",
    "imprecise documentation goes well beyond issues of the software environment itself : incomplete documentation of parameters involved meant as few as 30% of analyses ( @xmath0 ) using the popular software structure could be reproduced in the study of [ 10 ] .",
    "software dependencies are not static elements , but receive regular updates that may fix bugs , add new features or deprecate old features ( or even entire dependencies themselves ) .",
    "any of these changes can potentially change the results generated by the code . as some of these changes may indeed resolve valid bugs or earlier problems with underlying code",
    ", it will often be insufficient to demonstrate that results can be reproduced when using the original versions , a problem sometimes known as `` code rot .",
    "'' researchers will want to know if the results are robust to the changes .",
    "the case studies in [ 16 ] provide examples of these problems .",
    "technological solutions such as workflow software , virtual machines , continuous integration services , and best practices from software development would address many of the issues frequently frustrating reproducibility .",
    "however , researchers face significant barriers to entry in learning these tools and approaches which are not part of their typical curriculum , or lack incentives commensurate with the effort required [ 7 , 15 ] .",
    "though a wide variety of approaches exists to work around these challenges , few operate on a low enough level to provide a general solution .",
    "[ 3 ] provide an excellent description of this situation :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ in scientific computing the environment was commonly managed via makefiles & unix - y hacks , or alternatively with monolithic software like matlab .",
    "more recently , centralized package management has provided curated tools that work well together .",
    "but as more and more essential functionality is built out across a variety of systems and languages , the value  and also the difficulty  of coordinating multiple tools continues to increase . whether we are producing research results or web services",
    ", it is becoming increasingly essential to set up new languages , libraries , databases , and more .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    there are two dominant approaches to this issue of coordinating multiple tools : workflows and virtual machines ( vms ) .",
    "two dominant paradigms have emerged to address these issues so far : workflow software [ 1 , 13 ] and virtual machines [ 5 , 12 ] .",
    "workflow software provides very elegant technical solutions to the challenges of communication between diverse software tools , capturing provenance in graphically driven interfaces , and handling issues from versioning dependencies to data access .",
    "workflow solutions are often built by well - funded collaborations between domain scientists and computer scientists , and can be very successful in the communities within which they receive substantial adoption .",
    "nonetheless , most workflow systems struggle with relatively low total adoption overall [ 5 , 9 ] .",
    "dudley & butte [ 5 ] give several reasons that such comprehensive workflow systems have not been more successful :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 .",
    "efforts are not rewarded by the current academic research and funding environment ; ( ii ) commercial software vendors tend to protect their markets through proprietary formats and interfaces ; ( iii ) investigators naturally tend to want to ` own ' and control their research tools ; ( iv ) even the most generalized software will not be able to meet the needs of every researcher in a field ; and finally ( v ) the need to derive and publish results as quickly as possible precludes the often slower standards - based development path . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in short , workflow software expects a new approach to computational research .",
    "in contrast , virtual machines ( vms ) offer a more direct approach .",
    "since the computer operating system ( os ) already provides the software layer responsible for coordinating all the different elements running on the computer , the vm approach captures the os and everything running on it whole - cloth . to make this practical , dudley & butte [ 5 ] and howe",
    "[ 12 ] both propose using virtual machine images that will run on the cloud , such as amazon s ec2 system , which is already based upon this kind of virtualization .",
    "critics of the use of vms to support reproducibility highlight that the approach is too much of a black box and thus ill suited for reproducibility [ 28 ] . while the approach sidesteps the need to either install or even document the dependencies , this also makes it more difficult for other researchers to understand , evaluate , or alter those dependencies .",
    "moreover , other research can not easily build on the virtual machine in a consistent and scalable way .",
    "if each study provided it s own virtual machine , any pipeline combining the tools of multiple studies would quickly become impractical or impossible to implement .",
    "the problems highlighted here are not unique to _ academic _ software , but impact software development in general .",
    "while the academic research literature has frequently focused on the development of workflow software dedicated to particular domains , or otherwise to the use of virtual machines , the software development community has recently emphasized a philosophy ( rather than a particular tool ) , known as _ development _ and systems _ operation _ , or more frequently just `` devops . ''",
    "the approach is characterized by scripting , rather than documenting , a description of the necessary dependencies for software to run , usually from the operating system ( os ) on up .",
    "[ 3 ] describe the devops approach along with both its relevance to reproducible research and examples of its use in the academic research context .",
    "they identify the difficulties i have discussed so far in terms of effective documentation :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ documentation for complex software environments is stuck between two opposing demands . to make things easier on novice users , documentation must explain details relevant to factors like different operating systems . alternatively , to save time writing and updating documentation , developers like to abstract over such details .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _    the authors contrast this to the devops approach , where dependency documentation is _ scripted _ :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ a devops approach to `` documenting '' an application might consist of providing brief descriptions of various install paths , along with scripts or `` recipes '' that automate setup . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this elegantly addresses both the demand for simplicity of use ( one executes a script instead of manually managing the environmental setup ) and comprehensiveness of implementation .",
    "clark _ et al . _",
    "[ 3 ] are careful to note that this is not so much a technological shift as a philosophical one :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the primary shift that s required is not one of new tooling , as most developers already have the basic tooling they need .",
    "rather , the needed shift is one of philosophy . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    nevertheless , a growing suite of tools designed explicitly for this purpose have rapidly replaced the use of general purpose tools ( such as makefiles , bash scripts ) to become synonymous with the devops philosophy .",
    "[ 3 ] reviews many of these devops tools , their different roles , and their application in reproducible research .",
    "i focus the remainder of this paper on one of the most recent and rapidly growing among these , called docker , and the role it can play in reproducible research .",
    "docker offers several promising features for reproducibility that go beyond the tools highlighted in [ 3 ] .",
    "nevertheless , my goal in focusing on this technology is not to promote a particular solution , but to anchor the discussion of technical solutions to reproducibility challenges in concrete examples .",
    "docker is an open source project that builds on many long - familiar technologies from operating systems research : lxc containers , virtualization of the os , and a hash - based or git - like versioning and differencing system , among others .",
    "i introduce the most relevant concepts from docker through the context of the four challenges for reproducible research i have discussed above .",
    "a docker based approach works similarly to a virtual machine image in addressing the dependency problem by providing other researchers with a binary image in which all the software has already been installed , configured and tested .",
    "( a machine image can also include all data files necessary for the research , which may simplify the distribution of data . )",
    "a key difference between docker images and other virtual machines is that the docker images share the linux kernel with the host machine . for the end user",
    "the primary consequence of this is that any docker image must be based on a linux system with linux - compatible software , which includes ( r , python , matlab , and most other scientific programming needs ) .",
    "sharing the linux kernel makes docker much more light - weight and higher performing than complete virtual machines  a typical desktop computer could run no more than a few virtual machines at once but would have no trouble running 100 s of docker containers ( a container is simply the term for running instance of an image ) .",
    "this feature has made docker particularly attractive to industry and is largely responsible for the immense popularity of docker . for our purposes",
    "this is a nice bonus , but the chief value to reproducible research lies in other aspects .",
    "though docker images can be created interactively , this leaves little transparent record of what software has been installed and how .",
    "dockerfiles provide a simple script ( similar to a makefile ) that defines exactly how to build up the image , consistent with the devops approach i mentioned previously .    with a syntax that is simpler than other provisioning tools ( _ e.g. _ chef , puppet , ansible ) or continuous integration ( ci ) platforms ( _ e.g. _ travis ci , shippable ci ) ; users need little more than a basic familiarity with shell scripts and a linux distribution software environment ( _ e.g. _ debian - based ` apt - get ` ) to get started writing dockerfiles .",
    "this approach has many advantages :    * while machine images can be very large ( many gigabytes ) , a dockerfile is just a small plain text file that can be easily stored and shared . *",
    "small plain text files are ideally suited for use with a version management system such as ` subversion ` or ` git ` , which can track any changes made to the ` dockerfile ` * the ` dockerfile ` provides a human readable summary of the necessary software dependencies , environmental variables and so forth needed to execute the code .",
    "there is little possibility of the kind of holes or imprecision in such a script that so frequently cause difficulty in manually implemented documentation of dependencies .",
    "this approach also avoids the burden of having to tediously document dependencies at the end of a project , since they are instead documented as they are installed by writing the ` dockerfile ` .",
    "* unlike a ` makefile ` or other script , the ` dockerfile ` includes all software dependencies down to the level of the os , and is built by the docker ` build ` tool , making it very unlikely that the resulting build will differ when being built on different machines .",
    "this is not to say that all builds of a dockerfile are bitwise identical . in particular , builds executed later will install more recent versions of the same software , if available , unless the package managers used are explicitly configured otherwise .",
    "i address this issue in the next section .",
    "* it is possible to add checks and tests following the commands for installing the software environment , which will verify that the setup has been successful .",
    "this can be important in addressing the issue of code - rot which i discuss next .",
    "* it is straightforward for other users to extend or customize the resulting image by editing the script directly .",
    "as i have discussed above , changes to the dependencies , whether they are the result of security fixes , new features , or deprecation of old software , can break otherwise functioning code .",
    "these challenges can be significantly reduced because docker defines the software environment to a particular operating system and suite of libraries , such as the ubuntu or debian distribution .",
    "such distributions use a staged release model with ` stable ` , ` testing ` and ` unstable ` phases subjected to extensive testing to catch such potential problems [ 20 ] , while also providing regular security updates to software within each stage .",
    "nonetheless , this can not completely avoid the challenge of code - rot , particularly when it is necessary to install software that is not ( yet ) available for a given distribution .    to address this concern , one must archive a binary copy of the image used at the time the research was first performed .",
    "docker provides a simple utility to save an image as a portable ` tarball ` file that can be read in by any other docker installation , providing a robust way to run the exact versions of all software involved . by testing both the ` tarball ` archive and the image generated by the latest dockerfile",
    ", docker provides a simple way to confirm whether or not code rot has effected the function of a particular piece of code .    to simplify this process , docker also supports _ automated builds _ through the docker hub ( http://hub.docker.com[hub.docker.com ] ) .",
    "this acts as a kind of continuous integration ( ci ) service that verifies the image builds correctly whenever the dockerfile is updated , particularly if the dockerfile includes checks for the environment .",
    "the hub also provides a convenient distribution service , freely storing the pre - built images , along with their metadata , for download and reuse by others .",
    "the docker hub is a free service and an open source software product so that users can run their own private versions of the hub on their own servers , for instance , if security of the data or the longevity of the public platform is a concern .      a technical solution ,",
    "no matter how elegant , will be of little practical use for reproducible research unless it is both easy to use and adapt to the existing workflow patterns of practicing domain researchers .    though most of the concerns i have discussed so far can be addressed through well - designed workflow software or the use of a devops approach to provisioning virtual machines by scripts , neither approach has seen widespread adoption by domain researchers , who work primarily in a local rather than cloud - based environment using development tools native to their personal operating system . to gain more widespread adoption",
    ", reproducible research technologies must make it easier , not harder , for a researcher to perform the tasks they are already doing ( before considering any additional added benefits ) .",
    "these issues are reflected both during the original research or development phase and in any subsequent reuse .",
    "another researcher may be less likely to build on existing work if it can only be done by using a particular workflow system or monolithic software platform with which they are unfamiliar .",
    "likewise , a user is more likely to make their own computational environment available for reuse if it does not involve a significant added effort in packaging and documenting [ 23 ] .",
    "though docker is not immune to these challenges , it offers a interesting example of a way forward in addressing these fundamental concerns . here",
    "i highlight five of these features in turn :    * local environment * modular reuse * portable environments * public repository for sharing * versioning      perhaps the most important feature of a reproducible research tool is that it be easy to learn and fit relatively seamlessly into existing workflow patterns of domain researchers .",
    "this , more than any other concern , can explain the relatively low uptake of previously proposed solutions .",
    "being a new and unfamiliar tool to most domain scientists , docker is far from immune to the same critique .",
    "nevertheless , docker takes us several key steps towards an approach that can be easily adopted in a research context .",
    "while proponents of virtual machines for reproducible research propose that these machines would be available exclusively as cloud computing environments [ 5 ] , many researchers work _ locally _ , that is , primarily with software that is installed on their laptop or desktop computer , and turning to cloud - based or other remote platforms only for certain collaborative tasks or when the work is mature enough to need increased computational power .",
    "working locally allows a researcher to rely more on the graphic interface tools for tasks such as managing files , text editing , debugging , ides , or interacting with version control systems .",
    "scientific computing on remote machines , by contrast , still relies largely on potentially less familiar text based command line functions for these tasks ( though web based interfaces like rstudio server are rapidly filling this gap ) .",
    "docker can be easily installed on most major platforms ( see https://docs.docker.com/installation[https://docs.docker.com/installation ] ; on systems not already based on the linux kernel , such as mac or windows , this is accomplished through the use of a small virtualbox - based vm running on the host os called ` boot2docker ` ) and run locally .",
    "docker allows a user to link any directory ( such as the working directory for a particular script or project ) to the running docker container .",
    "this allows a user to rely on the familiar tools of the host os for roles such as text editing , file browsing , or version control , while still allowing code execution to occur inside the controlled development environment of the container .",
    "for example , one launches an interactive r console in a container that is linked to our current working directory like so :    run -v :/ -it cboettig / rstudio /usr",
    "/ bin / r    the resulting system behaves almost identically ) is one way around this . ] to running r on the command line of the host os .",
    "( clearly a similar command could be used just as well with interactive shells from other languages such as ` ipython ` or ` irb ` ) .",
    "an alternative approach for working locally with familiar tools is to leverage web - based clients such as rstudio . in the r environment",
    ", the open source rstudio ide provides another key component in making this system accessible to most domain scientists .",
    "because the rstudio ide is written completely with standard web languages ( javascript , css , and html ) , its web - based rstudio server looks and feels identical to its popular desktop ide .",
    "rstudio server provides a way to interact with r on a remote environment without the latency , x tunnelling , and so forth typically involved in running r on a remote server .",
    "rstudio server provides users a way to interact with r , the file system , git , text editors , and graphics running on a docker container .",
    "users already familiar with the popular ide can thus benefit from the reproducibility and portability features provided by running r in a container environment without having to adapt to a new workflow .    to accompany this paper ,",
    "i provide a docker image for running rstudio server , which can be launched as follows . from the terminal ( or boot2docker terminal on mac or windows client ) , run :    docker run -d -p 8787:8787 cboettig / ropensci    that will take a while to download the image the first time you run it .",
    "a boot2docker user will then need to determine the ip address assigned to boot2docker as shown below , while a linux user can just specify ` http://localhost ` .",
    "ip    add the port ` : 8787 ` to the end of this address and paste it into your browser address bar , which should open to the rstudio welcome screen .",
    "a user can now login with user / password ` rstudio / rstudio ` , run r scripts , install packages , use git , and so forth .",
    "user login and other configurations can be customized using environmental variables ; see details at https://github.com/ropensci/docker[https://github.com/ropensci/docker ]      a particular advantage of this approach is that the resulting computational environment is immediately _ portable_. lxc containers by themselves are unlikely to run in the same way , if at all , across different machines , due to differences in networking , storage , logging and so forth .",
    "docker handles the packaging and execution of a container so that it works identically across different machines , while exposing the necessary interfaces for networking ports , volumes , and so forth .",
    "this is useful not only for the purposes of reproducible research , where other users may seek to reconstruct the computational environment necessary to run the code , but is also of immediate value to the researcher themselves .",
    "for instance , a researcher might want to execute their code on a cloud server which has more memory or processing power then their local machine , or would want a co - author to help debug a particular problem . in either case , the researcher can export a snapshot of their running container :    export container - name container.tar    and then run this identical environment on the cloud or collaborators machine .    sharing these images",
    "is further facilitated by the docker hub technology .",
    "while docker images tend to be much smaller than equivalent virtual machines , moving around even 100 s of gigabytes can be a challenge . in their work on virtual machines , dudley _ et al .",
    "_ [ 5 ] recommend only running these tools on cloud servers such as the amazon ec2 system .",
    "as most researchers still develop software locally and may not have ready access to these resources , such a requirement adds an additional barrier to reuse .",
    "docker provides a convenient way to share any image publicly or privately through the hub after creating a free account .",
    "docker hub is both a publicly available service and also available as a separate open source platform that can be deployed on private servers .",
    "one can share a public copy of the image just created by using the ` docker push ` command , followed by the name of the image using the command :    push username / r - recommended    if a dockerfile is made available on a public code repository such as https://github.com[github ] or https://bitbucket.org[bitbucket ] , the hub can automatically build the image whenever a change is made to the dockerfile , making the ` push ` command unnecessary . a user can update their local image using the ` docker pull < imagename > ` , which downloads any changes that have since been made to the copy of the image on the hub .",
    "the approach of linux containers represented by docker offers a technical solution to what is frequently seen as the primary weakness of the standard virtual machine approach to reproducibility - reusing and remixing elements . to some extent this is already addressed by the devops approach of dockerfiles , providing a scripted description of the environment that can be tweaked and altered , but also includes something much more fundamental to docker .    the challenge to reusing virtual machines can be summarized as `` you ca nt install an image for every pipeline you want  ''",
    "in contrast , this is exactly how docker containers are designed to work .",
    "there are at least two ways in which docker supports this kind of extensibility .",
    "first , docker facilitates modular reuse by build one container on top of another . rather than copy a dockerfile and then start adding more lines to the bottom , one can declare a new dockerfile is built on an old one using the ` from ` directive .",
    "here is an example dockerfile that adds the r statistical computing environment to a basic ubuntu linux distribution .",
    ".... from ubuntu : latest run apt - get update   run apt - get -y install r - recommended ....    this acts like a software dependency ; but unlike other software , a dockerfile must have exactly one dependency ( one ` from ` line ) .",
    "note that a particular version of the dependency can be specified using the ` : ` notation .",
    "one can in fact be much more precise , declaring not only version numbers like ` ubuntu:14:04 ` , but specific cryptographic hashes that ensure we get the exact same image every time .",
    "one can now build this dockerfile and give it name , by running in the working directory :    build -t username / r - recommended .",
    "the key point here is that other researchers can easily build off this image just created , extending our work directly , rather than having to go back to the original image .",
    "if this image is shared ( either directly or through a docker hub ) , another user can now build directly on our image , rather than on the ` ubuntu : latest ` image used as a base in the first dockerfile .",
    "to do so , one simply specifies a different image in the ` from ` directive of the dockerfile , followed by the lines required to add any additional software required .    .... from",
    "username / r - recommended   run apt - get update run apt - get -y install r - cran - matrix ....    though this shows only very minimal examples that add a single piece of software in each step , clearly this approach can be particularly powerful in building up more complex environments .",
    "each one acts as a building block providing just what is necessary to run one particular service or element , and exposing just what is necessary to link it together with other blocks .",
    "for instance , one could have one container running a postgresql database which serves data to another container running a python environment to analyze the data :    run -d name db training / postgres run -d -p link db : db training / webapp python app.py    unlike the much more heavyweight virtual machine approach , containers are implemented in way such that a single computer can easily run 100s of such services each in their own container , making it easy to break computational elements down into logically reusable chunks that come , batteries included , with everything they need to run reproducibly .",
    "a researcher could connect a container providing a computational environment for a different language to this same postgresql container , and so forth .",
    "in addition to version managing the dockerfile , the images themselves are versioned using a git - like hash system ( _ e.g. _ see ` docker commit ` , ` docker push`/`docker pull ` , ` docker history ` , ` docker diff ` ) .",
    "docker images and containers have dedicated metadata specifying the date , author , parent image , and other details ( see ` docker inspect ` ) .",
    "one can roll back an image through the layers of history of its construction , then build off an earlier layer , or roll back changes made interactively in a container . for instance , here i inspect recent changes made to the ` ubuntu : latest ` ] conclusions -----------      the effectiveness of this approach for supporting reproducible research nonetheless depends on how each of these features are adopted and implemented by individual researchers .",
    "i summarize a few of these practices here :    * _ use docker containers during development_. a key feature of the docker approach is the ability to mimic as closely as possible the current workflow and development practices of the user .",
    "code executing inside a container on a local machine can appear identical to code running natively , but with the added benefit that one can simply recreate or snapshot and share the entire computational environment with a few simple commands .",
    "this works best if researchers set up their computational environment in a container from the outset of the project .",
    "* _ write dockerfiles instead of installing interactive sessions_. as we have noted already , docker can be used in a purely interactive manner to record and distribute changes to a computational environment . however , the approach is most useful for reproducible research when researchers begin by defining their environment explicitly in the devops fashion by writing a dockerfile . *",
    "_ adding tests or checks to the dockerfile_. dockerfile commands need not be limited to installing software , but can also include execution .",
    "this can help verify that an image has build successfully with all the software necessary to run the research code of interest . *",
    "_ use and provide appropriate base images_. though docker supports modular design , it remains up to the researchers to take advantage of it .",
    "an appropriate workflow might involve one dockerfile that includes all the software dependencies a researcher usually uses in the course of their development , which can then be extended by separate docker images for particular projects .",
    "re - using existing images reduces the effort required to set up an environment , contributes to the standardization of computational environments within a field , and best leverages the ability of docker s distribution system to download only differences . *",
    "_ share docker images and dockerfiles_. the docker hub significantly reduces the barriers for making even large images ( which can exceed the file size limits of journals common scientific data repositories such as dryad and figshare ) readily available to other researchers . * _ archive tarball snapshots_. despite similar semantics to git , docker s versioning system works rather differently than version management of code .",
    "docker can roll back aufs layers that have been added to an image , but not revert to the earlier state of a particular layer . in consequence , to preserve a bitwise identical snapshot of a container used to generate a given set of results , it is necessary to archive the image tarball itself ",
    "one can not simply rely on the docker history to recover an earlier state .",
    "docker has the potential to address shortcomings of certain existing approaches to reproducible research challenges that stem from recreating complex computational environments .",
    "docker also provides a promising case study in other issues .",
    "its versioning , modular design , portable containers , and simple interface have proven successful in industry and could have promising implications for reproducible research in scientific communities .",
    "nonetheless , these advances raise questions and challenges of their own .",
    "* docker does not provide complete virtualization but relies on the linux kernel provided by the host .",
    "systems research can provide insight on what limitations to reproducibility this introduces [ 11 ] .",
    "* docker is limited to 64 bit host machines , making it impossible to run on older hardware ( at this time ) . * on mac and windows machines docker",
    "must still be run in a fully virtualized environment .",
    "though the boot2docker tool streamlines this process , it remains to be seen if the performance and integration with the host machine s os is sufficiently seamless or creates a barrier to adoption by users on of these systems .",
    "* potential computer security issues may still need to be evaluated . among other changes ,",
    "future support for digitally signing docker images may make it easier to build off of only trusted binaries .",
    "* most importantly , it remains to be seen if docker will be significantly adopted by any scientific research or teaching community .",
    "using docker containers to distribute reproducible research should be seen as an approach that is synergistic with , rather than an alternative to , other technical tools for ensuring computational reproducibility .",
    "existing tools for managing dependencies for a particular language [ 21 ] can easily be employed within a docker - based approach , allowing the operating - systems level virtualization to sidestep potential issues such as external library dependencies or conflicts with existing user libraries .",
    "other approaches that facilitate reproducible research also introduce additional software dependencies and possible points of failure [ 7 ] .",
    "one example includes dynamic documents [ 17 , 22 , 26 ] which embed the code required to re - generate the results within the manuscript . as a result ,",
    "it is necessary to package the appropriate typesetting libaries ( _ e.g. _ latex ) along with the code libaries such that the document executes successfully for different researchers and platforms .",
    "i noted at the outset that cultural expectations responsible for a lack of code sharing practices in many fields are a far more extensive primary barrier to reproducibility than the technical barriers discussed here .",
    "nevertheless , it may be worth considering how solutions to these technical barriers can influence the cultural landscape as well .",
    "many researchers may be reluctant to publish code today because they fear a it will be primarily a one - way street : more technical savvy researchers then themselves can benefit from their hard work , while they may not benefit from the work produced by others .",
    "lowering the technical barriers to reuse provides immediate practical benefits that make this exchange into a more balanced , two - way street .",
    "another concern is that the difficulty imposed in preparing code to be shared , such as providing even semi - adequate documentation or support for other users to be able to install and run it in the first place is too high [ 23 ] .",
    "thus , lowering these barriers to re - use through the appropriate infrastructure may also reduce certain cultural barriers to sharing .",
    "cb acknowledges support from nsf grant dbi-1306697 , and also from the sloan foundation support through the ropensci project .",
    "cb also wishes to thank scott chamberlain , dirk eddelbuettel , rich fitzjohn , yihui xie , titus brown , john stanton - geddes and many others for helpful discussions about reproducibility , virtualization , and docker that have helped shape this manuscript .",
    "[ 1]altintas , i. et al . 2004 .",
    "kepler : an extensible system for design and execution of scientific workflows . _ proceedings .",
    "16th international conference on scientific and statistical database management , 2004 . _ ( 2004 ) .",
    "[ 10]gilbert , k.j .",
    "et al . 2012 .",
    "recommendations for utilizing and reporting population genetic analyses : the reproducibility of genetic clustering using the program structure .",
    "_ mol ecol_. 21 , 20 ( sep .",
    "2012 ) , 49254930 ."
  ],
  "abstract_text": [
    "<S> as computational work becomes more and more integral to many aspects of scientific research , computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike . </S>",
    "<S> though computational reproducibility seems more straight forward than replicating physical experiments , the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge . in this paper , </S>",
    "<S> i explore common reasons that code developed for one research project can not be successfully executed or extended by subsequent researchers . </S>",
    "<S> i review current approaches to these issues , including virtual machines and workflow systems , and their limitations . </S>",
    "<S> i then examine how the popular emerging technology docker combines several areas from systems research - such as operating system virtualization , cross - platform portability , modular re - usable elements , versioning , and a ` devops ' philosophy , to address these challenges . </S>",
    "<S> i illustrate this with several examples of docker use with a focus on the r statistical environment . </S>"
  ]
}