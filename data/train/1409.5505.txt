{
  "article_text": [
    "_ information fusion _ is an umbrella term for concepts and methodologies whose primary goal is to integrate heterogeneous pieces of information from diverse sources .",
    "an information fusion algorithm is a vital ingredient of virtually any autonomous system  @xcite .",
    "some other applications are sensor networks  @xcite , biometrics  @xcite , and intelligent decision support systems  @xcite . here",
    "we consider pieces of information whose correlations are unknown and some of which may originate from unreliable sources . `",
    "pieces of information ' may refer to estimates of unknown parameters or state variables , or to other related statistical measures such as ( unnormalized ) probability density functions , fisher information and shannon entropy .",
    "we axiomatize information fusion ( definition  [ d : quandloid ] ) , and we define an _ information fusion network _",
    "( definition  [ d : updatenetwork ] ) .",
    "a similar concept of a _ tangle machine _ was defined in @xcite .",
    "information fusion networks admit a natural notion of equivalence ( [ s : similarity ] ) .",
    "when one or more streams of information becomes faulty ( _ e.g. _ biased or inconsistent ) , the faults will propagate differently in equivalent networks . at every moment",
    ", an information fusion network may be adaptively configured to its ` least faulty ' equivalent configuration .",
    "examples are given in sections  [ s : example ] and  [ s : resilience ] .",
    "our notion of equivalence parallels the notion of _ ambient isotopy _ in knot theory . as such",
    ", it represents a link between information fusion and low dimensional topology .",
    "as discussed in @xcite , low dimensional topology provides insight into the characteristic quantities or _",
    "invariants _ of information fusion networks , such as how much information is required to uniquely specify the network ( its _ capacity _ ) and how many ` independent sub - networks ' the network contains ( its _ complexity _ ) .",
    "this example illustrates two different _ information fusion networks _ for fusing estimates .",
    "these networks are _ equivalent _ in the sense that any information in one network can uniquely be recovered from the information in the other , but they differ in the consistency of intermediate fused estimates . thus , one network might be ` better ' than the other .",
    "consider three estimators @xmath0 , @xmath1 and @xmath2 for the same random variable @xmath3 .",
    "the correlation between these estimators is unknown .",
    "we are also provided with estimators @xmath4 , @xmath5 , and @xmath6 for the error covariances : @xmath7 { \\stackrel{\\textup{\\tiny def}}{=}}e\\left[(x-\\hat{x}_i)(x-\\hat{x}_i)^t \\right ]",
    "\\\\ - e\\left[x-\\hat{x}_i\\right ] e\\left[x-\\hat{x}_i\\right]^t \\quad \\text{$i=0,1,2$,}\\end{gathered}\\ ] ] where @xmath8 $ ] denotes the expectation taken with respect to the underlying joint probability distribution .",
    "a _ consistent estimator _",
    "@xmath9 , also called a _ conservative estimator _ , is one which is not _ too _ optimistic about its belief of what the value of @xmath3 is  @xcite : @xmath10\\ ] ] _ i.e. _ the matrix difference @xmath11 $ ] is positive semi - definite .",
    "we would like all estimators to be consistent because inconsistent estimators may diverge and cause errors .",
    "_ covariance intersection _ ( ci ) provides a method for fusing * a pair * of consistent estimates whose correlations are unspecified  @xcite .",
    "the working principle of ci is that if @xmath12 and @xmath13 are consistent estimators of @xmath3 , then so is their convex combination ( the proof is provided in @xcite ) :    [ eq : ci ] @xmath14 @xmath15    where @xmath16 is a weight parameter . different choices of the parameter @xmath17 can be used to optimize the update with respect to different performance criteria .",
    "our goal is to fuse * the triple * @xmath18 , @xmath19 , and @xmath20 to obtain a single consistent estimator for @xmath3 .",
    "two fusion schemes are :    1 .   first fuse @xmath18 with @xmath19 with a parameter @xmath17 , then fuse the resulting estimator with @xmath20 with a parameter @xmath21 .",
    "first fuse both @xmath18 and @xmath19 with @xmath20 with the parameter @xmath21 . then fuse the resulting fused estimators with the parameter @xmath17 .",
    "later , we will represent these two fusion schemes by figure  [ f : fusionnets ] .",
    "pairs are fused using ci using the same weights @xmath17 and @xmath21 .",
    "a short computation confirms that both of the above fusion schemes for a consistent triple @xmath18 , @xmath19 , and @xmath20 result in the same consistent estimator for @xmath3 .",
    "but what if @xmath18 and @xmath20 were consistent , but @xmath19 was inconsistent ?",
    "then both fusion schemes * ultimately * lead to the same estimate of @xmath3 , which is consistent for an appropriate choice of @xmath17 and of @xmath21 . but * at an intermediate stage * , the first fusion scheme involves the inconsistent estimate `` @xmath18 fused with @xmath19 with parameter @xmath17 '' , whereas all intermediate fused estimates in the second scheme are consistent . in this case",
    "the second fusion scheme is _",
    "better _ than the first .",
    "conversely , if @xmath19 is highly consistent compared to @xmath18 and @xmath20 , then the first fusion scheme would be better than the second .",
    ".48 [ c]@xmath22 [ c]@xmath23 [ c]@xmath24 [ c]@xmath25 [ c]@xmath26 [ c]@xmath27 [ c ] [ c]@xmath28 [ c]@xmath29     .48 [ c]@xmath22 [ c]@xmath23 [ c]@xmath24 [ c]@xmath30 [ c]@xmath31 [ c]@xmath27 [ c ] [ c]@xmath28 [ c]@xmath29     this section constitutes a preliminary discussion of the concept of an information fusion network in the context of our example , in anticipation of its definition in section  [ s : ifn ] .",
    "an _ information fusion network _ is made up of labeled directed edges whose incident nodes may either be fixed points in the plane called _ endpoints _ or boxes called _",
    "interactions_. each interaction involves one distinguished edge called the _ agent _ which goes ` all the way though ' vertically and ` emerges on the other side ' ( _ i.e. _ we identify the edge incident to the top to the bottom of the interaction ) .",
    "other edges are called _",
    "patients _ , and come in pairs there is one patient coming into the interaction for each patient going out of the interaction . figure  [ f : fusionnets ] contains two subfigures , representing the two information fusion schemes in section  [ ss : example ] .",
    "each have three _ input edges _ , labeled @xmath22 , @xmath23 , @xmath24 , denoting estimates @xmath18 , @xmath19 , and @xmath20 correspondingly , and a distinguished output edge labeled @xmath26 in [ f : netsub1 ] and @xmath31 in [ f : netsub2 ] .",
    "their interactions are labeled by operations @xmath28 for some @xmath32 , which represents an application of the fusion rule with weight @xmath17 .",
    "explicitly , agents are weighted @xmath17 and patients are weighted @xmath33 .    a _ fusion process _",
    "is a sequence of estimates stored in edges going from an initial to a terminal edge .",
    "subfigure  [ f : netsub1 ] contains three fusion processes , labeled @xmath34 , @xmath35 , and @xmath36 .",
    "we write @xmath37 for the fusion of the estimate @xmath18 with @xmath38 according to the fusion rule with a weighting parameter @xmath17 .",
    "the resulting estimate @xmath39 is then passed on to the second interaction where it fuses with @xmath20 with parameter @xmath21 , and resulting estimate @xmath40 is stored in @xmath26 .",
    "the network of subfigure  [ f : netsub2 ] differs only in its first process , which reads : @xmath41 above we described a pair of equivalent information fusion networks which have different local performance .",
    "alternating between these two networks to match a time evolution of initial estimator consistencies adaptively optimizes the consistency of the intermediate estimator at each point in time . in future sections we consider the general case .",
    "consider a sensor network  @xcite . in distributed information fusion architectures ,",
    "nodes behave as intelligent proxies fusing raw measurements streaming from their sensors with information received from neighboring nodes  @xcite .",
    "fusion may be carried out within a node using a statistical filtering algorithm , _",
    "e.g. _ the kalman filter .",
    "such algorithms normally use cross dependencies between the incoming pieces of information ( _ i.e. _ raw measurements and estimates from other nodes ) .",
    "however , large scale and complex networks generally inhibit calculations of the required statistical interdependencies among nodes  @xcite .",
    "covariance intersection ( ci ) does not require knowledge of correlations , hence it is suitable for fusion in large scale settings  @xcite .",
    "definition  [ d : quandloid ] abstracts the key properties of ci to axiomatize information fusion .",
    "chief among these is self - distributivity or _ no double counting _ which guarantees equality of outputs of the two networks of section  [ s : example ] .      in this section",
    "we formulate an algebra structure of ` information ' subject to a binary ` update ' operation .",
    "we name such a structure a _ quandloid _ , a portmanteau of `` quandle '' and `` groupoid '' .",
    "[ d : quandloid ] a _ quandloid _ is a set @xmath42 , whose elements , called _ colours _ , represent pieces of information , together with a set @xmath43 of partially - defined binary operations representing ` updates ' , satisfying the following properties :    * _ coherence of information_. a piece of information may update itself , and this neither generates new information nor loses information . symbolically : @xmath44 * _ causal invertibility_. all update operations are left invertible .",
    "thus , any input can uniquely be recovered from its corresponding output together with the agent .",
    "symbolically , for every @xmath45 there exists an ` left - inverse operation ' @xmath46 such that : @xmath47 more precisely , if @xmath48 exists then @xmath49 exists and equals @xmath25 . *",
    "_ no double counting_. updating @xmath50 by @xmath51 with @xmath52 gives the same result as the updated piece of information @xmath53 by @xmath27 with @xmath54 .",
    "thus @xmath27 counts towards the final result only once , and there is no redundancy . symbolically : @xmath55 in particular , the left - hand side exists if and only if the right - hand side exists . *",
    "_ identity_. the set @xmath43 includes an ` identity element ' @xmath56 such that @xmath57 for all @xmath58 .    by abuse of notation , we often write @xmath42 as a shorthand for @xmath59 .",
    "similar self - distributive structures have been studied in knot theory ( _ e.g. _ @xcite ) and in the theory of computation ( _ e.g. _ @xcite ) . specifically , if we were to require that all binary operations in @xmath43 be fully defined _",
    "i.e. _ that @xmath48 exists for all @xmath58 and for all @xmath45 then our notion would recover the notion of a multi - quandle @xcite .      from equation  [ eq : ci ]",
    ", we see that an example of a quandloid is the set @xmath42 of all pairs @xmath60 of an estimator @xmath12 for a random variable @xmath3 with an estimator @xmath61 for its error covariance matrix , whose update operations are @xmath28 with @xmath62 and their formal inverses @xmath63 ( where defined ) .",
    "generalizing this example , we make a definition .",
    "[ d : slq ] equipping a real vector space @xmath64 with operations @xmath65 such that : @xmath66 with @xmath67 where @xmath68 ( by causal invertibility ) but @xmath69 ( by identity ) defines a quandloid called a _",
    "linear quandloid_.    a second class of examples of quandloids is given below :    [ d : lslq ] let @xmath42 be a space of measures defined over the @xmath70-algebra of some set @xmath71 , whose elements we think of as unnormalized probability density functions .",
    "then equipping @xmath42 with the operations @xmath72 again with @xmath67 where @xmath68 ( by causal invertibility ) but @xmath69 ( by identity ) defines a quandloid called a _ log - linear quandloid_.    our next quandloids will be derived from log - linear quandloids using _",
    "a _ homomorphism _ of quandloids is a function @xmath73 , such that @xmath74      the covariance intersection update rules are obtained via a homomorphism from a particular log - linear quandloid .",
    "explicitly :    [ thm : ci ] let @size7@mathfonts @@@#1@xmath75 be the space of unnormalized gaussian probability density functions over @xmath76 .",
    "the underlying space of parameters @xmath77 together with the operations @xmath78",
    "@xmath79 @xmath80    for every @xmath81 , with @xmath62 , form the linear quandloid of estimators and ci , considered at the beginning of this note .",
    "the proof , which is straightforward , is deferred to the appendix .",
    "let @xmath82 be the _ observed _ fisher information matrix associated with the unnormalized joint probability density function : @xmath83 where @xmath84 is a random parameter vector whose prior is @xmath85 , and where @xmath86 , @xmath87 . then @xmath82 satisfies : @xmath88 where : @xmath89 is a binary operation for a linear quandloid .",
    "note that , in the case of a random parameter vector , the normalizing factor is independent of the parameters , and hence we may use the unnormalized @xmath90 in the expression for the observed fisher information matrix .",
    "note that _ expected _ fisher information matrices do not form a quandloid in general .",
    "exceptional cases , when expected fisher information matrices do form a quandloid , are either when @xmath91 or when the underlying expectation is taken exclusively with respect to the prior @xmath85 .",
    "we give examples of both of these cases .",
    "assume that @xmath92 and @xmath93 are colours of a log - linear gaussian quandloid @xmath42 , where @xmath84 is a mode whose prior @xmath85 is also gaussian .",
    "then @xmath94 is a homomorphism and @xmath95 is a linear quandloid : @xmath96 where @xmath97,@xmath98 and @xmath99 denote the covariances of @xmath100 , @xmath101 and @xmath102 , and @xmath103 .",
    "here is another example . consider a log - linear quandloid whose colours are of the form @xmath104 and @xmath105 where the underlying conditionals are exponential densities whose @xmath84-dependent rate parameters are @xmath106 and @xmath107 . as before @xmath85 denotes the prior of @xmath84 .",
    "additionally , we assume that the second derivative of any rate parameter vanishes @xmath108 .",
    "in such a case , indeed : @xmath109 and thus @xmath110 a linear quandloid .",
    "this example was discussed in @xcite .",
    "a binary information source is described by a bernoulli random variable @xmath3 .",
    "the entropy of @xmath3 , denoted @xmath111 , has an operational meaning given by shannon s source coding theorem .",
    "very long independent identically distributed sequences generated by such a source fall into two categories : they are either _ typical _ or not .",
    "the probability of a typical sequence stabilizes around the value @xmath112 which implies that not more than @xmath113 bits are required to encode any typical message with ` negligible ' loss of information .",
    "let @xmath42 be a log - linear quandloid whose colours are uniform probability densities of typical sequences associated with infinitely many information sources @xmath114 the set of entropies @xmath115 with operations @xmath65 constitute a linear quandloid : @xmath116 which follows from the homomorphism @xmath117 .",
    "an update in this quandloid may describe a source @xmath118 which behaves like @xmath3 in @xmath119 fraction of times and like @xmath120 in the rest .",
    "for example , generating a message of @xmath121 symbols from @xmath118 , one expects that approximately @xmath122 of them will make up a typical sequence from @xmath3 whereas the remaining @xmath123 symbols will look as though they where generated by @xmath120 . in other words , the source @xmath118 concatenates parts of the message from @xmath3 with parts of the message from @xmath120 .",
    "we assemble information updates into a network . the philosophical position underlying its definition",
    "is that non - associative self - distributive algebraic structures ( _ e.g. _ quandloids ) should not label graphs , but rather they should label low - dimensional ` tangled ' topological objects .    [",
    "d : updatenetwork ] an _ information fusion network _ is :    * a directed graph @xmath124 whose vertices ( drawn as boxes _",
    "e.g. _ in figure  [ f : fusionnets ] ) have either degree @xmath23 or have positive even degree .",
    "vertices of even degree are called _ interactions _ , and the in - degree of each interaction equals its out - degree .",
    "vertices of degree @xmath23 are called _ endpoints_. an endpoint is _ initial _ if it is a source , and is _ terminal _ if it is a sink . * for each interaction @xmath125 , whose degree we denote @xmath126 , a partition of edges incident to @xmath125 into pairs : @xmath127 we consider each of the pairs @xmath128 as though it were a single edge , and refer to that pair as the _ agent _ of @xmath125 , and we call each @xmath129 an _ input _ of @xmath125 , and its corresponding edge @xmath130 an _ output _ of @xmath125 . all edges with superscript ` in ' ( _ i.e. _ @xmath131 and @xmath132 ) are directed towards @xmath125 , and all edges with superscript ` out ' are directed away from @xmath125 . * a _ colouring function _",
    "@xmath133 where we define @xmath134 and @xmath135 , where @xmath59 is a quandloid",
    ". function @xmath136 must satisfy : 1 .   if @xmath128 is the agent of @xmath125 , then @xmath137 .",
    "2 .   for each input - output pair",
    "@xmath138 we have either @xmath139 or else @xmath140 where @xmath141 denotes @xmath142 , and @xmath143 is the colour of the agent of @xmath125 . + each transition",
    "@xmath144 is called an _ update _ if @xmath139 and is called a _ discount _ if @xmath140 .",
    "our diagrammatic convention is to update from right to left of the agent edge(s ) , so that if the agent edge is drawn pointing from top to bottom then the colour of an edge to the left of a box is updated by @xmath141 to become the colour of the corresponding edge the right of the box , and if the agent edge is drawn pointing from bottom to top then the opposite .",
    "note that the number of initial endpoints of an information fusion network equals its number of terminal endpoints .",
    "this relates information fusion to reversible computation , thanks to causal invertibility @xcite .",
    "if @xmath59 were a multi - quandle , then the definition of an information fusion network is equivalent to the definition of a tangle machine in @xcite .",
    "in this section we describe three local modifications on information fusion networks .",
    "reidemeister moves _ are drawn in figures  [ f : reidemeistermoves ] and  [ f : r3 ] .",
    "two information fusion networks which differ by a finite sequence of these modifications are considered to be _",
    "equivalent_. for this reason , we think of these modifications as _",
    "conservation laws_.    .4 [ c]@xmath28 [ c]@xmath25 [ c ] [ c ]     .5 [ c]@xmath26[c]@xmath25[c]@xmath25[r][ld]@xmath145[c ] [ c]@xmath28      +    [ c]*(r3 ) *     * _ reidemeister _ .",
    "this local move modifies a network by eliminating or introducing an update of a edge by itself . by coherence of information ,",
    "no information is gained or lost when we perform this move . * _ reidemeister _ .",
    "this local move modifies a network by updating an edge , and immediately discounting it by the same agent . by causal invertibility doing such a thing",
    "does not effect the colour of the edge , and so no information is gained or lost when we perform this move . *",
    "_ reidemeister _ .",
    "this local move modifies a network by replacing updated outputs with a common agent by corresponding updated inputs updated by the correspondingly updated agent . by ` no double counting ' doing such a thing does not effect the colour of the edge , and so no information is gained or lost when we perform this move .    in low dimensional topology , the _",
    "reidemeister theorem _ tells us that two diagrams of tangles are related by a finite sequence of reidemeister moves if and only if the tangles which they represent are _ ambient isotopic_. combined with a result stating that a tangle is equivalent to the set of all of its colourings , tells us that the reidemeister moves are the unique set of local moves on tangles which preserve the information content of the tangle _ i.e. _ the set of all possible tangle colourings .",
    "the appearance of reidemeister moves signifies that the theory of information fusion networks has a low dimensional topological flavour .",
    "we believe that the reidemeister moves are diagrammatic representations of fundamental symmetries of information fusion ( although there may also be other symmetries ) , and therefore that the formalism of information fusion networks subject to reidemeister moves is a topological candidate for a suitably flexible diagrammatic language with which to discuss adaptive networks of information fusion .",
    "in many applications , raw data is acquired from external sources ( _ e.g. _ from sensors ) over a period of time . in such cases , statistical properties of the input information",
    "are time - dependent .",
    "suppose that we are given many such information input streams , and that our goal is to fuse some of them , maybe to discount others ( perhaps in order to isolate the contribution of one set of streams over another , or perhaps for a different reason ) , and ultimately to generate some set of output streams .",
    "in doing so , we form a complicated information fusion network whose interaction parameters we compute to optimize some global objective function",
    ".    for example , in a network coloured by a log - linear quandloid , we may choose the _ chernoff information _ as our global objective @xcite . to find optimal parameters @xmath146 , compute : @xmath147,\\ ] ] where @xmath148 denotes the unnormalized probability density in the @xmath149-th output .",
    "the global goal of the network is to generate its output colours .",
    "however , the results of intermediate computations may also matter to us , for example in order to backtrack to correct an error .",
    "reidemeister moves are local , so they change only a small part of the network , with the rest of the network remaining unchanged . at every moment",
    "the network has a ` best ' representation , which is the representative in our equivalence class of information fusion networks for which some chosen local objective function is maximized .",
    "the network may adaptively be configured as follows :    1 .",
    "optimize the network quandloid parameters @xmath150 with respect to some global objective function ( e.g. ) .",
    "this defines an equivalence class of networks @xmath151 $ ] .",
    "2 .   adaptively optimize the network @xmath152 $ ] within its equivalence class with respect to some local objective function .    the algorithmic aspect of designing such a topological fault - tolerance scheme to optimize a network with respect to a given local objective function might be complicated in general . to illustrate the utility of our theory , we give an example for which it is easy .",
    "consider the network illustrated in the upper left corner of figure  [ fig : topo ] .",
    "this network has a set of outputs outside the bounding disk ( not shown ) .",
    "some set of intermediate edges lies inside the subnetwork designated by @xmath153 and represented as an empty circle .    in the course of network operation , erroneous streams of data cause one or more of the edges @xmath22,@xmath23 , and @xmath24 , to carry faulty pieces of information , _",
    "e.g. _ biased , inconsistent and otherwise unreliable estimates .",
    "this is detected inside the network . to inhibit the influence of this contamination on edges within @xmath153 , the network performs reidemeister moves on itself , transforming itself into an equivalent network .",
    "this is achieved by ` sliding ' the faulty edges all the way over @xmath153 , by repeated application of the second and third reidemeister moves . in the resulting topology ,",
    "the faulty edges have no effect on @xmath153 , and so local costs are improved .",
    "in this note , we provided an axiomatic characterization of information fusion as an operation of a _",
    "quandloid_. the key properties of information fusion are no  double  counting ( distributivity ) and causal  invertibility .",
    "we showed that covariance intersection of estimators , fusion of observed fisher information matrices , and fusion of shannon information are all quandloid operations , and that they are all obtained from a single log - linear quandloid by means of homomorphisms .",
    "inspired by the low - dimensional topological theory of tangle diagrams , we defined an _ information fusion network _ , which comes equipped with a natural notion of equivalence .",
    "two information fusion networks are equivalent if they differ by a finite sequence of reidemeister moves .",
    "our examples demonstrated that information fusion networks are fault - tolerant , in the sense that they can adaptively be optimized to minimize the effect of faulty input information on the network .",
    "carter , s.j .",
    "2009 a survey of quandle ideas . in",
    "_ introductory lectures on knot theory : selected lectures presented at the advanced school and conference on knot theory and its applications to physics and biology _ , 2253 ."
  ],
  "abstract_text": [
    "<S> we provide an axiomatic characterization of information fusion , on the basis of which we define an _ information fusion network_. our construction is reminiscent of tangle diagrams in low dimensional topology . </S>",
    "<S> information fusion networks come equipped with a natural notion of _ equivalence_. equivalent networks ` contain the same information ' , but differ locally . </S>",
    "<S> when fusing streams of information , an information fusion network may adaptively optimize itself inside its equivalence class . </S>",
    "<S> this provides a fault tolerance mechanism for such networks . </S>"
  ]
}