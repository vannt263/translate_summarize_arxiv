{
  "article_text": [
    "the purpose of this paper is to propose a versatile mechanism for learning multivariate distributions from sets of data .",
    "this learning mechanism is based on a simple parameter - learning algorithm and a simple structure - learning algorithm .",
    "markov networks are versatile tools for modeling multivariate probability distributions , because they do not require any assumptions except for the markov property of the problem . in this paper",
    ", we treat finite discrete systems ; thus all variables take finite discrete values .",
    "however , appropriately learning a markov network from a given data set is not simple ( koller and friedman , 2009 ) .",
    "let us give a geometrical view of this problem .",
    "let @xmath0 be the neighbors of @xmath1 , and @xmath2 be the variables in the network except for @xmath1 . given a graph @xmath3 , the markov network that has this graph represents a manifold of distributions .",
    "@xmath4 the hammersley - clifford theorem ( besag , 1974 ) proves that this manifold is identical to : @xmath5 where @xmath6 is the clique in @xmath3 , @xmath7 denotes variables in @xmath6 , and @xmath8 denotes the normalizing constant .    [",
    "fig : markovlearning ]    given an empirical distribution @xmath9 , the role of _ structure - learning _ is to determine a manifold @xmath10 and the role of _ parameter - learning _ is to determine a distribution @xmath11 .",
    "if we consider maximizing likelihood ( i.e. , minimizing kullback - leibler divergence ) , then structure - learning algorithms should place @xmath10 close to @xmath9 , and parameter - learning algorithms should place @xmath12 at : @xmath13 the difficulties that arise in designing learning algorithms are :    * @xmath12 and @xmath14 have no closed form . *",
    "the problem of obtaining @xmath12 is not decomposable ; in other words , we can not obtain @xmath15 independently .",
    "* it is intractable to find @xmath12 in cases where the number of variables is large .    to avoid these difficulties various approaches",
    "have been attempted ( see chapter 20.9 in koller and friedman , 2009 ) . in this paper , we take a new approach that avoids these difficulties .",
    "firstly , we propose a new network system , named a _ firing process network_. this is not a conventional graphical model , and it is obtained by relaxing the constraints of markov networks .    in section 2 , we formulate the firing process network that the proposed learning algorithms work on , and illustrate the information geometry aspects of the firing process network . in section 3 , we introduce the parameter - learning and structure - learning algorithms , as well as aspects of their information geometry .",
    "we also present some information criteria that ensure the structure - learning algorithm is not overfitted . in section 4 ,",
    "we show how to draw samples from the model distribution , and also show that this model is able to draw samples from posterior distributions .",
    "section 5 provides experimental demonstrations that the proposed model works appropriately .",
    "the firing process network consists of @xmath16 nodes . herein , these nodes are indexed by the numbers @xmath17 .",
    "each node has a variable @xmath1 and a _ conditional probability table _ @xmath18 .",
    "node @xmath19 references other nodes in the network , denoted by @xmath0 , and we call _ information source_.    we now assume that @xmath20 . ",
    "firing node @xmath19 \" means drawing a sample from distribution @xmath21 ( see footnote , and their values are denoted by lower case , @xmath22 .",
    "we also use shortened forms , such as @xmath23 . ] ) and assigning it to the value of @xmath1 .",
    "the firing process network is formulated as follows .",
    "@xmath24 : firing process network .",
    "+ @xmath3 : directed graph .",
    "+ @xmath25 : nodes in @xmath3 .",
    "+ @xmath0 : information source of @xmath1 , i.e. , nodes that have edges to @xmath1 .",
    "+ @xmath26 : set of node numbers included in @xmath0 .",
    "+ @xmath27 : parameters .",
    "+ @xmath28 : conditional probability table @xmath18 .",
    "+ @xmath29 : linear operator ( = matrix ) that moves a distribution @xmath30 to the distribution @xmath31 , i.e. @xmath32 this operator represents the transition matrix caused by firing node @xmath19 .",
    "+ @xmath33 : either a _ sequential firing process _ or _",
    "random firing process_. the firing processes are markov chains . at each time @xmath34 ,",
    "one node is chosen and fired .",
    "similarly to the gibbs sampling ( gilks , richardson and spiegelhalter 1996 ) , there are at least two methods to choose a node to be fired at time @xmath34 .",
    "one method is that we choose a node in a sequential and cyclic manner , such as @xmath35 . in this case , the markov chain is a time - inhomogeneous chain because the transition matrix changes at every @xmath34 , such as , @xmath36 .",
    "we call this markov chain _ sequential firing process_. a sequential firing processes is a time - inhomogeneous chain , however , if we observe this chain every time @xmath16 , such as , @xmath37 then the observed subsequence is a time - homogeneous chain which has the transition matrix : @xmath38    another method is that we choose a node in a random manner .",
    "every time @xmath34 , a random number @xmath19 is drawn from the distribution @xmath39 and the node @xmath19 is fired . ] .",
    "we call this markov chain _ random firing process_. a random firing process is a time - homogeneous chain , and its transition matrix is : @xmath40 let @xmath41 be a data set where @xmath42 denotes @xmath43 at time @xmath34 in a firing process , and let @xmath44 be the empirical distribution of @xmath45 . in the case of a random firing process , @xmath46 under the assumption of the ergodicity of @xmath47 . then , by the law of large numbers , @xmath48 in the case of a sequential firing process , @xmath49 under the assumption of the ergodicity of @xmath50 .",
    "let @xmath51 , then we again get eq.([eq : pinfty ] ) , because the data are considered to be drawn equally likely from @xmath16 time - homogeneous chains that each of their state distribution converges to @xmath52 .",
    "we define the model distribution of the firing process @xmath12 by the limiting distribution @xmath53 in eq.([eq : pinfty ] ) , i.e. : @xmath54    markov networks are a special subclass of the firing process network .",
    "consider the following constraints .",
    "graph constraint : :    all edges in @xmath3 are _ bi - directed _",
    ", i.e. , if there is an    edge from @xmath1 to @xmath55 , then there is an    edge from @xmath55 to @xmath1 .",
    "parameter constraint : :    there exists @xmath11 such that , for all    @xmath19 , @xmath56 .",
    "if the sequential or the random firing processes run under these constraint , they are equivalent to the gibbs sampling and the empirical distribution of the samples converges to @xmath12 . for a given markov network , if we replace its edges @xmath57 with @xmath58 and @xmath59 , then we have a firing process network that is equivalent to the given markov network .",
    "the information geometry ( amari and nagaoka , 1993)(amari , 1995 ) illustrates important aspects of the firing process network .",
    "we define a _",
    "conditional part manifold _",
    "( see appendix ) as : @xmath60 when a node @xmath19 is fired , the distribution of @xmath43 moves from @xmath61 to @xmath62 ; in other words , the distribution of @xmath43 moves from @xmath63 to its m - projection onto @xmath64 .    in a sequential firing process ,",
    "let @xmath65 be the limiting distribution ( = stationary distribution ) of @xmath66 in eq.([eq : seqtransition ] ) , or in a random firing process , let @xmath67 .",
    "then , @xmath65 is a distribution on @xmath64 , and @xmath9 is a mixture of them .",
    "this implies that the model distribution of the firing process network is determined by @xmath16 manifolds @xmath68 , but by a single manifold such as @xmath10 in markov networks .",
    "further , note that each @xmath65 has a rigorous markov property @xmath69 , however , these rigorous markov properties are lost in the model distribution @xmath12 .",
    "learning algorithms are usually designed by solving some optimization problem , i.e. , to minimize or to maximize some score ( e.g. likelihood ) .",
    "however , we take a different approach in this paper .",
    "firstly , we determine a simple parameter - learning algorithm and show that this parameter - learning algorithm works appropriately under certain conditions .",
    "our parameter - learning algorithm is simply : @xmath70 since @xmath71 is an empirical distribution of a data set , it is easily obtained by counting the samples in the data set .    in the firing process network ,",
    "we compare two cases : @xmath3 is complete / not complete . in the case where @xmath3 is complete : @xmath72 thus , the firing process ( sequential , random ) is equivalent to  gibbs sampling \" and @xmath73 . in the case where @xmath3 is not complete : @xmath70 we call this firing process _ incomplete gibbs sampling_.    figs.[fig : cgs ] and [ fig : igs ] illustrates the notion of information geometry of gibbs sampling and incomplete gibbs sampling , respectively , with the sequential firing process . as described in section [ sec : geometry of fn ] , each time a node @xmath19 fires , the distribution of @xmath43 moves to the m - projection onto @xmath64 .",
    "figs.[fig : cgs ] and [ fig : igs ] give us some intuition :    * in the gibbs sampling , every @xmath64 intersects at @xmath9 .",
    "thus , the distribution of @xmath43 converges to @xmath9 . * in the incomplete gibbs sampling , each @xmath64 does not pass @xmath9 .",
    "thus , the distribution of @xmath43 does not converges to @xmath9 .",
    "however , if every @xmath64 is close to @xmath9 , then the distribution of @xmath43 hovers around @xmath9 , thus , the model distribution @xmath12 is close to @xmath9 .",
    "we provide more theoretical evidence for the second of these points . for the theoretical simplicity ,",
    "we treat only the random firing process in later parts of this paper .",
    "we define a conditional part manifold @xmath74 and a marginal part manifold @xmath75:@xmath76 and define the kl - divergence between a distribution @xmath63 and a manifold @xmath77 : @xmath78    here , we define the following bregman divergence ( censor and zenios , 1997)(see appendix ) that we call _ full - conditional divergence _ : @xmath79 where @xmath80 denotes a conditional entropy ( cover and thomas , 1991 ) . as",
    "kl - divergence is a bregman divergence , which has a potential @xmath81 , @xmath82 is a bregman divergence .",
    "thus , we can use it as a pseudo - distance .",
    "the following inequality implies that if every conditional part manifold @xmath83 is close to @xmath9 then the model distribution @xmath12 is also close to @xmath9 .    *",
    "upper bound of fcd ) * @xmath84 proof ) the transition matrix of the random firing process is @xmath85 the model distribution @xmath12 is clearly equal to the limiting distribution(=stationary distribution ) of this markov chain .",
    "thus : @xmath86 here , we define : @xmath87 then : @xmath88 now , consider @xmath14 .",
    "@xmath89 where @xmath90 note that @xmath91 , by the convexity of @xmath92 .",
    "fig.[fig : pipi_ipi ] illustrates information geometric relation between @xmath93 and @xmath9 . by pythagoras theorem in information geometry(amari and nagaoka , 1993)(amari , 1995 ) ,",
    "@xmath94 note that : @xmath95 subtracting : @xmath96 from eq.([eq : pipi_ipi ] ) , we get @xmath97 since @xmath91 , we get the upper bound of the full - conditional divergence .",
    "( end of proof      we have already determined the parameter - learning algorithm in the previous subsection , then , forming a good model depends on the structure - learning algorithm , the role of which is to determine @xmath98 for each node @xmath19 .    in any machine learning algorithm",
    ", we must consider two conflicting requirements for constructing a good model :    a. : :    the model distribution @xmath12 should be close to the data    distribution @xmath9 .",
    "b. : :    the complexity of the model should be low to avoid overfitting .",
    "the previous section showed that we should place the conditional part manifold @xmath64 close to @xmath9 for requirement a. since @xmath99 minimizing @xmath100 is equivalent to minimizing @xmath101 .",
    "information theory ( cover and thomas , 1991 ) states that if we add a new node to @xmath0 , then @xmath101 decreases .",
    "however , if we add a new node to @xmath0 , then the complexity of the model increases . for an ultimate example , if we let @xmath102 then    * graph @xmath3 becomes the complete graph .",
    "* the firing process becomes gibbs sampling .",
    "* @xmath73 ; however , the model is overfitted .",
    "we thus use the following information criteria to determine the trade - off between the requirement a and requirement b.      one method of evaluating the _ goodness _ of a model is to use some general information criteria such , as mdl ( minimum description length ( rissanen , 2007 ) ) or aic ( akaike information criteria ( akaike , 1974 ) ) .",
    "however , it is difficult to apply them directly to the whole system , and therefore we apply information criteria to each node .",
    "if we treat the conditional manifold @xmath64 as a model manifold , then the maximum likelihood for a data set that has @xmath103 sample and an empirical distribution @xmath9 is : @xmath104 the second term of the right - hand side can be neglected , because it is a constant in the situation where we select @xmath0 .",
    "let @xmath105 be the number of free parameters in the conditional distribution tables @xmath106 in the node @xmath19 : @xmath107 where @xmath108 denotes the number of values that * takes .",
    "we define : @xmath109 and call it _ node - by - node mdl_.    similarly , we define : @xmath110 and call it _ node - by - node aic_.    which information criteria to use depends on what assumptions we have about the underlying real distribution that the data comes from . we use @xmath111 in later sections .      to find an information source @xmath0 that minimizes @xmath112 , we must examine all combinations of variables in @xmath2 , which causes the computational costs to rise unacceptably .",
    "therefore , we use the following greedy algorithm ( written in pseudo - java ) .    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1234=@xmath113 ; + while(true)\\ { + @xmath114 ; + if(@xmath115))\\ { + @xmath116 ; + continue ; + } + @xmath117 ; + if(@xmath118))\\ { + @xmath119 ; + continue ; + } + break ; + } _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this algorithm is similar to the forward - backward algorithms used in feature selection ( guyon and elisseeff , 2003 ) .      in this subsection",
    ", we describe the relation between the number of data @xmath103 and the model distribution @xmath12 . when the number of data is small , the second term on the right - hand side of eq.([eq : nnmdl ] ) dominates @xmath111 , and thus the number of information sources is suppressed .",
    "fig.[fig : data012 ] illustrates the relation between the number of data @xmath103 and the proposed model . in this figure @xmath120",
    "denotes the underlying real distribution that the data is drawn from , and dashed lines denote @xmath64 .",
    "note that our goal is not to approximate @xmath9 , but rather @xmath120 . in the ultimate case ,",
    "@xmath113 for all nodes and @xmath3 has no edges , @xmath12 is equal to the mean field approximation of @xmath9 , and all @xmath64 intersect at @xmath12 . as @xmath103 increases , all @xmath64 move toward @xmath9 , and @xmath12 approaches @xmath9 .",
    "in the case where @xmath121 , @xmath122 and all @xmath64 intersect at @xmath122 .",
    "this behavior is reasonable because the model trusts @xmath9 when it is close to @xmath120 .",
    "the key to the proposed algorithms is that computation is independently performed by each node .",
    "this independence simplifies the situation .",
    "constructing a table of @xmath71 requires @xmath123 computations , as it is formed by counting @xmath103 samples .",
    "in addition , evaluating @xmath101 requires @xmath123 .    adding a node to an information source of another node requires @xmath124 computations , as it requires the evaluation of @xmath101 at most @xmath16 times .",
    "similarly , subtracting a node from an information source of a node requires @xmath124 .",
    "experiments show that subtracting nodes from information sources rarely occurs in the structure - learning .",
    "thus , approximately @xmath125 node additions occur during the structure - learning of node @xmath19 . by eq.[eq : nnmdl ] , we get : @xmath126 thus , @xmath127 and : @xmath128 therefore , one node requires @xmath129 and the whole system requires @xmath130 computations for the structure - learning .    to compute @xmath12 numerically , we must compute the eigenvector for eigenvalue 1 of the @xmath131 transition matrix , which requires @xmath132 computations .",
    "therefore , it is intractable to compute @xmath12 for large models .",
    "this section describes the use of our model after learning data .",
    "this model is used as a markov chain monte carlo method ( gilks , richardson and spiegelhalter , 1996 ) .",
    "we do not compute the model distribution @xmath12 numerically , but rather draw samples from @xmath12 .",
    "this is performed by the firing process described in section [ sec : firing process network ] .      here",
    ", we separate variables in the network into two parts : @xmath133 . in the gibbs sampling , if we fix the value of @xmath134 to @xmath135 and only fire the nodes in @xmath136 , then we can draw samples from @xmath137 . in this paper , we call this _ partial sampling _ we can also conduct the partial sampling in the proposed model",
    ".    we also separate @xmath0 into two parts : @xmath138 , where @xmath139 is the variables included both in @xmath0 and @xmath136 , @xmath140 is the variables included both in @xmath0 and @xmath134 .",
    "suppose we already finished learning and obtained a network @xmath141 .",
    "let @xmath142 be the following firing process network :    * nodes in @xmath134 are removed from @xmath143 . *",
    "the conditional probability table of node @xmath19 is @xmath144 in @xmath142 , while it is @xmath18 in @xmath143 .",
    "values @xmath145 are fixed by @xmath135 .    then",
    ", it is clear that the partial sampling on @xmath143 and the normal firing process on @xmath142 are equivalent .",
    "let @xmath146 be the model distribution of @xmath142 , and @xmath147 be the conditional part manifold of node @xmath19 in @xmath142 , i.e. : @xmath148 here , we can derive the following equation : @xmath149 this equation shows that the average of @xmath150 is equal to @xmath100 .",
    "thus , if @xmath100 is small , then @xmath150 is , on average , small , and the distribution of the samples drawn by the partial sampling converges to @xmath146 , which is , on average , close to @xmath137 .",
    "we used a @xmath151 ising model shown in fig.[fig:3x3ising ] for the first experiment . in this case",
    ", we could compute @xmath12 numerically , as the size of problem is small .",
    "we used four data sets , each of which used different random seeds to draw i.i.d .",
    "( independent and identically distributed ) samples from @xmath120 , as shown in fig.[fig:3x3ising ] . in fig.[fig:3x3result ] , the figures under the graphs are @xmath152 . note that in these results :    * @xmath153 ; i.e. , @xmath9 is closer to @xmath12 than to @xmath120 .",
    "* @xmath154 ; i.e. , @xmath120 is closer to @xmath12 than to @xmath9 .      in learning a multivariate distribution , we often encounter the situation that @xmath156 .",
    "therefore , we expanded the previous ising model to @xmath155 , and similarly formed data sets by i.i.d . sampling with three different random seeds . in this case ,",
    "@xmath157 and it is intractable to compute @xmath12 numerically because it would require @xmath132 computations .",
    "however , we can observe how the model learns the structure .",
    "fig.[fig:5x5result ] shows that the proposed model successfully retrieved the structure from the given data sets , and that retrieval depends on @xmath103 rather than @xmath158 .",
    "we give the following as an example of a real - world problem .",
    "for a one - day stock price , we define : @xmath159 we followed 10 stocks and topix ( the overall index of stock prices on tokyo stock exchange ) ; thus , the vector @xmath43 consists of 11 binary variables .",
    "we took @xmath160 samples from the real market ( 2009/01/05 - 2011/12/28 ) and set the proposed model to learn the distribution .",
    "we do not know the real distribution that these samples are drawn from .",
    "however we can observe the graph @xmath3 constructed by the learning algorithm .    in fig.[fig",
    ": c11mdl ] , every node takes other nodes in its sector or topix as its information source , except for docomo@xmath161astellas .",
    "if we remove topix from the graph , it can be noted that the nodes are separated to three groups : domestic industry ( pharmacy , cellphones ) , exporting industry ( car manufacturers ) and importing industry ( general merchants ) .",
    "the important difference between conventional graphical models ( markov networks , bayesian networks ) and firing process networks is :    * in the conventional graphical models , the structure determines a single manifold for the entire system , and the model distribution is located on this manifold . * in the firing process networks , each node has a manifold respectively , thus the whole system has @xmath16 manifolds , and the model distribution is determined by these @xmath16 manifolds .",
    "this difference makes the learning algorithms for the firing process networks simple ; since each node is only responsible for its manifold , and it does not need to know what other nodes do during learning .      * comparisons with conventional learning algorithms that work on conventional graphical models . * revised version of learning algorithms . *",
    "expansion to continuous models .",
    "* theory for sequential firing process .                              in this paper",
    ", we often assumed the existence of a unique limiting distribution of a markov chain . here",
    ", we describe when this assumption is satisfied .",
    "we consider only time - homogeneous markov chains with finite state spaces here . the following theorem for markov chains can be found in many text books .",
    "however , we can not use this theorem directly in this paper , because the first assumption requires @xmath162 .",
    "for example , in the case that the number of data is smaller than the size of the range of @xmath43 , the empirical distribution of the data never satisfies this assumption .",
    "therefore , we use the following extended version .",
    "let @xmath163 be any stochastic variables , and @xmath164 be one of their joint probability . by bayes rule , @xmath165 . here ,",
    "we call @xmath30 _ marginal part _ of @xmath63 and call @xmath166 _ conditional part _ of @xmath63 .",
    "we also define two manifolds : @xmath167 we call @xmath168 _ marginal part manifold _ of @xmath63 and call @xmath169 _ conditional part manifold _ of @xmath63 .",
    "these manifolds have the following properties :              let @xmath182 be any vectors in @xmath183 and @xmath184 be a continuously - differentiable , real - valued , and strictly convex function .",
    "bregman divergence is defined as : @xmath185 where @xmath186 denotes the inner product operator .",
    "we call @xmath184 _ potential _ of @xmath187 .",
    "bregman divergence has following properties :"
  ],
  "abstract_text": [
    "<S> in this paper , we propose a simple , versatile model for learning the structure and parameters of multivariate distributions from a data set . learning a markov network from a given data </S>",
    "<S> set is not a simple problem , because markov networks rigorously represent markov properties , and this rigor imposes complex constraints on the design of the networks . </S>",
    "<S> our proposed model removes these constraints , acquiring important aspects from the information geometry . </S>",
    "<S> the proposed parameter- and structure - learning algorithms are simple to execute as they are based solely on local computation at each node . </S>",
    "<S> experiments demonstrate that our algorithms work appropriately . </S>"
  ]
}