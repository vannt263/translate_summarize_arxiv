{
  "article_text": [
    "there is an increasing need of a reliable and precise modeling of corneal surfaces , motivated both by technological and clinical applications .    given the significance of the shape of the front surface of the cornea to the refraction of the eye @xcite and the ability to correct refractive errors by laser ablation of the front surface of the cornea ,",
    "a detailed wavefront error analysis of individual corneal topography data is crucial for the clinicians as a basis for a customized treatment .",
    "it has been recognized that the corneal front surface generally provides the bulk of the ocular aberrations in the postsurgical or pathologic eye @xcite .",
    "corneal modeling can be used also as a tool for screening corneal diseases .",
    "keratoconus , for example , distorts the corneal shape and results in a significant vision loss .",
    "keratoconic patients should be screened for refractive surgeries because such treatments may worsen the corneal shape and lead to corneal transplantation .",
    "hence , corneal modeling plays an essential role in diagnosing and managing keratoconus to assess suitability of a subject for the treatment and prevent improper refractive surgeries @xcite .",
    "also , the great role of the reliable visualization tools in clinical practice should not be underestimated .",
    "modern techniques of design and fit of soft contact lenses can take into account features of the patient s eye , adapting the back surface of a lens to match the specific elevations of the cornea .",
    "these methods require again a detailed corneal topographic analysis of the anterior face of the cornea .    with the introduction of the high - speed videokeratoscopy @xcite in the study of the dynamics of corneal surface topography @xcite and tear film stability @xcite ,",
    "the storage needs have become significant , motivating another important application of corneal surface modeling : data compression @xcite .",
    "the vast majority of modern corneal topographers collects the data ( either elevation , curvature , mire displacement or others ) in a finite and discrete set of points .",
    "typically , these points present a quasi - structure ; for instance , those devices based on the placido rings technology provide elevations and curvatures at the discretized images of the mires , whose deformation is proportional to the complexity of the surface . in any case , the data is contaminated by the error , which stems from several sources : the natural device noise , measurement and digitalization errors , algorithm errors ( like those converting the displacement in elevation ) , rounding errors and others . hence , we face the problem of the parsimonious fit of the actual surface data contaminated by noise , with a minimum number of coefficients or parameters , for its clinical and technological applications .    the solutions to this problem are usually classified into the so - called zonal and modal methods .",
    "in the former group , the domain where the data are collected is subdivided in more elementary subdomains ( e.g. , triangles ) , and the surface is approximated in each subdomain with a relative independence from the other regions .",
    "the standard tool here are splines , in particular , the numerically stable b - splines @xcite , widely used in the computer - aided geometric design .    in the modal methods of reconstruction",
    "the approximation is found as a ( typically , linear ) combination of functions from the given set or dictionary , defined by a number of parameters . in this sense ,",
    "crucial decisions to make are the set of functions to use , the value of their parameters , and the number of functions needed to recover the relevant information without fitting ( at least , in a large scale ) the inevitable error ( the so - called model selection problem ) .    among the advantages of the zonal methods",
    "is the flexibility and the accuracy of fit , but they lack the simplicity of the modal approach , which renders functional expressions valid across the whole domain , suitable for further calculations ( such as ray tracing and others ) .",
    "zonal techniques are also substantially more computer - intensive and encode the final shape in a larger amount of data .    a standard functional basis for the modal reconstruction , used commonly in ophthalmology to express ocular wavefront error are the zernike polynomials @xcite .",
    "the coefficients of their expansions have interpretation in terms of the basic aberrations such as defocus , astigmatism or coma , along with higher order aberrations such as trefoil and spherical aberrations . as a fitting routine , zernike polynomials",
    "are not limited to analysis of wavefront error surfaces , but can be applied to other ocular surfaces as well , including the anterior corneal surface @xcite .",
    "it has been suggested that zernike analysis may be applicable in the development of corneal topography diagnostic tools , using the zernike coefficients as inputs into corneal classification of neural networks @xcite , replacing or supplementing the currently used corneal indices included with many topography devices .",
    "however , potential limitations in this approach have been reported in the literature @xcite .",
    "there is a growing concern that the zernike fitting method itself may be inaccurate in abnormal conditions .",
    "furthermore , it is very difficult to assess a priori how many terms are necessary to achieve acceptable accuracy in the zernike reconstruction of any given corneal shape @xcite .",
    "it is known @xcite that limiting zernike analysis to only a few orders may cause incorrect assessment of the severity of the more advanced stages of keratoconus @xcite .",
    "this information is particularly needed in the discriminant analysis of the decease markers , or when selecting the numerical inputs for neural network  based diagnostic software such as corneal classification and grading utilities for condition severity .",
    "in this sense , several alternatives to the modal least - square fit with zernike polynomials have been recently suggested .",
    "some of them intent to combine the modal and zonal approaches in order to preserve the best of both worlds @xcite or to use non - linear methods @xcite .",
    "the idea of the possibility of getting the accuracy and flexibility of the zonal methods within the framework of the linear modal approach by means of localized radial basis functions has been expressed in @xcite , but without developing an actual implementation or procedure . in this paper we describe an adaptive and multi - scale working algorithm for the parsimonious fit of the surface data , based on residual iteration with knot insertion , that allows to adapt the number of functions used in the reconstruction to the conditions of each cornea .",
    "the residual iteration is well - known in many branches of mathematics ; it is related for instance with the iterative refinement methods of solution of systems of linear equations . in the context of purely radial basis functions",
    "an adaptive greedy approximation algorithm using interpolation has been proposed in @xcite .",
    "the adaptive increase of the number of basis functions as a technique used to improve the quality of a given initial approximation is also standard , see for instance ( * ? ? ?",
    "21 ) for a general discussion and references .",
    "the method proposed here allows to build iteratively an approximation function as a linear combination of anisotropic gaussian basis functions , implementing also a dynamical selection of the parameters and the management of noise .",
    "it can be used to reconstruct altimetric data , corneal power maps , and others . although it has been tuned up for the placido ring based keratoscopes , with the data nodes located in almost concentring rings , the technique is actually applicable to any scattered data approximation .",
    "part of this approach was announced in @xcite .",
    "the input data is a 3d cloud @xmath0 , @xmath1 , corresponding to either elevation or corneal power @xmath2 by a corneal topographer at the node @xmath3 of the anterior corneal surface with cartesian coordinates @xmath4 .",
    "we will discuss the case when @xmath2 corresponds to elevation .",
    "taking into account the global shape of the cornea , a standard procedure is to `` flatten '' the data by fitting it with the best - fit sphere @xcite of the form : @xmath5 where @xmath6 and @xmath7 are its radius and the cartesian coordinates of its center , respectively .",
    "although the common practice is to fit with the standard linear least squares , better results are obtained with a weighted least square fit , using @xmath8 as the weight , in accordance with the typical error distribution @xcite .    as a result of the previous step , the residual errors @xmath9 contain both the relevant information at different scales and noise .",
    "our aim is to fit these residuals by a function @xmath10 in such a way that an analytic expression for the corneal height is given by @xmath11 in this way , @xmath12 accounts for the global shape of the cornea , while @xmath13 captures the small irregularities in the surface .",
    "function @xmath13 is given by a linear combination of @xmath14 functions from a given dictionary , @xmath15 in an ideal setting , @xmath14 depends on the actual data , and should be large enough to allow all relevant information from the elevation measured modeled by @xmath13 , but not too large to prevent from overparametrizing the problem and fitting pure noise . in order to circumvent the difficulties of the zernike polynomials mentioned above we use as basis functions the gaussians of the form @xmath16 where the superscript @xmath17 denotes the matrix transpose , @xmath18 is a certain point on the plane ( `` center '' ) , and @xmath19 is a positive - definite matrix in @xmath20 .",
    "for such a matrix the @xmath19-norm of a point ( column vector ) @xmath21 in @xmath22 is defined as @xmath23    in general , these are anisotropic radial basis functions , that boil down to standard radial basis gaussian functions ( rbgf ) when both eigenvalues of @xmath19 coincide ( in other words , when @xmath19 is a positive multiple of the identity matrix @xmath24 ) .",
    "one of the advantages of these functions is that they are quasi compactly supported : for @xmath25 , @xmath26 , that is , achieves less than 5% of its maximum height .",
    "hence , we seek the expression of the form @xmath27 clearly , a fitting routine should allow for an adequate selection of all parameters , namely    * centers @xmath28 ; * shape matrices ( or shape parameters ) @xmath29 ; * scaling factors @xmath30 ; * number of terms @xmath14 in the functional representation .",
    "we propose an iterative algorithm of reconstruction , such that in each step we fit partially the residual error by one anisotropic rbgf ( a - rbgf ) , and compute the new residuals , which will become the input for the next iteration ( residual iteration with knot insertion ) . to preserve the maximum possible degrees of freedom , the centers , the shape parameters and the scaling factors",
    "will be chosen dynamically depending on the residual data in each step .",
    "let @xmath31 be already computed ( we take @xmath32 ) .",
    "the input data for the @xmath33 s iteration ( @xmath34 ) is the cloud @xmath35 of nodes @xmath36 and the corresponding residuals @xmath37 , @xmath38 ; recall that @xmath9 are the residual errors after the weighted best sphere fit .",
    "we perform the following steps :    step 1 : selection of the center @xmath28 .",
    "the problem of the selection of a center of a radial basis function has been discussed in @xcite . there",
    "the center is chosen among the data nodes @xmath3 using the criterion of maximum cross - correlation .",
    "another criterion uses the power function ( see e.g.  @xcite , @xcite , @xcite ) . both methods ,",
    "although computationally demanding , can be implemented to perform step 1 .",
    "however , in our practice we found the much simpler criterion of maximal residual ( strategy for so - called greedy approximation ) to be as satisfactory , at a minimum cost ; it correlates also with the geometry of the a - rbgf . hence",
    ", we choose @xmath39 and denote @xmath40    step 2 : dynamical filtering .",
    "as it was mentioned before , the altimetric data obtained from measuring devices such as a keratographer are contaminated by noise .",
    "although there are some indications about statistical distribution of these errors , the information is still very limited . in order to cope with this problem we need to filter out those data that clearly correspond to the measurement error and thus spoil the quality of the reconstruction .",
    "we can do it in advance , before starting the fitting procedure , like in @xcite .",
    "but we have chosen a simpler alternative , that yields satisfactory results : once the center @xmath28 has been selected , we check the number , @xmath41 , of nodes @xmath42 lying in the largest disk , centered at @xmath28 and containing only nodes with the residues of the same sign as @xmath43 .",
    "if @xmath44 , we consider @xmath28 an outlier and exclude it from consideration at this iteration",
    ". this can be done by simply setting @xmath45 , after which we return to step 1 .",
    "otherwise , we proceed to the next step .",
    "obviously , this step can be ignored if we know that the error is negligible .",
    "step 3 : selection of the shape parameters .",
    "we determine first the influence nodes @xmath46 , defined as the maximal set of at most @xmath47 nodes @xmath3 closest to @xmath28 with residues of the same sign than @xmath43 .",
    "observe that @xmath48 if @xmath49 .",
    "it is convenient to parallelize the subsequent computations for several values of @xmath50 : we have performed experiments using the vector of values @xmath51 $ ] , where @xmath52 , with @xmath41 defined in step 2 .    the interpolating conditions @xmath53 are equivalent to the overdetermined linear system @xmath54 in the 3 unknown entries of the shape matrix @xmath55 we solve this system in the sense of weighted linear least squares ( wls ) , where the @xmath56-th equation is multiplied by the weight @xmath57 in order to account for the bigger influence of the neighboring nodes on @xmath29 .",
    "this solution is obtained by standard methods , using either the @xmath58 factorization of the collocation matrix corresponding to or its singular value decomposition , see e.  g.  @xcite .",
    "observe that due to the selection of the active center @xmath28 , @xmath59 however , this condition does not guarantee that the solution @xmath29 of in the sense of the wls described above will be positive definite .",
    "this can typically fail in the periphery of the convex hull of the nodes , where the lack of data in some direction might yield non - positive definite @xmath29 .",
    "although the corresponding function @xmath60 might fit the data correctly locally , it is not valid globally due to its exponential increase in the direction of the eigenvector of a negative eigenvalue of @xmath29 .    in order to overcome this problem we examine the solution @xmath29 of : if it is not positive definite , we interpret that there is a lack of data in a neighborhood of @xmath28 and force @xmath60 to be an isomorphic ( a bona fide ) radial basis function : @xmath61 . in this way ,",
    "is reduced to @xmath62 whose solution in the sense of the wls is @xmath63 with @xmath64 and @xmath65 .",
    "observe that in this case @xmath66 is positive by construction , and we define @xmath67    step 4 : selection of the scaling factor .",
    "we can calculate the coefficient @xmath30 from @xmath68 using the wls with the same weights @xmath69 : @xmath70 with @xmath71    it should be noted however that numerical experiments show that in many cases the much simpler interpolation condition @xmath72 yields comparable results",
    ".    step 4 : computation of the new residuals .    with the values of @xmath30 and @xmath29",
    "just computed we update @xmath73 as it was mentioned before , all the computations have been performed in parallel for different values of @xmath50 ( typically , from 3 to 5 values between 50 and 300 ) , and hence , different nested sets of influence nodes @xmath46 .",
    "we now keep the value of @xmath50 ( and the corresponding values of @xmath30 and @xmath29 ) that yields the smallest norm of the residue vector @xmath74 , and discard the other values . as a result",
    ", we find the new approximation , @xmath75 .    as a final step , we check the stopping criterium that will be discussed below .",
    "if this is not satisfied , we increment the iteration counter @xmath33 in 1 and return to step 1 .      in theory , the algorithm run indefinitely yields an interpolating function , and in consequence , a zero residue vector . in the real life situation of the data contaminated by errors ,",
    "a very important problem is that of the model order selection : we want to capture all the relevant information without over - parametrizing the model and without fitting the noise .",
    "many solutions to this problem are described in the literature .",
    "for instance , the choice of the number of zernike polynomials for the modal reconstruction of the altimetric data has been discussed in @xcite .",
    "the statistical methods of selection of the appropriate number @xmath14 in usually make assumptions about the noise .",
    "however , a priori information about the measurement error bounds or measurement error distribution is limited . according to @xcite",
    ", the errors can not be assumed i.i.d .",
    "random variables , although the assumption that they are normally distributed ( with the variance proportional to the square of the distance of the node to the center ) is apparently reasonable .",
    "they are also computationally intensive , @xcite .",
    "less demanding methods use information theory criteria , such as the akaike information criterion ( aic ) , or the efficient detection criterion ( edc ) @xcite , which studies the evolution of @xmath76 with @xmath77 the value of @xmath78 is usually tuned up experimentally .",
    "however , we can gain information analyzing directly the behavior of the normalized errors @xmath79 defined in .",
    "typically , these errors start decaying with an exponential rate and average order greater than @xmath80 . after a number of iterations we observe a stabilization in this rate of decay that becomes linear ; this typically happens when values of @xmath79 are between @xmath81 and @xmath82 @xmath83m@xmath84 .",
    "based on this experience we have used successfully the following stopping criterion : we allow the algorithm run for up to 50 iterations ( this takes less than 2 seconds to complete ) and calculate the weighted slopes @xmath85 the sequence @xmath86 , although oscillatory , is negative and tends to zero , so we find the last iteration @xmath87 when @xmath88 . if @xmath89 @xmath83m@xmath84 , we fix @xmath90 as the stopping iteration .",
    "otherwise we seek for the last iteration @xmath91 when @xmath92 , and stop the algorithm at the @xmath93-th iteration .",
    "in this section , we present a comparison of the numerical results obtained with our method applied both to simulated and real cornea surfaces . all the procedures were implemented in matlab 7 and run on standard platforms ( windows pc and mac with average configuration ) .",
    "the altimetric and curvature data from in - vivo corneas used for experiments described below were collected by the cso topography system ( cso , firenze , italy ) , which in ideal conditions digitizes up to 24 rings with 256 equally distributed points on each mire .",
    "since the procedure is meant for real - time reconstruction of the corneal data , any extremely computer - intensive methods should be discarded . however , in our matlab implementation the execution time was always below 2 seconds , so this becomes less and less of a concern with the progress of the software optimization and computing power .",
    "we demonstrate first the power of the proposed methodology using some elementary surface models , starting with the simplest example : a surface given by a linear combination of three exponentials , @xmath94 with @xmath95 , @xmath96 , @xmath97 , @xmath98 , @xmath99 , @xmath100 , and @xmath101 the surface is obviously exaggerated with respect to the typical residue of the standard cornea , but this is made with illustrative purpose .",
    "the result of the first three iterations of the algorithm are shown in figure  [ figs:3peaks ] .    [ cols=\"^,^ \" , ]",
    "in this work , we develop an adaptive fitting method for corneal data , combining modal simplicity with advantages of zonal reconstruction .",
    "it consists of a preliminary fit of the data with some global function ( sphere or a combination of zernike polynomials of a low order ) and an iterative procedure that adds terms to the analytic representation of the corneal data .",
    "each term consists of a scaled anisotropic radial basis gaussian function .",
    "the coefficients are computed dynamically and allow to fit the data in each iteration independently of the scale .",
    "the method comprises also a filtering procedure that discards the outliers ( data clearly corresponding to measurement noise ) and a stopping criterium that chooses the final number of functions in the analytic representation in accordance with the evolution of the residual error .",
    "the numerical implementation of this algorithm in a standard personal computer is very fast ( execution time below 2 seconds ) .",
    "experimental results allow us to draw the following conclusions :    * the least square approximation by a linear combination of zernike polynomials of a radial order up to 6 ( which is the standard in modern aberrometers @xcite ) fits adequately the altimetric data in the case of a normal cornea .",
    "it can be used also to capture the major features of the shape of the surface . however , for strongly aberrated corneas the zernike - based procedure saturates relatively early , and we need a high number of terms to achieve the desired accuracy at regions of localized steepening , at the price of overparametrizing the model and fitting the measurement noise .",
    "last but not least , the complexity of each individual term in the functional representation increases with its index . *",
    "in contrast , the iterative method presented here exhibits a steady exponential error decay , independently of complexity of the cornea .",
    "its actual rate is basically influenced by the residue distribution : the fast decrease in the first iterations , when all salient features are reconstructed , is followed by a stable linear decay , when essentially errors are being fit .",
    "this can be used as a stopping criterium for the iterations . in this way , the minimal amount of functions in the analytic representation of the cornea is used .",
    "* unlike in the case of zernike polynomials , the complexity of each term in the functional representation with a - rbgf is the same , but their parameters vary to fit the current scale .",
    "this scale is determined only by the residual errors and not by the number of the iteration . * due to the localized character of a - rbgf , the position and clustering of their centers , as well as the size of the shape parameters , provides an additional spatial information about the regions of higher irregularity .",
    "these ideas were actually used in elaboration of new cornea irregularity indices that are currently under study .",
    "* zernike - based reconstruction , being center - oriented , is also very sensitive to rings with incomplete data . in clinical practice this is usually motivated by eye lashes obstruction or a tear film disruption . still , a large portion of data of each incomplete mire is available and used by the iterative reconstruction with the a - rbgf .",
    "the iterative adaptive algorithm for the cornea modeling proposed here provides a method of obtaining a compact mathematical description of the shape or power map of the cornea .",
    "all information is ultimately encoded in the following set of values : center and radius of the best - fit sphere , plus the center locations , shape parameters and scaling factors .",
    "this description can be used for global visualization of the cornea or of its portions , capturing smaller details than with standard procedures .",
    "it can serve also as the input data for resampling and computation of some other relevant values via ray tracing , numerical integration and others .",
    "a.m .- f . is supported in part by junta de andaluca grants fqm-229 and p09-fqm-4643 , and by the ministry of science and innovation of spain ( project code mtm2008 - 06689-c02 - 01 ) .",
    "both a.m .- f . and",
    "are also supported in part by junta de andaluca grant p06-fqm-01735 .",
    "10 url # 1`#1`urlprefix          j.  nemeth , b.  erdelyi , b.  csakany , p.  gaspar , a.  soumelidis , f.  kahlesz , z.  lang , high - speed videotopographic measurement of tear film build - up time , invest .",
    "sci . 43  ( 6 ) ( 2002 ) 17831790 .",
    "m.  a. halstead , b.  barsky , s.  a. klein , r.  b. mandell , a spline surface algorithm for reconstruction of corneal topography from a videokeratographic reflection pattern , optometry and vision science 72  ( 11 ) ( 1995 ) 821827 .",
    "s.  d. klyce , m.  d. karon , m.  k. smolek , advantages and disadvatages of the zernike expansion for representing wave aberration of the normal and aberrated eye , j. refractive surgery 20 ( 2004 ) s537s541 .",
    "a.  martnez - finkelshtein , a.  m. delgado , g.  m. castro , a.  zarzo , j.  l. ali , comparative analysis of some modal reconstruction methods of the shape of the cornea from the corneal elevation data , invest .",
    "50  ( 12 ) ( 2009 ) 56395645 .",
    "a.  martnez - finkelshtein , d.  ramos - lpez , g.  m. castro - luna , j.  l. ali , a new efficient method of corneal reconstruction as an alternative to zernike polynomials fit , invest .",
    "51  ( 5 ) ( 2010 ) arvo e  abstract 5690 .",
    "w.  alkhaldi , d.  r. iskander , a.  m. zoubir , m.  j. collins , enhancing the standard operating range of a placido disk videokeratoscope for corneal surface estimation , ieee trans . biomed .",
    "56  ( 3 ) ( 2009 ) 800809",
    ".        d.  alonso - caneiro , r.  iskander , m.  j. collins , estimating corneal surface topography in videokeratoscopy in the presence of strong signal interference , ieee trans . biomed .",
    "55  ( 10 ) ( 2008 ) 23812387 ."
  ],
  "abstract_text": [
    "<S> in this paper we describe an adaptive and multi - scale algorithm for the parsimonious fit of the corneal surface data that allows to adapt the number of functions used in the reconstruction to the conditions of each cornea . </S>",
    "<S> the method implements also a dynamical selection of the parameters and the management of noise . </S>",
    "<S> it can be used for the real - time reconstruction of both altimetric data and corneal power maps from the data collected by keratoscopes , such as the placido rings based topographers , decisive for an early detection of corneal diseases such as keratoconus .    </S>",
    "<S> numerical experiments show that the algorithm exhibits a steady exponential error decay , independently of the level of aberration of the cornea . </S>",
    "<S> the complexity of each anisotropic gaussian basis functions in the functional representation is the same , but their parameters vary to fit the current scale . </S>",
    "<S> this scale is determined only by the residual errors and not by the number of the iteration . </S>",
    "<S> finally , the position and clustering of their centers , as well as the size of the shape parameters , provides an additional spatial information about the regions of higher irregularity . </S>",
    "<S> these results are compared with the standard approximation procedures based on the zernike polynomials expansions .    </S>",
    "<S> = 1    zernike polynomials ; surface reconstruction ; surface modeling ; corneal irregularities ; gaussian functions ; radial basis functions ; multi - scale methods </S>"
  ]
}