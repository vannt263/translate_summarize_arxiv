{
  "article_text": [
    "given a graph @xmath0,e)$ ] , and a positive parameter @xmath1 the _ ferromagnetic ising model on @xmath2 _ is the pairwise markov random field @xmath3 over binary variables @xmath4 , @xmath5 . apart from being one of the best studied models in statistical mechanics @xcite ,",
    "the ising model is a prototypical undirected graphical model . since the seminal work of hopfield @xcite and hinton and sejnowski @xcite , it has found application in numerous areas of machine learning , computer vision , clustering and spatial statistics .",
    "the obvious generalization of the distribution ( [ eq : isingmodel ] ) to edge - dependent parameters @xmath6 , @xmath7 is of central interest in such applications , and will be introduced in section [ sec : pseudo ] .",
    "let us stress that we follow the statistical mechanics convention of calling ( [ eq : isingmodel ] ) an ising model even if the graph @xmath2 is not a grid .",
    "in this paper we study the following structural learning problem :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ given @xmath8 i.i.d .",
    "samples @xmath9 , @xmath10 ,  ,",
    "@xmath11 with distribution @xmath12 , reconstruct the graph @xmath2 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    for the sake of simplicity , we assume in most of the paper that the parameter @xmath13 is known , and that @xmath2 has no double edges ( it is a ` simple ' graph ) .",
    "we focus therefore on the key challenge of learning the graph structure associated to the measure @xmath12 .",
    "this structure is particularly important for extracting the qualitative features of the model , since it encodes its conditional independence properties .",
    "it follows from the general theory of exponential families that , for any @xmath14 , the model ( [ eq : isingmodel ] ) is identifiable @xcite .",
    "in particular , the structural learning problem is solvable with unbounded sample complexity and computational resources .",
    "the question we address is : for which classes of graphs and values of the parameter @xmath13 is the problem solvable under realistic complexity constraints ? more precisely , given an algorithm @xmath15 , a graph @xmath2 , a value @xmath13 of the model parameter , and a small @xmath16 , the sample complexity is defined as @xmath17 where @xmath18 denotes probability with respect to @xmath8 i.i.d .",
    "samples with distribution @xmath19 .",
    "further , we let @xmath20 denote the number of operations of the algorithm @xmath15 , when run on @xmath21 samples .",
    "the general problem is therefore to characterize the functions @xmath21 and @xmath20 , and to design algorithms that minimize the complexity .",
    "let us emphasize that these are not the only possible definitions of sample and computational complexity .",
    "alternative definitions are obtained by requiring that the reconstructed structure @xmath22 is only partially correct . however , for the algorithms considered in this paper , such definitions should not result in qualitatively different behavior by separately estimating the neighborhood of each node @xmath23 .",
    "this implies that any significant probability of error results in a substantially different graph . ]",
    "general upper and lower bounds on the sample complexity @xmath21 were proved by santhanam and wainwright @xcite , without however taking into account computational complexity . on the other end of the spectrum ,",
    "several low complexity algorithms have been developed in the last few years ( see section [ sec : relatedwork ] for a brief overview ) .",
    "however the resulting sample complexity bounds only hold under specific assumptions on the underlying model ( i.e. on the pair @xmath24 ) . a general understanding of the trade - offs between sample complexity and computational complexity is largely lacking .",
    "this paper is devoted to the study of the tradeoff between sample complexity and computational complexity for some specific structural learning algorithms , when applied to the ising model .",
    "an important challenge consists in the fact that the model ( [ eq : isingmodel ] ) induces subtle correlations between the binary variables @xmath25 .",
    "the objective of a structural learning algorithm is to disentangle pairs @xmath26 that are conditionally independent given the other variables ( and hence are not connected by an edge ) from those that are instead conditionally dependent ( and hence connected by an edge in @xmath2 ) .",
    "this becomes particularly difficult when @xmath13 becomes large and hence pairs @xmath27 , @xmath28 that are not connected by an edge in @xmath2 become strongly dependent . the next section sets the stage for our work by discussing a simple and concrete illustration of this phenomenon .       and @xmath29 whose distributions @xmath30 and @xmath31 merge as @xmath32 gets large . ]    as a toy illustration of the challenges of structural learning , we will study the two families of graphs in figure [ fig : simplegraph ] .",
    "the two families will be denoted by @xmath33 and @xmath34 and are indexed by the number of vertices @xmath32 .",
    "graph @xmath35 has @xmath32 vertices and @xmath36 edges .",
    "two of the vertices ( vertex @xmath37 and vertex @xmath38 ) have degree @xmath39 , and @xmath39 have degree @xmath38 .",
    "graph @xmath29 has also @xmath32 vertices , but only one edge between vertices @xmath37 and @xmath38 . in other words ,",
    "graph @xmath40 corresponds to variables @xmath41 and @xmath42 interacting ` directly ' ( and hence not conditionally independent ) , while graph @xmath35 describes a situation in which the two variables interact ` indirectly ' through numerous weak intermediaries ( but still are conditionally independent since they are not connected ) .",
    "fix @xmath32 , and assume that one of @xmath35 or @xmath29 is chosen randomly and i.i.d .",
    "samples @xmath9, ",
    ",@xmath43 from the corresponding ising distribution are given to us .",
    "can we efficiently distinguish the two graphs , i.e. infer whther the samples were generated using @xmath35 or @xmath29 ? as mentioned above , since the model is identifiable , this task can be achieved with unbounded sample and computational complexity .",
    "further , since model ( [ eq : isingmodel ] ) is an exponential family , the @xmath44 matrix of empirical covariances @xmath45 provides a sufficient statistic for inferring the graph structure .    in this specific example",
    ", we assume that different edge strengths are used in the two graphs : @xmath13 for graph @xmath35 and @xmath46 for graph @xmath40 ( i.e. we have to distinguish between @xmath30 and @xmath31 ) .",
    "we claim that , by properly choosing the parameters @xmath13 and @xmath46 , we can ensure that the covariances approximately match @xmath47 .",
    "indeed the same remains true for all marginals involving a bounded number of variables .",
    "namely , for all subsets of vertices @xmath48 $ ] of bounded size @xmath49 .",
    "low - complexity algorithms typically estimate each edge using only a small subset low  dimensional marginal .",
    "hence , they are bound to fail unless the number of samples @xmath8 diverges with the graph size @xmath32 .",
    "on the other hand , a naive information - theoretic lower bound ( in the spirit of @xcite ) only yields @xmath50 .",
    "this sample complexity is achievable by using global statistics to distinguish the two graphs .    in other words , even for this simple example , a dichotomy emerges : either a number of samples has to grow with the number of parameters , or algorithms have to exploit a large number of marginals of @xmath19 .    to confirm our claim , we need to compute the covariance of the ising measures distributions @xmath30 , @xmath31",
    "we easily obtain , for the latter graph @xmath51 the calculation is somewhat more intricate for graph @xmath35 , so we defer complete formulae to appendix [ sec : toy_examp_comp ] and report here only the result for @xmath52 , @xmath53 : @xmath54 in other words , variables @xmath41 and @xmath42 are strongly correlated ( although not connected ) , while all the other variables are weakly correlated . by letting @xmath55",
    "this covariance structure matches eqs .",
    "( [ eq : simple1 ] ) , ( [ eq : simple2 ] ) up to corrections of order @xmath56 .",
    "notice that the ambiguity between the two models @xmath35 and @xmath29 arises because several weak , indirect paths between @xmath41 and @xmath42 in graph @xmath35 , add up to the same effect as a strong direct connection .",
    "this toy example is hence suggestive of the general phenomenon that strong long - range correlations can ` fake ' a direct connection .",
    "however , the example is not completely convincing for several reasons :    1 .",
    "most algorithms of interest estimate each edge on the basis of a large number of low - dimensional marginals ( for instance _ all _ pairwise correlations ) .",
    "reconstruction guarantees have been proved for graphs with bounded degree @xcite , while here we are letting the maximum degree be as large as the system size .",
    "notice however that a the graph considered here are only sparse ` on average ' .",
    "3 .   it may appear that the difficulty in distinguishing graph @xmath35 from @xmath29 is related to the fact that in the former we take @xmath57 .",
    "this is however the natural scaling when the degree of a vertex is large , in order to obtain a non - trivial distribution .",
    "if the graph @xmath35 had @xmath13 bounded away from @xmath58 , this would result in a distribution @xmath59 concentrated on the two antipodal configurations : all-@xmath60 and all-@xmath61",
    ". structural learning would be equally difficult in this case .    despite these points ,",
    "this model provides already a useful counter - example . in appendix",
    "[ sec : rlf_for_gp ] we will show why , even for bounded @xmath32 ( and hence @xmath13 bounded away from @xmath58 ) the model @xmath35 in figure [ fig : simplegraph ] ` fools ' regularized logistic regression algorithm of ravikumar , wainwright and lafferty @xcite .",
    "regularized logistic regression reconstructs @xmath29 instead of @xmath35 .",
    "the rest of this paper is devoted to bounding the sample complexity @xmath62 and computational complexity @xmath63 for a number of graph models , as a function of @xmath13 .",
    "results of this analysis are presented in section [ sec : results ] for three algorithms : a simple thresholding algorithm , the conditional independence test method of @xcite and the penalized pseudo - likelihood method of @xcite . in section [ sec : num_exper ] , we validate our analysis through numerical simulations . finally , section [ sec : proofs_main ] contains the proofs with some technical details deferred to the appendices .",
    "this analysis unveils a general pattern : _ when the model ( [ eq : isingmodel ] ) develops strong correlations , several low - complexity algorithms fail , or require a large number of samples . _ what does ` strong correlations ' mean ? as the toy example in the previous section demonstrates , correlations arise from a trade - off between the degree ( which we will characterize here via the maximum degree @xmath64 ) , and the interaction strength @xmath13 .",
    "it can be ascribed to a few strong connections ( large @xmath13 ) or to a large number of weak connections ( large @xmath64 ) .",
    "is there any meaningful way to compare and combine these quantities ( @xmath13 and @xmath64 ) ?",
    "an answer is suggested by the theory of gibbs measures which predicts a dramatic change of behavior when @xmath13 crosses the so - called ` uniqueness threshold ' @xmath65 @xcite . for @xmath66 gibbs",
    "sampling mixes rapidly and far apart variables in @xmath2 are roughly independent @xcite .",
    "vice versa , for any @xmath67 there exist graph families on which gibbs sampling is slow , and far apart variables are strongly dependent @xcite .",
    "while polynomial sampling algorithms exists for all @xmath1 @xcite , for @xmath68 , in the regime @xmath69 sampling is arguably @xmath70-p hard @xcite .",
    "related to the uniqueness threshold is also the phase transition threshold , which is graph dependent , with typically @xmath71 .",
    "we will see that this is indeed a relevant way of comparing interaction strength and degree , even for structural learning .",
    "al the algorithms we analyzed ( mentioned above ) provably fail for @xmath72 , for a number of ` natural ' graph families .",
    "our work raises several fascinating questions , the most important being the construction of structural learning algorithm with provable performance guarantees in the strongly dependent regime @xmath73 .",
    "the question as to whether such an algorithm exists is left open by the present paper ( but see next section for an overview of earlier work ) .",
    "let us finally emphasize that we do not think that any of the specific families of graphs studied in the present paper is intrinsically ` hard ' to learn .",
    "for instance , we show below that the regularized logistic regression method of @xcite fails on random regular graphs , while it is easy to learn such graphs using the simple thresholding algorithm of section [ sec : simplethr ] .",
    "the specific families where indeed chosen mostly because they are analytically tractable .",
    "traditional algorithms for learning ising models were developed in the context of boltzmann machines @xcite .",
    "these algorithms try to solve the maximum likelihood problem by gradient ascent . estimating the gradient of the log - likelihood function requires to compute expectations with respect to the ising distribution . in these works ,",
    "this was done using the markov chain monte carlo ( mcmc ) method , and more specifically gibbs sampling .",
    "we shall not consider this approach in our study for two type of reasons .",
    "first of all , it does not output a ` structure ' ( i.e. a sparse subset of the @xmath74 potential edges ) : because of approximation errors , it yields non - zero values for all the edges .",
    "this problem can in principle be overcome by using suitably regularized objective functions , but such a modified algorithm was never studied .",
    "second , the need to compute expectation values with respect to the ising distribution , and the use of mcmc to achieve this goal , poses some fundamental limitations .",
    "as mentioned above , the markov chain commonly used by these methods is simple gibbs sampling .",
    "this is known to have mixing time that grows exponentially in the number of variables for @xmath67 , and hence does not yield good estimates of the expectation values in practice .",
    "while polynomial sampling schemes exist for models with @xmath1 @xcite , they do not apply to @xmath68 or to general models with edge - dependent parameters @xmath6 .",
    "already in the case @xmath68 , estimating expectation values of the ising distribution is likely to be @xmath70-p hard @xcite .",
    "abbeel , koller and ng @xcite first developed a method with computational complexity provably polynomial in the number of variables , for bounded maximum degree , and logarithmic sample complexity .",
    "their approach is based on ingenious use of the hammersley - clifford representation of markov random fields .",
    "unfortunately , the computational complexity of this approach is of order @xmath75 which becomes unpractical for reasonable values of the degree and network size ( and superpolynomial for @xmath64 diverging with @xmath32 ) .",
    "the algorithm by bresler , mossel and sly @xcite studied in section [ sec : localind ] presents similar limitations , that the authors overcome ( in the small @xmath13 regime ) by exploiting the correlation decay phenomenon .",
    "an alternative point of view consists in using standard regression methods . in the context of ising models , ravikumar , wainwright and lafferty",
    "@xcite showed that the neighborhood of a vertex @xmath23 can be efficiently reconstructed by solving an appropriate regularized regression problem .",
    "more precisely , the values of variable @xmath27 are regressed against the value of all the other variables .",
    "the logistic regression log - likelihood is regularized by adding an @xmath76-penalty that promotes the selection of sparse graph structures .",
    "we will analyze this method in section [ sec : pseudo ] .",
    "the approach of @xcite extends to non - gaussian models earlier work by meinshausen and bhlmann @xcite .",
    "let us notice in passing that the case of gaussian graphical models is substantially easier since the log - likelihood of a given model can be evaluated easily in this case @xcite .",
    "a short version of this paper was presented at the 2009 neural information processing systems symposium . since then",
    ", at least two groups explored the challenges put forward in our work .",
    "anandkumar , tan and willsky @xcite prove that , for sequences of random graphs which are sparse on average ( i.e. with bounded average degree ) , structural learning is possible throughout the correlation decay regime @xmath77 .",
    "this result generalizes our analysis of random regular graphs ( see next section ) , to the more challenging case of graphs with random degrees .",
    "cocco and monasson @xcite proposed and ` adaptive cluster ' heuristics and demonstrated empirically good performances for specific graph families , also for @xmath78 .",
    "a mathematical analysis of their approach is lacking .",
    "in order to illustrate the interplay between graph structure , sample complexity and interaction strength @xmath13 , it is instructive to consider a simple example .",
    "the thresholding algorithm reconstructs @xmath2 by thresholding the empirical correlations @xmath79 for @xmath80 .",
    "ll + 1 : & compute the empirical correlations @xmath81 ; + 2 : & for each @xmath82 + 3 : & if @xmath83 , set @xmath7 ; +    we will denote this algorithm by @xmath84 . notice that its complexity is dominated by the computation of the empirical correlations , i.e. @xmath85 . the sample complexity @xmath86 can be bounded for specific classes of graphs as follows ( for proofs see section [ sec : simp_thres_proofs ] ) .    if @xmath2 is a tree , and @xmath87 , then @xmath88 [ th : tresh1 ]    if @xmath2 has maximum degree @xmath89 and if @xmath90 then there exists @xmath91 such that @xmath92 further , the choice @xmath93 achieves this bound.[th : tresh2 ]    there exists a numerical constant @xmath94 such that the following is true .",
    "if @xmath95 and @xmath96 , there are graphs of bounded degree @xmath64 such that for any @xmath97 , @xmath98 , i.e. the thresholding algorithm always fails with high probability .",
    "[ th : tresh3 ]    these results confirm the idea that the failure of low - complexity algorithms is related to long - range correlations in the underlying graphical model .",
    "if the graph @xmath2 is a tree , then correlations between far apart variables @xmath27 , @xmath28 decay exponentially with the distance between vertices @xmath23 , @xmath99 .",
    "hence trees can be learnt from @xmath100 samples irrespectively of their topology and maximum degree ( assuming @xmath101 ) .",
    "the same happens on bounded - degree graphs if @xmath102 .",
    "however , for @xmath103 , there exists families of bounded degree graphs with long - range correlations .      in this section",
    "we characterize @xmath20 and @xmath21 for more advanced algorithms .",
    "we again obtain very distinct behaviors of these algorithms depending on the strength of correlations .",
    "we focus on two type of algorithms and only include the proof of our most challenging result , theorem [ th : mart2 ] ( for the proof see section [ sec : proofmaintheorem ] ) .    in the following",
    "we denote by @xmath104 the neighborhood of a node @xmath105 ( @xmath106 ) , and assume the degree to be bounded : @xmath107 .      a recurring approach to structural learning",
    "consists in exploiting the conditional independence structure encoded by the graph @xcite .",
    "let us consider , to be definite , the approach of @xcite , specializing it to the model ( [ eq : isingmodel ] ) .",
    "fix a vertex @xmath108 , whose neighborhood we want to reconstruct , and consider the conditional distribution of @xmath109 given its neighbors is a vector and @xmath110 is a set of indices then we denote by @xmath111 the vector formed by the components of @xmath112 with index in @xmath110 . ] : @xmath113 .",
    "any change of @xmath27 , @xmath114 , produces a change in this distribution which is bounded away from @xmath58 .",
    "let @xmath115 be a candidate neighborhood , and assume @xmath116 . then changing the value of @xmath28",
    ", @xmath117 will produce a noticeable change in the marginal of @xmath118 , even if we condition on the remaining values in @xmath115 and in any @xmath119 , @xmath120 . on the other hand , if @xmath121 , then it is possible to find @xmath119 ( with @xmath120 ) and a node @xmath122 such that , changing its value after fixing all other values in @xmath123 will produce no noticeable change in the conditional marginal .",
    "( just choose @xmath124 and @xmath125 ) .",
    "this procedure allows us to distinguish subsets of @xmath126 from other sets of vertices , thus motivating the following algorithm .",
    "ll + 1 : & select a node @xmath127 ; + 2 : & set as its neighborhood the largest candidate neighbor @xmath115 of + & size at most @xmath64 for which the score function @xmath128 ; + 3 : & repeat for all nodes @xmath127 ; +    the score function @xmath129 depends on @xmath130 and is defined as follows , @xmath131 in the minimum , @xmath132 and @xmath117 . in the maximum",
    ", the values must be such that @xmath133 @xmath134 is the empirical distribution calculated from the samples @xmath135 .",
    "we denote this algorithm by @xmath136 . the search over candidate neighbors @xmath115 , the search for minima and maxima in the computation of the @xmath137 and the computation of @xmath134 all contribute for @xmath138 .    both theorems that follow",
    "are consequences of the analysis of @xcite , hence omitted .",
    "let @xmath2 be a graph of bounded degree @xmath139 .",
    "for every @xmath13 there exists @xmath140 , and a numerical constant @xmath94 , such that @xmath141 more specifically , one can take @xmath142 , @xmath143.[th : mossel1 ]    this first result implies in particular that @xmath2 can be reconstructed with polynomial complexity for any bounded @xmath64 .",
    "however , the degree of such polynomial is pretty high and non - uniform in @xmath64 .",
    "this makes the above approach impractical .    a way out was proposed in @xcite .",
    "the idea is to identify a set of ` potential neighbors ' of vertex @xmath108 via thresholding : @xmath144 for each node @xmath127 , we evaluate @xmath137 by restricting the minimum in eq .",
    "( [ eq : scoredef ] ) over @xmath145 , and search only over @xmath146 .",
    "we call this algorithm @xmath147 . the basic intuition here is that @xmath148 decreases rapidly with the graph distance between vertices @xmath108 and @xmath23 . as mentioned above , this is true at low temperature .",
    "let @xmath2 be a graph of bounded degree @xmath139 .",
    "assume that @xmath149 for some small enough constant @xmath94 .",
    "then there exists @xmath150 such that @xmath151 more specifically , we can take @xmath152 , @xmath142 and @xmath143 .",
    "[ th : mossel2 ]      a different approach to the learning problem consists in maximizing an appropriate empirical likelihood function @xcite . in order to control statistical fluctuations , and select sparse graphs ,",
    "a regularization term is often added to the cost function .",
    "as a specific low complexity implementation of this idea , we consider the @xmath76-regularized pseudo - likelihood method of @xcite .",
    "for each node @xmath108 , the following likelihood function is considered @xmath153 where @xmath154 is the vector of all variables except @xmath109 and @xmath155 is defined from the following extension of ( [ eq : isingmodel ] ) , @xmath156 where @xmath157 is a vector of real parameters .",
    "model ( [ eq : isingmodel ] ) corresponds to @xmath158 and @xmath159 .",
    "the function @xmath160 depends only on @xmath161 and is used to estimate the neighborhood of each node by the following algorithm , @xmath162 ,    ll + 1 : & select a node @xmath127 ; + 2 : & calculate @xmath163 ; [ eq : rlr_conv_prob ] + 3 : & if @xmath164 , set @xmath165 ; +    our first result shows that @xmath162 indeed reconstructs @xmath2 if @xmath13 is sufficiently small .",
    "there exists numerical constants @xmath166 , @xmath167 , @xmath168 , such that the following is true .",
    "let @xmath2 be a graph with degree bounded by @xmath169 .",
    "if @xmath170 , then there exist @xmath171 such that @xmath172 further , the above holds with @xmath173.[th : mart1 ]    this theorem is proved by noting that for @xmath170 correlations decay exponentially , which makes all conditions in theorem 1 of @xcite ( denoted there by a1 and a2 ) hold , and then computing the probability of success as a function of @xmath8 with slightly more care .",
    "the details of the proof are written in appendix [ sec : succ_reg_log_reg ] .    in order to prove a converse to the above result",
    ", we need to make some assumptions on @xmath171 .    given @xmath1",
    ", we say that @xmath171 is _ reasonable _ for that value of @xmath13 if the following conditions hold : @xmath174 @xmath162 is successful with probability larger than @xmath175 on any star graphs ( a graph composed by a vertex @xmath108 connected to @xmath64 neighbors , plus isolated vertices ) if @xmath8 is chosen sufficiently high ; @xmath176 @xmath177 for some sequence @xmath178 .    in other words ,",
    "assumption @xmath174 requires the algorithm to be successful on a particularly simple class of graphs , and hence does not entail any loss of generality .",
    "assumption @xmath176 encodes instead the standard way of scaling regularization terms , by letting them vanish as the number of samples increases .",
    "this is necessary in order to get asymptotic consistency of the parameter values @xmath6 . with these assumptions we can state the following converse theorem ,",
    "whose proof is deferred to section [ sec : proofmaintheorem ] .",
    "there exists a numerical constant @xmath94 such that the following happens .",
    "if @xmath96,@xmath179 , then there exists graphs @xmath2 of degree bounded by @xmath64 such that for all reasonable @xmath171 , @xmath180 , i.e. regularized logistic regression fails with high probability .",
    "[ th : mart2 ]    the graphs for which regularized logistic regression fails are not contrived examples .",
    "indeed , as part of the proof of theorem [ th : mart2 ] , and as proved in appendix [ sec : inco_other_graphs ] , we have the following facts about @xmath162 :    * if @xmath2 is a tree , then @xmath162 recover @xmath2 with high probability for any @xmath13 ( for a suitable @xmath171 ) ; * for every graph @xmath35 in the family described in section [ sec : toy_example ] , @xmath162 fails with high probability for @xmath13 large enough and for all @xmath171 ; * if @xmath2 is sampled uniformly from the ensemble of regular graphs @xmath162 fails with high probability for @xmath13 large enough and @xmath171 ` reasonable ' ; * if @xmath2 is a large two dimensional grid it fails with high probability for @xmath13 large enough and @xmath171 ` reasonable ' .",
    "we note here that theorem [ th : mart2 ] relies on proving that a so - called ` incoherence condition ' is necessary for @xmath181 to successfully reconstruct @xmath2 .",
    "although a similar result was proven in @xcite for model selection using the lasso , this paper is the first to prove that a similar incoherence condition is also necessary when the underlying model is the ising model .",
    "the intuition behind this is quite simple .",
    "begin by noticing that when @xmath182 , and under the restriction that @xmath183 , solutions given by @xmath181 converge to @xmath184 as @xmath182 @xcite .",
    "hence , for large @xmath8 , we can expand @xmath185 in a quadratic function centered around @xmath184 plus a small stochastic error term .",
    "consequently , when adding the regularization term to @xmath185 , we obtain cost function analogous to the lasso plus an error term that needs to be controlled .",
    "the study of the dominating contribution leads to the incoherence condition .",
    "in general there are no practical ways to evaluate the incoherence condition for a given graphical model .",
    "this requires in fact to compute expectations with respect to the ising distribution . as discussed above , this is hard for @xmath186 .",
    "hence this condition was not checked for families of graphs .",
    "a large part of our technical contribution consists indeed in filling this gap . to this end , we use tools from mathematical statistical mechanics , namely low temperature series for ising models on grids @xcite , and local weak convergence results for ising models on random graphs @xcite .",
    "in order to explore the practical relevance of the above results , we carried out extensive numerical simulations using the regularized logistic regression algorithm @xmath162 . among other learning algorithms ,",
    "@xmath162 strikes a good balance of complexity and performance .",
    "samples from the ising model ( [ eq : isingmodel ] ) where generated using gibbs sampling ( a.k.a .",
    "glauber dynamics ) . mixing time can be very large for @xmath187 , and was estimated using the time required for the overall bias to change sign ( this is a quite conservative estimate at low temperature ) .",
    "generating the samples @xmath188 was indeed the bulk of our computational effort and took about @xmath189 days cpu time on pentium dual core processors .",
    "notice that @xmath162 had been tested in @xcite only on tree graphs @xmath2 , or in the weakly coupled regime @xmath190 . in these cases sampling from the ising model is easy , but structural learning is also intrinsically easier .",
    "( @xmath191 ) two - dimensional grid from @xmath192 ising models samples , using regularized logistic regression .",
    "left : success probability as a function of the model parameter @xmath13 and of the regularization parameter @xmath193 ( darker corresponds to highest probability ) .",
    "right : the same data plotted for several choices of @xmath171 versus @xmath13 .",
    "the vertical line corresponds to the model critical temperature .",
    "the thick line is an envelope of the curves obtained for different @xmath171 , and should correspond to optimal regularization.,title=\"fig : \" ]   ( @xmath191 ) two - dimensional grid from @xmath192 ising models samples , using regularized logistic regression .",
    "left : success probability as a function of the model parameter @xmath13 and of the regularization parameter @xmath193 ( darker corresponds to highest probability ) .",
    "right : the same data plotted for several choices of @xmath171 versus @xmath13 .",
    "the vertical line corresponds to the model critical temperature .",
    "the thick line is an envelope of the curves obtained for different @xmath171 , and should correspond to optimal regularization.,title=\"fig : \" ] ( -525,115)@xmath193 ( -390,10)@xmath13 ( -120,-5)@xmath13 ( -250,100)p@xmath194    figure reports the success probability of @xmath162 when applied to random subgraphs of a @xmath195 two - dimensional grid .",
    "each such graphs was obtained by removing each edge independently with probability @xmath196 .",
    "success probability was estimated by applying @xmath162 to each vertex of @xmath197 graphs ( thus averaging over @xmath198 runs of @xmath162 ) , using @xmath192 samples .",
    "we scaled the regularization parameter as @xmath199 ( this choice is motivated by the algorithm analysis @xcite and is empirically the most satisfactory ) , and searched over @xmath193 .",
    "the data clearly illustrate the phenomenon discussed in the previous pages . despite the large number of samples @xmath200 ,",
    "when @xmath13 crosses a threshold , the algorithm starts performing poorly irrespective of @xmath171 .",
    "intriguingly , this threshold is not far from the critical point of the ising model on a randomly diluted grid @xmath201 @xcite .     from ising models samples , using regularized logistic regression . left : success probability as a function of the number of samples @xmath8 for several values of @xmath13 .",
    "dotted : @xmath202 , @xmath203 , @xmath204 , @xmath205 , @xmath206 ( in all these cases @xmath207 ) . dashed : @xmath208 , @xmath209 , @xmath210 , @xmath211 , @xmath212 ( @xmath213 , some of these are indistinguishable from the axis ) .",
    "right : the same data plotted for several choices of @xmath171 versus @xmath13 as in fig .",
    "[ fig : grid ] , right panel.,title=\"fig : \" ]   from ising models samples , using regularized logistic regression . left : success probability as a function of the number of samples @xmath8 for several values of @xmath13 .",
    "dotted : @xmath202 , @xmath203 , @xmath204 , @xmath205 , @xmath206 ( in all these cases @xmath207 ) . dashed : @xmath208 , @xmath209 , @xmath210 , @xmath211 , @xmath212 ( @xmath213 , some of these are indistinguishable from the axis ) .",
    "right : the same data plotted for several choices of @xmath171 versus @xmath13 as in fig .",
    "[ fig : grid ] , right panel.,title=\"fig : \" ] ( -500,100)p@xmath194 ( -390,125)@xmath202 ( -435,110)@xmath214 ( -310,105)@xmath208 ( -310,32)@xmath208 ( -360,-5)@xmath8 ( -100,-5)@xmath13 ( -250,100)p@xmath194    figure [ fig : randomg ] presents similar data when @xmath2 is a uniformly random graph of degree @xmath215 , over @xmath216 vertices .",
    "the evolution of the success probability with @xmath8 clearly shows a dichotomy .",
    "when @xmath13 is below a threshold , a small number of samples is sufficient to reconstruct @xmath2 with high probability . above the threshold",
    "even @xmath217 samples are to few . in this case",
    "we can predict the threshold analytically , cf .",
    "lemma [ th : mart23 ] below , and get @xmath218 , which compares favorably with the data .",
    "before proceeding it is convenient to introduce some notation and make some important remarks .",
    "if @xmath219 is a matrix and @xmath110 is an index set then @xmath220 denotes the vector formed by all entries whose index lies in @xmath110 and similarly , if @xmath221 is a matrix and @xmath222 are index sets then @xmath223 denotes the submatrix with row indices in @xmath110 and column indices in @xmath224 . as before , we let @xmath108 be the vertex whose neighborhood we are trying to reconstruct and define @xmath225 and @xmath226 . since the cost function @xmath227 only depends on @xmath228 through its components",
    "@xmath229 , we will hereafter neglect all the other parameters and write @xmath228 as a shorthand of @xmath230 .",
    "let @xmath231 be a subgradient of @xmath232 evaluated at the true parameters values , @xmath233 .",
    "let @xmath234 be the parameter estimate returned by @xmath162 when the number of samples is @xmath8 .",
    "note that , since we assumed @xmath235 , we have @xmath236 and hence @xmath237 .",
    "define @xmath238 to be the hessian of @xmath239 and @xmath240 . by the law of large numbers @xmath241 exists",
    "is the hessian of @xmath242 where @xmath243 is the expectation with respect to ( [ eq : isingmodel2 ] ) and @xmath244 is a random variable distributed according to ( [ eq : isingmodel2 ] ) .",
    "it is convenient to recall here the expressions for the hessian and gradient of @xmath185 for finite @xmath8 and in the limit when @xmath182 . for all @xmath245 we have , @xmath246_i & = \\frac{1}{n } \\sum^n_{\\ell = 1 } x^{(\\ell)}_i \\big(\\tanh \\big(\\sum_{t \\in v \\backslash \\{r\\ } } \\theta_{rt } x^{(\\ell)}_t \\big ) -   x^{(\\ell)}_r\\big),\\\\ [ \\nabla l(\\utheta)]_i & = \\e_{g,\\utheta^ * } \\big\\ { x_i \\tanh \\big(\\sum_{t \\in v \\backslash \\{r\\ } } \\theta_{rt } x_t   \\big ) \\big\\ } - \\e_{g,\\utheta^ * } \\ { x_i x_r \\ } \\label{eq : grad_expression}.\\end{aligned}\\ ] ] note that from the last expression it follows that @xmath247 .",
    "we will denote the maximum and minimum eigenvalue of a symmetric matrix @xmath221 by @xmath248 and @xmath249 respectively .",
    "recall that @xmath250 .",
    "we will omit arguments whenever clear from the context . any quantity evaluated at the true parameter values",
    "will be represented with a @xmath251 , e.g. @xmath252 .",
    "quantities under a @xmath253 depend on @xmath8 .",
    "when clear from the context and since all the examples that we work on have @xmath254 } , we will write @xmath255 as @xmath243 or even simply @xmath256 . similarly , @xmath155 will be sometimes written as simply @xmath257 or just @xmath258 .",
    "a subscript @xmath8 under @xmath155 , i.e. @xmath259 , will be introduced to denote the product measure formed by @xmath8 copies of model . through out",
    "this section @xmath260 will denote the probability of success of a given algorithm , that is , the probability that the algorithm is able to recover the underlying @xmath2 exactly .    throughout this section",
    "@xmath2 is a graph of maximum degree @xmath64 .      in the following",
    "we let @xmath261 where expectation is taken with respect to the ising model .",
    "( theorem [ th : tresh1 ] ) if @xmath2 is a tree then @xmath262 for all @xmath263 and @xmath264 for all @xmath265 . to see this notice that only paths that connect @xmath23 to @xmath99 contribute to @xmath266 and given that @xmath2 is a tree there is only one such path and its length is exactly 1 if @xmath267 and at least 2 when @xmath268 .",
    "the probability that @xmath84 fails is @xmath269 let @xmath270 . applying azuma - hoeffding inequality to @xmath271 we have that if @xmath267 then , @xmath272 and if @xmath268 then similarly , @xmath273 applying union bound over the two possibilities , @xmath267 or @xmath268 , and over the edges ( @xmath274 ) , we can bound @xmath260 by @xmath275 imposing the right hand side to be larger than @xmath276 proves our result .",
    "( theorem [ th : tresh2 ] ) we will prove that , for @xmath277 , @xmath278 for all @xmath267 and @xmath279 for all @xmath280 .",
    "in particular @xmath281 for all @xmath268 and all @xmath282 .",
    "the theorem follows from this fact via union bound and azuma - hoeffding inequality as in the proof of theorem [ th : tresh1 ] .",
    "the bound @xmath278 for @xmath263 is a direct consequence of griffiths inequality @xcite : compare the expectation of @xmath283 in @xmath2 with the same expectation in the graph that only includes edge @xmath284 .",
    "the second bound is derived using the technique of @xcite , i.e. , bound @xmath266 by the generating function for self - avoiding walks on the graphs from @xmath23 to @xmath99 .",
    "more precisely , assume @xmath285 and denote by @xmath286 the number of self avoiding walks of length @xmath287 between @xmath23 and @xmath99 on @xmath2 .",
    "then @xcite proves that @xmath288 if @xmath289 the above implies @xmath290 which is our claim .",
    "( theorem [ th : tresh3 ] ) the theorem is proved by constructing @xmath2 as follows : sample a uniformly random regular graph of degree @xmath64 over the @xmath291 vertices @xmath292 $ ] .",
    "add an extra edge between nodes @xmath293 and @xmath32 .",
    "the resulting graph is not connected .",
    "we claim that for @xmath294 and with probability converging to @xmath37 as @xmath295 , there exist @xmath296 $ ] such that @xmath297 and @xmath298 . as a consequence",
    ", thresholding fails .",
    "obviously @xmath299 .",
    "choose @xmath300 $ ] uniformly at random , and @xmath99 a node at a fixed distance @xmath301 from @xmath23 .",
    "we can compute @xmath266 as @xmath295 using the same local weak convergence result as in the proof of lemma [ th : mart23 ] .",
    "namely , @xmath266 converges to the correlation between the root and a leaf node in the tree ising model .",
    "in particular one can show , @xcite , that @xmath302 where @xmath303 and @xmath304 is the unique positive solution of eq . .",
    "the proof is completed by showing that @xmath305 for all @xmath306 .      in order to prove theorem [ th : mart2 ] , we need a few auxiliary results .",
    "our first auxiliary results establishes that , if @xmath171 is small , then @xmath307 is a sufficient condition for the failure of @xmath162 .",
    "we recall here that the subgradient of @xmath308 evaluated at @xmath184,that is @xmath231 , satisfies @xmath309 .",
    "assume @xmath310_i \\geq 1 + \\epsilon$ ] for some @xmath311 and some row @xmath312 , @xmath313 , and @xmath314 .",
    "then the success probability of @xmath162 is upper bounded as @xmath315 where @xmath316 and @xmath317 .",
    "[ th : mart21 ]    the next lemma implies that , for @xmath171 to be ` reasonable ' ( in the sense introduced in section [ sec : pseudo ] ) , @xmath318 must be unbounded with respect to @xmath32 . in fact , by this lemma , if we choose @xmath8 to be very large and choose a sequence of star graphs of increasing number of nodes but with only one edge between the central node and the remaining nodes , then , unless @xmath94 is increasing with @xmath32 , @xmath162 will fail to reconstruct the graph with a probability greater than @xmath175 , which is a contradiction if @xmath171 is ` reasonable ' .",
    "there exist @xmath319 decreasing with @xmath94 for @xmath1 such that the following is true : if @xmath2 is the ( star ) graph with vertex set @xmath320 $ ] and edge set @xmath321 ( e.g. @xmath322 , @xmath323 ) and @xmath324 , then @xmath325 [ th : mart22 ]    finally , our key result shows that the condition @xmath326 is violated with high probability for large random graphs .",
    "the proof of this result relies on a local weak convergence result for ferromagnetic ising models on random graphs proved in @xcite .",
    "[ th : key_result_reg_graph ] let @xmath2 be a uniformly random regular graph of degree @xmath179 .",
    "then , there exists @xmath327 such that , for @xmath328 , @xmath329 with probability converging to @xmath37 as @xmath295 ( @xmath330 and @xmath331 as @xmath332 ) .",
    "furthermore , for large @xmath64 , @xmath333 .",
    "the constant @xmath334 is given by @xmath335 and @xmath336 is the unique positive solution of @xmath337 [ th : mart23 ] finally , there exist @xmath338 dependent only on @xmath64 and @xmath13 such that @xmath339 with probability converging to @xmath37 as @xmath295 .",
    "the proofs of lemmas [ th : mart21 ] , [ th : mart22 ] and [ th : mart23 ] are sketched in the next subsection .",
    "( theorem [ th : mart2 ] ) fix @xmath179 , @xmath340 ( where @xmath94 is a large enough constant independent of @xmath64 ) , and @xmath341 and both small enough . by lemma",
    "[ th : mart23 ] , for any @xmath32 large enough we can choose a @xmath64-regular graph @xmath342,e_p)$ ] and vertex @xmath343 such that @xmath344 for some @xmath345 ( indeed most vertices @xmath108 and graphs @xmath35 will work ) .    by theorem 1 in @xcite",
    "we can assume without loss of generality @xmath346 for some small constant @xmath347 .",
    "further by lemma [ th : mart22 ] , @xmath348 for some @xmath349 as @xmath295 and the condition of lemma [ th : mart21 ] on @xmath171 is satisfied since by the assumption that @xmath171 is ` reasonable ' we have @xmath350 as @xmath182 . using these results in eq .",
    "( [ th : mart21prob ] ) of lemma [ th : mart21 ] we get the following upper bound on the success probability @xmath351 in particular @xmath352 as @xmath295 .",
    "( lemma [ th : mart21 ] ) this proof follows closely the proof of proposition 1 in @xcite . for a matter of clarify of exposition",
    "we will include all the steps , even if these do not differ from the exposition done in @xcite .",
    "we will show that ( under the assumptions of the lemma on the incoherence condition , @xmath353 and @xmath171 ) if @xmath354 with @xmath355 then the probability that @xmath162 returns @xmath356 is upper bounded as in eq .  . more specifically , we will show that this @xmath356 will not satisfy the stationarity condition @xmath357 with high probability for any subgradient @xmath358 of the function @xmath232 at @xmath356 .    to simplify notation",
    "we will omit @xmath188 in all the expressions involving and derived from @xmath185 .    assume the event @xmath357 holds for some @xmath356 as specified above .",
    "an application of the mean value theorem yields @xmath359 = w^n   - \\lambda \\hat{z } - r^n\\ , , \\ ] ] where @xmath360 and @xmath361_j = [ \\nabla^2 l ( \\bar{\\utheta}^{(j ) } )",
    "- \\nabla^2 l ( \\utheta^*)]_j^t ( \\hat{\\utheta } - \\utheta^*)$ ] with @xmath362 a point in the line from @xmath363 to @xmath184 .",
    "notice that by definition @xmath364 . to simplify notation we will omit the @xmath365 in all @xmath366 .",
    "all @xmath367 in this proof are thus evaluated at @xmath184 .    breaking this expression into its @xmath368 and @xmath369 components and since @xmath370",
    "we can write @xmath371 eliminating @xmath372 from the two expressions we obtain @xmath373 - q^n_{s^c s}(q^n_{ss})^{-1 } [ w^n_s - r^n_s ] + \\lambda   q^n_{s^c s}(q^n_{ss})^{-1 } \\hat{z}_s = \\lambda \\hat{z}_{s^c}\\ , .\\ ] ] now notice that @xmath374 where @xmath375\\ , , \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\ ; t_2   =   [ q^n_{s^c s } - q^*_{s^c s } ] { q^*_{ss}}^{-1}\\ , , \\\\ t_3 & =   [ q^n_{s^c s } - q^*_{s^c s } ] [ ( q^n_{ss})^{-1 } - ( q^*_{ss})^{-1}]\\ , , \\;\\;\\;\\;\\;\\;\\;\\;\\;\\ ; t_4   =   q^*_{s^cs } { q^*_{ss}}^{-1 }   \\ , .\\end{aligned}\\ ] ] recalling that @xmath376 and using the above decomposition we can lower bound the absolute value of the indexed-@xmath23 component of @xmath377 by @xmath378_i \\|   \\left ( \\big\\|   \\frac{w^n_s}{\\lambda } \\big\\|_\\infty + \\big\\| \\frac{r^n_s}{\\lambda}\\big\\|_\\infty   \\right ) . \\nonumber\\end{aligned}\\",
    "] ] we will now assume that the samples @xmath379 are such that the following event holds ( notice that @xmath380 ) , @xmath381 where @xmath382 and @xmath383 .    from relations",
    "to in section [ sec : notation_remarks ] we know that @xmath384 , @xmath385 and that both @xmath386 and @xmath387 are sums i.i.d .",
    "random variables bounded by 2 . from this , a simple application of azuma - hoeffding inequality yields .",
    "@xmath388 for all @xmath23 and @xmath99 .",
    "applying union bound we conclude that the event @xmath389 holds with probability at least @xmath390 where @xmath391 and @xmath392 .    if the event @xmath389 holds then @xmath393 . since @xmath394_i\\|_{\\infty } \\leq \\|{q^n_{ss}}^{-1}\\|_2 \\|q^n_{s i}\\|_2 $ ] and @xmath395 we can write @xmath394_i\\|_{\\infty } \\leq 2 \\sqrt{\\delta } / c_{\\min}$ ] and simplify our lower bound to @xmath396 the proof is completed by showing that the event @xmath389 and the assumptions of the theorem imply that each of last @xmath397 terms in this expression is smaller than @xmath398 .",
    "since @xmath399_i^t \\hat{z}^n_s|\\ge 1+\\eps$ ] by assumption , this implies @xmath400 which can not be true since any subgradient of the @xmath37-norm has components of magnitude at most @xmath37 .",
    "taking into account that @xmath401 and that @xmath89 , the last condition on @xmath389 immediately bounds all terms involving @xmath387 by @xmath398 .",
    "some straightforward manipulations imply ( see lemma 7 from @xcite for a similar computation ) @xmath402_i\\|_\\infty\\ , , \\\\",
    "\\|t_{3,i } \\|_1 & \\leq \\frac{2 \\delta}{c_{\\rm min}^2 } \\|q^n_{ss } - q^*_{ss}\\|_\\infty    \\|[q^n_{s^c s } - q^*_{s^c s}]_i\\|_\\infty \\ , , \\end{aligned}\\ ] ] and thus , again making use of the fact that @xmath403 , all will be bounded by @xmath398 when @xmath389 holds .",
    "the final step of the proof consists in showing that if @xmath389 holds and @xmath171 satisfies the condition given in the lemma enunciation then the terms involving @xmath404 will also be bounded above by @xmath398 . the details of this calculation are included in appendix [ sec : bound_on_r_n ] .",
    "( lemma [ th : mart23 ] . )",
    "let us state explicitly the local weak convergence result mentioned in sec .",
    "[ sec : proofmaintheorem ] right before our statement of lemma [ th : mart23 ] .",
    "for @xmath405 , let @xmath406 be the regular rooted tree of degree @xmath64 of @xmath301 generations and define the associated ising measure as @xmath407 here @xmath408 is the set of leaves of @xmath409 and @xmath304 is the unique positive solution of @xmath410 it was proved in @xcite that non - trivial local expectations with respect to @xmath411 converge to local expectations with respect to @xmath412 , as @xmath295 .",
    "more precisely , let @xmath413 denote a ball of radius @xmath301 around node @xmath414 ( the node whose neighborhood we are trying to reconstruct ) .",
    "for any fixed @xmath301 , the probability that @xmath413 is not isomorphic to @xmath409 goes to @xmath58 as @xmath295 .",
    "let @xmath415 be any function of the variables in @xmath413 such that @xmath416 .",
    "then almost surely over graph sequences @xmath35 of uniformly random regular graphs with @xmath32 nodes ( expectations here are taken with respect to the measures ( [ eq : isingmodel ] ) and ( [ isingtree ] ) ) @xmath417 notice that this characterizes expectations completely since if @xmath418 then , @xmath419 the proof consists in considering @xmath420_i$ ] for @xmath421 bounded .",
    "we then write @xmath422 and @xmath423 for some functions @xmath424 and apply the weak convergence result ( [ eq : weak ] ) to these expectations .",
    "we thus reduced the calculation of @xmath420_i$ ] to the calculation of expectations with respect to the tree measure ( [ isingtree ] ) .",
    "the latter can be implemented explicitly through a recursive procedure , with simplifications arising thanks to the tree symmetry and by taking @xmath425 .",
    "the actual calculations consist in a ( very ) long exercise in calculus and is deferred to appendix [ sec : rand_reg_incoh_cond ] .",
    "the lower bound on @xmath426 is proved by a similar calculation .",
    "this work was partially supported by a terman fellowship , the nsf career award ccf-0743978 and the nsf grant dms-0806211 and by a portuguese doctoral fct fellowship .",
    "in this section we compute the covariance matrix for the ising model on the graph @xmath35 introduced within the toy example of section [ sec : toy_example ] , see fig .",
    "[ fig : simplegraph ] . in fact we only need to compute @xmath427 , @xmath428 and @xmath429 , since all other covariances reduce to one of these tree by symmetry",
    ". first recall that by @xcite we can write the correlation between @xmath27 and @xmath28 as follows @xmath430 where:@xmath174 @xmath431 is the set of all subsets of edges of graphs of @xmath2 with odd number of edges adjacent to node @xmath23 and @xmath99 and even number of edges adjacent to every other node ; @xmath176 @xmath432 is the set of all subsets of edges of @xmath2 with even number of edges in all nodes ; @xmath433 @xmath434 is the number of edges in @xmath435 .",
    "expression implies three basic facts that we will use to compute the correlations of @xmath35 .",
    "some of these observations can be proved in different and maybe simpler ways but for a matter of unity , we will explain them from the point of view of .    first , if @xmath436 are two nodes in a graph @xmath2 and @xmath437 two nodes in a graph @xmath438 and we ` glue ' @xmath99 and @xmath287 together ( i.e. we fix @xmath439 ) to form a new graph @xmath440 ( see figure [ fig : comp_corr ] ( a ) ) then @xmath441    second , if instead we ` glue ' @xmath23 with @xmath287 and @xmath99 with @xmath442 ( i.e. we fix @xmath443 and @xmath444 ) ( see figure [ fig : comp_corr ] ( b ) ) then @xmath445 note that in this second case we are computing @xmath446 and not @xmath447 .    finally , if @xmath2 is the square graph formed by nodes @xmath448 and edge set @xmath449 and @xmath438 is some other graph to which nodes @xmath23 and @xmath99 belong and we ` glue ' node @xmath37 with @xmath23 and node @xmath38 with @xmath99 ( i.e. @xmath450 and @xmath451 ) to form @xmath440 ( see figure [ fig : comp_corr ] ( c ) ) then @xmath452    ( -385,7)@xmath453 ( -300,7)@xmath454 ( -430,15)@xmath23 ( -343,15)@xmath455 ( -245,15)@xmath442 ( -230,42)@xmath456 ( -127,42)@xmath457 ( -175,55)@xmath453 ( -175,10)@xmath454 ( -102,45)@xmath458 ( -54,97)@xmath459 ( 2,45)@xmath460 ( -42,-2)@xmath461 ( -83,70)@xmath453 ( -54,45)@xmath454    with these three relationships we can quickly compute @xmath462 , @xmath428 and @xmath463",
    ". let @xmath464 and note that from we have that @xmath465 .",
    "since @xmath35 is formed by @xmath291 copies of @xmath466 glued in ` parallel ' in between nodes 1 and 2 , by we have that @xmath467 .",
    "now notice that @xmath35 can also be seen as a single edge connecting 1 and 3 in parallel with the graph formed by connecting in series the edge @xmath468 to a copy of @xmath469 .",
    "this tells us that @xmath470 .",
    "finally , we can also see @xmath35 as a square graph formed by nodes @xmath471 and edges @xmath449 to which we add @xmath472 as a ` bridge ' in between nodes 1 and 2 . making use of we get that @xmath473 from these closed form expressions it is now easy to obtain the behavior of the correlations for the regime @xmath474 and @xmath475 .",
    "( theorem [ th : mart1 ] ) the proof of this theorem consists in verifying the conditions of theorem 1 in @xcite ( denoted there by a1 and a2 ) and computing the probability of success as a function of @xmath8 with slightly more care .    in",
    "what follows , @xmath476 is a lower bound for @xmath426 and @xmath477 is an upper bound for @xmath478    we define @xmath479 and @xmath480 is the minimum absolute value of the components of @xmath184 . throughout this proof",
    "we will have @xmath481 and @xmath482 denote @xmath483 and @xmath484 respectively and @xmath485 .    consider the event , @xmath486 , that the following conditions hold ( these conditions are part of the conditions required for theorem 1 in @xcite to be applicable and are labeled by the names of the theorems that use them that help proving theorem 1 ) , @xmath487 @xmath488    note that these conditions imply that @xmath489 , @xmath490 and also , from the proof of proposition 1 in @xcite , they imply that without loss of generality we can assume @xmath491 . since the assumption @xmath492 follows from the assumption of lemma 5 in @xcite , all assumptions are in fact assumptions on the proximity , under different norms , of empirical vectors and matrices to their correspondent mean values .",
    "having the definition of @xmath486 in mind we beging by noting that theorem 1 can be rewritten in the following form .",
    "if @xmath493 , @xmath494 , @xmath495 and @xmath486 holds then will not fail.[th : refor_theom_1_martin ]    a straightforward application of azuma s inequality yields the following upper bound on the probability of these assumptions not occurring together , ( the first three terms are for the conditions involving matrix @xmath496 and the fourth with the event dealing with matrix @xmath119 ) , @xmath497 where @xmath498 under the assumption that @xmath499 for @xmath166 small enough we now calculate lower bounds for @xmath500 and @xmath501 and upper bound for @xmath502 which will allow us to verify the condition of theorem [ th : refor_theom_1_martin ] and simplify expression for the upper bound on @xmath503 .    first notice that by we have @xmath504 where @xmath505 .",
    "since @xmath506 and because @xmath507 we have , @xmath508 .",
    "now write @xmath509 and notice that by @xmath496 is a symmetric matrix whose values are non - negative and smaller than @xmath510 .",
    "since @xmath511 for some unit norm vector @xmath512 and since , by cauchy ",
    "schwarz inequality , we have @xmath513 , it follows that @xmath514 . consequently , @xmath515 . with the bound , and again for @xmath166 small",
    ", we can write @xmath516 a similar calculation yields @xmath517 .    for @xmath166 small enough , and looking at the bounds just obtained for @xmath500 and @xmath518 , the restriction on @xmath171 in theorem [ th : refor_theom_1_martin ] , namely @xmath519 can be simplified to @xmath520 .",
    "choosing @xmath521 it is easy to see we can simplify the expression for the probability upper bound and write @xmath522 for some constant @xmath167 which in turn implies the bound on @xmath523 .",
    "( lemma [ th : mart21 ] ) we outline here the upper bound on the term @xmath404 . note that we are omitting the samples @xmath524 in the argument of function @xmath185 and we are representing @xmath525 by @xmath228 .",
    "this proof is just a replica and fusion of lemmas 3 and 4 in @xcite . through out this proof we have @xmath526 .",
    "first we write , @xmath527^t_j [ \\hutheta - \\utheta^ * ] \\\\ & = \\frac{1}{n } \\sum^n_{i = 1 } [ \\eta(\\bar{\\utheta}^{(j ) } ) - \\eta(\\utheta^ * ) ] [ x^{(i ) } \\ , { x^{(i)}}^t]^t_j [ \\hutheta - \\utheta^*]\\end{aligned}\\ ] ] for some point @xmath362 lying in the line between @xmath356 and @xmath184,i.e .",
    "@xmath528 . since @xmath529 where @xmath530 another application of the chain rule yields , @xmath531 \\{x^{(i)}_j \\ , { x^{(i)}}^t [ \\hutheta - \\utheta^*]\\}\\\\ & = \\frac{1}{n } \\sum^n_{i = 1 } \\ { g'({\\bar{\\bar{\\utheta}}^{(j)}}^t x^{(i ) } ) { x^{(i)}_j \\ } \\ { [ \\bar{\\utheta}^{(j ) } - \\utheta^*]^t x^{(i ) } } \\ , { x^{(i)}}^t [ \\hutheta - \\utheta^ * ] \\}\\end{aligned}\\ ] ] where @xmath532 is a point in the line between @xmath362 and @xmath184 .",
    "let @xmath533^t x^{(i ) } \\ , { x^{(i)}}^t [ \\hutheta - \\utheta^ * ]   = t_j [ \\hutheta - \\utheta^*]^t x^{(i ) } \\ , { x^{(i)}}^t [ \\hutheta - \\utheta^ * ] \\geq 0\\ ] ] then , noticing that @xmath526 and @xmath534 we can apply holder s inequality to obtain , @xmath535^t \\left\\ { \\frac{1}{n }   \\sum^n_{i = 1 } x_s^{(i ) } \\ , { x_s^{(i)}}^t \\right\\ } [ \\hutheta_s - \\utheta_s^ * ] \\leq \\delta \\|\\hutheta_s - \\utheta_s^*\\|^2_2.\\ ] ]    slightly readapting the proof of lemma 3 from @xcite we now show that @xmath536    define @xmath537 .",
    "since @xmath538 and @xmath2 is strictly convex we have that if @xmath539 for @xmath540 then @xmath541 , where @xmath542 is the unique minimum point of @xmath543 . to prove we will compute a lower bound on the set of points for which @xmath539 .    by the mean value theorem we can write ,    @xmath544    note that @xmath360 .",
    "we now get bounds on each of the terms of the previous expression , @xmath545 thus can write , @xmath546 from which we derive expression .",
    "if @xmath389 holds we can assume without loss of generality @xmath547 .",
    "now notice that @xmath548 $ ] and thus we can write , @xmath549 if we now want that @xmath550 then we can simply impose that @xmath314 , which finishes the proof .",
    "( lemma [ th : mart22 ] ) in this proof @xmath552 and @xmath553 .",
    "we prove the lemma by computing a lower bound on the probability that @xmath554 under the assumption that @xmath324 and @xmath555 and @xmath556 .",
    ", necessary for correct reconstruction , allows us to ignore the @xmath557 and @xmath558 in what follows .",
    "] this will prove the corresponding upper bound on the probability of success of @xmath162 .",
    "first we show that there exists an @xmath559 such that if @xmath560 then with high probability @xmath162 fails .",
    "begin by noticing that @xmath561 and that @xmath562 .",
    "then use azuma s inequality to get the following bound , @xmath563 if @xmath564 for large enough @xmath559 then we can lower bound the previous expression by @xmath565 since @xmath566 contradicts the fact that @xmath356 is the optimal solution found by this shows that with high probability @xmath567 must be smaller than @xmath559 .    under the assumption that @xmath568 and @xmath324 we will now compute a lower bound for the event @xmath569 .",
    "@xmath570    where @xmath571 .    conditioned on @xmath572 all the @xmath573",
    "are independent and identically distributed .",
    "hence , choosing one particular @xmath574 , and defining @xmath575 we can rewrite the previous expression as , @xmath576 we now use the central limit theorem for independent nonidentical random variables to upper bound the conditional probability inside the expectation .",
    "it is easy to see that lyapunov conditions hold .",
    "in fact , let @xmath577 then for some @xmath578 , @xmath579 and @xmath580 thus we can write , @xmath581 where @xmath582 is the cumulative distribution of the normal(0,1 ) distribution and @xmath583 with @xmath8 .",
    "we can finally write , @xmath584 for @xmath8 big enough . in the above expression",
    "@xmath585 as @xmath586 . from this bound and we get the desired upper bound on the probability of success of .",
    "( lemma [ th : key_result_reg_graph ] ) we explain here the calculations with respect to the tree model . throughout all calculations",
    "we assume that @xmath587 .",
    "an important property that follows from the fixed point equation is that , if @xmath588 is a function of the variables in @xmath409 then @xmath589 with the obvious identification of @xmath409 as a subtree of @xmath590 .",
    "let @xmath108 be a uniformly random vertex in @xmath2 and @xmath591 two neighbors of @xmath108 . using the local weak convergence property with @xmath592 we get @xmath593 where @xmath594 is the sum of the variables on the leaves of a depth @xmath37 tree , and @xmath595 . for @xmath596 at distance @xmath597 from @xmath108",
    ", consider the @xmath64-dimensional vector in @xmath598 elements of @xmath599 are of the form @xmath600 where @xmath601 .",
    "these elements can take only two different values : one if @xmath596 is a child of @xmath99 and other if not .",
    "we denote the first value by @xmath602 and the second by @xmath603 .",
    "since @xmath604 is an eigenvector of @xmath605 with eigenvalue @xmath606 we can write , @xmath607 where @xmath608 in this expression , and through the rest of the proof , @xmath609 will denote @xmath610 where @xmath611 is the smallest value such that all the variables inside the expectation are in @xmath612 .",
    "now , conditioning on the value of @xmath613 ( @xmath614 ) we can write , @xmath615 where @xmath616 in the expression above the binomial coefficients are to be assume zero whenever its parameters are not integer values . in order to prove that the incoherence condition is violated",
    "we will now show that @xmath617 if @xmath13 is large enough .",
    "writing a first order recurrence relation for @xmath618 and @xmath619 it is not hard to see that , @xmath620 where @xmath621 and @xmath622 denotes a child of @xmath108 , i.e. , a node at distance @xmath623 from @xmath108 . recall that @xmath304 is the unique positive solution of . in the above expression @xmath624",
    "denotes the probability associated with the measure where again we can restrict @xmath625 to the smallest tree containing all the variables that compose the event whose probability we are trying to compute .",
    "since @xmath626 we have that @xmath627 a little bit of algebra allows us to write , @xmath628 in addition , taking into account that @xmath629 and @xmath630 can be expressed as , @xmath631 we have , @xmath632 expanding everything in powers of @xmath633 we get , @xmath634 since @xmath304 grows with @xmath13 ] this expansion proves the first part of lemma [ th : mart23 ] .",
    "in fact , this expression shows that for large @xmath13 , as @xmath13 increases , @xmath636 decays to 1 from above .",
    "hence , there exists a @xmath637 such that for all @xmath638 we will have @xmath639 .    [ sec : remark_on_incoh_region ] it is interesting to see that the condition for @xmath640 is equivalent to @xmath641 .",
    "this implies that if @xmath640 then @xmath642 and if @xmath643 then @xmath644 . hence , when @xmath645 we have @xmath646 and when @xmath647 we have @xmath648 .",
    "consequently , @xmath649 which does not depend on @xmath301 .",
    "it is not hard to prove that @xmath650 and thus , @xmath651 .",
    "we now study how @xmath327 scales with @xmath64 for large @xmath64 .",
    "notice that @xmath652 is equivalent to @xmath653 .",
    "it is not hard to see that this equation has a single solution .",
    ", this tells us that there is a single point where @xmath654 crosses 1 .",
    "] we show that if we search for solutions , @xmath13 , that scale like @xmath655 then in the limit when @xmath656 we get an expression that exhibits a single nontrivial zero .",
    "this means that for large @xmath64 the solution of @xmath657 must be of the form @xmath658 , where @xmath659 is the solution of the scaled equation .",
    "first notice that when @xmath656 and @xmath660 then @xmath304 converges to the solution of @xmath661 .",
    "we denote this solution by @xmath662 .",
    "hence , for large finite @xmath64 we can say that @xmath663 .",
    "we now write new expressions for @xmath664 and @xmath665 namely , @xmath666 expanding the function @xmath667 in @xmath501 and @xmath665 in powers of @xmath655 we can write @xmath668 note that we have not expanded @xmath304 in powers of @xmath655 . defining @xmath669 to be the expectation with respect to the tree model where all connections to node @xmath108 have been removed ( the field on each node is still @xmath304 ) we can write , @xmath670 in addition , making use of the symmetry of the regular tree and expanding @xmath671 around @xmath672 and @xmath673 ( @xmath674 and @xmath675 to be defined later ) we can write @xmath676 where @xmath677 and @xmath678 . using these relations , the law of large numbers and the relation @xmath663 where @xmath679 it is now possible to calculate the limit @xmath680 this finishes the proof of the second part of the lemma since @xmath336 can now be determined by @xmath681 and @xmath682 .    we now show how to deduce the above expression .",
    "let us introduce the following notation , @xmath683 with this in mind and recalling that @xmath684 we can write , @xmath685 now notice that expanding the @xmath686 inside @xmath687 in expression @xmath688 around @xmath689 we can rewrite the same expression as , @xmath690 inserting this in the above expression finally gives us , @xmath691    by the law of large numbers we have , @xmath692 and since all the variables inside the expectations are uniformly bounded , we can take the limit inside all the expectations of our expression for @xmath693 . doing so we get , @xmath694    if we now use the relation @xmath695 this expression can be simplified to , @xmath696    finally , we show that there exists a constant @xmath500 such that @xmath697 first notice that the eigenvalues of @xmath698 are @xmath699 and @xmath700 .",
    "it is immediate to see that @xmath701 .",
    "in addition , since @xmath702 it follows that @xmath703 .",
    "hence we can choose @xmath704 .",
    "as already discussed , the success of is closely related to the incoherence condition . for small graphs ,",
    "brute force computations allow to explicitly evaluate this condition .",
    "for example , consider the reconstruction of the neighborhood of the leftmost node in the graph of figure [ fig : simple_graph_incoh_cond ] .",
    "the corresponding incoherence parameter takes the for , @xmath705 where @xmath706 . for @xmath707{2}+2^{2/3}\\right)\\approx 0.44249",
    "$ ] ( i.e. for @xmath708 ) the right hand side is larger than @xmath37 , whence the incoherence condition is violated @xmath709 .",
    "this simple calculation strongly suggests that @xmath162 fails on the graph of figure [ fig : simple_graph_incoh_cond ] for @xmath710 , although it does not provide a complete proof of this failure . in this appendix",
    "we study three classes of graphs of increasing size .",
    "we show that with high probability succeeds in reconstructing trees . on the other hand , we show that it fails for @xmath13 large enough at reconstructing large two - dimensional grids , and that in fails in reconstructing graphs @xmath35 from the toy example in section [ sec : toy_example ] .        in what follows @xmath256 will denote @xmath255 . consider a node @xmath715 and let @xmath716 be the unique node in @xmath368 that belongs to the shortest path connecting @xmath596 to @xmath108 .",
    "let @xmath301 be the distance between @xmath596 and @xmath287 .",
    "for every @xmath717 one can write , @xmath718 this equation is still valid if @xmath719 .",
    "we can thus write that @xmath720 and hence @xmath721 where @xmath722 is a row vector with all entries equal to zero except @xmath723 entry that equals 1 . therefore we can write @xmath724 . since there",
    "must exist at least one node @xmath725 for which the corresponding node @xmath287 is at distance 1 from @xmath368 , that is for which @xmath726 , we conclude that @xmath727 .    to prove the spectral bounds first notice that the positive - semidefinite matrix @xmath605 has entries @xmath728 where @xmath729 and @xmath730 and where 1 and 2 are any two distinct nodes in @xmath368 .",
    "a matrix of this form has eigenvalues @xmath699 and @xmath731 .",
    "it is not hard to see that @xmath732 and hence @xmath733 since @xmath734 the lower bound follows .        if @xmath2 is a two dimensional grid with periodic boundary conditions ( each node connects to its four closest neighbors ) then for @xmath32 large enough @xmath739 we have @xmath740 and @xmath741 where @xmath742 , @xmath743 and @xmath500 are independent of @xmath32 .",
    "[ th : alpha_for_grid ]      label the central node as node 0 , the neighboring nodes as 1 , 2 , 3 and 4 .",
    "denote as node 5 be the common neighbor of node 1 and node 4 . throughout this proof",
    "we will denote @xmath255 by @xmath256 and @xmath257 by @xmath258 .        first notice that due to the periodic boundary condition there is symmetry along the vertical and horizontal axis in the lattice . knowing this , matrix @xmath605 can be written as @xmath746,\\ ] ] where @xmath747 , @xmath748 and @xmath749 , where @xmath750 , that is , @xmath221 is the sum of the variables in the neighborhood of @xmath23 ( @xmath23 not included ) . since we only want to prove a lower bound on @xmath751 we only consider the row of @xmath752 associated with node 5 .",
    "this row has the form , @xmath753,\\ ] ] where @xmath754 and @xmath755 . to compute the low temperature expansions of each of these quantities we first write , @xmath756 \\\\ & + & \\frac{1}{\\cosh^2 2 \\theta } [ \\prob ( |m| = 2 , x_i x_j = 1 ) - \\prob ( |m| = 2 , x_i x_j = -1)]\\\\ & + & \\frac{1}{\\cosh^2 4 \\theta } [ \\prob ( |m| = 4 , x_i x_j = 1 ) - \\prob ( |m| = 4 , x_i x_j = -1)].\\end{aligned}\\ ] ] the problem thus resumes to the computation of the above probabilities .",
    "we will exemplify the calculation of the low temperature expansion of @xmath757 , the calculation of the expansion for the other terms follows in a similar fashion .",
    "let @xmath758 , @xmath759 and @xmath760 where @xmath761 is the length of the boundary separating positive spins from negative spins in configuration @xmath762 .",
    "then , @xmath763 the term @xmath764 appears in all @xmath765 and @xmath766 and thus is irrelevant for the computation of @xmath767_5 $ ] .",
    "since only configurations with zero magnetization contribute to the sum there are two basic types of configurations we need to consider , both of which must have exactly two neighbors of node 0 with negative spin .",
    "these are represented in figure [ fig : grid_basic_confi_type ] .    .",
    "the number in front of each picture represents the number of equivalent symmetric configurations that need to be taken into account.,title=\"fig : \" ] .",
    "the number in front of each picture represents the number of equivalent symmetric configurations that need to be taken into account.,title=\"fig : \" ]    starting from these two basic states we need to consider the first few lowest energy configurations . to help the counting there are two parameters that we keep track of : the number of negative spins , @xmath301 , and the perimeter of the boundary , @xmath768 .",
    "the first type of state produces the counting expressed in table [ table : grid_mag_zero_first_conf_count ] .",
    "the associated configurations are represented in figure [ fig : grid_basic_confi_first_type_extended ] .",
    "for the expansion of @xmath770 we again have two basic states types from which all the other ones are built .",
    "the first type has all spins positive in the neighborhood of node 0 and the second type has all spins negative in the neighborhood of node 0 .",
    "the counting of states in printed in table [ table : grid_mag_four_first_and_second_conf_count ] .                    using the expansions for @xmath765 and @xmath766 and computing the series expansion of @xmath767_5 $ ] in powers of @xmath745",
    "we finally obtain , @xmath786\\|_{\\infty } \\geq \\|[q^*_{s^cs } { q^*_{ss}}^{-1}]_5\\|_1 = 1 + e^{-4 \\theta } + o(e^{-8 \\theta}).\\ ] ] following the ideas of @xcite one can then show that the above formal expansion converges ( a priori it could be case that one of the higher order terms would depend on @xmath771 ) .",
    "this finishes the first part of the proof .",
    "we now prove that there exists @xmath787 such that @xmath788 .",
    "this will prove the second part of the theorem .",
    "first notice that the eigenvalues of @xmath605 are @xmath789 .",
    "now notice that , @xmath790 where for @xmath791 and @xmath792 we made use of the symmetry of the lattice . since @xmath793 , @xmath221 and @xmath794 only depend on a fixed finite number of spins , and since @xmath795 , there is a positive probability , independent of @xmath32 , of their being non - zero .",
    "hence , all eigenvalues of @xmath605 are strictly positive even as @xmath796 .      in this section we show that @xmath162 fails to reconstruct the graphs @xmath35 defined in section [ sec : toy_example ] ( see figure [ fig : simplegraph ] ) for all @xmath171 when @xmath13 is large enough .",
    "note that this differs from previous analysis in the sense that we do not require that @xmath183 .",
    "we also show that this ` critical ' @xmath13 behaves like @xmath655 for large @xmath64 .",
    "our analysis is based on numerical evaluation of functions for which explicit analytic expressions can be given along the lines of section [ sec : toy_examp_comp ] .",
    "hence , our argument should be understood as a sketch of a proof .",
    "the success of @xmath162 is dictated by the behavior of @xmath797 when @xmath8 is large .",
    "in fact , it is easy to use concentration inequalities to show that the solution of @xmath181 for finite @xmath8 converges with high probability to the minima of @xmath798 where @xmath799 .",
    "if @xmath350 as @xmath800 , we have seen that the success of @xmath181 is dictated by the incoherence condition , which in turn is determined by the hessian of @xmath801 .",
    "it is not hard to see that for this family of graphs , @xmath802 is increasing with @xmath32 . for @xmath803 , eq .   tells us that the incoherence condition will be violated for @xmath13 high enough .",
    "hence , by lemma [ th : mart21 ] , @xmath181 will fail for all @xmath35 ( @xmath804 ) when @xmath350 as @xmath800 .",
    "the question now is : how does @xmath162 behave if @xmath183 does not hold ?",
    "if @xmath805 , the success of @xmath181 is dictated by the minima of @xmath798 .",
    "for this specific family of graphs , it is also not hard to see that for @xmath587 , @xmath806 is strictly convex and that due to symmetry the unique minimum of @xmath798 must satisfy @xmath807 for any @xmath171 .",
    "this allows us to consider @xmath801 as a function of only two parameters .",
    "we call it @xmath808 .",
    "now , the problem of understanding @xmath181 for @xmath809 , large @xmath8 and any @xmath32 becomes tractable and associated to understanding the following problem , @xmath810 we can analyze this optimization problem by solving it numerically . figure [ fig : patho_graphs_sol_plot ] shows the solution path of this problem as a function of @xmath171 for @xmath803 and for different values of @xmath13 .",
    "from the plots we see that for high values of @xmath13 , @xmath181 will never yield a correct reconstruction ( unless we assume @xmath813 ) since for these @xmath13s all curves are strictly above the horizontal axis , that is , @xmath814 .",
    "however , if @xmath13 is bellow a certain value , call it @xmath815 ( @xmath816 for graph @xmath817 ) , then there are solution that yield a correct reconstruction if we choose values of @xmath811 .",
    "in fact , for @xmath818 all curves exhibit a portion ( above a certain @xmath171 ) that have @xmath819 and @xmath820 .",
    "that is , for @xmath818 , @xmath181 makes a correct structural reconstruction .",
    "if we make @xmath13 even smaller then the curves identify themselves with the horizontal axis .",
    "we call by @xmath821 the value of @xmath13 below which this occurs .     as a function of @xmath171 for different values of @xmath13 and @xmath822 . along each curve",
    ", @xmath171 increases from right to left .",
    "plot points separated by @xmath823 are included to show the speed of the parameterization with @xmath171 .",
    "for @xmath824 all curves tend to the point @xmath825 .",
    "remark : curves like the one for @xmath826 are identically zero above a certain value of @xmath171.,title=\"fig : \" ] ( -150,25)@xmath827 ( -175,60)@xmath826 ( -220,210)@xmath828 ( -200,140)@xmath829 ( -60,15)@xmath813 ( -330,15)@xmath830 ( 0,10)@xmath831 ( -320,210)@xmath832    we again note that all previous considerations were made in the limit when @xmath182 .",
    "for high finite @xmath8 , with high probability the solution curves will not be the ones plotted but rather be random fluctuations around these . for @xmath813 , finite @xmath8 and @xmath833",
    ", the solution curves will no longer start from @xmath834 but will have a positive non vanishing probability of having @xmath835 .",
    "this reflects the fact that for finite @xmath8 the success of @xmath162 requires @xmath171 to be positive .",
    "however , for @xmath836 and @xmath811 such that we are in the region where the curves for @xmath837 are identically zero , the curves for finite @xmath8 will have an increasing probability of being identically zero too .",
    "thus , for these values of @xmath171 and @xmath13 , the probability of successful reconstruction will tend to 1 as @xmath182 . from the plots we also conclude that , unless the whole curve ( for @xmath837 ) is identified with zero , @xmath162 restricted to the assumption @xmath183 will fail with positive non vanishing probability for finite @xmath8 . for @xmath836 , when the curves ( for @xmath837 ) become identically zero",
    ", there will be a scaling of @xmath171 with @xmath8 to zero that will allow for a probability of success converging to 1 as @xmath182 .",
    "requiring @xmath183 makes @xmath821 be the critical value above which reconstruction with @xmath181 fails .",
    "this is the scenario in which we studied @xmath181 in section [ sec : pseudo ] .",
    "in fact , @xmath821 coincides with the value above which @xmath838 . for this family of graphs",
    "we thus conclude that the true condition required for successful reconstruction is not @xmath839 but rather that @xmath818 .",
    "surprisingly , for graphs in @xmath35 this condition coincides with @xmath840 , i.e. the correlation between neighboring nodes must be bigger than that between non - neighboring nodes .",
    "notice that this condition is in fact the condition required for @xmath841 to work .",
    "consequently , for this family of graphs , the thresholding algorithm will always have a working range in terms of @xmath13 larger than that of @xmath181 , when restricted to @xmath824 .",
    "in fact , a simple calculation using the local weak convergence used in proving lemma [ th : mart23 ] shows that with high probability , for large random regular graphs , the correlation between neighboring nodes is always strictly greater than between non - neighboring nodes .",
    "this shows that the thresholding algorithm has as operation range @xmath842 for random regular graphs , compared to @xmath843 for @xmath181 .",
    "we will now prove that for large enough @xmath844 there is a unique @xmath845 ( solution of @xmath846 ) that scales like @xmath847 and above which @xmath848 .",
    "let 1 and 2 be the two nodes with degree greater than 2 and let 3 be any other node ( of degree 2 ) , see figure [ fig : patho_graphs ] .",
    "define @xmath849 and @xmath850 .",
    "it is not hard to see that , @xmath851 from these expression we see that the condition @xmath852 is equivalent to @xmath853 . remembering that expectations on the ising model can be computed from subgraphs of @xmath2 , @xcite",
    ", an easy calculation shows that , @xmath854 where @xmath855 .",
    "since @xmath856 with @xmath64 then any @xmath815 also goes to @xmath58 with @xmath64 and attending to the slope and concavity of @xmath857 and @xmath858 for small @xmath13 it is easy to see that for large @xmath64 there will exist a unique solution @xmath845 .",
    "furthermore , the condition @xmath859 can now be written like , @xmath860 assuming @xmath861 , multiplying both sides of the previous equation by @xmath862 and taking the limit when @xmath863 we obtain , @xmath864 which will result in a non trivial relation for @xmath94 only if @xmath865 . in this case",
    "we get @xmath866 and thus for any @xmath743 , if @xmath64 is sufficiently high , there will be a ( unique ) solution of inside the interval @xmath867 $ ] .",
    "since @xmath855 then @xmath845 scales likes @xmath847 as we wanted to prove .",
    "g.  bresler , e.  mossel and a.  sly , _ reconstruction of markov random fields from samples : some observations and algorithms _ , proceedings of the 11th international workshop , approx 2008 , and 12th international workshop , 2008 , 343356 .",
    "o.  banerjee , l.  el ghaoui and a.  daspremont , _ model selection through sparse maximum likelihood estimation for multivariate gaussian or binary data _ , journal of machine learning research , 2008 , vol .",
    "9 , 485516 ."
  ],
  "abstract_text": [
    "<S> we consider the problem of learning the structure of ising models ( pairwise binary markov random fields ) from i.i.d . </S>",
    "<S> samples . </S>",
    "<S> while several methods have been proposed to accomplish this task , their relative merits and limitations remain somewhat obscure . by analyzing a number of concrete examples , </S>",
    "<S> we show that low - complexity algorithms often fail when the markov random field develops long - range correlations . </S>",
    "<S> more precisely , this phenomenon appears to be related to the ising model phase transition ( although it does not coincide with it ) . </S>"
  ]
}