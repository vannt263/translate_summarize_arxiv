{
  "article_text": [
    "consider a linear model where the observed data consists of outcomes @xmath4 and predictors @xmath5 that are related via the equation @xmath6 the @xmath0-dimensional vector @xmath7 is an unknown parameter and @xmath8 are unobserved errors . to simplify notation ,",
    "let @xmath9 , @xmath10 , and @xmath11 .",
    "then ( [ lm ] ) may be rewritten as @xmath12 .    in this paper",
    ", we study asymptotic minimax estimation of @xmath13 over spheres of growing dimension ( i.e. , @xmath14 ) , under the assumption that the data @xmath15 are jointly gaussian .",
    "this is a variant of a problem considered by goldenshluger and tsybakov @xcite ; it is closely related to the fundamental work of pinsker @xcite and others , for example , belitser and levit @xcite , beran @xcite , golubev @xcite , on sharp asymptotic minimax estimation in the gaussian sequence model . taken together ,",
    "the results in this paper provide a new example where sharp asymptotic minimax estimation is possible ; an example that illustrates connections between linear models with many predictors and now classical results on the spectral distribution of large random matrices .",
    "let @xmath16 denote the @xmath17 identity matrix .",
    "we assume throughout that @xmath18 are independent .",
    "more general models , where one might allow for positive definite @xmath19 and arbitrary @xmath20 , are discussed in section  [ sec1.4 ] .    given an estimator @xmath21 of @xmath13 , define the risk under squared - error loss @xmath22 where @xmath23 denotes the @xmath24-norm .",
    "the expectation in ( [ risk ] ) is taken with respect to the joint distribution of @xmath25 and the subscript @xmath13 in @xmath26 indicates that @xmath12 ( for expectations that do not involve @xmath27 , we will often omit the subscript ) .",
    "we emphasize that the expectation in ( [ risk ] ) is taken over the predictors @xmath28 as well as the errors @xmath29 ; in other words , rather than conditioning on @xmath28 , ( [ risk ] )  is the _ unconditional _ risk under squared - error loss .",
    "let @xmath30 be the sphere of radius @xmath31 in @xmath32 centered at the origin .",
    "the minimax risk for estimating @xmath13 over @xmath33 is given by @xmath34 where the infimum in ( [ mr ] ) is taken over all measurable estimators @xmath35 .",
    "the minimax problem determined by ( [ mr ] ) is the main focus of this paper .",
    "our analysis entails ( i ) identifying and analyzing specific estimators @xmath36 such that @xmath37 , and ( ii ) obtaining accurate closed - form approximations for @xmath38 , while focusing on settings where @xmath0 is large .      to better orient the reader",
    ", we give a brief section - by - section overview of the paper .",
    "we conclude this section with an additional comment on the nature of the asymptotic results derived herein .    _",
    "section  [ sec2 ] _ : _ ridge regression_. ridge regression ( hoerl and kennard @xcite and tihonov @xcite ) is a widely studied regularized estimation method whose use has been advocated in various settings where @xmath0 is large or @xmath28 is ill - conditioned . our analysis in section  [ sec2 ]",
    "yields a simple formula for the optimal ridge regularization parameter and a new closed - form expression for the associated ridge estimator s asymptotic risk .",
    "more specifically , we show that if @xmath3 , then the asymptotic risk of the ridge estimator is closely related to the stieltjes transform of the marenko  pastur distribution ( marenko and pastur @xcite ) , which plays a prominent role in random matrix theory , for example , bai _ et al . _",
    "@xcite , el  karoui @xcite , silverstein @xcite .",
    "settings where @xmath39 and @xmath40 are also considered .",
    "our results for ridge regression immediately provide an upper bound on @xmath38 , in the usual way : it is clear from ( [ mr ] ) that @xmath41 for all estimators @xmath36 ; taking @xmath36 to be the specified ridge estimator gives the desired upper bound .    _",
    "section  [ sec3 ] _ : _ an equivalent bayes problem_. an equivariance argument implies that @xmath38 is equal to the bayes risk for estimating @xmath13 under the prior distribution @xmath42 , where @xmath43 denotes the uniform distribution on @xmath33 ( this is an application of well - known results on equivariance , e.g. , chapter  6 of berger @xcite , and is essentially an illustration of the hunt  stein theorem ( bondar and milnes @xcite ) ) .",
    "additionally , we argue that when @xmath0 is large , the bayes risk for estimating @xmath13 under the prior distribution @xmath44 is close to the bayes risk for estimating @xmath13 under a normal prior distribution , which coincides with the risk of ridge regression .",
    "we conclude that the risk of ridge regression is asymptotically equivalent to @xmath38 and that ridge regression is asymptotically optimal for estimation over @xmath33 .    _",
    "section  [ sec4 ] _ : _ an adaptive ridge estimator_. the ridge regression estimator @xmath45 that is asymptotically optimal over @xmath33 depends on the radius @xmath46 , which is typically unknown . replacing @xmath47 with an estimate , we obtain an adaptive ridge estimator that does not depend on @xmath47 , but is asymptotically equivalent to @xmath45 .",
    "it follows that the adaptive ridge estimator is adaptive asymptotic minimax over spheres @xmath33 , provided @xmath48 .",
    "additionally , we show that the adaptive ridge estimator is asymptotically optimal among the class of all estimators for @xmath13 that are equivariant with respect to orthogonal transformations of the predictors , as @xmath14 .",
    "proofs may be found in the .    _ note on asymptotics_. throughout the paper , our asymptotic analysis is focused on settings where @xmath14 .",
    "we typically assume that @xmath49 along with @xmath0 and that @xmath50 $ ] .",
    "it will become apparent below that most of the `` action '' occurs when @xmath51 .",
    "indeed , one of the implications of our results is that if @xmath52 , then the minimax risk @xmath38 is influenced by the spectral distribution of the empirical covariance matrix @xmath53 . on the other hand , if @xmath54 , then the behavior of @xmath38 is more standard .",
    "if @xmath55 , then we will show that it is impossible to out - perform the trivial estimator @xmath56 for estimation over @xmath33 ; note the contrast with sparse estimation problems , where @xmath13 is assumed to be sparse and it may be possible to dramatically out - perform @xmath57 when @xmath40 , for example , bickel _ et al . _",
    "@xcite , bunea _ et al . _",
    "@xcite , candes and tao @xcite , raskutti _ et al . _",
    "@xcite , ye and zhang @xcite , zhang @xcite .",
    "the minimax problem ( [ mr ] ) is closely related to problems considered by goldenshluger and tsybakov @xcite , who studied minimax prediction problems over @xmath24-ellipsoids @xmath58 in an infinite - dimensional linear model with independent ( but not necessarily gaussian ) predictors .",
    "goldenshluger and tsykbakov s results apply to classes of ellipsoids with various constraints on @xmath59 and @xmath60 .",
    "taking @xmath61 , @xmath62 , and @xmath63 ( and following the convention that @xmath64 ) , the results in goldenshluger and tsybakov @xcite may be applied to obtain asymptotics for the minimax risk over the @xmath0-dimensional ball @xmath65 , @xmath66 results in goldenshluger and tsybakov @xcite yield adaptive estimators that are asymptotically minimax over classes of balls @xmath67 . in section  [ sec3.2 ] , we show that @xmath68 , when @xmath0 is large ( see ( [ mrbmr ] ) below ) .",
    "thus , goldenshluger and tsybakov s results are clearly related to the results presented here . however , as applied to balls @xmath67 , their results typically require that @xmath39 ( for instance , theorem  1 of goldenshluger and tsybakov @xcite requires that @xmath69 and assumption  3 of goldenshluger and tsybakov @xcite requires @xmath70 ) .",
    "by contrast , the results in this paper apply in settings where @xmath50 $ ] , with the bulk of our work focusing on @xmath71 .",
    "the analysis in this paper focuses on estimation over the sphere @xmath33 , rather than the ball @xmath67 ; that is , we focus on the minimax problem ( [ mr ] ) , as opposed to ( [ mrb ] ) .",
    "the ball @xmath67 and other star - shaped parameter spaces ( e.g. , ellipsoids or @xmath72-balls ) have been more frequently studied in the literature on asymptotic minimax problems over restricted parameter spaces ( donoho and johnstone @xcite , golubev @xcite , nussbaum @xcite ) .",
    "evidently , the problems ( [ mr ] ) and ( [ mrb ] ) are closely related . however , analysis of ( [ mr ] ) appears to be somewhat more complex ; in particular , obtaining lower bounds on @xmath38 seems more challenging . to justify our emphasis on the sphere @xmath33 , in section  [ sec3.2 ]",
    ", we show that asymptotics for @xmath73 follow easily from asymptotics for @xmath38 .",
    "additionally , by studying estimation over the sphere , we are able to draw deeper connections with equivariance than seem to be available if one focuses on the ball ( e.g. , proposition  [ oadapt ] below ) . a  similar approach has been considered by marchand @xcite and beran @xcite in their analysis of the finite - dimensional gaussian sequence mode .",
    "in fact , one of the key technical results in this paper ( theorem  [ main ] ) is essentially a multivariate extension of theorem  3.1 in marchand @xcite . while we believe that the additional insights provided by studying minimax problems over the sphere justify the added complexity , we also note that more standard approaches to obtaining lower bounds on the minimax risk over balls ( see , e.g. , nussbaum @xcite or chapter  3 of tsybakov @xcite ) may be applied to obtain lower bounds for @xmath73 directly .    finally in this section",
    ", we mention some of the existing work on random matrix theory that is especially relevant for our analysis of ridge regression in section  [ sec2 ] .",
    "theorem  [ mprisk ] in section  [ sec2.2 ] relies heavily on now classical results that describe the asymptotic behavior of the empirical distribution of the eigenvalues of @xmath53 in high dimensions ( bai @xcite , bai _ et al . _",
    "@xcite , marenko and pastur @xcite ) . additionally , we point out that while other authors have alluded to the relevance of random matrix theory for ridge regression ( el karoui and ksters @xcite ) , the results presented here on ridge regression s asymptotic risk seem to provide a greater level of detail than available elsewhere , in the specified setting .",
    "the linear model ( [ lm ] ) with distributional assumptions ( [ norm ] ) is highly specialized .",
    "however , similar models have been studied previously .",
    "stein @xcite , baranchik @xcite , breiman and freedman @xcite , brown @xcite and leeb @xcite studied estimation problems for linear models with jointly gaussian data , but , for the most part , these authors do not require @xmath74 .",
    "moreover , as discussed in section  [ sec1.3 ] , the infinite - dimensional linear model considered by goldenshluger and tsybakov @xcite is similar to the model studied in this paper . for our purposes , one of the more significant consequences of the normality assumption ( [ norm ] )",
    "is that the distributions of @xmath28 and @xmath29 are invariant under orthogonal transformations .",
    "this leads to substantial simplifications in many of the ensuing calculations .",
    "results in el karoui and ksters @xcite suggest that a general approach to relaxing some of the distributional assumptions made in this paper may be feasible , but this is not pursued further here .",
    "we point out that the assumption @xmath75 , which is implicit in ( [ norm ] ) , is not particularly limiting : if @xmath76 , then we can reduce to the mean 0 case by centering and de - correlating the data .",
    "the normality assumption ( [ norm ] ) also requires @xmath77 .",
    "if @xmath78 and @xmath79 is known , then this can be reduced to the case where @xmath77 by transforming the data @xmath80 ; the corresponding transformation for the parameters @xmath81 , @xmath79 is given by @xmath82 and the risk function should be scaled by @xmath79 , as well ( ultimately in this scenario , most of the results in this paper remain valid except that the signal - to - noise ratio @xmath83 replaces the signal strength @xmath84 ) .",
    "if @xmath79 is unknown and @xmath85 , then @xmath79 may be effectively estimated by @xmath86 , where @xmath87 is the ordinary least squares ( ols ) estimator ; one can subsequently reduce to the case where @xmath88 .",
    "( throughout , if the square matrix @xmath89 is not invertible , then we take @xmath90 to be its moore  penrose pseudoinverse ; typically , the matrices we seek to invert will be invertible with probability 1 . )",
    "recent work suggests that @xmath79 may also be effectively estimated when @xmath91 .",
    "_ @xcite and sun and zhang @xcite propose methods for estimating @xmath79 when @xmath91 and @xmath13 is sparse ( see also related work by belloni _",
    "_ @xcite and dalalyan and chen @xcite on estimating @xmath13 in high dimensions when @xmath79 is unknown ) ; dicker @xcite considers estimating @xmath79 when @xmath92 and @xmath13 is not sparse .    under the gaussian assumption ( [ norm ] ) , the predictors @xmath93 are uncorrelated at the population level , that is , @xmath94 .",
    "the results in this paper are easily adapted to settings where @xmath19 is a known positive definite matrix by transforming the data @xmath95 , and making corresponding transformations of the parameters and risk function .",
    "if @xmath19 is unknown , but @xmath96 is an operator norm consistent estimator , then it is straigthforward to check that most of our asymptotic results remain valid , mutatis mutandis , for the transformed data @xmath97 . on the other hand , in high - dimensional settings where @xmath98 , an operator norm consistent estimator for @xmath99 may not exist . in dicker",
    "@xcite , the author considers a prediction problem closely related to the estimation problem considered in this paper , with unknown @xmath19 ; the author identifies an asymptotically optimal equivariant estimator and derives expressions for the estimator s asymptotic risk ( theorems 23 and corollary  1 of dicker @xcite ) .",
    "one interpretation of the results in dicker @xcite is that they quantify the loss in efficiency of equivariant estimators when @xmath19 is unknown , as compared to the results presented here for the case where @xmath94 is known .",
    "define the ridge regression estimator @xmath100.\\ ] ] the parameter @xmath101 is referred to as the `` regularization '' or `` ridge '' parameter and is subject to further specification . by convention , we take @xmath102 and @xmath103 to be the ols estimator .",
    "our first result identifies the optimal ridge parameter @xmath101 and yields an oracle ridge estimator with minimal risk .",
    "a simplified expression for the oracle ridge estimator s risk is also provided .",
    "[ rrisk ] suppose that @xmath104 .",
    "then @xmath105 } r \\bigl\\{\\hat{\\bb}_r(t),\\bb \\bigr\\ } = e \\bigl [ \\tr \\bigl\\ { \\bigl(x^tx + d/\\tau^2i_d \\bigr)^{-1 } \\bigr\\ } \\bigr].\\ ] ]    [ ubcor ] suppose that @xmath31 . then @xmath106.\\ ] ]    proposition  [ rrisk ] is proved in appendix and it implies that the optimal ridge parameter is given by the signal strength @xmath46 .",
    "notice that the risk of @xmath45 is constant over the sphere @xmath104 .",
    "corollary  [ ubcor ] , which gives an upper bound on @xmath38 , follows immediately from proposition  [ rrisk ] and the definition of @xmath38 .    in practice ,",
    "the signal strength @xmath46 is typically unknown .",
    "thus , with @xmath104 , @xmath107 may be viewed as an oracle estimator . in cases where the signal strength is not prespecified",
    ", proposition  [ rrisk ] implies that @xmath108 is the oracle estimator with minimal risk among ridge estimators .",
    "we will refer to both @xmath45 and @xmath108 as the oracle ridge estimator , according to whether or not @xmath109 has been specified in advance . in section  [ sec4 ] , we discuss adaptive ridge estimators that utilize an estimate of the signal strength .",
    "expressions similar to those in proposition  [ rrisk ] for the optimal ridge parameter and the risk ridge estimators have appeared previously in the literature ( see , e.g. , the review article by draper and van  nostrand @xcite ) . however , other existing results on the risk of ridge estimators tend to either ( i ) be significantly more complex than proposition  [ rrisk ] or ( ii ) pertain to the bayes risk of ridge regression , assuming that @xmath13 follows a normal prior distribution .",
    "proposition  [ rrisk ] is a simple , yet conclusive result for the optimal ridge parameter with respect to the frequentist risk @xmath110 .",
    "its simplicity follows largely from the symmetry in our formulation of the problem ; in particular , we are focusing on unconditional risk and the distribution of @xmath28 is orthogonally invariant .",
    "it appears that the risk formula ( [ rrisk1 ] ) can not be further simplified with ease .",
    "however , results from random matrix theory yield a closed - form expression for the asymptotic risk . for @xmath111 , the marenko  pastur density @xmath112 is defined by @xmath113 where @xmath114 , @xmath115 , @xmath116 is the dirac delta , and @xmath117 is the indicator function of the open interval @xmath118 .",
    "the density @xmath112 determines the marenko ",
    "pastur distribution , which is the limiting distribution of the eigenvalues of @xmath53 , if @xmath49 and @xmath119 ( marenko and pastur @xcite ) ; it also determines the corresponding cumulative distribution function , @xmath120 .",
    "the stieltjes transform of the marenko ",
    "pastur distribution is defined by @xmath121\\\\[-8pt ]   & = & -\\frac{1}{2\\rho s } \\bigl\\{s + \\rho- 1 + \\sqrt{(s + \\rho- 1)^2 - 4\\rho s } \\bigr\\},\\qquad   s",
    "< 0.\\nonumber\\end{aligned}\\ ] ] the main result of this section implies that if @xmath104 , then the risk of the oracle ridge estimator may be approximated by @xmath122 .",
    "[ mprisk ] suppose that @xmath123 for some fixed constants @xmath124 .",
    "a.   if @xmath125 or @xmath126 and @xmath127 , then @xmath128 b.   if @xmath129 , then @xmath130    theorem  [ mprisk ] is proved in appendix . since @xmath131 is constant over @xmath132 , the supremums in parts ( a ) and ( b ) of theorem  [ mprisk ] are somewhat superfluous ; however , they serve to emphasize that the upper bounds do not depend on any particular value of @xmath109 .",
    "let @xmath133 denote the ordered eigenvalues of @xmath53 and define the empirical cumulative distribution function @xmath134}(s)$ ] .",
    "there are two keys to the proof of theorem  [ mprisk ] .",
    "the first is the observation that if @xmath104 , then , by proposition  [ rrisk ] , @xmath135 = e \\biggl\\{\\int\\frac{1}{s + d/(n\\tau^2 ) } \\,\\mathrm{d}\\f_{n , d}(s ) \\biggr\\};\\ ] ] in other words , the risk of the oracle ridge estimator is the expected value of the stieltjes transform of @xmath136 .",
    "the second key is theorem  1.1 of bai _ et al . _",
    "@xcite , which states that under the conditions of theorem  [ mprisk ] , @xmath137 the different rates in ( [ bai ] ) depending on whether or not @xmath138 helps to explain why these situations are considered separately in theorem  [ mprisk ] above ; more fundamentally , the major difference between the two cases is that if @xmath139 ( corresponding to the setting where @xmath140 ) , then 0 is contained in the support of the continuous part of the marenko  pastur distribution , which complicates the analysis .",
    "the asymptotic risk of the oracle ridge estimator , when @xmath3 , is given explicitly in the following corollary , which follows immediately from theorem  [ mprisk ] .    [ corrisk ] for @xmath111 and @xmath141 define the asymptotic risk of the oracle ridge estimator @xmath142.\\ ] ]    a.   if @xmath143 , then @xmath144 b.   if @xmath145 is a fixed real number , then @xmath146    in corollary  [ corrisk ] and throughout the paper , the notation @xmath147 indicates the limit as @xmath49 and @xmath148 .",
    "corollary  [ corrisk ] implies that if @xmath149 , then the risk of the oracle ridge estimator @xmath108 converges to the asymptotic risk @xmath150 uniformly over all @xmath151 ; if @xmath139 , then the convergence is uniform over compact sets .",
    "it is clear from theorem  [ mprisk ] and corollary  [ corrisk ] that if @xmath3 , then the spectral distribution of @xmath53 plays a prominent role in determining the risk of the oracle ridge estimator via the marenko ",
    "pastur law ; if @xmath39 or @xmath40 , then its role subsides , as illustrated by the following proposition .",
    "[ r0inf ]    a.   for @xmath152 define @xmath153 then @xmath154 b.   let @xmath145 be a fixed real number .",
    "then @xmath155    proposition  [ r0inf ] is proved in appendix .",
    "it gives the asymptotic risk of the oracle ridge estimator in settings where @xmath39 and @xmath156 .",
    "expressions like ( [ r0inf1 ] ) are common in the analysis of linear estimators for the gaussian sequence model ( pinsker @xcite ) .",
    "thus , if @xmath39 , then features of @xmath157 deriving from the random predictors @xmath28 are less apparent .",
    "now consider the null estimator @xmath56 and notice that @xmath158 .",
    "proposition  [ r0inf](b ) implies that if @xmath40 , then the oracle ridge estimator is asymptotically equivalent to @xmath57 . in section  [ sec3 ] , we argue that if @xmath40 , then @xmath57 is in fact asymptotically minimax for the problem ( [ mr ] ) . in other words ,",
    "non - trivial estimation is impossible in ( [ mr ] ) when @xmath159 .",
    "combined with theorem  [ mprisk ] , proposition  [ r0inf ] implies that the asymptotic risk of the oracle ridge estimator @xmath160 extends continuously to @xmath54 and @xmath55 . for @xmath31 , we define @xmath161 and @xmath162 .",
    "in this section , we use an equivariance argument to reduce the minimax problem ( [ mr ] ) to an equivalent bayes problem .",
    "we then show that ridge regression solves the bayes problem , asymptotically .",
    "let @xmath43 denote the uniform measure on @xmath164 .",
    "define the bayes risk @xmath165 where the expectation @xmath166 is taken with respect to the joint distribution of @xmath167 , with @xmath42 independent of @xmath25 .",
    "the bayes estimator @xmath168 satisfies @xmath169    let @xmath170 denote the group of @xmath171 orthogonal matrices .",
    "as with @xmath29 and @xmath28 , the distribution @xmath43 is invariant under orthogonal transformations ; that is , if @xmath172 and @xmath44 , then @xmath173 .",
    "a corresponding feature of the estimator @xmath174 is that it is _ equivariant _ with respect to orthogonal transformations .",
    "[ ee ] an estimator @xmath21 is _ orthogonally equivariant _ if @xmath175 for all @xmath171 orthogonal matrices @xmath176 .",
    "let @xmath177 then one easily checks that @xmath178 .",
    "additionally , notice that @xmath179 is orthogonally equivariant .",
    "the following proposition is proved in appendix .",
    "[ mrequiv]suppose that @xmath31 and that @xmath180 .",
    "a.   if @xmath36 is an orthogonally equivariant estimator , then the risk of @xmath36 is constant over @xmath33 ; that is , @xmath181 .",
    "b.   @xmath182    proposition  [ mrequiv](a ) implies that all orthogonally equivariant estimators have constant risk over spheres @xmath33 ; we first noted that ridge regression possesses this property in a remark following proposition  [ rrisk ] .",
    "proposition  [ mrequiv](b ) implies that the bayes problem ( [ bayes ] ) and the minimax problem ( [ mr ] ) are equivalent .",
    "proposition  [ mrequiv](b ) also implies that the estimator @xmath174 is minimax over @xmath33 .",
    "while this , in a sense , `` solves '' the main problem of interest ( [ mr ] ) , there are several caveats .",
    "for instance , the estimator @xmath174 is an oracle estimator ( it depends on @xmath47 ) and is difficult to compute , even if @xmath47 is known .",
    "furthermore , proposition  [ mrequiv ] provides no information about the magnitude of @xmath38 . in the next section ,",
    "we show that when @xmath0 is large , @xmath183 for @xmath104 .",
    "in addition to providing quantitative information about @xmath38 , this result suggests that ridge regression may be an appealing alternative to @xmath174 , especially when combined with results on adaptive ridge estimators in section  [ sec4 ] .",
    "recall that the minimax estimator @xmath174 is the posterior mean of @xmath13 , under the assumption that @xmath184 is uniformly distributed on the sphere @xmath33 . on the other hand",
    ", the oracle ridge estimator @xmath185 may be interpreted as the posterior mean of @xmath13 under the assumption that @xmath186 is normally distributed and independent of @xmath25 .",
    "if @xmath0 is large , then the normal distribution @xmath187 is `` close '' to the uniform distribution on @xmath33 ( there is an enormous body of literature that makes this idea more precise  diaconis and freedman @xcite attribute early work to borel @xcite and lvy @xcite ) .",
    "thus , it is reasonable to expect that if @xmath0 is large and @xmath104 , then @xmath188 and that the two estimators have similar risk properties .",
    "this is the content of the main result in this section , which is essentially a multivariate extension of theorem  3.1 from marchand @xcite .",
    "[ main ] suppose that @xmath189 and let @xmath190 denote the nonzero ( with probability @xmath191 ) eigenvalues of @xmath53 .",
    "let @xmath31 .",
    "a.   if @xmath192 and @xmath104 , then @xmath193.\\ ] ] b.   if @xmath91 and @xmath104 , then @xmath194 \\\\ & & { } + \\frac{2(d - n)}{\\tau^2(n-2)}e \\biggl[\\tr \\biggl\\ { \\biggl(xx^t + \\frac{d}{\\tau^2}i_n \\biggr)^{-2 } \\biggr\\ } \\biggr].\\end{aligned}\\ ] ]    theorem  [ main ] is proved in appendix .",
    "the bound @xmath195 follows immediately from proposition  [ mrequiv](b ) and corollary  [ ubcor ] . proving the required upper bounds on @xmath131 ( which , by proposition  [ mrequiv](b )",
    ", are equivalent to lower bounds on @xmath38 ) is fairly complex and involves transforming the linear model into an equivalent sequence model , along with the application of classical information identities ( brown @xcite ) and inequalities ( stam @xcite ) . in the remainder of this section ,",
    "we discuss some of the implications of theorem  [ main ] .",
    "asymptotically , theorem  [ main ] is primarily significant for settings where @xmath3 .",
    "if @xmath149 , then the upper bounds in theorem  [ main ] are @xmath196 and @xmath197 , where @xmath109 ; by corollary  [ corrisk ] , we can further conclude that @xmath198 .",
    "the case where @xmath139 is somewhat problematic , because then @xmath199 ; however , some conclusions can be made in this case by continuity arguments , for example , corollary  [ rhoposcor](b ) below .    [ rhopos ] suppose that @xmath123 for some fixed constants @xmath124 and that @xmath125 or @xmath126 . if @xmath127 , then @xmath200    [ rhoposcor ] let @xmath160 be the asymptotic risk of the ridge estimator defined in corollary  [ corrisk ] .",
    "a.   if @xmath143 , then @xmath201 b.   if @xmath145 is a fixed real number , then @xmath202    proposition  [ rhopos ] follows directly from theorem  [ main ] and lemma  [ c2 ] ( found in appendix )",
    ". corollary  [ rhoposcor](a ) follows immediately from proposition  [ rhopos ] and corollary  [ corrisk](a ) .",
    "corollary  [ rhoposcor](b ) may be proved similarly to part ( a ) , while making use of the inequality @xmath203 for integers @xmath204 in order to avoid issues around @xmath205 .",
    "corollary  [ rhoposcor ] implies that if @xmath119 , then the minimax risk @xmath38 is asymptotically equivalent to the asymptotic risk of the oracle ridge estimator and that the oracle ridge estimator is asymptotically minimax .",
    "corollary  [ rhoposcor ] also provides the means for relating the minimax problem over @xmath24-spheres ( [ mr ] ) to the minimax problem over @xmath24-balls ( [ mrb ] ) .",
    "since @xmath206 , we have @xmath207 .",
    "furthermore , one easily checks that @xmath208 thus , if @xmath119 , then @xmath209 it follows that if @xmath3 , then the minimax risk over @xmath33 is equivalent to the minimax risk over @xmath67 and that the ridge estimator @xmath45 is asymptotically minimax for both problems .    when @xmath39 or @xmath156 , asymptotics for the minimax risk @xmath38 are more straightforward .",
    "the following proposition summarizes the behavior of @xmath38 in these settings .",
    "[ rhoalt ]    a.   let @xmath210 be the risk function ( [ r0inf1 ] )",
    ". then @xmath211 b.   let @xmath212 be fixed .",
    "then @xmath213    proposition  [ rhoalt](a ) is a straightforward consequence of theorem  [ main ] , proposition  [ r0inf ] , and lemma  [ c2 ] .",
    "proposition  [ rhoalt](b ) follows from general properties of orthogonally equivariant estimators ; in particular , one can check that if @xmath214 , then @xmath215 for all orthogonally equivariant estimators @xmath36 .",
    "proposition  [ rhoalt ] gives precise asymptotics for @xmath38 when @xmath14 and @xmath39 or @xmath156 . while proposition  [ rhoalt ] does not directly reference the ridge estimator , combined with proposition  [ r0inf ] it implies that @xmath45 is asymptotically optimal for the minimax problem ( [ mr ] ) when @xmath1 and @xmath216 or @xmath156",
    "note that the null estimator @xmath56 is also asymptotically optimal for ( [ mr ] ) when @xmath40 .",
    "we point out that the condition @xmath14 in proposition  [ rhoalt](a ) appears to be necessary , as it drives the approximation @xmath217 underlying theorem  [ main ] .",
    "to this point , we have focused on the oracle ridge estimator @xmath45 , where @xmath46 is the signal strength .",
    "typically , @xmath47 is unknown and , consequently , @xmath45 is non - implementable .",
    "a natural strategy is to replace @xmath47 with an estimate , @xmath218 .",
    "define @xmath219 and define the adaptive ridge estimator @xmath220 observe that @xmath221 is orthogonally equivariant .",
    "one can check that @xmath222 whenever @xmath49 ( see lemma  [ c5 ] ) ; thus , @xmath218 is a reasonable estimator for @xmath47 .",
    "the next result relates the risk of the adaptive ridge estimator @xmath223 to that of the oracle ridge estimator .",
    "it is proved in appendix .",
    "[ adapt ] suppose that @xmath224 , where @xmath225 are fixed constants satisfying @xmath226 or @xmath227 .",
    "also suppose that @xmath228 and @xmath229 .",
    "then @xmath230 and @xmath231 where @xmath160 is the asymptotic risk of the oracle ridge estimator defined in corollary  [ corrisk ] .",
    "theorem  [ adapt ] implies that if @xmath149 , then the risk of the adaptive ridge estimator converges uniformly to that of the oracle ridge estimator and its asymptotic risk is given explicitly by @xmath160 . if @xmath149 and @xmath232 , then it follows from theorem  [ adapt ] that @xmath233 . on the other hand ,",
    "if @xmath149 and @xmath234 , then @xmath235 and the limit of @xmath236 does not follow readily from theorem  [ adapt ] .",
    "in other words , the effectiveness of the adaptive ridge estimator is less clear when @xmath237 is very small .",
    "if @xmath39 or @xmath139 , then results similar to theorem  [ adapt ] may be obtained for the adaptive ridge estimator , but the results are more delicate ; results for @xmath238 are , in a sense , unnecessary because the oracle ridge estimator is equivalent to @xmath57 in this setting . if @xmath39 , then the relevant quantity is the risk ratio @xmath236 , rather than the risk difference considered in theorem  [ adapt ] , and one must carefully track the magnitude of @xmath239 relative to @xmath240 . ultimately , however , when @xmath39 the message is the same as the case where @xmath241 : if @xmath242 is not too small , then the adaptive ridge estimator performs nearly as well as the oracle ridge estimator .",
    "if @xmath139 , then the rate in ( [ adapt1 ] ) may be different , depending on @xmath242 and the magnitude of @xmath243 , for example , bai _ et al .",
    "_ @xcite .",
    "theorem  [ adapt ] compares the risk of the adaptive ridge estimator to that of the oracle ridge estimator .",
    "the next result , which follows immediately from theorem  [ adapt ] and proposition  [ rhopos ] , compares the risk of the adaptive ridge estimator to @xmath38 .",
    "[ adaptmr ] suppose that @xmath244 are fixed constants satisfying @xmath245 or @xmath246 .",
    "suppose further that @xmath123 .",
    "if @xmath247 and @xmath229 , then @xmath248    combined with proposition  [ rhopos ] , proposition  [ adaptmr ] implies that if @xmath149 , then @xmath223 is adaptive asymptotic minimax over spheres @xmath33 , provided @xmath48 .      in section  [ sec3.1 ]",
    ", we discussed connections between the minimax problem ( [ mr ] ) and equivariance .",
    "previously in this section , we noted that the adaptive ridge estimator @xmath223 is orthogonally equivariant and adaptive asymptotic minimax over spheres @xmath164 .",
    "the following is an asymptotic optimality result for @xmath223 , which pertains to the class of orthogonally equivariant estimators @xmath249 .",
    "[ oadapt ] suppose that @xmath143 .",
    "then @xmath250    by proposition  [ mrequiv ] , @xmath251 .",
    "thus , proposition  [ oadapt ] is a direct consequence of proposition  [ adaptmr ] .",
    "proposition  [ oadapt ] implies that if @xmath241 , then the adaptive ridge estimator @xmath223 is asymptotically optimal among all orthogonally equivariant estimators .",
    "note that the caveats discussed after the statement of theorem  [ adapt ] relating to small @xmath252 also apply to proposition  [ oadapt ] . more specifically ,",
    "if @xmath253 , then the ratio @xmath254 is more relevant than the risk difference considered in proposition  [ oadapt ] and the precise asymptotic behavior of this ratio is less clear .",
    "this appendix contains proofs of results stated in the main text , with the exception of theorem  [ main ] ; a proof of theorem  [ main ] may be found in appendix .",
    "proof of proposition  [ rrisk ] fix @xmath255 $ ] and suppose that @xmath104 .",
    "then @xmath256 since @xmath28 is orthogonally invariant ( i.e. , @xmath28 and @xmath257 have the same distribution for any @xmath172 ) , it follows that @xmath258 where @xmath259 is the @xmath260th standard basis vector .",
    "summing over @xmath261 above and dividing by @xmath0 , we obtain @xmath262.\\ ] ] additionally , it is clear that @xmath263.\\ ] ] combining this with ( [ prop1a ] ) and ( [ prop1b ] ) yields @xmath264 + e \\bigl[\\tr \\bigl\\{t^4 \\bigl(t^2x^tx + d i_d \\bigr)^{-2}x^tx \\bigr\\ } \\bigr ] \\\\ & = & e \\bigl[\\tr \\bigl\\ { \\bigl(t^2x^tx + d i_d \\bigr)^{-2 } \\bigl(t^4x^tx + d \\tau^2i_d \\bigr ) \\bigr\\ } \\bigr].\\end{aligned}\\ ] ] now let @xmath265 denote the eigenvalues of @xmath53 . then @xmath266.\\end{aligned}\\ ] ] clearly , the right - hand side above is minimized by taking @xmath267 and @xmath268 $ ] .",
    "proof of theorem  [ mprisk ] suppose that @xmath109 and let @xmath136 be the empirical cumulative distribution function of the eigenvalues of @xmath53 . using integration by parts , for @xmath269 , @xmath270 similarly , @xmath271\\\\[-8pt ] & & { } - \\int_c^{\\infty } \\frac{1}{\\{s + d/(n\\tau^2)\\}^2 } \\bigl\\{1 - f_{d / n}(s ) \\bigr\\ } \\,\\mathrm{d}s .",
    "\\nonumber\\end{aligned}\\ ] ]    now let @xmath272 .",
    "taking @xmath273 in ( [ mpriska ] ) and ( [ mpriskb ] ) implies @xmath274 where we have used the fact that @xmath275 , with probability 1 .",
    "thus , it follows from theorem  1.1 of bai _ et al . _",
    "@xcite ( see equation ( [ bai ] ) in section  [ sec2.2 ] above ) that @xmath276 part ( b ) of theorem  [ mprisk ] follows immediately .    to prove theorem  [ mprisk](a )",
    "we show that , in fact , @xmath277 if @xmath125 or @xmath227 . first",
    ", suppose that @xmath125 .",
    "then , for @xmath278 , @xmath279 and @xmath280 \\,\\mathrm{d}s \\biggr{\\vert}\\\\ & \\leq & e \\biggl\\{\\int_0^c s^{-1 } \\,\\mathrm{d}\\f_{n , d}(s ) \\biggr\\ } + \\frac{1}{c + d/(n\\tau^2 ) } e \\bigl\\{\\f_{n , d}(c ) \\bigr\\ } \\\\ & & { } + \\frac{1}{c + d/(n\\tau^2)}\\sup_{s \\geq c } \\bigl{\\vert}e \\bigl\\ { \\f _ { n , d}(s ) \\bigr\\ } - f_{d / n}(s ) \\bigr{\\vert}\\\\ & \\leq & e \\bigl[s_d^{-1 } \\1_{\\ { s_d < c\\ } } \\bigr ] + \\frac{1}{c + d/(n\\tau^2)}p(s_d < c ) \\\\ & & { } + \\frac{1}{c + d/(n\\tau^2)}\\sup_{s \\geq c } \\bigl{\\vert}e \\bigl\\ { \\f _ { n , d}(s ) \\bigr\\ } - f_{d / n}(s ) \\bigr{\\vert}\\\\ & \\leq & \\bigl\\{e \\bigl(s_d^{-2 } \\bigr ) \\bigr \\}^{1/2}p(s_d < c)^{1/2 } + c^{-1}p(s_d < c ) + c^{-1}\\sup_{s \\geq c } \\bigl{\\vert}e \\bigl\\ { \\f_{n , d}(s ) \\bigr\\ } - f_{d / n}(s ) \\bigr{\\vert},\\end{aligned}\\ ] ] where @xmath281 is the smallest eigenvalue of @xmath53 , @xmath282 is the indicator function of the event @xmath283 , and @xmath284 denotes the probability measure induced by the joint distribution of @xmath25 .",
    "we bound the first two terms and the last term on right - hand side above separately . bounding the first two terms",
    "relies on a result of davidson and szarek @xcite .",
    "their theorem ii.13 , which is a consequence of concentration of measure , implies that    @xmath285    provided @xmath286 .",
    "additionally , lemma  [ c2 ] in appendix implies that @xmath287 if @xmath288 .",
    "taking @xmath289 , it follows that @xmath290 ( in fact , we can conclude that the quantities on the left above decay exponentially , but this is not required for the current result ) .",
    "it now follows from theorem  1.1 of bai _ et al .",
    "_ @xcite that @xmath291 . for the case",
    "where @xmath227 , we note that the same argument as above may be applied , except that both @xmath292 and @xmath293 have a mass of weight @xmath294 at 0 , which cancel . theorem  [ mprisk](a ) follows .",
    "proof of proposition  [ r0inf ] proposition  [ r0inf](b ) follows directly from proposition  [ rrisk ] .",
    "part ( a ) follows from two applications of jensen s inequality .",
    "if @xmath295 , then @xmath296 \\\\ & \\geq & d \\biggl[\\frac{1}{d}e \\bigl\\{\\tr \\bigl(x^tx \\bigr ) \\bigr\\ } + \\frac{d}{{\\vert}\\bb { \\vert}^2 } \\biggr]^{-1 } \\\\ & = & \\frac{{\\vert}\\bb{\\vert}^2d / n}{{\\vert}\\bb{\\vert}^2 + d / n } \\\\ & = & r_r^0\\bigl({\\vert}\\bb{\\vert},d / n\\bigr)\\end{aligned}\\ ] ] and , since @xmath297 = d/(n - d-1)$ ] ( problem 3.6 of muirhead @xcite ) , @xmath296 \\\\ & \\leq & \\frac{e[\\tr\\{(x^tx)^{-1}\\}]}{1 + \\sklfrac{1}{{\\vert}\\bb{\\vert}^2}e[\\tr \\{(x^tx)^{-1}\\ } ] } \\\\ & = & \\frac{{\\vert}\\bb{\\vert}^2d/(n - d-1)}{{\\vert}\\bb{\\vert}^2 + d/(n - d-1 ) } \\\\ & = & r_r^0 \\bigl\\{{\\vert}\\bb{\\vert},d/(n - d-1 ) \\bigr \\}.\\end{aligned}\\ ] ] thus , @xmath298 . it follows that if @xmath39 , then @xmath299    proof of proposition  [ mrequiv ] suppose that @xmath300 and that @xmath109",
    ". let @xmath301 denote the first standard basis vector and let @xmath172 satisfy @xmath302 . then , since @xmath303 and @xmath25 has the same distribution as @xmath304 , @xmath305 part ( a ) of the proposition follows .    to prove part ( b ) ,",
    "we first show that @xmath306 given an estimator @xmath36 ( not necessarily orthogonally equivariant ) , define @xmath307 where @xmath308 is the uniform ( haar ) measure on @xmath170 .",
    "then @xmath303 and , since @xmath28 and @xmath257 have the same distribution for any @xmath309 , @xmath310 the identity ( [ prop3a ] ) follows .",
    "thus , by part ( a ) and the fact that @xmath178 , @xmath311 which completes the proof of the proposition .",
    "proof of theorem  [ adapt ] suppose that @xmath109 .",
    "it is clear that ( [ adapt2 ] ) follows from ( [ adapt1 ] ) and theorem  [ mprisk ] . to prove ( [ adapt1 ] ) , consider the risk decomposition of the oracle and adaptive ridge estimators @xmath312 the triangle inequality implies @xmath313 where @xmath314 to prove the theorem , we bound the terms @xmath315 , @xmath316 , and @xmath317 separately .",
    "let @xmath265 denote the ordered eigenvalues of @xmath53 and let @xmath172 be a @xmath171 orthogonal matrix such that @xmath318 is diagonal .",
    "additionally , let @xmath319 and let @xmath320 , where @xmath321 denotes the moore ",
    "penrose pseudoinverse of @xmath322 if @xmath323 is not invertible .",
    "then @xmath324 since @xmath325 for @xmath326 , @xmath327 & \\leq & \\biggl(\\frac{d}{n } \\biggr)^2\\frac{{\\vert}\\tau^2 - \\hat{\\tau}^2{\\vert}}{\\hat{\\tau}^2 + d / n } \\biggl ( \\frac{1}{\\hat { \\tau}^2 + d / n } + \\frac{1}{\\tau^2 + d / n } \\biggr ) \\biggl(\\frac { 1}{s_{d\\wedge n}^2 } + s_1 \\biggr).\\end{aligned}\\ ] ] similarly , we have @xmath328 & = & \\frac{1}{n } \\biggl{\\vert}\\sum_{j = 1}^d \\frac{(d / n)\\tilde{\\d}_j^2s_j(\\hat{\\tau}^2 - \\tau^2)}{(\\hat{\\tau } ^2s_j + d / n)(\\tau^2s_j + d / n ) } \\biggl(\\frac{\\hat{\\tau}^2}{\\hat{\\tau}^2s_j + d / n } + \\frac{\\tau^2}{\\tau^2s_j + d / n } \\biggr ) \\biggr { \\vert}\\\\[1pt ] & \\leq&\\frac{1}{n}\\sum_{j = 1}^{d\\wedge n } \\frac{(d / n)\\tilde{\\d}_j^2{\\vert}\\hat{\\tau}^2 - \\tau^2{\\vert}}{(\\hat{\\tau}^2 + d / n)(\\tau^2 + d / n ) } \\biggl(\\frac { 1}{s_j } + s_j \\biggr ) \\\\[1pt ] & \\leq&\\frac{d}{n^2}{\\vert}\\tilde{\\dd}{\\vert}^2 \\frac{{\\vert}\\hat{\\tau}^2 - \\tau^2{\\vert}}{(\\hat{\\tau}^2 + d / n)(\\tau^2 +",
    "d / n ) } \\biggl ( \\frac{1}{s_{d \\wedge",
    "n } } + s_1 \\biggr).\\end{aligned}\\ ] ] repeated application of hlder s inequality and lemmas [ c2 ] , [ c3 ] and [ c5 ] ( found in appendix  ) imply that @xmath329    to bound @xmath317 , we condition on @xmath28 and use integration by parts ( stein s lemma , e.g. , lemma  3.6 of tsybakov @xcite ) : @xmath330 & = & \\frac{2d}{n^3 } e_{\\bb } \\biggl[\\y^tx \\biggl ( \\frac{d}{n}i_d - \\frac { \\hat{\\tau}^2}{n}x^tx \\biggr ) \\biggl(\\frac{\\hat{\\tau}^2}{n}x^tx + \\frac{d}{n}i_d \\biggr)^{-3 } \\bb\\1_{\\{{\\vert}\\y{\\vert}^2 \\geq n\\ } } \\biggr ] \\\\ & = & \\frac{2d}{n^3 } e_{\\bb } \\biggl[\\sum _ { j = 1}^d \\frac{(ns_j\\tilde{\\beta}_j + n^{1/2}s_j^{1/2}\\tilde{\\d } _",
    "j)(d / n - \\hat{\\tau}^2s_j)\\tilde{\\beta}_j}{(\\hat{\\tau}^2s_j + d / n)^3 } \\1_{\\ { { \\vert}\\y{\\vert}^2 \\geq n\\ } } \\biggr].\\end{aligned}\\ ] ] it follows that @xmath331 where we have used lemmas [ c2 ] and [ c3 ] to obtain the last bound .",
    "the theorem follows from ( [ adapta ] ) and ( [ adaptc ] ) .",
    "this appendix is devoted to a proof of theorem  [ main ] , which is fairly involved .",
    "our first step is to show that the minimax problem ( [ mr ] ) may be reformulated as a minimax problem for an equivalent sequence model .",
    "ultimately , this will substantially simplify notation and allow for a direct application of results from marchand @xcite that are important for theorem  [ main ] .",
    "let @xmath99 be a random orthogonally invariant @xmath332 positive semidefinite matrix with rank @xmath333 , almost surely ( by orthogonally invariant , we mean that @xmath99 and @xmath334 have the same distribution for any @xmath335 ) .",
    "additionally , let @xmath336 be an @xmath333-dimensional gaussian random vector that is independent of @xmath99 .",
    "suppose that the observed data are @xmath337 , where @xmath338 and @xmath339 is an unknown parameter .    for an estimator @xmath340 ,",
    "define the risk under squared error loss @xmath341 where , abusing notation , the expectation @xmath342 is taken with respect to @xmath343 and the subscript @xmath344 indicates that @xmath345 ( we will sometimes drop the subscript @xmath344 in @xmath342 if the integrand does not depend on @xmath344 ) . to distinguish @xmath342 from expectations",
    "@xmath346 considered elsewhere in the paper , we emphasize that all expectations considered in this section ( appendix ) refer to the sequence model ( [ seq0 ] ) .",
    "most of the key concepts initially introduced in the context of the linear model ( [ lm ] ) have analogues in the sequence model ( [ seq0 ] ) .",
    "define @xmath347 to be the posterior mean of @xmath344 under the assumption that @xmath348 is uniformly distributed on @xmath349 and define @xmath350 to be the posterior mean under the assumption that @xmath351 ( for both of these bayes estimators we assume that @xmath344 is independent of @xmath352 and @xmath99 ) .",
    "the estimators @xmath353 and @xmath354 are analogous to the minimax estimator @xmath174 and the optimal ridge estimator @xmath45 in the linear model , respectively .",
    "now define the minimax risk over @xmath349 for the sequence model @xmath355 where the infimum is over all measurable estimators for @xmath344 .",
    "we have the following analogue to proposition  [ mrequiv](b ) .    [ b0 ]",
    "suppose that @xmath31 and that @xmath356 .",
    "then @xmath357 and @xmath358    the proof of lemma  [ b0 ] is essentially the same as that of proposition  [ mrequiv ] and is omitted .",
    "the next result gives an equivalence between the linear model ( [ lm ] ) and the sequence model ( [ seq0 ] ) when @xmath192 .",
    "[ lemmab1 ] suppose that @xmath359 and that @xmath360 .",
    "let @xmath31 .",
    "if @xmath361 , then @xmath362 and @xmath363    lemma  [ lemmab1 ] follows directly upon identifying @xmath364 with @xmath365 ( x^tx)^{-1}x^t\\ee$ ] .",
    "lemma  [ lemmab1 ] implies that it suffices to consider the sequence model ( [ seq0 ] ) ( in particular , @xmath366 and @xmath367 ) in order to prove theorem  [ main](a ) .",
    "note that lemma  [ lemmab1 ] does not apply when @xmath92 . indeed ,",
    "if @xmath368 , then the usual ols estimator is not defined ( moreover , if one uses a pseudoinverse in place of @xmath369 , then @xmath370 is not necessarily in @xmath33 ) .",
    "the case where @xmath91 is considered separately below .      in this section ,",
    "we prove theorem  [ main](a ) by bounding @xmath371 by lemma  [ lemmab1 ] , this is equivalent to bounding @xmath372 .",
    "the lower bound @xmath373 follows immediately from lemma  [ b0 ] .",
    "marchand @xcite obtained an upper bound on ( [ boundthis ] ) in the case where @xmath374 for fixed @xmath375 ( i.e. , in the gaussian sequence model with i.i.d .",
    "errors ) , which is one of the keys to the proof of theorem  [ main](a ) .",
    "[ lemmab2 ] suppose that @xmath374 for some fixed @xmath376 and that @xmath377",
    ". then @xmath378    thus , in the gaussian sequence model with i.i.d .",
    "errors , the risk of @xmath354 is nearly as small as that of @xmath379 .",
    "marchand s result relies on somewhat delicate calculations involving modified bessel functions ( robert @xcite ) . a direct approach to bounding ( [ boundthis ] ) for general @xmath99 might involve attempting to mimic these calculations .",
    "however , this seems daunting ( bickel @xcite ) .",
    "brown s identity , which relates the risk of a bayes estimator to the fisher information , allows us to sidestep these calculations and apply marchand s result directly .",
    "define the fisher information of a random vector @xmath380 , with density @xmath381 ( with respect to lebesgue measure on @xmath382 ) by @xmath383 where @xmath384 is the gradient of @xmath385 .",
    "brown s identity has typically been used for univariate problems or problems in the sequence model with i.i.d .",
    "gaussian errors ( bickel @xcite , brown and gajek @xcite , brown and low @xcite , dasgupta @xcite ) . the next proposition is a straightforward generalization to the correlated multivariate gaussian setting . its proof is based on stein s lemma .",
    "[ lemmab3 ] let @xmath386 denote the fisher information of @xmath387 , conditional on @xmath99 , under the assumption that @xmath388 is independent of @xmath352 and @xmath99 .",
    "if @xmath389 , then @xmath390.\\ ] ]    suppose that @xmath389 and let @xmath391 be the density of @xmath345 , conditional on @xmath99 and under the assumption that @xmath388 . then @xmath392 it follows that @xmath393\\\\[-8pt ] & & { } + e_{\\pi_{s^{m-1}(\\tau ) } } \\biggl\\{\\frac{\\nabla f(\\w)^t\\s ^2\\nabla f(\\w)}{f(\\w)^2 } \\biggr\\ } \\nonumber \\\\ & = & e \\bigl\\{\\tr(\\s ) \\bigr\\ } + 2e_{\\pi_{s^{m-1}(\\tau ) } } \\biggl\\ { \\frac{\\dd^t\\s ^{3/2}\\nabla f(\\w)}{f(\\w ) } \\biggr\\ } \\nonumber \\\\ & & { }   + e \\bigl[\\tr \\bigl\\{\\s^2 i_{\\s } \\bigl ( \\bth+ \\s^{1/2}\\dd \\bigr ) \\bigr\\ } \\bigr].\\nonumber\\end{aligned}\\ ] ] by stein s lemma ( lemma  3.6 of tsybakov @xcite ) , @xmath394\\nonumber \\\\[-8pt]\\\\[-8pt ] & = & -e \\bigl[\\tr \\bigl\\{\\s^2 i_{\\s } \\bigl(\\bth+ \\s^{1/2}\\dd \\bigr ) \\bigr\\ } \\bigr ] . \\nonumber\\end{aligned}\\ ] ] brown s identity follows by combining ( [ lemmab2a ] ) and ( [ lemmab2b ] ) .",
    "using brown s identity , fisher information bounds may be converted to risk bounds , and vice - versa .",
    "its usefulness in the present context springs from two observations : ( i ) the decomposition @xmath395 where @xmath396 are independent of @xmath99 , @xmath397 is the smallest eigenvalue of @xmath99 , and @xmath398 is a constant ; and ( ii ) stam s inequality for the fisher information of sums of independent random variables .",
    "[ lemmab4 ] let @xmath399 be independent random variables that are absolutely continuous with respect to lebesgue measure on @xmath382 .",
    "then @xmath400 \\leq\\tr \\bigl[\\psi \\bigl\\{i(\\u ) ^{-1 } + i(\\vv)^{-1 } \\bigr\\}^{-1 } \\bigr]\\ ] ] for all @xmath332 positive definite matrices @xmath401 .    notice in ( [ decomp ] ) that @xmath402 may be viewed as an observation from the gaussian sequence model with i.i.d .",
    "errors , conditional on @xmath99 .",
    "the necessary bound on ( [ boundthis ] ) is obtained by piecing together brown s identity , the decomposition ( [ decomp ] ) , and stam s inequality , so that marchand s inequality ( lemma  [ lemmab2 ] ) may be applied to @xmath403 .",
    "[ lemmab5 ] suppose that @xmath99 has rank @xmath333 with probability @xmath191 and that @xmath389 .",
    "let @xmath404 denote the eigenvalues of @xmath99",
    ". then @xmath405.\\ ] ]    since @xmath99 is orthogonally invariant and independent of @xmath352 , @xmath406 \\\\ & & { } + e \\bigl[\\tr \\bigl\\ { \\bigl(\\tau^2/m \\bigr)^2 \\s \\bigl(\\s+ \\tau^2/mi_m \\bigr)^{-2 } \\bigr\\ } \\bigr]\\nonumber \\\\ & = & e \\bigl[\\tr \\bigl\\{\\tau^2/m\\s \\bigl(\\s+ \\tau^2/mi_m \\bigr)^{-1 } \\bigr\\ } \\bigr]\\nonumber \\\\   & = & e \\bigl[\\tr",
    "\\bigl\\ { \\bigl(\\s^{-1 } + m/ \\tau^2i_m \\bigr)^{-1 } \\bigr\\ } \\bigr].\\nonumber\\end{aligned}\\ ] ] thus , brown s identity and ( [ normalrisk ] ) imply @xmath407 \\\\ & & { } + e \\bigl[\\tr \\bigl\\ { \\bigl(\\s^{-1 } + m/\\tau^2i_m \\bigr)^{-1 } \\bigr\\ } \\bigr ] - e \\bigl\\{\\tr(\\s ) \\bigr\\ } \\\\ & = & e \\bigl[\\tr \\bigl\\{\\s^2i_{\\s } \\bigl(\\bth+ \\s^{1/2}\\dd \\bigr ) \\bigr\\ } \\bigr ] \\\\ & & { } - e \\bigl[\\tr \\bigl\\{\\s^2 \\bigl(\\s+ \\tau^2/mi_m \\bigr)^{-1 } \\bigr\\ } \\bigr].\\end{aligned}\\ ] ] taking @xmath408 , @xmath409 , and @xmath410 in stam s inequality , where @xmath411 , @xmath412 , and @xmath413 are given in ( [ decomp ] ) , one obtains @xmath414^{-1 } \\bigr ) \\bigr\\ } \\\\ & & \\qquad { } - e \\bigl[\\tr \\bigl\\{\\s^2 \\bigl(\\s+ \\tau^2/mi_m \\bigr)^{-1 } \\bigr\\ } \\bigr].\\end{aligned}\\ ] ] by orthogonal invariance , @xmath415 for some @xmath416 .",
    "thus , @xmath417 \\biggr)\\nonumber \\\\[-8pt]\\\\[-8pt ]   & & { } - e \\bigl[\\tr",
    "\\bigl\\{\\s^2 \\bigl(\\s+ \\tau^2/mi_m \\bigr)^{-1 } \\bigr\\ } \\bigr].\\nonumber\\end{aligned}\\ ] ] next we bound @xmath418 .",
    "conditioning on @xmath99 , applying brown s identity with @xmath419 in place of @xmath99 , and applying marchand s inequality ( lemma  [ lemmab2 ] ) with @xmath420 , we obtain @xmath421 \\leq m \\g\\sigma_m - \\biggl(1 - \\frac{1}{m } \\biggr ) \\frac{\\tau^2\\g\\sigma_mm}{\\tau^2 + \\g\\sigma_mm}.\\ ] ] dividing by @xmath422 above , it follows that @xmath423 further rearranging implies that @xmath424 hence , combining this with ( [ zineq ] ) , @xmath425 \\biggr ) \\\\ & & { } - e \\bigl[\\tr \\bigl\\{\\s^2 \\bigl(\\s+ \\tau^2/mi_m \\bigr)^{-1 } \\bigr\\ } \\bigr].\\end{aligned}\\ ] ] finally , taking @xmath426 above yields @xmath427 \\biggr ) \\\\ & & { } - e \\bigl[\\tr \\bigl\\{\\s^2 \\bigl(\\s+ \\tau^2/mi_m \\bigr)^{-1 } \\bigr\\ } \\bigr ] \\\\ & \\leq & e \\biggl [ \\biggl(\\frac{\\sigma_1}{m\\sigma_m } \\wedge1 \\biggr)\\tr \\bigl\\ { \\bigl ( \\s^{-1 } + m/\\tau^2i_m \\bigr)^{-1 } \\bigr\\ } \\biggr],\\end{aligned}\\ ] ] where it is elementary to verify the second inequality upon diagonalizing @xmath99 .",
    "this completes the proof of the lemma .",
    "theorem  [ main](a ) follows immediately from ( [ lboundthis ] ) and lemmas [ lemmab1 ] and [ lemmab5 ] .",
    "it remains to prove theorem  [ main](b ) , which is achieved through a sequence of lemmas .",
    "similar to the proof of theorem  [ main](a ) , the initial steps involve reducing the problem from the linear model to the sequence model . in the following lemma",
    ", we derive a basic property of orthogonally equivariant estimators for @xmath13 ( in the linear model ) when @xmath91 .",
    "[ obigd ] suppose @xmath91 and that @xmath300 is an orthogonally equivariant estimator for @xmath13 in the linear model ( [ lm ] ) .",
    "further suppose that @xmath428 , where @xmath429 , @xmath283 is an @xmath430 diagonal matrix , and @xmath431 is an @xmath432 matrix with orthonormal columns .",
    "let @xmath433 be a @xmath434 matrix so that @xmath435",
    ". then @xmath436 .",
    "let @xmath437 and let @xmath438 .",
    "then @xmath439 since ( [ obigd1 ] ) holds for all @xmath440 , we must have @xmath441 .    in the next lemma",
    ", we relate the minimax risk under the linear model @xmath38 to the risk under the sequence model .",
    "[ sbigd ] suppose that @xmath91 and let @xmath442 . in the sequence model ( [ seq0 ] ) , suppose that @xmath443 and @xmath444 .",
    "for @xmath445 , let @xmath446 be the projection onto the first @xmath2 coordinates .",
    "then @xmath447    by proposition  [ mrequiv ] , @xmath448 assume that @xmath300 and let @xmath449 be the decomposition in lemma  [ obigd ] .",
    "additionally , let @xmath450 be the first @xmath2 coordinates of @xmath36 . then",
    ", under the linear model ( [ lm ] ) , @xmath451 let @xmath452 .",
    "integrating @xmath13 over @xmath33 with respect to the uniform measure , making the change of variables @xmath453 and using the fact that @xmath303 , it follows that @xmath454 next , for @xmath455 and @xmath430 positive definite matrices @xmath99 , define the estimator for the sequence model @xmath456 .",
    "then , with @xmath457 and @xmath458 , @xmath459 by equivariance , @xmath460 is constant over spheres @xmath461 , which implies that @xmath462 .",
    "hence , @xmath463 the lemma follows from ( [ sbigd1 ] ) and ( [ sbigd2 ] ) .",
    "the proof of theorem  [ main](b ) will follow from a calculation involving lemmas [ lemmab5 ] and [ sbigd ] . the key part of this calculation is contained in the following lemma .",
    "[ lemmab7 ] suppose that @xmath464 .",
    "let @xmath465 denote the nonzero eigenvalues of @xmath53 .",
    "then @xmath466 + \\frac { d - n}{d}\\tau^2.\\ ] ]    with @xmath467 , @xmath457 and @xmath468 , lemma  [ lemmab5 ] and ( [ normalrisk ] ) imply that @xmath469 \\\\ & = & e \\biggl [ \\biggl\\ { \\biggl(1 - \\frac{s_1}{ns_n } \\biggr)\\vee0 \\biggr\\ } \\tr \\biggl\\ { \\biggl(xx^t + \\frac{n}{{\\vert}\\bth_n{\\vert}^2}i_n \\biggr)^{-1 } \\biggr\\ } \\biggr].\\nonumber\\end{aligned}\\ ] ] additionally , if @xmath470 , then @xmath471 in distribution , where @xmath472 ; using basic properties of the chi - squared distribution , it follows that @xmath473 where @xmath474 is the projection of @xmath445 onto the first @xmath2 coordinates .",
    "thus , by ( [ lbbigd ] ) , jensen s inequality and ( [ invid ] ) , @xmath475 \\\\ & & \\quad   \\geq e \\biggl [ \\biggl(1 - \\frac{s_1}{ns_n } \\biggr)\\tr \\biggl\\ { \\biggl(xx^t + \\frac{n(d-2)}{\\tau^2(n-2)}i_n \\biggr)^{-1 } \\biggr\\ } \\biggr].\\end{aligned}\\ ] ] the lemma follows by combining the last inequality above with lemma  [ sbigd ] .",
    "we now have the tools to complete the proof of theorem  [ main](b ) .",
    "suppose that @xmath92 and @xmath104 .",
    "then @xmath476 + \\frac{d - n}{d}\\tau^2.\\ ] ] since @xmath477 , lemma  [ lemmab7 ] implies @xmath478 \\\\ & & { } - e \\biggl [ \\biggl(1 - \\frac{s_1}{ns_n } \\biggr)\\tr \\biggl\\ { \\biggl(xx^t + \\frac{n(d-2)}{\\tau^2(n-2)}i_n \\biggr)^{-1 } \\biggr\\ } \\biggr ] \\\\ & \\leq&\\frac{1}{n}e \\biggl[\\frac{s_1}{s_n}\\tr \\biggl\\ { \\biggl(xx^t + \\frac{d}{\\tau^2}i_n \\biggr)^{-1 } \\biggr\\ } \\biggr ] \\\\ & & { } + \\frac{2(d - n)}{\\tau^2(n-2)}e \\biggl[\\tr \\biggl\\ { \\biggl(xx^t + \\frac{d}{\\tau^2}i_n \\biggr)^{-2 } \\biggr\\ } \\biggr].\\end{aligned}\\ ] ] theorem  [ main](b ) follows .",
    "[ c1 ] let @xmath479 denote the smallest eigenvalue of @xmath53 .",
    "suppose that @xmath480 is a positive real number and that @xmath481 .",
    "if @xmath482 , then @xmath483 . if @xmath484 , then @xmath485    suppose first that @xmath482 .",
    "then @xmath486 is a chi - squared random variable on @xmath2 degrees of freedom . by theorem  1 of keki and vasi @xcite , which gives convenient bounds on the ratio of two gamma functions , @xmath487 this proves the first part of the lemma .",
    "now suppose that @xmath484 .",
    "suppose further that ( [ lemmac1statement ] ) is true for @xmath488 . if @xmath489 , then @xmath490 and ( [ lemmac1statement ] ) holds for @xmath491 .",
    "thus , we may assume that @xmath492 .",
    "let @xmath493 be a fixed positive number .",
    "then @xmath494 + t^{-a}.\\ ] ] muirhead @xcite ( corollary  3.2.19 ) gives the joint density of the ordered eigenvalues , @xmath495 , of @xmath496 : @xmath497 where @xmath498 and @xmath499 is the multivariate gamma function .",
    "let @xmath500 .",
    "then , @xmath501 & = & \\int _ { t_d \\cap\\{s_d < t\\ } } s_d^{-a}f_{d , n}(s_1 , \\ldots , s_d ) \\,\\mathrm{d}s_1 \\cdots \\,\\mathrm{d}s_d \\\\ & \\leq&\\int_{t_{d-1 } } \\biggl\\{\\int_0^t s_d^{-a } f_{d , n}(s_1 , \\ldots , s_d ) \\,\\mathrm{d}s_d\\biggr\\ } \\,\\mathrm{d}s_1 \\cdots \\,\\mathrm{d}s_{d-1 } \\\\ & \\leq&\\frac{c_{d , n}}{c_{d-1,n}}\\int_{t_{d-1 } } \\biggl(\\prod _ { j = 1}^{d-1 } s_j \\biggr)^{1/2 } f_{d-1,n}(s_1,\\ldots , s_{d-1 } ) \\,\\mathrm{d}s_1 \\cdots \\,\\mathrm{d}s_{d-1 } \\\\ & & { } \\cdot\\int_0^t s^{(n - d-1)/2-a } \\mathrm{e}^{-ns/2 } \\,\\mathrm{d}s \\\\ & \\le&\\frac{c_{d , n}}{c_{d-1,n } } e",
    "\\bigl\\{\\det \\bigl(n^{-1}z^tz \\bigr)^{1/2 } \\bigr\\}t^{(n - d+1)/2 - a},\\end{aligned}\\ ] ] where @xmath502 is an @xmath503-dimensional matrix with i.i.d . @xmath504 entries and the last inequality above follows from the fact that @xmath505 . it is easy to check that @xmath506 additionally , it is well known ( problem 3.11 in muirhead @xcite , for instance ) that @xmath507 by corollary  1.2 of batir @xcite ( a variant of stirling s approximation ) , @xmath508 it follows that , @xmath509 and @xmath510 \\leq t^{(n - d+1)/2-a}\\frac{\\uppi}{4}\\sqrt{\\frac{n^5}{(d-1)(n - d)^2 } } \\mathrm{e}^{n + 1/2}.\\ ] ] thus , by ( [ lemmac1a ] ) @xmath511 taking @xmath512^{-2/(n - d+1)}$ ] gives ( [ lemmac1statement ] ) .",
    "[ c2 ] let @xmath513 denote the largest and smallest eigenvalues of @xmath53 , respectively .",
    "suppose that @xmath480 is a fixed positive real number and that @xmath514 for some fixed constant @xmath515 .",
    "a.   @xmath516",
    ". b.   if @xmath517 , then @xmath518 .",
    "the constants implicit in the bounds from parts and depend on the exponent @xmath519 .",
    "part ( a ) is well known and may be easily derived from large deviations results for @xmath520 ( see , e.g. , theorem ii.13 of davidson and szarek @xcite ) .",
    "part ( b ) follows directly from lemma  [ c1 ] .",
    "[ c3 ] let @xmath480 be a fixed positive real number . if @xmath521 , then @xmath522 where the implicit constant in the big-@xmath523 bound depends on the exponent @xmath519 .",
    "suppose that @xmath104 .",
    "since @xmath524 has a chi - squared distribution with @xmath2 degrees of freedom , @xmath525    [ c4 ] let @xmath526 denote the probability measure induced by the joint distribution of @xmath15 , where @xmath527 .",
    "then @xmath528    suppose that @xmath104 .",
    "let @xmath529 be fixed .",
    "since @xmath530 has a chi - squared distribution with @xmath2 degrees of freedom , it follows that @xmath531 taking @xmath532 and using the fact that @xmath533 for all @xmath534 yields @xmath535    [ c5 ] suppose @xmath480 is a fixed positive real number",
    ". then @xmath536 where the implicit constant in the big-@xmath523 bound depends on the exponent @xmath519 .",
    "suppose that @xmath104 .",
    "from the definition of @xmath537 , @xmath538 since @xmath539 , @xmath540 additionally , lemma  [ c4 ] implies @xmath541 the lemma follows by combining ( [ lemmac4a ] ) and ( [ lemmac4c ] ) .",
    "the author would like to thank alan edelman , bill strawderman , cun - hui zhang and sihai zhao for their helpful comments and inspiration .",
    "the author thanks the associate editor and the referees for their careful reading of the paper and their suggestions that helped to greatly improve its presentation . supported by nsf grant dms-1208785 ."
  ],
  "abstract_text": [
    "<S> we study asymptotic minimax problems for estimating a @xmath0-dimensional regression parameter over spheres of growing dimension ( @xmath1 ) . assuming that the data follows a linear model with gaussian predictors and errors , we show that ridge regression is asymptotically minimax and derive new closed form expressions for its asymptotic risk under squared - error loss . </S>",
    "<S> the asymptotic risk of ridge regression is closely related to the stieltjes transform of the marenko  </S>",
    "<S> pastur distribution and the spectral distribution of the predictors from the linear model . </S>",
    "<S> adaptive ridge estimators are also proposed ( which adapt to the unknown radius of the sphere ) and connections with equivariant estimation are highlighted . </S>",
    "<S> our results are mostly relevant for asymptotic settings where the number of observations , @xmath2 , is proportional to the number of predictors , that is , @xmath3 .    ./style / arxiv - general.cfg </S>"
  ]
}