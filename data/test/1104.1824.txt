{
  "article_text": [
    "the trend for massively parallel computation is moving from the more common multi - core cpus towards gpus for several significant reasons @xcite .",
    "one important reason for such a trend in recent years include the low consumption in terms of power of gpus compared to setting up machines and infrastructure which will utilize multiple cpus in order to obtain the same level of parallelization and performance @xcite .",
    "another more important reason is that gpus are architectured for _ massively parallel computations _ since unlike most general purpose multicore cpus , a large part of the architecture of gpus are devoted to parallel execution of arithmetic operations , and not on control and caching just like in cpus @xcite .",
    "arithmetic operations are at the heart of many basic operations as well as scientific computations , and these are performed with larger speedups when done in parallel as compared to performing them sequentially . in order to perform these arithmetic operations on the gpu",
    ", there is a set of techniques called @xmath2 ( general purpose computations on the gpu ) coined by mark harris in 2002 which allows programmers to do computations on gpus and not be limited to just graphics and video processing alone @xcite .",
    "_ membrane computing _ or its more specific counterpart , a _ p system _ , is a turing complete computing model ( for several p system variants ) that perform computations nondeterministically , exhausting all possible computations at any given time .",
    "this type of unconventional model of computation was introduced by gheorghe pun in 1998 and takes inspiration and abstraction , similar to other members of _ natural computing _",
    "( e.g. dna / molecular computing , neural networks , quantum computing ) , from nature @xcite .",
    "specifically , p systems try to mimic the constitution and dynamics of the living cell : the multitude of elements inside it , and their interactions within themselves and their environment , or outside the cell s @xmath3 ( the cell s outermost membrane ) . before proceeding ,",
    "it is important to clarify what is meant when it is said that nature @xmath4 , particularly life or the cell : computation in this case involves reading information from memory from past or present stimuli , rewrite and retrieve this data as a stimuli from the environment , process the gathered data and act accordingly due to this processing @xcite .",
    "thus , we try to extend the classical meaning of computation presented by allan turing .",
    "sn p systems differ from other types of p systems precisely because they are @xmath5 and the working alphabet contains only _ one object type_. these characteristics , among others , are meant to capture the workings of a special type of cell known as the @xmath6 .",
    "neurons , such as those in the human brain , communicate or compute by sending indistinct signals more commonly known as action potential or _ spikes _ @xcite .",
    "@xmath7 is then communicated and encoded not by the spikes themselves , since the spikes are unrecognizable from one another , but by ( a ) the time elapsed between spikes , as well as ( b ) the number of spikes sent / received from one neuron to another , oftentimes under a certain time interval @xcite .",
    "it has been shown that sn p systems , given their nature , are representable by matrices @xcite .",
    "this representation allows design and implementation of an sn p system simulator using parallel devices such as gpus .",
    "since the time p systems were presented , many simulators and software applications have been produced @xcite . in terms of",
    "_ high performance computing _",
    ", many p system simulators have been also designed for clusters of computers @xcite , for reconfigurable hardware as in fpgas @xcite , and even for gpus @xcite .",
    "all of these efforts have shown that parallel architectures are well - suited in performance to simulate p systems .",
    "however , these previous works on hardware are designed to simulate _ cell - like _ p system variants , which are among the first p system variants to have been introduced .",
    "thus , the efficient simulation of snp systems is a new challenge that requires novel attempts .",
    "a matrix representation of sn p systems is quite intuitive and natural due to their graph - like configurations and properties ( as will be further shown in the succeeding sections such as in subsection [ computesnp ] ) .    on the other hand , _",
    "linear algebra _ operations have been efficiently implemented on parallel platforms and devices in the past years .",
    "for instance , there is a large number of algorithms implementing @xmath8 and @xmath9 operations on the gpu .",
    "these algorithms offer huge performance since dense linear algebra readily maps to the data - parallel architecture of gpus @xcite .",
    "it would thus seem then that a matrix represented sn p system simulator implementation on highly parallel computing devices such as gpus be a natural confluence of the earlier points made .",
    "the matrix representation of sn p systems bridges the gap between the theoretical yet still computationally powerful sn p systems and the applicative and more tangible gpus , via an sn p system simulator .",
    "the design and implementation of the simulator , including the algorithms deviced , architectural considerations , are then implemented using cuda .",
    "the compute unified device architecture ( cuda ) programming model , launched by nvidia in mid-2007 , is a hardware and software architecture for issuing and managing computations on their most recent gpu families ( g80 family onward ) , making the gpu operate as a highly parallel computing device @xcite .",
    "cuda programming model extends the widely known ansi c programming language ( among other languages which can interface with cuda ) , allowing programmers to easily design the code to be executed on the gpu , avoiding the use of low - level graphical primitives .",
    "cuda also provides other benefits for the programmer such as abstracted and automated scaling of the parallel executed code .",
    "this paper starts out by introducing and defining the type of snp system that will be simulated . afterwards the nvidia cuda model and architecture are discussed , baring the scalability and parallelization cuda offers .",
    "next , the design of the simulator , constraints and considerations , as well as the details of the algorithms used to realize the snp system are discussed .",
    "the simulation results are presented next , as well as observations and analysis of these results .",
    "the paper ends by providing the conclusions and future work .",
    "the objective of this work is to continue the creation of p system simulators , in this particular case an sn p system , using highly parallel devices such as gpus .",
    "fidelity to the computing model ( the type of snp system in this paper ) is a part of this objective .",
    "the type of snp systems focused on by this paper ( scope ) are those without delays i.e. those that spike or transmit signals the moment they are able to do so @xcite .",
    "variants which allow for delays before a neuron produces a spike , are also available @xcite .",
    "an snp system without delay is of the form :    [ snpdefn ] @xmath10 where :    1 .",
    "@xmath11 is the alphabet made up of only one object , the system spike @xmath12 .",
    "2 .   @xmath13 are @xmath14 number of neurons of the form @xmath15 where : 1 .",
    "@xmath16 gives the initial number of @xmath12s i.e. spikes contained in neuron @xmath17 2 .",
    "@xmath18 is a finite set of rules of with two forms : 1 .",
    "@xmath19 , are known as _ spiking rules _",
    ", where @xmath20 is a regular expression over @xmath12 , and @xmath21 , such that @xmath22 number of spikes are produced , one for each adjacent neuron with @xmath17 as the originating neuron and @xmath23 .",
    "@xmath24 , are known as _ forgetting rules _ , for @xmath25 , such that for each rule @xmath26 of type ( b-1 ) from @xmath18 , @xmath27 .",
    "@xmath28 , a special case of ( b-1 ) where @xmath20 = @xmath29 , @xmath30 .",
    "@xmath31 are the synapses i.e. connection between neurons .",
    "@xmath32 are the input and output neurons , respectively .",
    "furthermore , rules of type ( b-1 ) are applied if @xmath17 contains @xmath33 spikes , @xmath34 and @xmath30 . using this type of rule",
    "uses up or consumes @xmath33 spikes from the neuron , producing a spike to each of the neurons connected to it via a forward pointing arrow i.e. away from the neuron . in this manner , for rules of type ( b-2 )",
    "if @xmath17 contains @xmath35 spikes , then @xmath35 spikes are forgotten or removed once the rule is used .",
    "the non - determinism of sn p systems comes with the fact that more than one rule of the several types are applicable at a given time , given enough spikes .",
    "the rule to be used is chosen non - deterministically in the neuron . however , only one rule can be applied or used at a given time @xcite . the neurons in an sn p system operate in parallel and in unison , under a global clock @xcite . for figure [ snp_ex ] no input neuron is present , but neuron 3 is the output neuron , hence the arrow pointing towards the environment , outside the snp system .    the sn p system in figure [ snp_ex ] is @xmath36 , a 3 neuron system whose neurons are labeled ( neuron 1/@xmath37 to neuron 3/@xmath38 ) and whose rules have a total system ordering from ( 1 ) to ( 5 ) .",
    "neuron 1/@xmath37 can be seen to have an initial number of spikes equal to 2 ( hence the @xmath39 seen inside it ) .",
    "there is @xmath40 input neuron , but @xmath38 is the output neuron , as seen by the arrow pointing towards the environment ( not to another neuron ) .",
    "more formally , @xmath36 can be represented as follows :    @xmath41 where @xmath42 , @xmath43 , ( neurons 2 to 3 and their @xmath44s and @xmath18s can be similarly shown ) , @xmath45 are the synapses for @xmath36 , @xmath46 .",
    "this sn p system generates all numbers in the set @xmath0 - \\{@xmath1 } , hence it does nt @xmath47 , which can be easily verified by applying the rules in @xmath36 , and checking the spikes produced by the output neuron @xmath38 .",
    "this generated set is the result of the computation in @xmath36 .    , generating all numbers in @xmath0 - \\{@xmath1 } , from @xcite . ]",
    "a matrix representation of an sn p system makes use of the following vectors and matrix definitions @xcite .",
    "it is important to note that , just as in figure [ snp_ex ] , a total ordering of rules is considered .",
    "_ configuration vector _",
    "@xmath48 is the vector containing all spikes in every neuron on the @xmath49 computation step / time , where @xmath50 is the initial vector containing all spikes in the system at the beginning of the computation . for @xmath36 ( in figure [ snp_ex ] )",
    "the initial configuration vector is @xmath51 .    _",
    "spiking vector _ shows at a given configuration @xmath48 , if a rule is applicable ( has value _ 1 _ ) or not ( has value _ 0 _ instead ) . for @xmath36",
    "we have the spiking vector @xmath52 given @xmath50 .",
    "note that a 2nd spiking vector , @xmath52 , is possible if we use rule ( 2 ) over rule ( 1 ) instead ( but not both at the same time , hence we can not have a vector equal to @xmath53 , so this @xmath54 is invalid ) .",
    "@xmath55 in this case means that only one among several applicable rules is used and thus represented in the spiking vector .",
    "we can have all the possible vectors composed of @xmath56s and @xmath1s with length equal to the number of rules , but have only some of them be valid , given by @xmath57 later at subsection [ siminspect ] .    _ spiking transition matrix _",
    "@xmath58 is a matrix comprised of @xmath59 elements where @xmath59 is given as    [ defi - snp - mat ] @xmath60    for @xmath36 , the @xmath58 is as follows :    @xmath61    in such a scheme , rows represent rules and columns represent neurons .",
    "finally , the following equation provides the configuration vector at the @xmath62 step , given the configuration vector and spiking vector at the @xmath49 step , and @xmath58 :    @xmath63",
    "nvidia , a well known manufacturer of gpus , released in 2007 the cuda programming model and architecture @xcite . using extensions of the widely known c language ,",
    "a programmer can write parallel code which will then execute in multiple threads within multiple thread blocks , each contained within a grid of ( thread ) blocks .",
    "these grids belong to a single device i.e. a single gpu .",
    "each device/ gpu has multiple cores , each capable of running its own _ block of threads _",
    "the program run in the cuda model scales up or down , depending on the number of cores the programmer currently has in a device .",
    "this scaling is done in a manner that is abstracted from the user , and is efficiently handled by the architecture as well .",
    "automatic and efficient scaling is shown in figure [ cuda_scale ] .",
    "parallelized code will run faster with more cores than with fewer ones @xcite .",
    "code alongside the parallel execution of the @xmath64 function on the @xmath65 side , from @xcite . ]",
    "figure [ cuda_model ] shows another important feature of the cuda model : the host and the device parts .",
    "the host controls the execution flow while the device is a highly - parallel co - processor .",
    "device pertains to the gpu / s of the system , while the host pertains to the cpu / s .",
    "a function known as a _ kernel function _",
    ", is a function called from the host but executed in the device .    a general model for creating a cuda enabled program",
    "is shown in listing [ cuda - code ] .    ....",
    "//allocate memory on gpu e.g. cudamalloc ( ( void**)&dev_a , n * sizeof(int )    //populate arrays   . .",
    "//copy arrays from host to device e.g. cudamemcpy ( dev_a , a , n * sizeof(int ) ,   cudamemcpyhosttodevice )    //call kernel ( gpu ) function e.g. add<<<n , 1 > > > ( dev_a , dev_b , dev_c ) ;    // copy arrays from device to host e.g. cudamemcpy ( c , dev_c , n * sizeof ( int ) ,   cudamemcpydevicetohost )    //display results    //free memory e.g. cudafree ( dev_a ) ; ....    lines 2 and 21 , implement cuda versions of the standard c language functions e.g. the standard c function @xmath66 has the cuda c function counterpart being @xmath67 , and the standard c function @xmath68 has @xmath69 as its cuda c counterpart .",
    "lines 8 and 15 show a cuda c specific function , namely @xmath70 , which , given an input of pointers ( from listing [ cuda - code ] host code pointers are single letter variables such as @xmath12 and @xmath71,while device code variable counterparts are prefixed by @xmath72 such as @xmath73 and @xmath74 ) and the size to copy ( as computed by the @xmath75 function ) , moves data from host to device ( parameter @xmath76 ) or device to host ( parameter @xmath77 ) .",
    "a kernel function call uses the triple @xmath78 and @xmath79 operator , in this case the kernel function    @xmath80@xmath81 .",
    "this function adds the values , per element ( and each element is associated to 1 thread ) , of the variables @xmath73 and @xmath82 sent to the device , collected in variable @xmath74 before being sent back to the host / cpu .",
    "the variable @xmath83 in this case allows the programmer to specify @xmath83 number of threads which will execute the @xmath84 kernel function in parallel , with 1 specifying only one block of thread for all @xmath83 threads .",
    "since the kernel function is executed in parallel in the device , the function needs to have its inputs initially moved from the cpu / host to the device , and then back from the device to the host after computation for the results .",
    "this movement of data back and forth should be minimized in order to obtain more efficient , in terms of time , execution . implementing an equation such as ( [ next - config ] ) , which involves multiplication and addition between vectors and a matrix , can be done in parallel with the previous considerations in mind . in this case ,",
    "@xmath48 , @xmath54 , and @xmath58 are loaded , manipulated , and pre - processed within the host code , before being sent to the kernel function which will perform computations on these function arguments in parallel . to represent @xmath48 , @xmath54 , and @xmath58 ,",
    "text files are created to house each input , whereby each element of the vector or matrix is entered in the file in order , from left to right , with a blank space in between as a delimiter .",
    "the matrix however is entered in row - major ( a linear array of all the elements , rows first , then columns ) order format i.e. for the matrix @xmath58 seen in ( [ snp_mat ] ) , the row - major order version is simply @xmath85    row major ordering is a well - known ordering and representation of matrices for their linear as well as parallel manipulation in corresponding algorithms @xcite .",
    "once all computations are done for the @xmath62 configuration , the result of equation ( [ next - config ] ) are then collected and moved from the device back to the host , where they can once again be operated on by the host / cpu .",
    "it is also important to note that these operations in the host / cpu provide logic and control of the data / inputs , while the device / gpu provides the arithmetic or computational muscle , the laborious task of working on multiple data at a given time in parallel , hence the current dichotomy of the cuda programming model @xcite .",
    "the gpu acts as a _ co - processor _ of the central processor .",
    "this division of labor is observed in listing [ cuda - code ] .      once all 3 initial and necessary inputs are loaded ,",
    "as is to be expected from equation [ next - config ] , the device is first instructed to perform multiplication between the spiking vector @xmath54 and the matrix @xmath58 . to further simplify computations at this point ,",
    "the vectors are treated and automatically formatted by the host code to appear as single row matrices , since vectors can be considered as such .",
    "multiplication is done per element ( one element is in one thread of the device / gpu ) , and then the products are collected and summed to produce a single element of the resulting vector / single row matrix .",
    "once multiplication of the @xmath54 and @xmath58 is done , the result is added to the @xmath48 , once again element per element , with each element belonging to one thread , executed at the same time as the others .    for this simulator ,",
    "the host code consists largely of the programming language _ python _ , a well - known high- level , object oriented programming ( oop ) language .",
    "the reason for using a high - level language such as python is because the initial inputs , as well as succeeding ones resulting from exhaustively applying the rules and equation ( [ next - config ] ) require manipulation of the vector / matrix elements or values as _",
    "strings_. the strings are then concatenated , checked on ( if they conform to the form ( b-3 ) for example ) by the host , as well as manipulated in ways which will be elaborated in the following sections along with the discussion of the algorithm for producing all possible and valid @xmath54s and @xmath48s given initial conditions .",
    "the host code / python part thus implements the logic and control as mentioned earlier , while in it , the device / gpu code which is written in c executes the parallel parts of the simulator for cuda to be utilized .",
    "the current snp simulator , which is based on the type of snp systems without time delays , is capable of implementing rules of the form ( b-3 ) i.e. whenever the regular expression @xmath20 is equivalent to the regular expression @xmath86 in that rule .",
    "rules are entered in the same manner as the earlier mentioned vectors and matrix , as blank space delimited values ( from one rule to the other , belonging to the same neuron ) and $ delimited ( from one neuron to the other ) .",
    "thus for the snp system @xmath87 shown earlier , the file @xmath88 containing the blank space and _ $ _ delimited values is as follows : @xmath89    that is , rule ( 1 ) from figure [ snp_ex ] has the value @xmath90 in the file @xmath88 ( though rule ( 1 ) is nt of the form ( b-3 ) it nevertheless consumes a spike since its regular expression is of the same regular expression type as the rest of the rules of @xmath87 ) .",
    "another implementation consideration was the use of @xmath91 in python , since unlike dictionaries or tuples , lists in python are _ mutable _ , which is a direct requirement of the vector / matrix element manipulation to be performed later on ( concatenation mostly ) .",
    "hence a @xmath92 is represented as @xmath93 $ ] in python .",
    "that is , at the @xmath49 configuration of the system , the number of spikes of neuron 1 are given by accessing the index ( starting at zero ) of the configuration vector python @xmath94 variable @xmath95 , in this case if @xmath96\\ ] ]    then @xmath97 = 2 $ ] gives the number of spikes available at that time for neuron 1 , @xmath98 = 1 $ ] for neuron 2 , and so on .",
    "the file @xmath88 , which contains the ordered list of neurons and the rules that comprise each of them , is represented as a _ list of sub- lists _ in the python / host code . for snp system @xmath87 and from ( [ rules ] ) we have the following : @xmath99 , [ 1 ] , [ 1 , 2 ] ] \\ ] ]    neuron 1 s rules are given by accessing the sub - lists of @xmath88 ( again , starting at index zero ) i.e. rule ( 1 ) is given by @xmath100 [ 0 ] = 2 $ ] and rule ( 4 ) is given by @xmath101 [ 1 ] = 1 $ ] .",
    "finally , we have the input file @xmath102 , which holds the python @xmath94 version of ( [ row - maj ] ) .",
    "the general algorithm is shown in algorithm [ sim - algo ] .",
    "each line in algorithm [ sim - algo ] mentions which part / s the simulator code runs in , either in the device * ( device ) * or in the host * ( host ) * part .",
    "step @xmath103 of algorithm [ sim - algo ] makes the algorithm stop with _ 2 stopping criteria _ to do this :    one is when there are no more available spikes in the system ( hence a zero value for a configuration vector ) , and the second one being the fact that all previously generated configuration vectors have been produced in an earlier time or computation , hence using them again in part i of algorithm [ sim - algo ] would be pointless , since a redundant , infinite loop will only be formed .",
    "input files : @xmath95 , @xmath104 .",
    "i. * ( host ) * load input files . note that @xmath102 and @xmath88 need only be loaded once since they are unchanging , @xmath50 is loaded once , and then @xmath48s are loaded afterwards .",
    "( host ) * determine if a rule / element in @xmath88 is applicable based on its corresponding spike value in @xmath95 , and then generate all valid and possible spiking vectors in a list of lists @xmath105 given the 3 initial inputs .",
    "* ( device ) * from part ii .",
    ", run the kernel function on @xmath105 , which contains all the valid and possible spiking vectors for the current @xmath95 and @xmath88",
    ". this will generate the succeeding @xmath48s and their corresponding @xmath54s .    \\iv . *",
    "( host+device ) * repeat steps i to iv ( except instead of loading @xmath50 as @xmath95 , use the generated @xmath48s in iii ) until a zero configuration vector ( vector with only zeros as elements ) or further @xmath48s produced are repetitions of a @xmath48 produced at an earlier time .",
    "( stopping criteria in subsection [ snp - sim - algo ] )    another important point to notice is that either of the stopping criterion from [ snp - sim - algo ] could allow for a deeply nested computation tree , one that can continue executing for a significantly lengthy amount of time even with a multi - core cpu and even the more parallelized gpu .",
    "the more detailed algorithm for part @xmath106 of algorithm [ sim - algo ] is as follows .",
    "recall from the definition of an snp system ( definitin [ snpdefn ] ) that we have @xmath14 number of @xmath107s .",
    "we related @xmath14 to our implementation by noticing the cardinality of the python list @xmath88 .",
    "@xmath108    where    @xmath109    means the total number of rules in the @xmath110 neuron which satisfy the regular expresion @xmath20 in ( b-3 ) . @xmath14",
    "gives the total number of neurons , while @xmath57 gives the expected number of @xmath111 and @xmath112 @xmath54s which should be produced in a given configuration .",
    "we also define @xmath113 as both the largest and last integer value in the sub - list ( neuron ) created in step ii of algorithm [ sim - algo ] and further detailed in algorithm [ sim - algo2 ] , which tells us how many elements of that neuron satisfy @xmath20 .    during the exposition of the algorithm , the previous python lists ( from their vector / matrix counterparts in earlier sections ) ( [ confvec ] ) and ( [ rule - list ] ) will be utilized . for part @xmath106 algorithm [ sim - algo ]",
    "we have a sub - algorithm ( algorithm [ sim - algo2 ] ) for generating all valid and possible spiking vectors given input files @xmath102 , @xmath95 , and @xmath88 .",
    "create a list @xmath114 , a copy of @xmath88 , marking each element of @xmath114 in increasing order of @xmath0 , as long as the element / s satisfy the rule s regular expression @xmath20 of a rule ( given by list @xmath88 ) .",
    "elements that do nt satisfy @xmath20 are marked with 0 .",
    "+    to generate all possible and valid spiking vectors from @xmath114 , we go through each neuron i.e. all elements of @xmath114 , since we know a priori @xmath14 as well as the number of elements per neuron which satisfy @xmath20 .",
    "we only need to iterate through each neuron / element of @xmath114 , @xmath113 times .",
    "( from ii-1 ) .",
    "we then produce a new list , @xmath115 , which is made up of a sub - list of strings from all possible and valid _",
    "\\{1,0 } _ strings i.e. spiking vectors per neuron . +    to obtain all possible and valid _",
    "\\{1,0 } _ strings ( @xmath54s ) , given that there are multiple strings to be concatenated ( as in @xmath115 s case ) , pairing up the neurons first , in order , and then exhaustively distributing every element of the first neuron to the elements of the 2nd one in the pair .",
    "these paired - distributed strings will be stored in a new list , @xmath116 .",
    "algorithm [ sim - algo2 ] ends once all _ \\{1,0 } _ have been paired up to one another . as an illustration of algorithm [ sim - algo2 ] , consider ( [ confvec ] ) , ( [ rule - list ] ) , and ( [ snp_mat ] ) as inputs to our snp system simulator .",
    "the following details the production of all valid and possible spiking vectors using algorithm [ sim - algo2 ] .    initially from ii-1 of algorithm [ sim - algo2 ]",
    ", we have    @xmath117 , [ 1 ] , [ 1 , 2 ] ] $ ] .    proceeding to illustrate ii-2 we have the following passes .",
    "1st pass : @xmath118 , [ 1 ] , [ 1 , 2 ] ] $ ] + _ remark / s _ : previously , @xmath119 [ 0 ] $ ] was equal to 2 , but now has been changed to 1 , since it satisfies @xmath20 ( @xmath120 = 2 $ ] w / c is equal to 2 , the number of spikes consumed by that rule).@xmath121    2nd pass : @xmath118 , [ 1 ] , [ 1 , 2 ] ] $ ] + _ remark / s _ : previously @xmath122 [ 1 ] = 2 $ ] , which has now been changed ( incidentally ) to 2 as well , since it s the 2nd element of @xmath37 which satisfies @xmath20 .",
    "3rd pass : @xmath118 , [ 1 ] , [ 1 , 2 ] ] $ ] + _",
    "remark / s _ : 1st ( and only ) element of neuron 2 which satisfies @xmath20 .",
    "4th pass : @xmath118 , [ 1 ] , [ 1 , 2 ] ] $ ] + _",
    "remark / s _ : same as the 1st pass    5th pass : @xmath118 , [ 1 ] , [ 1 , 0 ] ] $ ] + _ remark / s _ : element @xmath123 [ 1 ] $ ] , or the 2nd element / rule of neuron 3 does nt satisfy @xmath20 .    final result : @xmath118 , [ 1 ] , [ 1 , 0 ] ] $ ]    at this point we have the following , based on the earlier definitions :    @xmath14 = 3 ( 3 neurons in total , one per element / value of @xmath95 )    @xmath124    @xmath57 tells us the number of valid strings of _ _ 1__s and _ _",
    "0__s i.e. @xmath54s , which need to be produced later , for a given @xmath48 which in this case is @xmath125 .",
    "there are only 2 valid @xmath54s / spiking vectors from ( [ confvec ] ) and the rules given in ( [ rule - list ] ) encoded in the python list @xmath88 .",
    "these @xmath54s are @xmath126 @xmath127 in order to produce all @xmath54s in an algorithmic way as is done in algorithm [ sim - algo2 ] , it s important to notice that first , _ all possible and valid _ @xmath54s ( made up of _ _ 1__s and _ _",
    "0__s ) per @xmath107 have to be produced first , which is facilitated by ii-1 of algorithm [ sim - algo2 ] and its output ( the current value of the list @xmath114 ) .",
    "continuing the illustration of ii-1 , and illustrating ii-2 this time , we iterate over neuron 1 twice , since its @xmath113 = 2 , i.e. neuron 1 has only 2 elements which satisfy @xmath20 , and consequently , it is its 2nd element ,    @xmath122 [ 1 ] = 2.$ ]    for neuron 1 , our first pass along its elements / list is as follows .",
    "its 1st element ,    @xmath122 [ 0 ] = 1 $ ]    is the first element to satisfy @xmath20 , hence it requires a _ 1 _ in its place , and _ 0 _ in the others .",
    "we therefore produce the string _10_ for it .",
    "next , the 2nd element satisfies @xmath20 and it too , deserves a _ 1 _ , while the rest get _ _ 0__s .",
    "we produce the string _01_ for it .    the new list , @xmath115 , collecting the strings produced for neuron 1 therefore becomes    @xmath128 ] $ ]    following these procedures , for neuron 2 we get @xmath115 to be as follows :    @xmath128 , [ 1 ] ] $ ]    since neuron 2 which has only one element only has 1 possible and valid string , the string 1 . finally , for neuron 3 , we get @xmath115 to be    @xmath128 , [ 1 ] , [ 10 ] ] $ ]    in neuron 3 , we iterated over it only once because @xmath113 , the number of elements it has which satisfy @xmath20 , is equal to 1 only .",
    "observe that the sublist    @xmath129 = [ 10 , 01 ] $ ]    is equal to all possible and valid \\{_1,0 _ } strings for neuron 1 , given rules in ( [ rule - list ] ) and the number of spikes in @xmath130 .",
    "illustrating ii-3 of algorithm [ sim - algo2 ] , given the valid and possible \\{_1,0 _ } strings ( spiking vectors ) for neurons 1 , 2 , and 3 ( separated per neuron - column ) from ( [ confvec ] ) and ( [ rule - list ] ) and from the illustration of ii-2 , all possible and valid list of \\{_1,0 _ } string / s for neuron 1 : [ 10,01 ] , neuron 2 : [ 1 ] , and neuron 3 : [ 10 ] .",
    "first , pair the strings of neurons 1 and 2 , and then distribute them exhaustively to the other neuron s possible and valid strings , concatenating them in the process ( since they are considered as @xmath131 in python ) .    10 + 1 @xmath132 101    01 + and    10    01 + 1 @xmath132 011    now we have to create a new list from @xmath115 , which will house the concatenations we ll be doing . in this case ,    @xmath133 $ ]    next , we pair up @xmath116 and the possible and valid strings of neuron 3    101 + 10 @xmath132 10110    011 + and    101    011 + 10 @xmath132 01110    eventually turning @xmath116 into    @xmath134 $ ]    the final output of the sub - algorithm for the generation of all valid and possible spiking vectors is a list ,    @xmath134 $ ]    as mentioned earlier , @xmath57 = 2 is the number of valid and possible @xmath54s to be expected from @xmath88 , @xmath135 , and @xmath50 = [ 2,1,1 ] in @xmath36 .",
    "thus @xmath116 is the list of all possible and valid spiking vectors given ( [ confvec ] ) and ( [ rule - list ] ) in this illustration .",
    "furthermore , @xmath116 includes all possible and valid spiking vectors for a given neuron in a given configuration of an sn p system with all its rules and synapses ( interconnections ) .",
    "part ii-3 is done ( @xmath136 ) times , albeit exhaustively still so , between the two lists / neurons in the pair .",
    "the snp system simulator ( combination of python and cuda c ) implements the algorithms in section [ sect - snp - algo ] earlier .",
    "a sample simulation run with the snp system @xmath36 is shown below ( most of the output has been truncated due to space constraints ) with @xmath50 = [ 2,1,1 ]    .... * * * * sn p system simulation run starts here * * * * spiking transition matrix :   ...     rules of the form a^n",
    "/ a^m - > a or a^n ->a loaded :   [ ' 2 ' , ' 2 ' , ' $ ' , ' 1 ' , ' $ ' , ' 1 ' , ' 2 ' ]     initial configuration vector : 211    number of neurons for the sn p system is 3   neuron 1   rules criterion / criteria and total order   ...      tmplist =   [ [ ' 10 ' , ' 01 ' ] , [ ' 1 ' ] , [ ' 10 ' ] ]    all valid spiking vectors : allvalidspikvec =   [ [ ' 10110 ' , ' 01110 ' ] ]   all generated cks are allgenck = [ ' 2 - 1 - 1 ' , ' 2 - 1 - 2 ' , ' 1 - 1 - 2 ' ]    end of c0   * *   * *   * *    initial total ck list is     [ ' 2 - 1 - 1 ' , ' 2 - 1 - 2 ' , ' 1 - 1 - 2 ' ]   current confvec : 212   all generated cks are allgenck = [ ' 2 - 1 - 1 ' , ' 2 - 1 - 2 ' , ' 1 - 1 - 2 ' , ' 2 - 1 - 3 ' , ' 1 - 1 - 3 ' ]   * *   * *   * *   current confvec : 112   all generated cks are allgenck = [ ' 2 - 1 - 1 ' , ' 2 - 1 - 2 ' , ' 1 - 1 - 2 ' , ' 2 - 1 - 3 ' , ' 1 - 1 - 3 ' , ' 2 - 0 - 2 ' , ' 2 - 0 - 1 ' ]   * *   * *   ...    current confvec : 109 all generated cks are allgenck = [ ' 2 - 1 - 1 ' , ' 2 - 1 - 2 ' , ...   ' 1 - 0 - 7 ' , ' 0 - 1 - 9 ' , ' 1 - 0 - 8 ' , ' 1 - 0 - 9 ' ]    * * * * * *    no more cks to use ( infinite loop / s otherwise ) . stop . * * * * sn p system simulation run ends here * * * * ....    that is , the computation tree for snp system @xmath36 with @xmath50 = [ 2,1,1 ] went down as deep as @xmath137 . at that point ,",
    "all configuration vectors for all possible and valid spiking vectors have been produced .",
    "the python list variable @xmath138 collects all the @xmath48s produced . in algorithm [ sim - algo2 ]",
    "all the values of @xmath116 are added to @xmath138 .",
    "the final value of @xmath138 for the above simulation run is     + _ allgenck = [ 2 - 1 - 1 , 2 - 1 - 2 , 1 - 1 - 2 , 2 - 1 - 3 , 1 - 1 - 3 , 2 - 0 - 2 , 2 - 0 - 1 , 2 - 1 - 4 , 1 - 1 - 4 , 2 - 0 - 3 , 1 - 1 - 1 , 0 - 1 - 2 , 0 - 1 - 1 , 2 - 1 - 5 , 1 - 1 - 5 , 2 - 0 - 4 , 0 - 1 - 3 , 1 - 0 - 2 , 1 - 0 - 1 , 2 - 1 - 6 , 1 - 1 - 6 , 2 - 0 - 5 , 0 - 1 - 4 , 1 - 0 - 3 , 1 - 0 - 0 , 2 - 1 - 7 , 1 - 1 - 7 , 2 - 0 - 6 , 0 - 1 - 5 , 1 - 0 - 4 , 2 - 1 - 8 , 1 - 1 - 8 , 2 - 0 - 7 , 0 - 1 - 6 , 1 - 0 - 5 , 2 - 1 - 9 , 1 - 1 - 9 , 2 - 0 - 8 , 0 - 1 - 7 , 1 - 0 - 6 , 2 - 1 - 10 , 1 - 1 - 10 , 2 - 0 - 9 , 0 - 1 - 8 , 1 - 0 - 7 , 0 - 1 - 9 , 1 - 0 - 8 , 1 - 0 - 9 ] _     + it s also noteworthy that the simulation for @xmath36 did nt stop at the 1st stopping criteria ( arriving at a zero vector i.e. @xmath48 = [ 0,0,0 ] ) since @xmath36 generates all natural counting numbers greater than 1 , hence a loop ( an infinite one ) is to be expected .",
    "the simulation run shown above stopped with the 2nd stopping criteria from section [ sect - snp - algo ] .",
    "thus the simulation was able to exhaust all possible configuration vectors and their spiking vectors , stopping only since a repetition of an earlier generated @xmath95/@xmath48 would introduce a loop ( triggering the 2nd stopping criteria in subsection [ snp - sim - algo ] ) .",
    "graphically ( though not shown exhaustively ) the computation tree for @xmath36 is shown in figure [ c211_tree ] .",
    "with @xmath50 = [ 2 , 1 , 1 ] ]    the @xmath139 followed by ( ... ) are the @xmath139 that went deeper i.e. produced more @xmath48s than figure [ c211_tree ] has shown .",
    "using a highly parallel computing device such as a gpu , and the nvidia cuda programming model , an snp system simulator was successfully designed and implemented as per the objective of this work .",
    "the simulator was shown to model the workings of an sn p system without delay using the system s matrix representation .",
    "the use of a high level programming language such as python for host tasks , mainly for logic and string representation and manipulation of values ( vector / matrix elements ) has provided the necessary expressivity to implement the algorithms created to produce and exhaust all possible and valid configuration and spiking vectors .",
    "for the device tasks , cuda allowed the manipulation of the nvidia cuda enabled gpu which took care of repetitive and highly parallel computations ( vector - matrix addition and multiplication essentially ) .",
    "future versions of the snp system simulator will focus on several improvements .",
    "these improvements include the use of an optimized algorithm for matrix computations on the gpu without requiring the input matrix to be transformed into a square matrix ( this is currently handled by the simulator by padding zeros to an otherwise non - square matrix input ) .",
    "another improvement would be the simulation of systems not of the form ( b-3 ) .",
    "byte - compiling the python / host part of the code to improve performance as well as metrics to further enhance and measure execution time are desirable as well .",
    "finally , deeper understanding of the cuda architecture , such as inter- thread / block communication , for very large systems with equally large matrices , is required .",
    "these improvements as well as the current version of the simulator should also be run in a machine or setup with higher versions of gpus supporting nvidia cuda .",
    "francis cabarle is supported by the dost - erdt scholarship program .",
    "henry adorna is funded by the dost - erdt research grant and the alexan professorial chair of the up diliman department of computer science , university of the philippines diliman .",
    "they would also like to acknowledge the algorithms and complexity laboratory for the use of apple imacs with nvidia cuda enabled gpus for this work .",
    "miguel a. martnez  del ",
    "amor is supported by `` proyecto de excelencia con investigador de reconocida vala '' of the `` junta de andaluca '' under grant p08-tic04200 , and the support of the project tin200913192 of the `` ministerio de educacin y ciencia '' of spain , both co - financed by feder funds .",
    "finally , they would also like to thank the valuable insights of mr .",
    "neil ibo .",
    "x. zeng , h. adorna , m. a. martnez - del - amor , l. pan , m. prez - jimnez , `` matrix representation of spiking neural p systems '' , _",
    "11th international conference on membrane computing _ , jena , germany , aug .",
    "2010 .",
    "cecilia , j.m .",
    "garca , g.d .",
    "guerrero , m.a .",
    "martnez - del - amor , i. prez - hurtado , m.j .",
    "prez - jimnez , `` simulating a p system based efficient solution to sat by using gpus '' , _ journal of logic and algebraic programming _ ,",
    "vol 79 , issue 6 , pp .",
    "317 - 325 , apr . 2010 .",
    "cecilia , j.m .",
    "garca , g.d .",
    "guerrero , m.a .",
    "martnez - del - amor , i. prez - hurtado , m.j .",
    "prez - jimnez , `` simulation of p systems with active membranes on cuda '' , _ briefings in bioinformatics _ ,",
    "vol 11 , issue 3 , pp .",
    "313 - 322 , mar .",
    "d. daz , c. graciani , m.a .",
    "gutirrez , i. prez - hurtado , m.j .",
    "prez - jimnez .",
    "software for p systems . in gh .",
    "pun , g. rozenberg , a. salomaa ( eds . ) _ the oxford handbook of membrane computing _ , oxford university press , oxford ( u.k . ) , chapter 17 , pp .",
    "437 - 454 , 2009 .",
    "v. nguyen , d. kearney , g. gioiosa . a region - oriented hardware implementation for membrane computing applications and its integration into reconfig - p . _ lecture notes in computer science _",
    ", 5957 , 385 - 409 , 2010 .",
    "k. fatahalian , j. sugerman , p. hanrahan , `` understanding the efficiency of gpu algorithms for matrix - matrix multiplication '' , _ in proceedings of the acm siggraph / eurographics conference on graphics hardware ( hwws 04 ) _ , acm , ny , usa , pp",
    ". 133 - 137 , 2004"
  ],
  "abstract_text": [
    "<S> we present in this paper our work regarding simulating a type of p system known as a spiking neural p system ( snp system ) using graphics processing units ( gpus ) . </S>",
    "<S> gpus , because of their architectural optimization for parallel computations , are well - suited for highly parallelizable problems . due to the advent of general purpose gpu computing in recent years , gpus are not limited to graphics and video processing alone , but include computationally intensive scientific and mathematical applications as well </S>",
    "<S> . moreover p systems , including snp systems , are inherently and maximally parallel computing models whose inspirations are taken from the functioning and dynamics of a living cell . </S>",
    "<S> in particular , snp systems try to give a modest but formal representation of a special type of cell known as the neuron and their interactions with one another . </S>",
    "<S> the nature of snp systems allowed their representation as matrices , which is a crucial step in simulating them on highly parallel devices such as gpus . </S>",
    "<S> the highly parallel nature of snp systems necessitate the use of hardware intended for parallel computations . </S>",
    "<S> the simulation algorithms , design considerations , and implementation are presented . finally , simulation results , observations , and analyses using an snp system that generates all numbers in @xmath0 - \\{@xmath1 } are discussed , as well as recommendations for future work .    </S>",
    "<S> * key words : * membrane computing , parallel computing , gpu computing </S>"
  ]
}