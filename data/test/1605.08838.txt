{
  "article_text": [
    "we consider bandit learning in personalized content recommendation with implicit pairwise comparisons . in our model , we offer pairs of items to a user and record implicit feedback on which offered item is preferred , seeking to learn the user s preferences over items quickly , while also ensuring that the fraction of time we fail to offer a high - quality item in our offered assortment is small .",
    "implicit pairwise comparisons avoid the inaccuracy of user ratings @xcite and the difficulty of engaging users in providing explicit feedback .",
    "we model items as related through covariates , and model regret as depending on the utility to the user of the best offered item .",
    "for example , consider a recommender system that delivers news articles to subscribers through push notifications .",
    "each news item is available through several different news sources , and so when we notify users of news , we may offer two different versions of the same news item from different sources , and record which one the user selects , so as to determine the user s favored news source .",
    "the problem that we study is a variant of the dueling bandit problem @xcite , in which a sequence of rounds are played , and in each round we forward two arms to the user and receive noisy feedback from the user telling us which arm is preferred , when an arm is preferred in a round , we say that arm  wins the duel \" in that round .    previous work on dueling bandits has focused on choosing between ranking algorithms @xcite , where query results from two rankers are interleaved @xcite , and the ranking algorithm that provided the first result chosen by the user is declared the winner of the duel . perhaps",
    "because of their focus on the ranking setting , previous work has focused on models that are appropriate for few arms that do not model the dependence between arms , and where zero regret requires pulling the best arm twice .",
    "we study a formulation of the dueling bandits problem with two differences from the standard setting that make it more appropriate for online content recommendation .",
    "first , we model the dependence between arms by endowing arms with covariates which are then modeled as interacting through a known function ( for example , the inner product ) with some latent vector describing the user s preferences , providing the user s utility for that arm . for example , in our example above , covariates for a news source could be determined by fitting a topic model to the text in past news items from that source , and the user s preference vector could be interpreted as the user s preference for each topic .",
    "second , we model regret as the difference in utility between the best arm , and the best arm offered .",
    "we make this modeling choice because the user is able to choose between the items offered , and is expected to choose only one .",
    "our main contribution is that we develop an algorithm _ comparing the best _",
    "( ctb ) , which has excellent performance in terms of regret but whose computational demands grow with the number of arms , and a more computationally tractable variant _ scalable - ctb _ ( sctb ) for problems with many arms .",
    "we then prove that both algorithms have constant expected cumulative regret , and demonstrate through numerical experiments on simulated and real datasets that they significantly outperform existing algorithms .",
    "the paper is structured as follows . in section  [ probform ]",
    ", we formulate our problem . in section",
    "[ methods ] , we introduce _ comparing the best _ ( ctb ) which works well for few arms and in section  [ results ] , we prove ctb  has constant expected cumulative regret . in section  [ imple ] ,",
    "we propose a scalable version of ctb  that could work well in high dimension with a large number of arms , which is called _ scalable - ctb _",
    "( sctb ) . in section",
    "[ numerical ] , we compare ctb  and sctb  with three benchmarks using both simulated and real dataset .",
    "the numerical results suggest ctb  and sctb  outperform all benchmarks we considered .",
    "most work on dueling bandits focuses on the case that arms are independent , and zero regret occurs only when both of the pulled arms are optimal . under these assumptions",
    ", @xcite shows that the lower bound for the expected cumulative regret up to time t is @xmath0 . under the assumption that a condorcet winner ( an arm that has winning probability greater or equal to @xmath1 versus any other arms ) exists , algorithms were proposed that can reach the optimal regret bound under different conditions in the finite horizon setting , such as interleaved filter ( if ) @xcite and beat the mean ( btm ) @xcite . @xcite proposed relative uper confidence bound ( rucb ) , which is the first algorithm that can reach the optimal regret bound in the horizonless setting .",
    "recent research focuses on the case where a condorcet winner does not exist . @xcite",
    "proposed two algorithms , copeland confidence bound ( ccb ) and scalable copeland bandits ( scb ) , which have an optimal regret bound without the assumption that a condorcet winner exists . because they model arms as independent",
    ", these algorithms all require a large number of iterations before they can find the best arm , especially with many arms .",
    "in contrast , our paper focuses on the setting where arms are dependent and regret is only related to the best arm shown .",
    "as far as we know , no other previous work on dueling bandits studies this setting . outside of the dueling bandit literature , in the literature on active learning , @xcite considers an active learning problem that lacks the bandit objective based on cumulative regret but is otherwise similar .",
    "the primary purpose of @xcite is to sort the arms based on the user s preference .",
    "it proposes a novel algorithm , the query selection algorithm ( qsa ) , with the property that , when the number of arms n is sufficiently large , the expected number of operations to sort @xmath2 arms in the noiseless case is @xmath3 ( d is the dimension of the space ) instead of @xmath4 .",
    "they also show a high probability result in the noisy case .",
    "denote the user s latent preference vector as @xmath5 .",
    "there are n ( @xmath6 ) distinct arms lying in the d - dimensional space , denoted as @xmath7 .",
    "the user prefers @xmath8 over @xmath9 if and only if @xmath10 , where @xmath11 is a known utility function .",
    "we assume that arms are ordered by the user s preferences , @xmath12 . throughout this paper",
    ", we use the terms `` arm @xmath8 '' and `` item @xmath8 '' interchangeably .    at time t ,",
    "the system chooses two items and forwards them to the user .",
    "we denote the index of these two arms at time t as @xmath13 and @xmath14 .",
    "suppose at time t , we forward item @xmath8 and @xmath9 to the user and the user prefers @xmath8 over @xmath9 . then the user chooses his / her favourite based on the following manner : the user chooses item @xmath8 with probability @xmath15 and item @xmath9 with probability @xmath16 . the system can observe the user s feedback @xmath17 , where @xmath18 means the user prefers @xmath19 and @xmath20 means the user prefers @xmath21 .",
    "here we denote @xmath22 , which is the lower bound of the probability that the user will choose his / her favourite item . based on its definition , we know p>0.5 .",
    "we briefly discuss two discrete choice models that can take advantage of our framework .",
    "the first model is logit model or bradley - terry model @xcite . in this case , the utility function is @xmath23 and the user will choose arm @xmath8 over @xmath9 with probability @xmath24 .",
    "another example is to model the user s choice with probit model @xcite . in this case , the utility function is still the inner product , but @xmath25 where @xmath26 is the cdf for a standard normal distribution given the difference between the two utilities follows a standard normal distribution .",
    "the regret r(t ) at time t is defined as @xmath27 , which is the difference in expected utility between the best arm overall and the best arm that the user can choose from those offered . since we think of the user as receiving the utility of the single arm chosen , we measure with respect to the best available arm , rather than some other function of the two offered arms .",
    "the cumulative regret up to time period t is defined as : @xmath28 .",
    "we measure the quality of an algorithm by its expected cumulative regret .",
    "now , we develop two algorithms ctb  and sctb , and show they have constant expected cumulative regret .",
    "in this section , we propose an algorithm _ comparing the best _ ( ctb ) for this problem setting .",
    "each pair of arms @xmath8 and @xmath9 uniquely decides a _ winning space _ @xmath29 .",
    "based on the definition of winning space , we know when @xmath30 , the user with this @xmath31 will prefer item @xmath8 over @xmath9 .",
    "when the utility function is a linear function , this winning space is a half space .",
    "further @xmath32 and @xmath33 are two different winning spaces and their union is @xmath34 . throughout this paper",
    ", we use the phrases `` arm @xmath35 wins over arm @xmath36 in a duel '' , and `` winning space @xmath32 wins the duel '' interchangeably .",
    "each pair of arm determines two winning spaces and all winning spaces partition the space @xmath34 in to a number of cells .",
    "each cell can be written as intersection of winning spaces . to formally define a cell ,",
    "we first denote @xmath37 when @xmath38 and @xmath39 when @xmath40 . then for a binary vector",
    "v , we denote the @xmath41 element of v as @xmath42 $ ] .",
    "finally , we define a cell as :    the _ cell _ c corresponding to a @xmath43 length binary vector v is defined as @xmath44}.\\end{aligned}\\ ] ]    in this definition , we use the @xmath45^{th}$ ] element of v to denote whether c belongs to @xmath32 or @xmath33 , for @xmath46 . in this paper",
    ", we use c(v ) to denote a cell that is defined by binary vector v.    consider a sequence of binary vectors , all of length @xmath43 that are ordered lexicographically . denote @xmath47 the @xmath41 binary vector that corresponding to a non - empty cell . denote the number of non - empty cells as m , and denote the cells as @xmath48 where @xmath49 is corresponding to @xmath50 . with this definition",
    ", @xmath51 is the cell that corresponding to @xmath52 $ ] and thus @xmath53 .",
    "further we know @xmath51 is the cell that contains @xmath31 .",
    "this is because for any arm @xmath8 and @xmath9 with @xmath46 , since the user prefers @xmath8 over @xmath9 , we know @xmath54 , which means @xmath30 .",
    "denote @xmath55 , which is the collection of index of the winning spaces that contains @xmath56 .",
    "figure  [ illustration ] is an illustration of winning spaces and cells .     and",
    "@xmath57 ; @xmath58 and @xmath59 ; @xmath60 and @xmath61 ; @xmath62 and @xmath61 ; @xmath63 and @xmath64 ; @xmath65 and @xmath66 ; @xmath67 and @xmath68 . ]    for each cell @xmath49 , denote the number of times that a winning space contains @xmath49 wins a duel before time t as @xmath69 .",
    "formally , @xmath70    each cell @xmath49 assigns a preference order to the arms .",
    "denote @xmath71 as the best arm suggested by cell i. formally , @xmath71 is the unique arm index j such that @xmath72 , @xmath73 . since @xmath51 is the cell that contains the true @xmath31 , we know @xmath74 .    here",
    "we propose an algorithm _ comparing the best _",
    "( ctb ) , which selects two arms that are `` most likely '' to be the best arm and forwards them to the user .",
    "ctb  stores a value for every cell , which can require an excessive amount of memory for problems with many arms .",
    "we introduce a scalable version of ctb in section  [ imple ] , but we first prove that ctb  has constant expected regret .",
    "in this section , we prove the expected cumulative regret of ctb  is bounded by a constant .",
    "the main idea behind our proof is to show that for each cell @xmath49 with @xmath75 , @xmath76 $ ] is bounded by a constant .",
    "we show this in turn by showing @xmath77 can be modeled by a random walk with a larger probability of increasing than of decreasing .",
    "the following lemma , whose proof is in the supplement , allows us to bound the number of times this stochastic process takes negative values .",
    "[ basic ] for any @xmath78 , suppose z(t ) is a stochastic process with filtration @xmath79 , @xmath80 and @xmath81 and @xmath82 , then we have @xmath83 \\leq \\frac{p}{(2p-1)^{2}}$ ]",
    ".    we now proceed with the larger proof by defining @xmath84 which is the number of times that we forward @xmath8 and @xmath9 to the user and the user prefers @xmath8 over @xmath9 up to time t. then we can rewrite @xmath69 in terms of @xmath85 : @xmath86    based on the definition of @xmath51 , we know @xmath87 and @xmath88 .",
    "denote @xmath89 as the number of times that the system forwards arm @xmath8 and @xmath9 to the user .",
    "the next lemma shows @xmath90 $ ] is bounded by a constant for @xmath91 .",
    "[ mainlemma ] for @xmath91 , we have @xmath90\\leq m\\frac{p}{(2p-1)^{2}}$ ] , where m is the total number of non - empty cells .    for @xmath91",
    ", we can only pull arm @xmath9 when there is cell @xmath92 which believes @xmath9 is the best arm and its corresponding @xmath93 is greater or equal to @xmath94 .",
    "thus we have @xmath95\\geq   0\\ } , \\nonumber \\end{aligned}\\ ] ]    where the last equation is because @xmath96 and thus @xmath97 .    denote @xmath98 $ ] .",
    "then @xmath99 is very `` close '' to a random walk :    * if we forward arm @xmath100 and @xmath101 to the user where @xmath102 and @xmath103 , then @xmath104 with probability @xmath105 and @xmath106 with probability @xmath107 , which is independent of previous history .",
    "further , since @xmath108 , every time we forward @xmath8 and @xmath9 to the user , @xmath99 will not remain the same . *",
    "if we forward arm @xmath100 and @xmath101 to the user where @xmath102 and @xmath109 , then @xmath110 .    define @xmath111 , @xmath112 , for @xmath113 . because @xmath114 is a non - decreasing right continuous stopping time",
    ", we know it is a valid random change of time @xcite .",
    "define @xmath115 , which is the life time of the random change of time .",
    "here we consider a new stochastic process @xmath116 defined as @xmath117 for @xmath118 . for all sample path that @xmath119 , we define @xmath120 and @xmath121 for all @xmath122 .",
    "denote the filtration for w(t ) up to time t as @xmath79 .",
    "then :    * for @xmath123 , we have @xmath124 . * for @xmath122 , based on its definition , we know @xmath125 .",
    "thus , we know @xmath116 is well defined and @xmath126 , @xmath127 and we know @xmath128 . since every time we forward arm @xmath8 and @xmath9 to the user ,",
    "@xmath129 must hold , thus @xmath130   & \\leq e\\left[\\sum_{b(s)=j}\\sum_{k=1}^{t}\\mathbbm{1}\\{\\sum_{(i^{'},j^{'})\\in j_{s}\\setminus j_{1}}[q_{i^{'},j^{'}}(k)-q_{j^{'},i^{'}}(k)]\\geq   0\\}\\right ] , \\nonumber \\\\",
    "\\leq & \\sum_{s : b(s)=j}\\left[e\\left[\\sum_{k=1}^{\\infty}\\mathbbm{1}\\{w(k)\\geq 0\\}\\right]\\right ] \\leq m \\frac{p}{(2p-1)^{2}}.\\nonumber \\hspace{15mm}\\qedhere \\end{aligned}\\ ] ]    finally , denote @xmath131 .",
    "based on lemma  [ mainlemma ] and a union bound , we obtain our main theorem , which is    [ thm:1 ] the expected cumulative regret for ctb  is bounded by @xmath132 .    since each cell assigns a ranking for arms and different cells",
    "give us different rankings , we can bound m by @xmath133 , which is the number of all permutations .",
    "when the utility function is linear , then based on the results in @xcite , we know m is @xmath134 for sufficiently large n.",
    "ctb  achieves a constant expected cumulative regret",
    ". however , it requires a great deal of memory to store @xmath69 for each cell , which makes it computationally infeasible for problems with many arms .",
    "instead of saving @xmath69 , equation  [ reconstruct ] suggests that we can save @xmath85 and use @xmath85 to reconstruct @xmath69 .",
    "based on this idea , we propose a new algorithm , sctb that that has performance comparable to ctb , and that can work on much larger - scale problems .    in sctb , we are going to set up step 1 and step 3 in ctb  as a optimization problem in terms of @xmath85 .",
    "denote @xmath135 as a binary variable where @xmath136 means the cell is in @xmath32 and 0 otherwise , then based on equation  [ reconstruct ] , maximizing @xmath69 is equivalent to maximizing @xmath137 subject to the constraint that the intersection of the winning spaces is not empty . in general , these constraints are not easy to describe in a way that admits optimization . instead ,",
    "in sctb , we introduce imaginary cells that simplify the constraints .",
    "`` imaginary cells '' are cells that correspond to a valid collection of binary variables , and a valid intersection of winning spaces , but that are empty .",
    "cell c(v ) is an _ imaginary cell _ if @xmath138}=\\emptyset$ ] .    to find the best arm suggested by @xmath139 , in sctb",
    ", we first find @xmath140 for each arm @xmath141 after introducing the imaginary cells , which is the cell with largest @xmath69 such that this cell believes @xmath141 is the best .",
    "the @xmath41 problem is defined as follows : @xmath142    for the @xmath41 problem , there are three conditions in equation  [ ip ] . the first condition says @xmath143 @xmath144 , which means cell @xmath145 that satisfies the first condition must lie in the winning space @xmath146 , @xmath144 . in other words ,",
    "@xmath145 ranks arm @xmath141 better than any others and thus @xmath147 .",
    "the second and third condition together guarantees that cell @xmath145 either belongs to @xmath32 or @xmath33 .",
    "these three constraints will introduce some imaginary cells into the feasible solutions .",
    "however , this will not hurt our algorithm since @xmath31 lies in the cell @xmath51 and eventually @xmath94 will be the largest .",
    "though equation  [ ip ] looks like an integer linear programming , it is in fact very easy to solve : the maximum value of this problem is reached when @xmath136 if @xmath148 for all @xmath149 , @xmath150 otherwise .",
    "denote the maximum value of the @xmath151 problem at time t as @xmath152 .    after knowing @xmath153 , then finding the best arm with largest @xmath69 is equivalent to finding @xmath154 .",
    "now we are ready to introduce the _ scalable - ctb _",
    "it is the same as ctb except we have introduced imaginary cells , simplifying the constraints in equation  [ ip ] .",
    "the sctb  algorithm is as follows .",
    "[ thm : imple ] the expected cumulative regret for sctb  is bounded by @xmath155 .",
    "the proof is similar to theorem  [ thm:1 ] , which is in the supplement .",
    "in this section , we compare ctb  and sctb  with three benchmarks : thompson sampling , relative upper confidence bound ( rucb ) and the query selection algorithm ( qsa ) @xcite .",
    "thompson sampling uses a posterior distribution over the cell containing theta , and this posterior is computed by beginning with a prior distribution on the location of @xmath31 , and updating this prior using bayes rule and knowledge of @xmath156 . at time t , we generate @xmath157 from the posterior distribution @xmath158 and forward the two arms that @xmath157 ranks the top two to the user and receives the user s feedback . in our implementation , we track the prior / posterior explicitly by storing a probability for each cell .",
    "an exact implementation of thompson sampling scales poorly with the number of cells and so we only compare against thompson sampling in the setting with fewer arms ( see section  [ small ] , where the prior on theta is uniform over the unit sphere ) . it may also be possible to implement thompson sampling using gibbs sampling although this would be substantially more complicated than sctb .",
    "we also emphasized that thompson sampling as we consider it here requires knowledge of @xmath156 which is not typically not available .",
    "we choose rucb as our benchmark because it works well when a condorcet winner exists , and existence of a condorcet winner is a consequence of our modeling assumptions .",
    "though there are algorithms that claim to outperform rucb such as ccb and scb @xcite , they mainly work better in the case where a condorcet winner does not exist .    throughout this section ,",
    "we assume the utility function is @xmath23 . in the first two examples with simulated data , both",
    "the arms and the user s preference vector @xmath31 are uniformly generated from the unit sphere .",
    "also , we assume @xmath159 for all @xmath46 . in the yelp academic dataset",
    ", we use the probit model to model the user s choice .",
    "[ numerical ]      in this section , we compare ctb  and sctb  with thompson sampling , rucb and qsa using 20 arms in 2-dimensional space .",
    "figure  [ fig:1 ] shows that ctb  is the best algorithm , which means that if we can store @xmath69 for all cells , then ctb  typically beats thompson sampling . though sctb  did not perform as well as ctb  and thompson sampling",
    ", it outperforms qsa and rucb .",
    "sctb  has an advantage over thompson sampling and ctb  in that it can work on a much larger - scale problem .          in this section ,",
    "we compare sctb  with rucb and qsa on a problem with 50 arms in 20-dimensional space .",
    "as can be seen from the figure  [ fig : simulated_data ] , rucb almost has a linear regret when the time is short .",
    "this is in general true in the dueling bandits literature , which typically requires @xmath160 iterations before it starts to achieve @xmath161 cumulative regret for 50 arms .",
    "our algorithm finds the optimal arm after roughly 500 iterations and reaches constant expected cumulative regret .    0.5        0.5       in this section , we compare sctb  with rucb and qsa using the yelp academic dataset @xcite . in this experiment , we choose 100 restaurants from las vegas as our arms .",
    "for each restaurant , we represent it by a 20-dim feature vector , calculated using doc2vec @xcite on its review .",
    "we select 49 users who have reviewed at least 20 of these 100 restaurants and calculate their preference vectors using linear regression .",
    "denote the estimated variance of the residuals from the linear regression as @xmath162 .    since for each user , there are some restaurants that he / she hasnt reviewed , we rank the preference for restaurants based on the inner product between the user s preference vector and the restaurant s feature vector . for restaurant",
    "i and restaurant j with feature vector @xmath8 and @xmath9 , the user with preference vector @xmath31 will choose restaurant i with probability @xmath163 , where @xmath26 is the cdf for the normal distribution with mean 0 and variance @xmath164 .",
    "the result is summarized in figure  [ fig : yelp_data ] .",
    "sctb  outperforms both rucb and qsa significantly .",
    "rucb has a linear regret when the time is short .",
    "in this paper , we consider dueling bandits for online content recommendation .",
    "we formulate a new setting which differs from the traditional dueling bandits where arms are dependent , and regret depends only on the best arm shown .",
    "we propose two algorithms ctb  and sctb  which are proved to have constant expected cumulative regret .",
    "numerical experiments suggest our algorithms outperform all existing algorithms considered , in both simulated and real dataset .",
    "denote @xmath166 $ ] and @xmath167 , then we know @xmath165=1+(1-p)(a+e[\\sum_{t=0}^{\\infty}\\mathbbm{1}\\{z(t)\\leq 0\\}])+pb(e[\\sum_{t=0}^{\\infty}\\mathbbm{1}\\{z(t)\\leq 0\\ } ] ) .",
    "\\nonumber \\end{aligned}\\ ] ] now we need to calculate the expression for a and b respectively .    based on the definition of a",
    ", we can rewrite a as @xmath168 $ ] .",
    "it is easy to show that @xmath169 is a martingale .",
    "here we define a stopping time @xmath170 as @xmath171 .",
    "then we know @xmath172 stops at @xmath170 is a martingale and thus @xmath173=e[z(\\tau)]-(2p-1)e[\\tau]=0 $ ] .",
    "thus @xmath174 .",
    "suppose w(t ) is a random walk and @xmath177 with probability p and @xmath178 with probability 1-p .",
    "based on the previous lemma , we just need to show @xmath165\\leq e[\\sum_{t=0}^{\\infty}\\mathbbm{1}\\{w(t)\\leq 0\\ } ] .",
    "\\label{bound}\\end{aligned}\\ ] ] because @xmath179=\\sum_{t=0}^{\\infty}p(w(t)\\leq 0)$ ] and @xmath180 thus , we know equation  [ bound ] holds true .",
    "based on the same proof , we can show that @xmath130&\\leq\\sum_{r}e\\left[\\sum_{k=1}^{t}\\mathbbm{1}\\{\\sum_{(i_{0},j_{0})\\in j_{j , r}\\setminus j_{1}}[q_{i_{0},j_{0}}(k)-q_{j_{0},i_{0}}(k)]\\geq   0\\}\\right ] \\nonumber \\\\      & \\leq 2^{\\frac{n(n-1)}{2}}\\frac{p}{(2p-1)^{2}}. \\nonumber\\end{aligned}\\ ] ] thus , we know our theorem holds true ."
  ],
  "abstract_text": [
    "<S> we consider online content recommendation with implicit feedback through pairwise comparisons . </S>",
    "<S> we study a new formulation of the dueling bandit problems in which arms are dependent and regret occurs when neither pulled arm is optimal . </S>",
    "<S> we propose a new algorithm , _ comparing the best _ </S>",
    "<S> ( ctb ) , with computational requirements appropriate for problems with few arms , and a variation of this algorithm whose computation scales to problems with many arms . </S>",
    "<S> we show both algorithms have constant expected cumulative regret . </S>",
    "<S> we demonstrate through numerical experiments on simulated and real dataset that these algorithms improve significantly over existing algorithms in the setting we study . </S>"
  ]
}