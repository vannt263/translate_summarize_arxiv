{
  "article_text": [
    "in contemporary neural computing , an active branch of research is the nature - inspired algorithms with diverse applications in engineering optimization .",
    "most of these algorithms are based on the so - called swarm intelligence , and usually involve some form of non - deterministic , stochastic components , which often appear in terms of random walks .",
    "such random walks can be surprisingly efficient when combined with deterministic components and elitism , as this has been demonstrated in many modern metaheuristic algorithms such as particle swarm optimization , firefly algorithm and other algorithms @xcite .",
    "recent studies in nature - inspired algorithms have shown promising results with divers algorithms , including new algorithms such as accelerated particle swarm optimization @xcite , bat algorithm @xcite , krill herd algorithm @xcite , flower algorithm @xcite , and other algorithms @xcite .",
    "a comprehensive review can be found in @xcite . in all these algorithms ,",
    "different degrees of randomization , exploration and exploitation have been used so as to maintain a good degree of solution diversity in the solution population , which helps to enhance the performance of these algorithms .",
    "applications of modern nature - inspired algorithms have been very diverse with promising results @xcite .    in order to gain insight into the working mechanism of a stochastic algorithm , mathematical analysis of the key characteristics of random walks",
    "is necessary .",
    "though there are some extensive studies of random walks with solid results in the statistical literature , most of these results are based on rigorous assumptions so as to obtain theoretical results using markov chain models and/or markov chain monte carlo methods @xcite",
    ". consequently , such results may be too theoretical , and thus have not much practical implications for designing optimization algorithms .",
    "in addition , it is necessary to translate any relevant theoretical results in the right context so that they are truly useful to the optimization communities .",
    "the current work has extended our earlier work extensively @xcite .",
    "therefore , the aims of this paper are two - folds : to introduce the random walks and lvy flights in the proper context of metaheuristic optimization , and to use these results in the framework of markov theory to analyze the iteration process of algorithms such as step sizes , efficiency and the choice of some key parameters .",
    "the rest of the paper is organized as follows : section 2 briefly introduce the eagle strategy ( es ) .",
    "section 3 introduces the fundamentals of random walks and discusses lvy flights , as well as their links to optimization via markov chain theories .",
    "section 4 analyzes the choice of step sizes , stopping criteria and efficiency .",
    "section 5 presents four case studies for engineering optimization applications .",
    "finally , we briefly draw the conclusions in section 6 .",
    "eagle strategy developed by xin - she yang and suash deb @xcite is a two - stage method for optimization .",
    "it uses a combination of crude global search and intensive local search employing different algorithms to suit different purposes .",
    "in essence , the strategy first explores the search space globally using a lvy flight random walk ; if it finds a promising solution , then an intensive local search is carried out by using a more efficient local optimizer such as hill - climbing and downhill simplex method . then , the two - stage process starts again with new global exploration followed by a local search in a new region .",
    "the main steps of this method can be represented as the pseudo code as outlined in fig .",
    "[ eagle - fig-50 ] .",
    "the advantage of such a combination is to use a balanced tradeoff between global search which is often slow and a fast local search .",
    "some tradeoff and balance are important .",
    "another advantage of this method is that we can use any algorithms we like at different stages of the search or even at different stages of iterations .",
    "this makes it easy to combine the advantages of various algorithms so as to produce better results .",
    "it is worth pointing out that this is a methodology or strategy , not an algorithm .",
    "in fact , we can use different algorithms at different stages and at different time of the iterations . the algorithm used for",
    "the global exploration should have enough randomness so as to explore the search space diversely and effectively .",
    "this process is typically slow initially , and should speed up as the system converges , or no better solutions can be found after a certain number of iterations . on the other hand , the algorithm used for the intensive local exploitation should be an efficient local optimizer .",
    "the idea is to reach the local optimality as quickly as possible , with the minimal number of function evaluations .",
    "this stage should be fast and efficient .    ' '' ''",
    "objective function @xmath0 + initialization and random",
    "initial guess @xmath1 + * while * ( stop criterion ) + global exploration by randomization ( e.g. lvy flights ) + evaluate the objectives and find a promising solution + intensive local search via an efficient local optimizer + ( a better solution is found ) + update the current best +   + update @xmath2 + * end * +    ' '' ''    for the local optimizer in this paper , we will use the accelerated particle swarm optimization ( apso ) @xcite which is a simple but efficient variant of particle swarm optimization .",
    "the apso essentially has one updating equation _",
    "i^t+1 = ( 1- ) _ i^t + * g*^ * + _ t , where @xmath3 is the current best solution among all the solutions @xmath4 at iteration @xmath5 .",
    "@xmath6 is a parameter , and @xmath7 is the scaling factor . here @xmath8 is a random number drawn from a standard normal distribution @xmath9 .",
    "as the typical scale @xmath10 of a problem may vary , @xmath11 should be linked to @xmath10 as @xmath12 where @xmath13 should decrease as the iterations proceed in the following form _",
    "t = _ 0 ^t , where @xmath14 and @xmath15 . from our previous parametric study , we will use @xmath16 , @xmath17 , and @xmath18 @xcite .      in almost all nature - inspired algorithms ,",
    "two conflicting and yet important components are exploration and exploitation , or diversification and intensification .",
    "the balance between these components are very important to ensure the good performance of an algorithm @xcite .",
    "in other words , a good degree of diversity should be maintained in the population of the solutions so that exploration and exploitation can be reflected in the evolving population .",
    "if the population is too diverse , it is good for global exploration , but it may slow down the convergence .",
    "on the other hand , if the diversity is too low , intensive local exploitation may lead to premature convergence , and thus may loose the opportunity of finding the global optimality .",
    "however , how to maintain good balance is still an unsolved problem , and different algorithms may have different ways of dealing with this issue .    in most algorithms such as the particle swarm optimization , exploration and diversity can be considered as the steps by using random numbers , while intensification and exploitation are by the use of current global best . however , there is no direct control on how to switch between these components . even in the accelerated particle swarm optimization ( aspo ) , diversity",
    "is mainly controlled by a random - walk - like term , while the control is indirectly carried out by an annealing - like reduction of randomness . on the other hand , eagle strategy provides a direct control of these two stages / steps in an iterative manner .",
    "first , solutions are sampled in a larger search space , and these solutions often have high diversity .",
    "these solutions are then fed into the apso for evolution so that a converged state can be reached , and at the converged state , solution diversity is low .",
    "then , a new set of samples are drawn again from the larger search space for another round of intensive apso iteration stage . in this way",
    ", both exploration and exploitation have been used to main a good degree of diversity in the overall population , which also allows the system to converge periodically towards global optimality .",
    "as we will see in the late analysis of random walks and search strategies , randomization techniques are often used for exploration to increase the diversity of the solutions , while the selection of good solutions and evolution of an algorithm tend to lead to convergence of the system . however",
    ", their role is subtle .",
    "for example , in memetic algorithms , the balance is even more subtle @xcite .",
    "it can be expected that the analysis in the rest of the paper can provide some insight into the working mechanisms and subtlety of random walks and randomization techniques in maintaining the good diversity of solutions in different algorithms .",
    "in modern stochastic optimization algorithms , especially those based on swarm intelligence , there are often a deterministic component and a stochastic component , though traditional algorithms such as the steepest descent method are purely deterministic .",
    "randomness is now an essential part of the stochastic search algorithms .",
    "randomization techniques such as random walks have become an integrated part of a search process in stochastic algorithms .",
    "however , how to achieve the effective randomization remains an open question .",
    "the exact form of randomization may depend on the actual algorithm of interest .",
    "one of the objective of this paper is to analyze and discuss the main concepts of random walks and lvy flights , and their role in metaheuristic optimization .",
    "in essence , a stochastic search process involves the use of a random process to generate new solutions in the search space so that the solutions can sample the landscape appropriately .",
    "however , the effectiveness of this sampling process depends on the random process used and the actual way of generating new solutions / samples .",
    "if the search space is treated as a black box ( thus no knowledge or assumption about the modality is made ) , a random walk is one of the most simplest ways to carry out the search for optimality . briefly speaking ,",
    "a random walk is a random process which consists of taking a series of consecutive random steps @xcite .",
    "that is , the total moves @xmath19 after @xmath20 steps are the sum of each consecutive random step @xmath21 : s_n=_i=1^n x_i = x_1 + ... + x_n = _",
    "i=1^n-1 x_i + x_n = s_n-1 + x_n , where @xmath22 is a random step drawn from a random distribution such as a normal distribution . depending on the perspective",
    ", the above relationship can also be considered as a recursive formula .",
    "that is , the next state @xmath19 will only depend on the current existing state @xmath23 and the move or transition @xmath24 from the existing state to the next state .",
    "in other words , the next state will depend only on the current state and the transition probability , and it has no direct link to the states in the past . from the markov theory , we know that this is typically the main property of a markov chain , to be introduced later .    it is worth pointing out that there is no specific restriction on the step sizes .",
    "in fact , the step size or length in a random walk can be fixed or varying .",
    "random walks have many applications in physics , economics , statistics , computer sciences , environmental science and engineering . mathematically speaking , a random walk can be defined as s_t+1= s_t + w_t , where @xmath25 is the current location or state at @xmath5 , and @xmath26 is a step or random variable drawn from a known probability distribution .",
    "if each step or jump is carried out in the @xmath27-dimensional space , the random walk @xmath19 discussed earlier becomes a random walk in higher dimensions .",
    "in addition , there is no reason why the step length should be fixed . in general",
    ", the step size can also vary according to a known distribution .",
    "if the step length obeys the gaussian distribution , the random walk becomes the brownian motion or a diffusion process .",
    "as the number of steps @xmath20 increases , the central limit theorem implies that the random walk should approach a gaussian distribution .",
    "if the steps are drawn from a normal distribution with zero mean , the mean of particle locations is obviously zero .",
    "however , their variance will increase linearly with @xmath5 .",
    "this is valid for the case without any drift velocity .    in a more generalized case in the @xmath27-dimensional space , the variance of brownian",
    "random walks can be written as ^2(t ) = |v_0|^2 t^2 + ( 2 d d ) t , where @xmath28 is the drift velocity of the system @xcite . here",
    "@xmath29 is the effective diffusion coefficient which is related to the step length @xmath30 over a short time interval @xmath31 during each jump . for example , the well - known brownian motion @xmath32 obeys a gaussian distribution with zero mean and time - dependent variance : b(t ) ~n(0 , ^2(t ) ) , where @xmath33 means the random variance obeys the distribution on the right - hand side ; that is , samples should be drawn from the distribution .    in physics and chemistry ,",
    "a diffusion process can be considered as a series of brownian motion , which obeys the gaussian distribution .",
    "therefore , standard diffusion is often referred to as the gaussian diffusion .",
    "if the motion at each step is not gaussian , then the diffusion is called non - gaussian diffusion . on the other hand ,",
    "if the step lengths are drawn from other distributions , we have to deal with more generalized random walks .",
    "for example , a very special case is when step lengths obey the lvy distribution , such a random walk is called lvy flight or lvy walk @xcite .",
    "it is worth pointing out that a lvy flight is also a markov chain .",
    "in fact , any algorithmic path traced by the current solution plus a transition probability forms a markov chain .",
    "this is one of the reason why markov chain theory can be used to analyzed stochastic algorithms such as simulated annealing and cuckoo search .    in section 4",
    ", we will discuss random walks without drift .",
    "that is , we will set @xmath34 .      in standard gaussian random walks ,",
    "the steps are drawn from a gaussian normal distribution @xmath35 , and these steps are mostly limited within @xmath36 . therefore , it can be expected that very large steps ( @xmath37 ) are extremely rarely .",
    "sometimes , it may be necessary to generate new solutions that are far from the current state so as to avoid being trapped in a local region for a long time . in this case ,",
    "random walks with varying step sizes may be desirable .",
    "for example , lvy flights are another class of random walks whose step lengths are drawn from the so - called lvy distribution .",
    "when steps are large , lvy distribution can be approximated as a simple power - law l(s ) ~|s|^-1- , where @xmath38 is an index @xcite .",
    "however , this power - law is just an approximation to the lvy distribution .    to be more accurate",
    ", lvy distribution should be defined in terms of the following fourier transform f(k)= , 0 < 2 , where @xmath39 is a scaling parameter . in general , the inverse of this integral is not straightforward , as no analytical form can be obtained , except for a few special cases .",
    "one special case @xmath40 corresponds to a gaussian distribution , and another case @xmath41 leads to a cauchy distribution .",
    "though the inverse integral is difficult , however , one useful technique is to approximate l(s ) = _ 0^ ( k s ) dk , when @xmath30 is large .",
    "that is , l(s ) , s , where the gamma function @xmath42 is defined as ( z ) = _",
    "0^ t^z-1 e^-t dt .",
    "obviously , when @xmath43 is an integer , it becomes @xmath44 .",
    "since the steps drawn from a lvy distribution can be occasionally very large , random walks in terms of lvy flights are more efficient than standard brownian random walks .",
    "it can be expected that lvy flights are efficient in exploring unknown , large - scale search space .",
    "there are many reasons to explain this high efficiency , and one reason is that the variance of lvy flights ^2(t ) ~t^3- , 1 2 , increases much faster than the linear relationship ( i.e. , @xmath45 ) of brownian random walks .",
    "it is worth pointing out that a power - law distribution is often linked to some scale - free characteristics , and lvy flights can thus show self - similarity and fractal behavior in the flight patterns .",
    "studies show that lvy flights can maximize the efficiency of the resource search process in uncertain environments .",
    "in fact , lvy flights have been observed among the foraging patterns of albatrosses , fruit flies , and spider monkeys .",
    "even humans such as the ju/hoansi hunter - gatherers can trace paths of lvy - flight patterns @xcite . in addition ,",
    "lvy flights have many applications .",
    "many physical phenomena such as the diffusion of fluorenscent molecules , cooling behavior and noise could show lvy - flight characteristics under right conditions .",
    "lvy flights have been successfully used in optimization to enhance the search efficiency of nature - inspired algorithms @xcite .",
    "the above nonlinear variance partly explain why . as we will see below , a good combination with other methods such as eagle strategy",
    "can be even more efficient .",
    "if we look at an algorithm from the markovian view , an algorithm is intrinsically related to markov chains because an algorithm is an iterative procedure whose aim is to generate new , better solutions from the current solution set so that the best solution can be reached in a finite number of steps , ideally , as fewer steps as possible . in this sense , the next solutions ( i.e. , states ) can depend only on the current solution ( states ) and the way to move ( the transition ) towards the new solution ( i.e. , new states )",
    "therefore , the solution paths are markov chains .    in the very simplest case ,",
    "a very good example is the so - called simulated annealing @xcite , which is a markov chain generating a piece - wise path in the search space . broadly speaking ,",
    "swarm - intelligence - based algorithms such as particle swarm optimization , bat algorithm and eagle strategy can all be considered as a system of multiple interacting markov chains @xcite .",
    "now , let us discuss these concepts in detail",
    ".    briefly speaking , a random variable @xmath46 is said to form a markov process if the transition probability , from state @xmath47 at time @xmath5 to another state @xmath48 , depends only on the current state @xmath49 , independent of any past states before @xmath5 .",
    "mathematically , we have p(i , j ) p(u_t+1=s_j|u_0=s_p , ... , u_t = s_i ) = p(u_t+1=s_j|u_t = s_i ) , which is independent of the states before @xmath5 . the sequence of random variables @xmath50 generated by a markov process",
    "is subsequently called a markov chain . obviously , a random walk is a markov chain .",
    "the transition probability p(i , j ) p ( i j)=p_ij , is also called the transition kernel of the markov chain . from the algorithmic point of view",
    ", different algorithms will have different transition kernel ; however , it is not known what kernels are most effective for a given problem . in order to solve an optimization problem ,",
    "the feasible solution set can be obtained by performing a random walk , starting from a good initial but random guess solution . however , simple or blind random walks are not efficient .    to be computationally efficient and effective in searching for",
    "new solutions , effective transition kernels should allow to generate new solutions near the truly optimal solutions as well as to increase the mobility of the random walk so as to explore the search space more effectively .",
    "in addition , the best solutions found so far should be kept in the population .",
    "ideally , the way to control the walk should be carried out in such a way that it can move towards the optimal solutions more quickly , rather than wandering away from the potential best solutions .",
    "these are the challenges for most metaheuristic algorithms , and various attempts are being made so as to design better optimization algorithms .",
    "in all metaheuristic algorithms , different forms of random walks are widely used for randomization and local search @xcite .",
    "obviously , a proper step size is very important .",
    "many algorithms typically use the following generic equation : ^t+1=^t + s * * _ t , where @xmath51 is drawn from a standard normal distribution with zero mean and unity standard deviation . here",
    ", the step size @xmath30 is essentially a scaling factor , controlling how far a random walker , such as an agent or a particle in metaheursitics , can move for a fixed number of iterations .    from the above equation",
    ", it can be expected that the new solution @xmath52 generated will be too far away from the old solution ( or more often the current best ) if @xmath30 is too large .",
    "then , a move that is too far away is unlikely to be accepted as a better solution . on the other hand ,",
    "if @xmath30 is too small , the change is too small to be significant , and the new solution may be too close to the existing solution . consequently , the diversity of the new solutions is limited , and thus the search process is not efficient . therefore , an appropriate step size is important to maintain the search process as efficient as possible .",
    "there are extensive good theoretical results about isotropic random walks in the literature @xcite , and one of the results concerns the average distance @xmath53 traveled in the @xmath27-dimension space , which is r^2=2 d d t. here , @xmath54 is the effective diffusion coefficient where @xmath30 is the step size or distance traveled at each jump . in addition , @xmath31 is the time taken for each jump . by re - arranging the above equation , we get s^2= , which can be used to estimate the typical step sizes for a give problem .",
    "for example , for a typical scale @xmath10 of dimensions of interest , the local search is typically limited in a region of @xmath55 . as the iterations are discrete",
    ", @xmath56 can used for simplicity .",
    "obviously , the number of iterations should not be too large ; otherwise , the computational costs are too high . typically , the number of generations is usually @xmath57 to @xmath58 for most applications .",
    "therefore , we have s = .",
    "[ stepsize - equ-555 ]    let us try to do some estimates .",
    "for @xmath59 and @xmath57 , we have @xmath60 , while @xmath61 for @xmath62 and @xmath63 . in addition , for @xmath64 and @xmath63 , we have @xmath65 . as",
    "step sizes could differ from variable to variable , a step size ratio @xmath66 is more generic .",
    "therefore , we can use @xmath67 to @xmath68 for most applications . in the rest of the paper",
    ", we will usually set the number of iterations as 200 in the case studies in section 5 .",
    "if an algorithm works well , the final accuracy of the obtained solution will depend on the number of iterations . in principle",
    ", a higher number of iterations may be more likely to obtain higher accuracy , though stagnation may occur .",
    "from the theory of random walks , we can estimate the number of iterations needed for a given tolerance , though such estimates are just guidelines .",
    "for example , in order to achieve the accuracy of @xmath69 , the number of steps or iterations @xmath70 needed by pure random walks can be estimated by n _ , which is essentially an upper bound . as an estimate for @xmath71 and @xmath64 , we have n _ 10 ^ 10 , [ nmax - old ] which is a huge number that is not easily achievable in practice . however , this number is still far smaller than that needed by a uniform or brute force search method .",
    "it is worth pointing out the above estimate is the upper limit for the worst - case scenarios . in reality , most metaheuristic algorithms require far fewer numbers of iterations .    though the above estimate may be crude ,",
    "it does imply another interesting fact that the number of iterations will not be affected much by dimensionality .",
    "in fact , higher - dimensional problems do not necessarily increase the number of iterations .",
    "this may lead to a rather surprising possibility that random walks may be efficient in higher dimensions if the optimization problem is highly multimodal .",
    "this may provide some hints for designing better algorithms by cleverly using random walks and other randomization techniques . as we will see below",
    ", different random walks will indeed lead to different convergence rates , and lvy flights are one of the best randomization techniques .      as mentioned earlier , the variance of a gaussian random walk increases linearly with time @xmath5 , while the variance of lvy flights usually increases nonlinearly at a higher rate . as a result , if lvy flights instead of gaussian random walks are used , the above estimate becomes n _ ( ) ^1/(3- ) .",
    "[ levy - step ] if we use @xmath72 together the same values of @xmath71 , @xmath64 and @xmath69 , we have n _ 4.6 10 ^ 6 . [ nmax - mid ] it can be clearly seen that lvy flights can reduce the number of iterations by about 4 orders [ @xmath73 from @xmath74 in eq .",
    "( [ nmax - old ] ) to @xmath75 in eq .",
    "( [ nmax - mid ] ) .",
    "ideally , the step sizes in any nature - inspired algorithm should be controlled in such a way that they can do both local and global search more efficiently . to illustrate this point ,",
    "let us split the search process into two stages as those in the efficient eagle strategy ( es ) , developed by xin - she yang and suash deb @xcite .",
    "the first stage uses a crude / large step , say , @xmath76 , and then in the second stage , a finer step size @xmath77 is used so as to achieve the same final accuracy as discussed in the previous section .",
    "the first stage can cover the whole region @xmath78 , while the second region should cover smaller , local regions of size @xmath79 .",
    "typically , @xmath80 . using the above values and @xmath81 and @xmath82 , then we have n_1 , 10 ^ 4 , n_2 , 10 ^ 4 .",
    "[ nmax - new ] it can be seen clearly that the number of iterations can be reduced by about 6 orders ( @xmath83 ) from @xmath74 [ see eq .",
    "( [ nmax - old ] ) ] to @xmath84 [ see eq .",
    "( [ nmax - new ] ) ] .",
    "this approximate values for the number of iterations have been observed and used in the literature @xcite .",
    "for example , the typical number of iterations for bat algorithm in @xcite and multiobjective cuckoo search in @xcite are typically 20,000 , which were indeed consistent with our estimations here .",
    "it is worth pointing out that the above reduction is by the two - stage eagle strategy only without using lvy flights .",
    "it can be expected that lvy flights can reduce the number of iterations even further .",
    "in fact , if lvy flights are used within the eagle strategy , then the above estimates can be reduced to n_1 , n_2 , 464 , which is obtained by substituting @xmath85 ( or @xmath79 ) and @xmath86 ( or @xmath87 ) into eq .",
    "( [ levy - step ] ) .",
    "the relative lower number of iterations can be both practical and realistic .",
    "therefore , the good combination of lvy flights with eagle strategy can reduce the number of iterations from @xmath74 to less than @xmath88 , which works almost like a magic .",
    "this shows that , with a combination of good algorithms , eagle strategy can significantly reduce the computational efforts and may thus increase the search efficiency dramatically",
    ". it may be possible that a multi - stage eagle strategy can be developed to enhance this efficiency even further .",
    "the above analyses and observations have indicated that a proper combination of randomization techniques such as lvy flights , eagle strategy and a good optimizer such as apso can reduce the computational efforts dramatically and thus improve the search efficiently significantly .",
    "henceforth , we will use eagle strategy with apso to solve four nonlinear benchmarks so as to validate the above theoretical results .",
    "the four optimization benchmarks are : design optimization of a pressure vessel , a speed reducer , a pid controller and a heat exchanger .",
    "the parameter settings for the algorithms used in the rest of paper have been based on a parametric study . for the eagle strategy",
    ", we used 5 rounds of two - stage iterations , and each round used the apso for an intensive search .",
    "the population size is @xmath89 , and the iteration for apso was set to @xmath90 .",
    "this leads to a total of @xmath91 function evaluations for each case study .",
    "in addition , the parameters in apso have been set to be @xmath92 , and @xmath18 .",
    "pressure vessels are literally everywhere such as champagne bottles and gas tanks . for a given volume and working pressure ,",
    "the basic aim of designing a cylindrical vessel is to minimize the total cost . typically , the design variables are the thickness @xmath93 of the head , the thickness @xmath94 of the body , the inner radius @xmath53 , and the length @xmath10 of the cylindrical section @xcite .",
    "this is a well - known test problem for optimization and it can be written as f ( ) = 0.6224 d_1 r l + 1.7781 d_2 r^2 + 3.1661",
    "d_1 ^ 2 l + 19.84 d_1 ^ 2 r , subject to the following constraints :    lll g_1 ( ) = -d_1 + 0.0193 r 0 + g_2 ( ) = -d_2 + 0.00954 r 0 + g_3 ( ) = - r^2 l - r^3 + 1296000 0 + g_4 ( ) = l -240 0 .",
    "the simple bounds are 0.0625 d_1 , d_2 99 0.0625 , and 10.0 r , l 200.0 .",
    "recently , cagnina et al @xcite used an efficient particle swarm optimiser to solve this problem and they found the best solution @xmath95 at _ * ( 0.8125 , 0.4375 , 42.0984 , 176.6366 ) .",
    "this means the lowest price is about @xmath96 .    using es with apso",
    ", we obtained the same results , but we used significantly fewer function evaluations , comparing with apso alone and other methods .",
    "in fact , we use @xmath97 stages and each stage with a total of @xmath98 iterations .",
    "this is at least 10 times less than the iterations needed by standard pso .",
    "this again confirmed that es is indeed very efficient",
    ".      another important benchmark is the design of a speed reducer which is commonly used in many mechanisms such as a gearbox @xcite .",
    "this problem involves the optimization of 7 variables , including the face width , the number of teeth , the diameter of the shaft and others .",
    "all variables are continuous within some limits , except @xmath99 which only takes integer values .",
    "@xmath100 -1.508 x_1 ( x_6 ^ 2+x_7 ^ 2)+7.4777 ( x_6 ^ 3+x_7 ^ 3 ) + 0.7854 ( x_4 x_6 ^ 2+x_5 x_7 ^ 2 )    g_1 ( ) = -1 0 , g_2 ( ) = -1 0 ,    g_3()= - 1 0 , g_4()= - 1 0 ,    g_5 ( ) = -1 0 ,    g_6 ( ) = -1 0 , g_7 ( ) = -1 0 , g_8 ( ) = -1 0 , g_9()= -1 0 , g_10 ( ) = -1 0 , g_11 ( ) = -1 0 , where the simple bounds are @xmath101 , @xmath102 , @xmath103 , @xmath104 , @xmath105 , @xmath106 , and @xmath107 . in one of latest studies ,",
    "cagnina et al .",
    "@xcite obtained the following solution _ * = ( 3.5 , 0.7 , 17 , 7.3 , 7.8 , 3.350214,5.286683 ) with @xmath108    using our es with apso , we have obtained the new best solution _ * = ( 3.5 , 0.7 , 17 , 7.3 , 7.8 , 3.34336449,5.285351 ) with the best objective @xmath109 . in existing studies",
    "@xcite , the total number of function evaluations was often 350,000 . here , we used @xmath89 for @xmath98 iterations and 5 rounds of eagle strategy runs , giving a total of @xmath110 function evaluations .",
    "this saves about 93% of the computational costs .",
    "we can see that es not only provides better solutions but also finds solutions more efficiently using fewer function evaluations . again",
    "the number of iterations ( 20,000 ) is consistent with our theoretical estimations given earlier in section 4 .",
    "let us use es with apso @xcite to design a well - known pid controller @xcite u(t)=k_p , where @xmath111 is the error signal between the response @xmath112 and the reference input @xmath113 , and @xmath114 is the input signal to the so - called plant model .",
    "the well - established ziegler - nichols tuning scheme can usually produce very good results . here",
    ", we use es with apso to minimize the rise time , the overshoot and settling time .    it is required to tune a third - order system with the following transfer function g(s ) = , so that responses of the closed loop system to track a reference meet the following requirements : rise time is less than 1.5 s , settling time is less than 5.5 s , and the overshoot is less than 5% .",
    "if we use the standard matlab control system toolbox @xcite , the obtained design by the ziegler - nichols scheme is g_pid(s)=0.311 ( 1 + + 0.5911 s ) , which gives a rise time of 1.6 s , a settling time of 4.95 , and overshoot of about 8.54% .",
    "clearly , not all two requirements are met .    in order to refine the designs , we use es with apso , and the results",
    "are shown in fig .",
    "[ fig-100 ] .",
    "the final design becomes g_pid , new(s)=0.5366 ( 1 + + 0.8485 s ) , which gives a rise time of 1.0 s , a settling time of 5.25 s , and the overshoot of 4.97% .",
    "all the design requirements are met by this new design .",
    "as before , the total number of function evaluations is 20,000 .    , width=288,height=192 ]      heat transfer management is very important in many applications such as central heating systems and microelectronics .",
    "there are many well - known benchmarks for testing design / optimization tools , and one of the benchmarks is the design of a heat exchanger @xcite .",
    "this design problem has 8 design variables and 6 inequality constraints , which can be written as f ( ) = x_1 + x_2 + x_3 , subject to g_1()=0.0025(x_4+x_6)-1 0 , g_2()=0.0025(x_5+x_7-x_4 ) -1 0 , g_3()=0.01(x_8-x_5 ) -1 0 , g_4()=833.33252 x_4 + 100 x_1 -x_1 x_6 - 83333.333 0 , g_5()=1250 x_5 + x_2 ( x_4 - x_7 ) -120 x_4 0 , g_6()=x_3 x_5 -2500 x_5 - x_3 x_8 + 1.25 10 ^ 6 0 .",
    "the first three constraints are linear , while the last three constraints are nonlinear .    by using es with apso for the same parameter values of @xmath89 , @xmath90 iterations and @xmath97 es stages",
    ", we obtained the best solution @xmath115 295.60118 , 217.98230 , 286.41653 , 395.60118 ) , which gives the optimal objective of @xmath116 .",
    "this is exactly the same as the best solution found by yang and gandomi @xcite and is better than the best solutions reported in the previous literature @xcite . in the study by jaberipour and khorram ,",
    "they used 200,000 function evaluations , while deb used 320,080 function evaluations@xcite . in the present study , we have used 20,000 function evaluations that is less than 10% of the computational costs by other researchers .    as we can see from the above 4 case studies , es with apso can save about 90% of the computational costs , which demonstrates the superior performance of es with apso . in order to show that the improvements are significant",
    ", we use the standard student @xmath5-test in terms of the numbers of functional evaluations . for @xmath117 ,",
    "the two - sample @xmath5-test gives @xmath118 , which means that the improvements are statistically significant .",
    "all swarm - intelligence - based algorithms such as pso and firefly algorithm can be viewed in a unified framework of markov chains ; however , theoretical analysis remains challenging .",
    "we have used the fundamental concepts of random walks and lvy flights to analyze the efficiency of random walks in nature - inspired metaheuristic algorithms .",
    "we have demonstrated that lvy flights can be significantly more efficient than standard gaussian random walks under appropriate conditions . by the right combination with eagle strategy ,",
    "significant computational efforts can be saved , as we have shown in the paper .",
    "the theory of interacting markov chains is complicated and yet still under active development ; however , any progress in such areas will play a central role in understanding how population- and trajectory - based metaheuristic algorithms perform under various conditions .",
    "even though we do not fully understand why metaheuristic algorithms work , this does not hinder us to use these algorithms efficiently .",
    "on the contrary , such mysteries can drive and motivate us to pursue further research and development in metaheuristics .",
    "further research can focus on the extensive testing of metaheuristics over a wide range of large - scale problems .",
    "in addition , various statistical measures and self - adjusting random walks can be used to improve the efficiency of existing metaheuristic algorithms .    on the other hand ,",
    "the present results are mainly concerned with gaussian random walks , lvy flights and eagle strategy .",
    "it can be expected these results may be further improved with parameter tuning and parameter control in metaheuristic algorithms .",
    "it is a known fact that the settings of algorithm - dependent parameters can influence the convergence behaviour of a given algorithm , but how to find the optimal setting remains an open question .",
    "it can be very useful to carry out more research in this important area .",
    "ramos - fernandez g , mateos jl , miramontes o , cocho g , larralde h , ayala - orozco b , ( 2004 ) .",
    "lvy walk patterns in the foraging movements of spider monkeys ( _ ateles geoffroyi_),_behav .",
    "_ , * 55 * , 223 - 230 .",
    "yang xs , deb s , and fong s , ( 2011 ) . accelerated particle swarm optimization and support vector machine for business optimization and applications , in : networked digital technologies 2011 , communications in computer and information science , * 136 * , pp .",
    "5366 ( 2011 ) .",
    "yang xs and deb s , ( 2011 ) .",
    "eagle strategy using lvy walk and firefly algorithms for stochastic optimization , in : nature inspired cooperative strategies for optimization ( nicso 2010 ) , springer , pp .",
    "101 - 111 ( 2011 ) .",
    "yang xs , ting to , karamanoglu m , ( 2013 ) .",
    "random walks , lvy flights , markov chains and metaheuristic optimization , in : future information communication technology and applications , _ lecture notes in electrical engineering _ , vol .",
    "1055 - 1064 ( 2013 ) ."
  ],
  "abstract_text": [
    "<S> all swarm - intelligence - based optimization algorithms use some stochastic components to increase the diversity of solutions during the search process . such randomization is often represented in terms of random walks . however , it is not yet clear why some randomization techniques ( and thus why some algorithms ) may perform better than others for a given set of problems . in this work </S>",
    "<S> , we analyze these randomization methods in the context of nature - inspired algorithms . </S>",
    "<S> we also use eagle strategy to provide basic observations and relate step sizes and search efficiency using markov theory . then </S>",
    "<S> , we apply our analysis and observations to solve four design benchmarks , including the designs of a pressure vessel , a speed reducer , a pid controller and a heat exchanger . </S>",
    "<S> our results demonstrate that eagle strategy with lvy flights can perform extremely well in reducing the overall computational efforts .    </S>",
    "<S> * citation details : * x. s. yang , m. karamanoglu , t. o. ting and y. x. zhao , applications and analysis of bio - inspired eagle strategy for engineering optimization _ neural computing and applications _ , vol . 25 , no . 2 , pp . </S>",
    "<S> 411 - 420 ( 2014 ) . </S>"
  ]
}