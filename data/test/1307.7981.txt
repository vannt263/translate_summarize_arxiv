{
  "article_text": [
    "we are concerned with the problem of speaker detection , where an automatic speaker recognizer is used to decide whether or not the voice of a designated target speaker is present in a given speech segment .",
    "current speaker recognition algorithms output uncalibrated _ scores _ , which have to be processed through a calibration stage before cost effective decisions can be made .",
    "this paper deals with the problem of designing the calibration stage .",
    "we implement the calibration stage in the form of a discriminative model , say @xmath0 , which outputs a posterior probability that the target speaker spoke the speech segment : @xmath1 .",
    "the trial score , @xmath2 , is computed by the speaker recognizer as a function of the target speaker and the speech segment .",
    "this posterior can be used in a straight - forward , standard way to make minimum - expected - cost bayes decisions .",
    "we shall take as the baseline discriminative model prior - weighted logistic regression  @xcite , which has become a standard recipe for calibration in speaker recognition , with implementations available in the focal  @xcite and bosaris  @xcite toolkits .",
    "logistic regression is the minimization of the expected value of a special cost function , known as the _ logarithmic proper scoring rule_. we are interested here in generalizing this recipe by modifying the cost function .",
    "our motivation derives from  @xcite , where it was demonstrated that a modified logistic regression that ignores scores below a suitable threshold can benefit applications with low false - alarm rate requirements . in this work we limit ourselves to cost functions which are",
    "_ proper scoring rules _  @xcite .",
    "we expand on our previous work  @xcite , to demonstrate theoretically and experimentally that we can tailor proper scoring rules to target the low false - alarm region .",
    "given a database of supervised trials , the sum over trials of a proper scoring rule forms an objective function that can be used to simply evaluate the goodness of a recognizer with probabilistic output , and indeed also to facilitate discriminative training of such recognizers .",
    "we restrict ourselves to _ binary _ proper scoring rules , a family of special cost functions of the form @xmath3 , which evaluates the goodness of the recognizer output @xmath4 , for a trial where hypothesis @xmath5 is true .",
    "we use the notation @xmath6 for a trial where the target speaker spoke and @xmath7 for one where some other speaker spoke . in",
    "what follows it will be convenient to work with recognizer outputs in the form of posterior probabilities : @xmath8 , where @xmath2 is the uncalibrated trial score and @xmath0 is the calibration model .",
    "later we show how to adapt this to recognizer outputs in likelihood - ratio form .",
    "a binary proper scoring can be seen as a _ model of an application _ of a detector  or more generally , a mixture of such applications .",
    "an application , @xmath9 , is represented by a cost function @xmath10 , which maps outcomes to real - valued consequences .",
    "the outcome is composed of the decision , @xmath11 , and the true hypothesis , @xmath12 .",
    "the sets from which decisions are chosen may differ between applications , for example @xmath13 , or @xmath14 , and so on .",
    "our application model assumes that the detector output , @xmath4 , is used to make a minimum - expected - cost bayes decision : @xmath15 the associated _ proper scoring rule _ is defined as the cost of this decision  @xcite : @xmath16 a convex combination of proper scoring rules is still a proper scoring rule , in the sense that it can be derived via   from a suitably constructed cost function that represents a mixture of different applications  @xcite .",
    "although applications may be defined via a large variety of cost functions , all of this variety can be conveniently represented in a surprisingly simple form  @xcite .",
    "all binary proper scoring rules can be expressed in the form : @xmath17 where @xmath18 , @xmath19 and @xmath20 .",
    "the constants @xmath21 do nt play any useful role in the bayes decision framework and may be set to @xmath22 and @xmath23 without loss of generality  @xcite",
    ".    the weighting distribution @xmath24 can be very general , including smooth functions , step functions or even impulses .",
    "the impulse @xmath25 represents a single , _ simple application _ , with binary decisions in @xmath13 , a cost function with penalties @xmath26 and @xmath27 and the bayes decision threshold at @xmath28 .",
    "a sum of impulses represents a discrete mixture of applications , while a smooth function represents a continuous mixture over a continuous spectrum of applications .",
    "the important point here is that all bayes decision applications ( or mixtures of applications ) can be represented by   via a suitable choice of @xmath24 .",
    "here we build an objective function , for training or evaluation , out of a proper scoring rule , @xmath29 .",
    "the proper scoring rule models the cost of making a bayes decision in a single detection trial . to turn this into an objective function ,",
    "we take the _ expected _ cost over a whole supervised database .",
    "we form this expectation via two hypothesis conditional averages , weighted by a synthetic class prior ( usually different from the database proportions ) , of the form @xmath30 , @xmath31 .",
    "the expected cost is : @xmath32 where @xmath33 is the recognizer s posterior for trial @xmath34 ; @xmath35 is a set of @xmath36 target trial indices ; and @xmath37 a set of @xmath38 non - target indices .",
    "now , we relieve the calibrator of the ( implicit ) responsibility to have a hypothesis prior and to produce posteriors . instead",
    ", we require it to output _ log - likelihood - ratios _ , denoted @xmath39 .",
    "since the prior is already fixed as a parameter of the objective  , the recognizer s posterior is given by bayes rule as : as the ratio of two generative likelihoods adds no value . instead",
    "should be taken as the definition of @xmath39 . ]",
    "@xmath40 where @xmath41 is prior log odds and @xmath42 is the logistic sigmoid : @xmath43 after some manipulation , we can express the functions of @xmath33 in   as functions of @xmath39 instead : @xmath44 where @xmath45 is a translated and modulated version of @xmath24 , where the modulation factor : @xmath46 is a raised and scaled sigmoid . if @xmath24 is normalized , then @xmath47 is normalizable in the sense : @xmath48 .",
    "the integrals in   can be interpreted as averaging over all possible cost functions , where @xmath24 determines the relative importance of different cost functions . in our construction of the objective function",
    ", we inherit this averaging over cost functions , but we seem to have fixed the prior at @xmath49 .",
    "since different applications of a speaker detector can be expected to have different priors , should we not also average over @xmath49 ?",
    "we can , but it adds no generality , because this would effectively just replace @xmath47 in   by some other normalized / normalizable weighting distribution , say @xmath50 .",
    "we can now reformulate our objective function in its most general form as : @xmath51 where @xmath52 we now have a general objective function , parametrized by @xmath50 , which effectively determines the relative weighting over a mixture of different applications , each of which can have a different cost function and target prior .",
    "notice that @xmath53 is just the log - likelihood - ratio threshold .",
    "simple @xmath54/@xmath55 applications use a single threshold , while more complex applications ( or mixtures ) have multiple thresholds .",
    "thus , the combination of application costs in   is accomplished via representing applications by their thresholds .",
    "here we introduce a practical choice for the weighting distribution , @xmath50 and show how it is used for calibration .",
    "since calibration involves optimization , smooth differentiable distributions are easier to work with .",
    "it is also desirable that the integrals have closed - form solutions . to this end",
    ", we adopt a 2-parameter ( here @xmath56 ) family of proper scoring rules proposed in  @xcite .",
    "this family is effectively augmented by a third parameter , @xmath57 , via the prior - weighting in  .",
    "this gives @xmath58 : @xmath59 where @xmath60 ; @xmath61 is defined in  ; @xmath62 ensures the distribution is normalized ; and @xmath63 is the beta distribution , transformed to log - odds domain : @xmath64 and @xmath65 is the beta function .",
    "when @xmath66 , then using @xmath67 in   gives closed - form solutions , which can be plugged into  , with @xmath68 and @xmath69 .",
    "while this recipe is practically realized via   and  , a theoretical interpretation is given by   and  , because for this parametrization we have @xmath70 .",
    "we exploit this in figure  [ fig : omega ] , where we plot   for several values of the parameters .",
    "parameters @xmath56 control left and right tails respectively  when they are increased tails become thinner and the distributions become narrower ( higher modes ) .",
    "location is indirectly controlled by @xmath41 , but this depends on @xmath56 . for the case @xmath71 , the distribution is _ invariant _ to @xmath41 . for @xmath72 ,",
    "the mode shifts only as far as @xmath73 , while the distribution is considerably widened .",
    "however , when @xmath74 , the mode shifts close to @xmath75 and the widening is less dramatic .",
    "we show in our experiments below that when we target applications with high thresholds ( low false - alarm rate ) , then the effective shifting allowed by @xmath74 leads to better performance than the halfway shifted and stretched version given by the baseline logistic regression solution with @xmath72 .      here",
    "we list some solutions for the integrals in  , which we used in our experiments .",
    "the _ boosting rule _",
    "@xcite , with @xmath71 : @xmath76 the _ logarithmic rule _ , with @xmath72 , forms the objective function for logistic regression and is our baseline : @xmath77 the parametrization @xmath78 gives ( up to scaling ) , the objective @xmath79 , proposed in  @xcite for the evaluation of goodness of recognizers with likelihood - ratio output .",
    "the _ brier rule _",
    "@xcite , with @xmath80 : @xmath81 an _ asymmetric _ rule , with @xmath82 : @xmath83      we assume that our recognizers output uncalibrated scores . let the score for a trial @xmath34 be denoted @xmath84 .",
    "we then apply a parametric ( affine ) calibration transformation : @xmath85 the calibration parameters @xmath86 need to be trained on a calibration training database . for training purposes ,",
    "we choose and fix the parameters @xmath87 and then minimize the objective   w.r.t .",
    "@xmath86 . in the special case @xmath72",
    "such training is known as logistic regression .",
    "since the objective and the calibration transformation are differentiable , one can obtain the gradient w.r.t .",
    "@xmath86 by backpropagation and then use any of a variety of well - known unconstrained numerical optimization algorithms . for this work , we used bfgs  @xcite .",
    "we performed calibration experiments on scores from a single speaker recognizer ( an i - vector plda system ) , which was part of the abc submission  @xcite to the nist sre12 speaker recognition evaluation .",
    "several calibration transformations of the form   were trained ( separately for males and females ) on a large development set with multiple microphone and telephone speech segments of 2019 speakers from sre04 , 05 , 06 , 08 and 10 .",
    "this gave about 120 million scores for calibration training .",
    "the different calibration transformations were obtained by using different objective function parameters , @xmath87 .",
    "we tested the goodness of these calibrators on the nist sre12 extended trial set  @xcite , where we pooled males and females and all 5 common evaluation conditions , giving about 80 million trials .",
    "our evaluation criterion was @xmath88 , with @xmath89 , as defined in  @xcite .",
    "it should be noted that this criterion can _ also _ be interpreted as an example of our objective function  , since @xmath90 , if we choose @xmath91 , defined as : @xmath92 which is concentrated in two impulses ] at the log - likelihood - ratio threshold values of @xmath93 and @xmath94 .",
    "this criterion was chosen by nist to be calibration - sensitive , but only in the ` low false - alarm region ' around these operating points .",
    "our experimental results are summarized in figure  [ fig : results ] , where we plotted @xmath88 obtained by using the calibrators formed by three representative proper scoring rules against the prior - weighting parameter , @xmath57 .",
    "our baseline ( blue triangles ) is logistic regression ( @xmath72 ) .",
    "the other two rules with @xmath74 ( red circles , green asterisks ) , gave better performance in the sense of having lower , wider minima .",
    "the boosting rule ( @xmath71 ) performed very poorly , at @xmath95 , and is not shown on the graph .",
    "its thick tails makes it vulnerable to outliers .",
    "the reason why different proper scoring rules perform differently is that the affine calibration transformation is limiting .",
    "it can not satisfy the requirement of good calibration at all operating points simultaneously .",
    "we have to choose , via @xmath50 , which operating points are important and which can be ignored .",
    "this is illustrated in figure  [ fig : pav ] , where we compare the log - likelihood - ratios produced for sre12 by two of the proper scoring rule calibrations ( horizontal axis ) , against ideal , reference log - likelihood - ratios ( vertical axis ) .",
    "ideally these plots should lie along the identity transform ( the black diagonal through the origin ) .",
    "but the affine calibration transformation can only try to fit these curves to the ideal straight line via scaling and shifting the curves along the horizontal axis .",
    "the logistic regression ( @xmath72 ) places more weight at lower threshold values and indeed manages to be closer to the ideal there , to the detriment of calibration at the higher @xmath96 operating points . on the other hand , the brier rule ( @xmath80 ) , which places more weight at the @xmath96 operating points , does better there , but pays for this by doing worse at lower threshold values .",
    "the ideal reference along the vertical axis of figure  [ fig : pav ] is achieved via an optimization algorithm known as _ pool adjacent violators _",
    "( pav)@xcite . this algorithm finds the optimal log - likelihood - ratio value for every trial non - parametrically , subject only to the constraint that when sorted along the real line , the order of the optimized values must be the same as the sorted order of the original uncalibrated scores .",
    "this is equivalent to constraining the calibration transformation to be monotonically rising .",
    "the pav output is optimal in the sense that it simultaneously optimizes all binary proper scoring rules at all values of the prior weighting  @xcite .",
    "the pav solution can be optimal everywhere because the non - parametric monotonicity constraint is less strict than the parametric affine transformation available to the proper scoring rule calibrators .",
    "it is important to note however that the true sre12 class labels were used to perform the pav optimization , while the proper scoring rule calibrations were optimized on the independent development data .",
    "if the pav had been optimized on the development data , it would no longer have this optimality on the evaluation data . very similar to the best proper scoring rule results shown in figure  [ fig : results ] .",
    "the details are out of scope for this paper . ]",
    "conclusions from our experimental results should not be extrapolated without caution .",
    "the superiority demonstrated here of rules with @xmath97 may not hold for : ( i ) small calibration training databases ; ( ii ) other recognizers ; ( iii ) applications with thresholds in other operating regions .",
    "the objective function family presented here could be more generally applied , not just for calibration .",
    "these objectives could be used for fusion of multiple recognizers , or indeed for more general discriminative training of speaker recognizers in the manner of  @xcite .",
    "however for more complex recognizers , the risk of overtraining is greater  and this risk may be compounded by more narrowly focussed objectives , such as the brier rule .",
    "in contrast , the wider focus of the logarithmic rule has a regularizing effect , which combats overtraining .",
    "10 niko brmmer et al",
    ". `` fusion of heterogeneous speaker recognition systems in the stbu submission for the nist speaker recognition evaluation 2006 '' , ieee transactions on audio , speech , and language processing , september 2007 .",
    "niko brmmer and johan du preez , `` application - independent evaluation of speaker detection '' , computer speech and language , 2006 .",
    "niko brmmer and edward de villiers , `` the bosaris toolkit : theory , algorithms and code for surviving the new dcf '' , nist sre11 analysis workshop , atlanta , december 2011 .",
    "online : http://sites.google.com/site/bosaristoolkit .",
    "george doddington , `` the role of score calibration in speaker recognition '' , interspeech , portland , september 2012 .",
    "tilmann gneiting and adrian e. raftery , `` strictly proper scoring rules , prediction , and estimation '' , journal of the american statistical association , vol .",
    "359378 , march 2007 .",
    "niko brmmer , `` the role of proper scoring rules in training and evaluating probabilistic speaker and language recognizers '' , invited talk , odyssey 2012 : the speaker and language recognition workshop , singapore , 2012 .",
    "online : http://www.odyssey2012.org/plenary.html .",
    "morris h. degroot , _ optimal statistical decisions _",
    ", mcgraw - hill , 1970 .",
    "niko brmmer , `` measuring , refining and calibrating speaker and language information extracted from speech '' , ph.d .",
    "dissertation , university of stellenbosch , december 2010 .",
    "andreas buja , werner stuetzle , and yi shen , `` loss functions for binary class probability estimation and classification : structure and applications '' , technical report , statistics department , the wharton school , university of pennsylvania , november 2005 .",
    "glenn w. brier , `` verification of forecasts expressed in terms of probability '' , monthly weather review , vol.78 , no.1 , pp .",
    "13 , january 1950 .",
    "jorge nocedal and stephen  j.  wright , _ numerical optimization _ , 2nd edition , springer 2006 .",
    "agnitio , but , crim , `` abc sre12 presentation '' , nist sre 2012 workshop , orlando , december 2012 .",
    "`` the nist year 2012 speaker recognition evaluation plan '' 2012 .",
    "online : http://www.nist.gov/itl/iad/mig/upload/nist_sre12_evalplan-v17-r1.pdf .",
    "bianca zadrozny and charles elkan , `` transforming classifier scores into accurate multiclass probability estimates '' , in proceedings of the eighth international conference on knowledge discovery and data mining , edmonton , alberta , canada , 2002 , pp .",
    "burget , l. et al .",
    ", `` discriminatively trained probabilistic linear discriminant analysis for speaker verification '' , ieee icassp , prague , 2011 ."
  ],
  "abstract_text": [
    "<S> prior - weighted logistic regression has become a standard tool for calibration in speaker recognition . </S>",
    "<S> logistic regression is the optimization of the expected value of the logarithmic scoring rule . </S>",
    "<S> we generalize this via a parametric family of proper scoring rules . </S>",
    "<S> our theoretical analysis shows how different members of this family induce different relative weightings over a spectrum of applications of which the decision thresholds range from low to high . </S>",
    "<S> special attention is given to the interaction between prior weighting and proper scoring rule parameters . </S>",
    "<S> experiments on nist sre12 suggest that for applications with low false - alarm rate requirements , scoring rules tailored to emphasize higher score thresholds may give better accuracy than logistic regression .    * index terms * : speaker recognition , calibration , proper scoring rule </S>"
  ]
}