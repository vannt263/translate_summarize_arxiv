{
  "article_text": [
    "statistics of neuronal activity is often described as a renewal point process , or even a poisson process , see @xcite and references therein . on the other hand , in some sets of experimental data correlations",
    "are observed between consecutive interspike intervals ( isi ) , @xcite , which does not conform with the renewal hypothesis .",
    "what could be the reason of such correlations ? in principle , any sort of memory in the neuronal firing mechanism could bring about memory into the sequence of isis , thus disrupting a possibility for it to be renewal .",
    "memory in the firing mechanism can appear due to partial reset of the membrane potential after firing , @xcite , or due to threshold fatigue @xcite , or for other reasons , see @xcite for a review .",
    "biologically , non - renewal statistics of neuronal activity can improve discrimination of weak signals @xcite and therefore is essential feature of functioning of a nervous system . in this context , it was checked in @xcite if it is possible to represent activity of electrosensory neuron as a markov chain of some finite order .",
    "conclusion made in @xcite is that the corresponding order , if any , can not be lower than 7 .",
    "normally , any neuron is embedded into a network .",
    "inter - neuronal communication in the network is delayed due to finite speed of nervous impulses . in a reverberating network , this brings about one more reason for non - renewal firing statistics  the delayed feedback .",
    "we study here the simplest possible case of a network  a single neuron with delayed feedback . in the previous paper @xcite ,",
    "it was proven for a concrete neuronal model  the binding neuron with threshold 2  stimulated with poisson stream of input impulses , that statistics of its isis is essentially non - markov . in this paper , we refine and extend methods of @xcite making those applicable to any neuron , which satisfies a number of very simple and natural conditions ( see cond0-cond4 in n. [ neuron ] ) . under those conditions ,",
    "we prove rigorously that isi statistics of a neuron with delayed feedback can not be represented as a markov chain of any finite order .",
    "we do not specify any concrete neuronal model , only expect that a neuron satisfies the following conditions :    * cond0 : neuron is deterministic : identical stimuli elicit identical spike trains from the same neuron .",
    "* cond1 : neuron is stimulated with input poisson stream of excitatory impulses .",
    "the input stream has intensity @xmath0 .",
    "* cond2 : neuron may fire a spike only at a moment when it receives an input impulse .",
    "* cond3 : just after firing , neuron appears in its standard state , which is always the same . *",
    "cond4 : the output interspike interval ( isi ) distribution is characterized with a probability density function ( pdf ) @xmath1 , which is positive : @xmath2 , and bounded : @xmath3 .",
    "the cond0 , above , is imposed in accordance with experimental observations , see e.g. @xcite .",
    "as regards the cond1 , poisson stream is a standard stimulation when neuronal random activity is studied .",
    "the cond2 , above , is satisfied for most threshold - type neuronal models , starting from standard leaky integrate and fire ( lif ) neuron @xcite and its modifications , see @xcite . in order the cond2 to be valid ,",
    "it is enough that the following three conditions are satisfied : ( i ) neuronal excitation gets abrupt increase at the moment of receiving input impulse - function form .",
    "] , ( ii ) after that moment , the degree of excitation does not increase ( it decreases for most neuronal models ) until the next input impulse .",
    "( iii ) the neuron fires when its degree of excitation exceeds a threshold level",
    ". the threshold can be either static , as in the basic lif model , or dynamic @xcite .",
    "these conditions seem to be standard for many threshold neuronal models used , see @xcite and citations therein .",
    "cond3 means that any kind of memory about previous input / output activity , which can be present in a neuron , is cleared after each triggering .",
    "due to cond3 , output stream of neuron without feedback will be a renewal stochastic process .",
    "cond4 seems to be natural for any neuronal model stimulated with poisson stream .",
    "at least , all the five conditions are satisfied for the binding neuron model and for the basic lif model , see @xcite , where @xmath1 is calculated exactly for each model , respectively .",
    "we expect that each output impulse fired by neuron is fed back to the neuron s input through a feedback line .",
    "the feedback line has the following properties :    * prop1 : the time delay in the line is @xmath4 .",
    "* prop2 : the line is able to convey no more than one impulse .",
    "* prop3 : the impulse conveyed to the neuronal input is identical to that from the input poisson stream .",
    "it is known that a neuron can form synapses ( autapses ) on its own body , or dendritic tree , e.g. @xcite .",
    "this substantiates consideration of a single neuron with feedback not only as the simplest reverberating `` network '' possible , bat also as an independent biologically relevant case .",
    "the delay @xmath5 comprises the time required by the output spike to pass the distance from axonal hillock , where it is generated , to the autapse and the synaptic delay .",
    "the prop2 is somehow related to the refractoriness even if we do not introduce here the refractoriness to its full extent .",
    "the prop3 means that we consider here an excitatory neuron .",
    "the important for us consequence of prop2 is that at any moment of time the feedback line is either empty , or conveys a single impulse .",
    "if it does convey an impulse , then its state can be described with a stochastic variable @xmath6 , which we call further `` time to live '' .",
    "the variable @xmath6 denotes the exact time required by the impulse to reach the output end of the line , which is the neuron s input , and to leave the line .",
    "it is clear that @xmath7 . in what follows ,",
    "we use the time to live @xmath6 only at moments when an isi starts ( just after triggering ) .",
    "now it is worth to notice that each triggering starts a new isi . and",
    "at the beginning of any isi the line is never empty , but holds an impulse .",
    "this happens for the following reasons :    * if neuron is triggered by an impulse from the poisson input stream , and the line was empty just before that moment , then the emitted impulse enters the line . at that moment the line is characterized with @xmath8 . *",
    "if neuron is triggered by an impulse from the poisson input stream , and the line already conveys an impulse at that moment with time to live @xmath6 , then that same impulse with that same time to live is retained at the beginning of the isi that starts after that triggering , and the line is characterized with that same @xmath6 . *",
    "if neuron is triggered by an impulse from the line , then the line is empty at the firing moment and the emitted impulse enters the line . after that moment the line is characterized with @xmath8 .      we expect that defined in nn .",
    "[ neuron ] , [ line ] system of neuron with delayed feedback line fed with poisson stream is in its stationary regime .",
    "this can be achieved if the system functions long enough that its initial state is forgotten .    in the stationary regime , let @xmath9 denotes the joint probability density function of neuron with delayed feedback .",
    "the probability to get , in the output , starting from the beginning , @xmath10 consecutive isis @xmath11 such that @xmath12 , @xmath13 with infinitesimal @xmath14 is given by @xmath15 .",
    "let @xmath16 denotes the conditional probability to get the duration of @xmath17-th isi in @xmath18 provided that previous @xmath19 isis had duration @xmath20 , respectively .",
    "now we reformulate in terms of probability density functions the definition from ( * ? ? ?",
    "* ch.2  6 ) :    the sequence of random variables @xmath21 , taking values in @xmath22 , is called the markov chain of the order @xmath23 , if @xmath24 and this equation does not hold for any @xmath25 .",
    "in particular , taking @xmath26 , we have the necessary condition @xmath27 required for the stochastic process @xmath21 to be @xmath10-order markov chain . in the case of isis",
    "one reads @xmath28 .",
    "we intend to prove that the relation ( [ def ] ) does not hold for any @xmath10 . for this purpose",
    "we calculate exact expression for @xmath29 as @xmath30 from which it will be clearly seen that the @xmath31-dependence in @xmath29 can not be eliminated whatever large the @xmath10 is .",
    "as it is seen from ( [ defcond ] ) , we need initially to calculate exact expressions for @xmath32 with arbitrary @xmath10 . in @xcite , for the binding neuron model with threshold 2 this is done by introducing an auxiliary stochastic process with events @xmath33 , where @xmath34 is the time to live at the beginning of isi @xmath35 .",
    "it was proven that the sequence of events @xmath33 , @xmath36 , is markov chain , which helps to calculate the joint probability density @xmath37 and then @xmath32 as marginal probability by integrating it over @xmath380;\\delta]$ ] with respect to each @xmath34 . to simplify this approach",
    ", it is worth to notice that in the sequence of consecutive random events @xmath39 only the values of variables @xmath40 are fairly random . indeed , with @xmath41 given",
    ", one can figure out exact value for the @xmath42 : if @xmath43 then @xmath44 , and @xmath45 otherwise .",
    "now , with @xmath46 known , the same way it is possible to find the exact value of @xmath47 and so on .",
    "this allows one to reconstruct unambiguously all the values @xmath48 from the given sequence of values of @xmath40 . having this in mind",
    ", we introduce the conditional joint probability density @xmath49 , which we use to calculate required joint pdfs as follows @xmath50 where @xmath6 ( dented previously as @xmath51 ) is the time to live at the beginning of isi @xmath31 , @xmath52 is the stationary pdf which describes distribution of times to live at the beginning of any isi in the stationary regime . in what follows",
    "we analyze the structure of functions @xmath52 and @xmath49 .",
    "it appears that @xmath52 has a singular component @xmath53 with @xmath54 , and @xmath49 has a @xmath55-function - type singularities at definite hyper - planes in the @xmath17-dimensional space of its variables @xmath56 .",
    "after integration in ( [ pdfs ] ) , some of those @xmath55-functions will survive , and one of those survived has its argument depending on @xmath31 .",
    "the latter statement depends on exact value of isis in the sequence @xmath57 .",
    "here , we limit our consideration to the domain in the @xmath17-dimensional space of variables @xmath56 , which is defined as follows @xmath58 notice that @xmath59 is not involved in ( [ domain ] ) .",
    "the @xmath31-dependent @xmath55-function will as well survive in the @xmath29 for any @xmath10 , which will complete the proof that the condition ( [ def ] ) can not be satisfied for any @xmath10 .",
    "a question remains of whether the domain ( [ domain ] ) has a strictly positive probability .",
    "this indeed takes place due to positiveness of pdfs @xmath60 for any positive values of @xmath56 .",
    "the latter follows from the exact expressions for @xmath60 given in n. [ form ] , eq .",
    "( [ pn ] ) .",
    "expect that the inequality ( [ domain ] ) holds . in order to perform integration in ( [ pdfs ] ) , we split the integration domain into the following @xmath62 disjoint sub - domains : @xmath63\\sum\\limits_{i=0}^{k-1}t_i\\,;~\\sum\\limits_{i=0}^{k}t_i\\right],~ k=0,\\dots , n,~~ d_{n+1}=\\left]\\sum\\limits_{i=0}^{n}t_i\\,;~\\delta\\right]\\,.\\ ] ] it is clear that @xmath640;\\delta].\\ ] ]    mutual disposition in time of @xmath6 and @xmath65 if @xmath66.,scaledwidth=66.0% ]    the conditional pdf @xmath61 has different structure at different domains . if @xmath66 , then a relation between @xmath6 and @xmath35 is as shown in fig .",
    "[ relk ] . as it could be suggested by fig .",
    "[ relk ] , the first @xmath67 isis are produced with the delay line not involved .",
    "the @xmath68-th isi is generated with the line involved .",
    "the corresponding time to live is @xmath69 , the next time to live is @xmath70 .",
    "therefore , the structure of @xmath61 at @xmath71 is as follows @xmath72    mutual disposition in time of @xmath6 and @xmath65 if @xmath73.,scaledwidth=66.0% ]    where @xmath74 . and if @xmath73 , then relation between @xmath6 and @xmath35 is as shown in fig .",
    "this suggests the following structure for @xmath61 @xmath75 here @xmath76 denotes the conditional pdf to get isi of duration @xmath77 if at its beginning , time to live of impulse in the feedback line is @xmath6 .    by utilizing the same reasoning with ( [ domain ] ) taken into account",
    ", one can represent the first factor in ( [ struk ] ) as follows @xmath78    representation of @xmath61 by means of @xmath1 and @xmath76 , similar to that displayed in ( [ struk ] ) , ( [ strun+1 ] ) , ( [ strukf ] ) , can be as well constructed if ( [ domain ] ) does not hold . for our purpose",
    "it is enough to have ( [ struk ] ) , ( [ strun+1 ] ) and ( [ strukf ] ) .",
    "expect that at the beginning of an isi , there is an impulse in the feedback line with time to live @xmath6 .",
    "then the probability that this isi will have its duration @xmath80 does not depend on the feedback line presence .",
    "therefore , @xmath81 the probability to get exactly @xmath82 is not zero , because in this case the impulse , which triggers the neuron and finishes the isi under consideration comes from the delay line .",
    "in order this to happen , it is necessary and sufficient that the following two events take place : ( i ) the neuron does not fire at the interval @xmath380;s[$ ] ; ( ii ) at the moment @xmath6 , the neuron , due to previous stimulation from the poisson stream , achieves such a state that adding one more input impulse will trigger it .",
    "the probability of ( i ) and ( ii ) is @xmath83 , which can be easily concluded from the definition of @xmath1 .",
    "thus , @xmath84s-\\epsilon;s+\\epsilon[\\,\\ , \\rightarrow\\ , p(t\\mid s ) = \\frac{p^0(t)}{\\lambda}\\delta(s - t)\\ ] ] with infinitesimal @xmath85 .",
    "if the neuron still not triggered at moment @xmath6 , then it is triggered by an input impulse from the poisson stream at @xmath86 .",
    "the probability to get such an impulse in @xmath87 is @xmath88 .",
    "therefore , one can expect that for @xmath86 , @xmath89 .",
    "based on the above reasoning we represent @xmath76 in the following form @xmath90 where @xmath91 is a bounded function is calculated exactly for the binding neuron model . ] .      in the stationary regime",
    ", the pdf @xmath52 must satisfy the following equation @xmath92 where the transition function @xmath93 gives the probability density to find at the beginning of an isi an impulse in the line with time to live @xmath6 provided at the beginning of the previous isi , there was an impulse with time to live @xmath94 .    to determine exact expression for @xmath93 we take into account that after single firing , time to live can either decrease , or become equal @xmath5 .",
    "therefore , @xmath95 if @xmath96 , then the firing , which causes transition from @xmath94 to @xmath6 , happens without the line involved .",
    "therefore , @xmath97 finally , it is possible that starting from @xmath94 one obtains @xmath8 after the next firing . in order",
    "this to happen , it is necessary and sufficient that no firing happens during @xmath94 units of time . and",
    "this happens with probability @xmath98 having this in mind , one could conclude that in the plane @xmath99 , at the straight line @xmath8 , @xmath94  any , the @xmath93 has singularity of the following form : @xmath100    now , with ( [ trans1])-([trans3 ] ) taken into account , eq .",
    "( [ trans ] ) can be rewritten as follows @xmath101 it is clear from this equation that @xmath52 has the following form is calculated exactly for the binding neuron model . ]",
    "@xmath102 where @xmath54 and @xmath103 is bounded and vanishes out of interval @xmath380;\\delta]$ ] .",
    "let @xmath105 . at @xmath106 , representations ( [ struk ] ) and ( [ strukf ] ) are valid .",
    "also at @xmath106 , @xmath52 reduces to @xmath103 . therefore",
    ", @xmath107 taking into account ( [ pstruc ] ) it can be concluded that expression ( [ intd ] ) , after performing integration , does not have any term with @xmath55-function depending on @xmath31 .",
    "consider now the remaining part of integral in ( [ pdfs ] )",
    ". with ( [ strun+1 ] ) taken into account one has : @xmath108after substituting here expressions ( [ pstruc ] ) , ( [ ff ] ) one obtains four terms : @xmath109 after performing integration , only the fourth term here includes a @xmath55-function . and",
    "argument of this @xmath55-function does depend on @xmath31 .    after taking ( [ intd ] ) and ( [ intdn+1 ] ) together",
    "we conclude that the required joint probability density has the following form @xmath110 where function @xmath111 does not have singularities depending on @xmath31 .",
    "if ( [ domain ] ) is satisfied , then we have similarly to ( [ struk ] ) , ( [ strun+1 ] ) @xmath112 @xmath113 again due to ( [ domain ] ) , and in analogy with ( [ strukf ] ) we have instead of the last two equations the following one : @xmath114 it is clear that expression similar to ( [ strun+1 ] ) turns here into the following @xmath115 now , due to ( [ strn ] ) , ( [ strn+1 ] ) we have @xmath116      now , with representations ( [ pn+1 ] ) for @xmath60 and ( [ pn ] ) for @xmath104 we can pose a question about the form of @xmath118 .",
    "the latter can be found as defined in ( [ defcond ] ) .",
    "first of all notice that due to ( [ pn ] ) and cond4 , @xmath104 is strictly positive for positive isis .",
    "this allows us to use it as denominator in the definition ( [ defcond ] ) .",
    "second , it can be further concluded from ( [ pn ] ) and cond4 , that @xmath104 is bounded , and therefore does not include any singularity of @xmath55-function type . the latter means that any singularity contained in the @xmath60 appears as well in the @xmath118 .",
    "it follows from the above that the conditional pdf @xmath118 can be represented in the following form : @xmath119 where @xmath120 does not contain any @xmath55-function depending on @xmath31 , and @xmath121 is strictly positive bounded function : @xmath122 the representation ( [ firepr ] ) thus proves unequivocally that for any @xmath10 , conditional pdf @xmath118 does depend on @xmath31 ( the second term in ( [ firepr ] ) ) and this dependence can not be eliminated .",
    "we have proven here that any neuronal model , which satisfies cond0-cond4 , above , and is equipped with a delayed feedback , will display essentially non - markov activity expressed in terms of output isis , when stimulated with poisson stream .",
    "this has a consequence for admissible approaches while modeling activity of neuronal networks with stochastic behavior .",
    "indeed , in a reverberating network , a delayed feedback mediated by other neurons is always present .",
    "our result suggests that in this case , activity of individual neurons in the network should be essentially non - markov .",
    "another situation in networks with instantaneous interneuronal communication . in the case of no delay communications ,",
    "the neuronal activity can well be markov , or even poisson , see example in @xcite .",
    "we used here a single neuron with delayed feedback as the simplest case of reverberating `` network '' . at the same time",
    ", neurons which send to themselves their output impulses are known in real nervous systems , @xcite .",
    "therefore , our conclusions about essentially non - markov behavior should be valid for those neurons even without taking into account their involvement in a wider network activity .",
    "the set of conditions cond0-cond4 while being rather natural and wide enough , leaves out of our consideration many neuronal models known in neuroscience .",
    "e.g. , cond2 excludes models with spike latency .",
    "cond3 excludes models with internal memory extending beyond a single isi duration .",
    "thus , we do not consider here partial afterspike resetting @xcite , threshold fatigue @xcite , another types of adaptation , like multi - timescale adaptive threshold @xcite .",
    "any kind of adaptation in individual neuron is by itself able to bring about a kind of memory in the neuronal output stream .",
    "therefore , considering neurons without adaptation we demonstrate here , that delayed feedback without additional memory - like mechanisms known for neurons makes neuronal output essentially non - markov .",
    "another limitation is cond1  we use a poisson process as a stimulus .",
    "it seems that the proof given here can be extended to a wide class of renewal processes taken as stimuli .",
    "this will be checked in further work .",
    "a.  k. vidybida .",
    "output stream of binding neuron with delayed feedback . in j.",
    "jzefczyk , w.  thomas , and m.  turowska , editors , _",
    "14th international congress of cybernetics and systems of wosc , wroclaw , poland , september 9 - 12 , 2008 _ , pages 292302 .",
    "oficyna wydawnicza politechniki wroclawskiej , 2008 ."
  ],
  "abstract_text": [
    "<S> for a class of excitatory spiking neuron models with delayed feedback fed with a poisson stochastic process , it is proven that the stream of output interspike intervals can not be presented as a markov process of any order .    </S>",
    "<S> * keywords . * spiking neuron ; poisson stochastic process ; probability density function ; delayed feedback ; non - markov stochastic process </S>"
  ]
}