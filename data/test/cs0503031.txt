{
  "article_text": [
    "the problem of time synchronization in large distributed systems consists of giving all the physically disjoint elements of the system a common time scale on which to operate .",
    "this common time scale is usually achieved by periodically synchronizing the clock at each element to a reference time source , so that the local time seen by each element of the system is approximately the same .",
    "time synchronization plays an important role in many systems in that it allows the entire system to cooperate and function as a cohesive group .",
    "time synchronization is an old problem  @xcite , but the question of scalability is not .",
    "recent advances in sensor networks show a clear trend towards the development of large scale networks with high node density .",
    "for example , a hardware simulation - and - deployment platform for wireless sensor networks capable of simulating networks with on the order of 100,000 nodes was recently developed  @xcite .",
    "as well , for many years the smart dust project sought to build cubic - millimeter motes for a wide range of applications  @xcite .",
    "also , there is work in progress on the drastic miniaturization of power sources  @xcite .",
    "these developments ( and many others ) indicate that large scale , high density networks are on the horizon",
    ".    large scale , high density networks have applications in a variety of situations .",
    "consider , for example , the military application of sniper localization .",
    "large numbers of wireless nodes can be deployed to find the shooter location as well as the trajectory of the projectile  @xcite .",
    "since the effective range of a long - range sniper rifle can be nearly @xmath0 km , in order to fully track the trajectory of the projectile it may be essential that our deployed network be tightly synchronized over distances of a few kilometers .",
    "another example might be the implementation of a distributed radio for communication . in extracting information from a deployed sensor network ,",
    "it may be beneficial for the nodes to cooperatively transmit information to a far away receiver  @xcite .",
    "such an application would require that nodes across the network be well synchronized .",
    "as a result , a need for the synchronization of large distributed systems is very real and one that requires careful study to understand the fundamental performance limits on synchronization .      the synchronization of large networks has been studied in fields ranging from biology to electrical engineering .",
    "the study of synchronous behavior has generally taken one of two approaches .",
    "the first approach is to consider synchronization as an emergent behavior in complex networks of oscillators . in that work",
    ", models are developed to describe natural phenomena and synchronization emerges from these models .",
    "the second approach is to develop and analyze algorithms that synchronize engineering networks .",
    "nodes are programmed with algorithms that estimate clock skew and clock offset to achieve network synchronization .",
    "however , both of these approaches have significant limitations .",
    "emergent synchronization properties in large populations has been the object of intense study in the applied mathematics  ( @xcite ) , physics  ( @xcite ) , and neural networks  ( @xcite ) literature .",
    "these studies were motivated by a number of examples observed in nature :    * in certain parts of south - east asia , thousands of male fireflies congregate in trees and flash in synchrony at night  @xcite .",
    "* pacemaker cells of the heart , which on average cause 80 contractions a minute during a person s lifetime  @xcite . * the insulin - secreting cells of the pancreas  @xcite .    for further information and examples ,",
    "see  @xcite , and the references therein .",
    "a number of models have been proposed to explain the emergence of synchrony , but perhaps one of the most successful and well known is the model of _ pulse - coupled oscillators _ by mirollo and strogatz  @xcite , based on dynamical systems theory .",
    "consider a function @xmath1\\to[0,1]$ ] that is smooth , monotone increasing , concave down ( i.e. , @xmath2 and @xmath3 ) , and is such that @xmath4 and @xmath5 . consider also a phase variable @xmath6 such that @xmath7 , where @xmath8 is the period of a cycle .",
    "then , each element in a group of @xmath9 oscillators is described by a state variable @xmath10 $ ] and a phase variable @xmath11 $ ] as follows :    * in isolation , @xmath12 . * if @xmath13 then @xmath14 , and if @xmath15 then @xmath16 .",
    "* when @xmath17 for any of the @xmath18 s and some time @xmath19 , then for all other @xmath20 , @xmath21 @xmath22 where @xmath23 denotes an infinitesimal amount of time after @xmath19 .",
    "that is , oscillator @xmath18 reaching the end of a cycle causes the state of all other oscillators to increase by the amount @xmath24 , and the phase variable to change accordingly .",
    "the state variable @xmath25 can be thought of as a voltage .",
    "charge is accumulated over time according to the nonlinearity @xmath26 and it discharges once it reaches full charge , resetting the charging process . upon discharging , it causes all other charges to increase by a fixed amount of @xmath24 , up to the discharge point . for this model ,",
    "it is proved in  @xcite that for all @xmath9 and for almost all initial conditions , the system eventually becomes synchronized .    for the network to converge into a synchronous state",
    ", one key assumption is that the behavior of every single oscillator is governed by the same function @xmath27 .",
    "this means that all oscillators must have the same frequency . from the literature",
    ", it appears that this requirement is nearly always needed .",
    "as far as we are aware , for a fully synchronous behavior to emerge , the oscillators need to have the same , or nearly the same , oscillation frequencies .",
    "the need for nearly identical oscillators presents a significant limitation for emergent synchronization .",
    "this emergence of synchrony is clearly desirable and it has been considered for communication and sensor networks in  @xcite . however , whether or not these techniques can be adapted to synchronize networks with nodes that have arbitrary oscillator frequencies ( clock skew ) is still unclear .",
    "thus , in order to overcome this limitation and find techniques capable of synchronizing a more general class of networks , we turn to algorithms designed to estimate certain unknown parameters such as clock skew .      there have been many synchronization techniques proposed for use in sensor networks .",
    "these algorithms generally allow each node to estimate its clock skew and clock offset relative to the reference clock .",
    "reference broadcast synchronization ( rbs )  @xcite eliminates transmitter side uncertainties by having a transmitter broadcast reference packets to the surrounding nodes .",
    "the receiving nodes then synchronize to each other using the arrival of the reference packets as synchronization events .",
    "tiny - sync / mini - sync  @xcite and the timing - sync protocol for sensor networks ( tpsn )  @xcite organize the network into a hierarchial structure and the nodes are synchronized using pair - wise synchronization . in lightweight tree - based synchronization ( lts )",
    "@xcite , pair - wise synchronization is also employed but the goal of lts is to reduce communication and computation requirements by taking advantage of relaxed accuracy constraints .",
    "the flooding time synchronization protocol ( ftsp )  @xcite achieves one - hop synchronization by having a root node broadcast timing information to surrounding nodes .",
    "these surrounding nodes then proceed to broadcast their synchronized timing information to nodes beyond the broadcast domain of the root node .",
    "this process can continue for multi - hop networks .",
    "the problem with each of these traditional synchronization techniques is that synchronization error will increase with each hop .",
    "since each node is estimating certain synchronization parameters , i.e. clock skew , there will be inherent errors in the estimate . as a result , a node multiple hops away from the node with the reference clock will be estimating its parameters from intermediate nodes that already have estimation errors .",
    "therefore , this introduces a fundamental _ scalability problem _ : as the number of hops across the network grows , the synchronization error across the network will also grow .",
    "current trends in network technology are clearly moving us in the direction of large , multi - hop networks .",
    "first , sensors are decreasing in size and this size decrease will most likely be accompanied by a decrease in communication range .",
    "thus , more hops will be required to traverse a network deployed over a given area .",
    "second , as we deploy networks over larger and larger areas , then for a given communication range , the number hops across the network will also increase . in either case , the increased number of hops required to communicate across the network will increase synchronization error . therefore , it is essential that we develop techniques than can mitigate the accumulation of synchronization error over multiple hops .        to decrease the error increase in each hop , we need to decrease the estimation error .",
    "there are two primary ways of achieving this .",
    "first , each node can increase the amount of timing information it obtains from neighboring nodes .",
    "for example , from a received timing packet , the node may be able to construct a data point telling it the approximate time at the reference clock and the corresponding time at its local clock . using a collection of these data points , the node can estimate clock skew and clock offset .",
    "so instead of using , say , five packets with timing information , a node can wait for ten packets .",
    "more data points will generally give better estimates .",
    "the drawback to such an approach is the increase in the number of packet exchanges .",
    "the second way in which to reduce estimation error is to increase the quality of each data point obtained by the nodes .",
    "this can be achieved through improving packet exchange algorithms and time stamping techniques .",
    "however , we believe that there is one fundamentally new approach to improving data point quality that has not be carefully studied . this is to use spatial averaging to improve the quality of each data point .",
    "the motivation for this approach is very simple .",
    "assume that each node has many neighbors .",
    "if all nodes in the network are to be synchronized , then the neighbors of any given node will also have synchronization information .",
    "is it possible to simultaneously use information from all the neighbors to improve the quality of a timing observation made by a node ?",
    "furthermore , it would seem to make sense that with more neighbors , hence more available timing information , the quality of the constructed data point should improve .",
    "if this is indeed the case , then achieving synchronization through the use of spatial averaging will provide a fundamentally new trade - off in improving synchronization performance .",
    "network designers would simply be able to increase the number and density of nodes to obtain better network synchronization .",
    "the study of cooperative time synchronization using spatial averaging is the focus of this work .      to obtain a model for developing cooperative synchronization in large wireless networks , we begin by looking at the signals observed by a node in a network with @xmath9 nodes uniformly deployed over a fixed finite area .",
    "to start , we assume propagation delay to negligible ( the general case is considered in section  [ sec : timedelay ] ) .",
    "all nodes transmit a pulse @xmath28 and a node @xmath29 will see a signal @xmath30 which is the superposition of all these pulses , @xmath31 in this expression , @xmath28 is the basic pulse transmitted by each node ( assumed to be the same for all nodes ) .",
    "@xmath32 is the ideal pulse transmit time , but since we assume imperfect time synchronization among the nodes we have @xmath33 modelling random errors in the pulse transmission time .",
    "@xmath34 models the amplitude loss in the signal transmitted by the @xmath18th node .",
    "@xmath35 is the maximum magnitude transmitted by a node .",
    "we scale each node s transmission by @xmath9 so that as the network density grows , the total power radiated does not grow unbounded .",
    "this model thus describes the received signal seen at a node @xmath29 for a network with @xmath9 nodes and this holds for any @xmath9 . increasing @xmath9 will have two effects : ( a ) node density will increase since the network area is fixed and ( b ) node signal transmission magnitude will decrease due to the @xmath36 scaling .",
    "therefore , by increasing @xmath9 this model allows us to study the scalability of networks as node density grows and node size decreases .",
    "given that these are the signals observed at each node , we ask : is it possible for @xmath30 to encode a time synchronization signal that will enable all nodes in the network to synchronize their clocks with bounded error , as @xmath37 ?",
    "the answer is yes , and the key to proving all our results is the law of large numbers",
    ".    our key idea is the following . if all nodes were able to determine when time @xmath32 ( in the reference time ) arrives , then by transmitting @xmath28 at time @xmath32 , the signal observed at any node @xmath29 would be @xmath38 , which is a suitably scaled version of @xmath28 centered at @xmath32 .",
    "in reality however , there will be some error in the determination of @xmath32 , which we account for by allowing for a node - dependent random error @xmath39 .",
    "but , if the distribution of @xmath39 satisfies certain conditions , then the effects of that timing error can be averaged out .",
    "a pictorial representation of why this should be the case is shown in fig .",
    "[ fig : why - sync - holds ] .",
    "therefore , intuitively we can see how the technique of _ cooperative time synchronization _ using spatial averaging can average out the inherent timing errors in each node . even though there is randomness and uncertainty in each node s estimates , by using cooperation among a large number of nodes it is possible to recover _ deterministic _ parameters from the resulting aggregate waveform ( such as the location of certain zero - crossings ) in the limit as node density grows unbounded .",
    "thus more nodes will give us better estimates .",
    "this is because the random waveform converges to a deterministic one as more and more nodes cooperatively generate an aggregate waveform . at the same time , the average power required by each node will decrease since smaller nodes send smaller signals .",
    "therefore , by programming suitable dynamics into the nodes , in this paper we show how it is possible to generate an aggregate output signal with _",
    "zero - crossings in the limit of asymptotically dense networks .",
    "thus , the detection of these zero - crossings plays the same role as that of an externally generated time reference signal based on which all nodes can synchronize .",
    "we develop this synchronization technique in three main steps .",
    "one , we set up the model for @xmath30 .",
    "two , we specify characteristics of the model ( i.e. the distribution of @xmath33 ) that allow us to prove desirable properties of the aggregate waveform ( such as a center zero - crossing at @xmath32 )",
    ". three , we develop the estimators needed for our synchronization technique and show that the estimators give us the desired characteristics .",
    "the main contributions presented in this paper are the following ;    * the definition of a probabilistic model for the study of the time synchronization problem in wireless networks .",
    "this model does contain the classical mirollo - strogatz model as a special case , but its formulation and the tools used to prove convergence results are of a completely different nature ( purely probabilistic , instead of based on the theory of dynamical systems ) . * using this model , we provide a rigorous analysis of a new cooperative time synchronization technique that employs spatial averaging and has favorable scaling properties .",
    "as the density of nodes increases , synchronization performance improves .",
    "in particular , in the limit of infinite density , deterministic parameters for synchronization can be recovered . *",
    "we show that cooperative time synchronization works perfectly for negligible propagation delay .",
    "when propagation delay is considered , we find that asymmetries at the boundaries reveal some limitations that need to be carefully considered in designing algorithms that take advantage of spatial averaging .    in analyzing the proposed cooperative time synchronization technique ,",
    "our goal is to show that the proposed technique can average out all random error and provide deterministic parameters for synchronization as node density grows unbounded .",
    "this asymptotic result can be viewed as a _ convergence in scale _ to synchrony .",
    "the result serves as a theoretical foundation for allowing a new trade - off between node density and synchronization performance .",
    "in particular , higher node density can yield better synchronization .",
    "the rest of this paper is organized as follows .",
    "the general model is presented in section  [ sec : systemmodel ] .",
    "of particular interest here is section  [ sec : specialcase ] , where we show how our model contains the model of mirollo and strogatz for pulse - coupled oscillators as a special case  @xcite . in section",
    "[ sec : timesync - setup ] we specialize the general model for our synchronization setup and develop waveform properties that will be used in time synchronization . in section  [ sec : timesynchronization ] we develop the cooperative time synchronization technique for no propagation delay .",
    "we extend the cooperative synchronization ideas to the case of propagation delay in section  [ sec : timedelay ] .",
    "the paper concludes in section  [ sec : conclusion ] with a detailed discussion on the scalability issue and how the technique proposed in this work lays the theoretical foundation for a general class of cooperative time synchronization techniques that use spatial averaging .",
    "we consider a network with @xmath9 nodes uniformly distributed over a fixed finite area .",
    "the behavior of each node @xmath18 is governed by a clock @xmath40 that counts up from @xmath41 .",
    "the introduction of @xmath40 is important since it provides a consistent timescale for node @xmath18 . by maintaining a table of pulse - arrival times",
    ", node @xmath18 can utilize the arrival times of many pulses over an extended period of time .",
    "the clock of one particular node in the network will serve as the reference time and to this clock we wish to synchronize all other nodes .",
    "we will call the node with the reference clock node @xmath42 and the clocks of other nodes are defined relative to the clock of node @xmath42 .",
    "we never adjust the frequency or offset of the local clock @xmath40 because we wish to maintain a consistent time scale for node @xmath18 .",
    "the clock of node @xmath42 , @xmath43 , will be defined as @xmath44 where @xmath45 .",
    "taking @xmath43 to be the reference clock , we now define the clock of any other arbitrary node @xmath18 , @xmath40 .",
    "we define @xmath40 as @xmath46 where    * @xmath47 is an unknown offset between the start times of @xmath40 and @xmath43 .",
    "* @xmath48 is a constant and for each @xmath18 , @xmath49 $ ] where @xmath50 are finite .",
    "this bound on @xmath51 means that the frequency offsets between any two nodes can not be arbitrarily large .",
    "* @xmath52 is a stochastic process modeling random timing jitter .",
    "thus , this model assumes that there is a bounded constant frequency offset between the oscillators of any two nodes as well as some random clock jitter .",
    "it is important to note that node @xmath42 does not have to be special in any way ; its clock is simply a reference time on which to define the clocks of the other nodes .",
    "this means that our clock model actually describes the relative relationship of all the clocks in the network by using an arbitrary node s clock as a reference .        from section  [ sec : intromodel ]",
    ", we see that we are interested in studying the aggregate waveform observed at a node @xmath29 . as a result , we are only concerned with the aggregate signal magnitude and do not care about the particular signal contribution from each surrounding node . with this in mind",
    ", we can develop a random model for pathloss that , for dense networks , gives the appropriate aggregate signal magnitude at node @xmath29 .",
    "such a model is ideal for our situation since we are studying asymptotically dense networks .",
    "we start with a general pathloss model @xmath53 , where @xmath54 for all distances @xmath55 , is non - increasing and continuous .",
    "@xmath53 is a fraction of the transmitted magnitude seen at distance @xmath56 from the transmitter .",
    "for example , if the receiver node @xmath29 is at distance @xmath56 from node @xmath18 , and node @xmath18 transmits a signal of magnitude @xmath57 , then node @xmath29 will hear a signal of magnitude @xmath58 .",
    "we derive @xmath53 from a power pathloss model since any pathloss model captures the _ average _ received power at a given distance from the transmitter .",
    "this average received power is perfect for modelling received signal magnitudes in our problem setup since we are considering asymptotically dense networks .",
    "due to the large number of nodes at any given distance @xmath56 from the receiver , using the average received magnitude at distance @xmath56 as the contribution from each node at that distance will give a good modelling of the amplitude of the aggregate waveform .",
    "the random pathloss variable @xmath59 will be derived from @xmath53 . to understand how @xmath59 and @xmath53 are related ,",
    "we give an intuitive explanation of the meaning of @xmath59 as follows : the @xmath60 $ ] is the fraction of nodes at distances @xmath56 from node @xmath29 such that @xmath61 , where @xmath62 is a small constant .",
    "this means that , roughly speaking , for any given scaling factor @xmath63 , @xmath64 is the fraction of received signals with magnitude scaled by approximately @xmath65 , where @xmath66 is the probability density function of @xmath59 .",
    "thus , if we scale the transmit magnitude @xmath57 from every node @xmath18 by an independent @xmath59 , then as the number of nodes , @xmath9 , gets large , node @xmath29 will see @xmath67 signals of approximate magnitude @xmath68 , and this holds for all @xmath65 in the range of @xmath59 .",
    "this is because taking a large number of independent samples from a distribution results in a good approximation of the distribution .",
    "thus , this intuition tells us that scaling the magnitude of the signal transmitted from every node @xmath18 by an independent sample of the random variable @xmath59 gives an aggregate signal at node @xmath29 that is the same magnitude as if we generated the signal using @xmath53 directly .",
    "even though the signals from two nodes at the same distance from a receiver have correlated magnitudes , we do not care about the signal magnitude from any particular node but only that an appropriate number of all possible received signal magnitudes contribute to the aggregate waveform . for a receiving node @xmath29",
    ", we choose therefore to work with the random variable @xmath59 instead of directly with @xmath53 because , for the goals of this paper , doing so has two major advantages : ( a ) we can obtain desirable limit results by placing very minimal restrictions on the distribution of the @xmath59 s ( and hence on @xmath53 ) and ( b ) we can apply tools from probability theory ( basically , the strong law of large numbers ) to carry out our analysis .      from the above intuition",
    "we can define the cumulative distribution function of @xmath59 as @xmath69 \\\\     1 & k\\in(1,\\infty )",
    "\\end{array } \\right.\\ ] ] where    * @xmath70 is the total area of the network , * @xmath71 is the area of the network contained in a circle of radius @xmath72 centered at node @xmath29 , * @xmath73 .    from the above discussion",
    "we see that the distribution of @xmath59 is only a function of node @xmath29 , the receiving node .",
    "we illustrate the relationship among node @xmath29 , @xmath53 , @xmath74 , and @xmath75 in fig  [ fig : propmodel - illus ] .",
    "we sometimes write @xmath34 with @xmath18 used to index each node surrounding node @xmath29 .",
    "@xmath18 is thus indexing a sequence of independent random variables @xmath34 for fixed @xmath29 .",
    "therefore , for a given @xmath29 , @xmath34 s are independent and identically distributed ( i.i.d . ) with a cumulative distribution function given by ( [ eq : prop_cdf ] ) for all @xmath18 .",
    "we assume that @xmath59 has the following properties :    * @xmath59 is independent from @xmath76 for all @xmath29 , @xmath77 , and @xmath78 . *",
    "@xmath79 , @xmath80 , and @xmath81 .",
    "the requirements on the random variable @xmath59 places restrictions on the model @xmath53 . any function @xmath53 that yields a @xmath59 with the above requirements can be used to model pathloss .      in this section",
    "we develop a more complex model to simultaneously model propagation delay and pathloss .",
    "this leads to the joint development of the delay random variable @xmath82 and a corresponding pathloss random variable @xmath59 .",
    "since we want to develop a model for both pathloss and time delay , we start by keeping the pathloss function @xmath53 defined in section  [ sec : prop - model ] .",
    "the general delay model assumes a function @xmath83 that models the time delay as a function of distance .",
    "@xmath83 describes the time in terms of @xmath43 that it takes for a signal to propagate a distance @xmath56 .",
    "for example , if node @xmath18 and node @xmath29 are distance @xmath84 apart , then a pulse sent by node @xmath18 at time @xmath85 will be seen at node @xmath29 at time @xmath86 .",
    "we make the reasonable assumption that @xmath83 is continuous and strictly monotonically increasing for @xmath55 .    as with the pathloss only model ,",
    "we want to define a delay random variable @xmath82 for each receiving node @xmath29 . recall that this means that for every node @xmath29 there is a random variable @xmath82 associated with it since , in general , each node @xmath29 will see different delays .",
    "there is a correlation between the delay random variable @xmath82 and the pathloss random variable @xmath59 .",
    "this correlation arises for two main reasons .",
    "first , since in section  [ sec : prop - model ] we define @xmath53 to be monotonically decreasing and continuous , it is possible for @xmath87 for @xmath88 , @xmath89 . this might be the case for a multi - hop network .",
    "in this situation , there will be a set of nodes whose transmissions will never reach node @xmath29 ( i.e. infinite delay ) even though according to @xmath83 these nodes should contribute a signal with finite delay .",
    "second , a small @xmath59 value would represent a signal from a far away node . as a result",
    ", the corresponding @xmath82 value should be large to reflect large delay .",
    "therefore , keeping these two points in mind , we proceed to develop a model for both pathloss and propagation delay .",
    "we define the cumulative distribution function of @xmath82 as @xmath90 \\\\",
    "a(x-\\delta(r))+\\frac{a(j , r)}{a_{t } } & x\\in(\\delta(r),\\delta(r+\\delta      r ) ] \\\\      1 & x\\in(\\delta(r+\\delta r),\\infty )      \\end{array } \\right.\\ ] ] where @xmath91 , @xmath92 is a constant , @xmath93 , and @xmath94 recall that @xmath71 , defined in section  [ sec : prop - model ] , is the area of the network contained in a circle of radius @xmath72 centered at node @xmath29 and @xmath70 is the total area of the network .",
    "note that @xmath95 can be infinite .    using the delay random variable @xmath82 with the cumulative distribution function in ( [ eq : delay_cdf ] )",
    ", we define @xmath59 as @xmath96 where @xmath97 is the deterministic pathloss function from section  [ sec : prop - model ] and @xmath98 is the inverse function of the deterministic delay function @xmath99 .",
    "note that @xmath100 exists since @xmath99 is continuous and strictly monotonically increasing on @xmath101 .",
    "to understand the distribution of @xmath82 , we need to consider the definition of @xmath59 as well .",
    "recall that a signal arriving with delay @xmath82 is scaled by the pathloss random variable @xmath59 .",
    "let us consider the cumulative distribution in two pieces , @xmath102 $ ] and @xmath103 .",
    "the case for @xmath104 is trivial .",
    "first , for @xmath102 $ ] , the probability that @xmath82 takes a value less than or equal to @xmath105 is simply the fraction of the network area around node @xmath29 such that the nodes are at distances @xmath56 with @xmath106 .",
    "the intuition is the same as that for the development of @xmath59 in section  [ sec : prop - model ] .",
    "second , for @xmath103 , the situation is more complex .",
    "note that a transmitted signal from a node at distance @xmath107 from @xmath29 will arrive at node @xmath29 with infinite delay since @xmath87 for @xmath107 .",
    "since any delay values in @xmath103 correspond to distances @xmath108 , the corresponding scaling value will be zero because @xmath59 and @xmath82 are related by ( [ eq : djkjconnection ] ) . as a result , it does not matter what delay values we assign to the fraction of the network area outside a circle of radius @xmath95 centered at node @xmath29 as long as their delay value @xmath105 is such that @xmath109 .",
    "thus , we can arbitrarily choose a constant @xmath110 value and construct a piecewise linear portion of the cumulative distribution function of @xmath82 on @xmath103 .",
    "the probability that @xmath111 will be the fraction of the network area outside a circle of radius @xmath95 around node @xmath29 . and",
    "since @xmath111 will have a corresponding @xmath59 value that is zero , this fraction of nodes will not contribute to the aggregate waveform at node @xmath29 .",
    "it is clear that the correlated @xmath82 and @xmath59 random variables work together to accurately model a signal arriving with both pathloss and propagation delay .",
    "an illustration of how @xmath53 , @xmath83 , node @xmath29 , and @xmath112 are related can be found in fig .",
    "[ fig : delaymodel - illus ] .",
    "we require that @xmath82 is bounded , has finite expectation , and has finite variance for all @xmath29 .",
    "note that @xmath113 by the requirement that @xmath114 .",
    "as well , since the cumulative distribution in ( [ eq : delay_cdf ] ) is continuous , and often absolutely continuous , we assume that @xmath82 has a probability density function @xmath115 . when we write @xmath116 , the @xmath18 indexes each node surrounding node @xmath29 .",
    "thus , the @xmath116 s are independent and identically distributed in @xmath18 for a given @xmath29 and have a cumulative distribution given by ( [ eq : delay_cdf ] ) .",
    "using the @xmath59 and @xmath82 developed in this section to simultaneously model pathloss and propagation delay , respectively , we will be able to closely approximate the received aggregate waveform at any node @xmath29 as @xmath37 .    to summarize , we see that our choice of the pathloss and delay random variables will depend on what we want to model .",
    "if we only consider pathloss and not propagation delay , then we will use the random variable @xmath59 defined in section  [ sec : prop - model ] .",
    "if we account for both pathloss and delay , then we will use the delay random variable @xmath82 in this section ( section  [ sec : delay - model ] ) and the pathloss random variable @xmath59 defined by ( [ eq : djkjconnection ] ) .",
    "the exchange of pulses is the method through which the network will maintain time synchronization .",
    "each node @xmath18 will periodically transmit a scaled pulse @xmath117 , where @xmath118 is a constant and @xmath28 , in general , can be any pulse .",
    "we call the interval of time during which a synchronization pulse is transmitted a _ synchronization phase_.    what each node does with a set of pulse arrival observations is determined by the pulse - connection function @xmath119 for node @xmath18 .",
    "the pulse - connection function is a function that determines the time , in the time scale of @xmath40 , when node @xmath18 will send its @xmath120th pulse .",
    "it can be a function of the current value of @xmath121 and past pulse arrival times .",
    "this function basically determines how any node @xmath18 reacts to the arrival of a pulse .",
    "the system model that we presented thus far is powerful because it is very general . in this section",
    "we show that it is a generalization of the pulse - coupled oscillator model proposed by mirollo and strogatz  @xcite . as a result",
    ", the results presented in that paper will hold under the simplified version of our model",
    ".      in setting up the system model , mirollo and strogatz make four key assumptions :    * pathloss model : the first assumption that is made is that there is all - to - all coupling among all @xmath9 oscillators .",
    "this means that each oscillator s transmission can be heard by all other oscillators .",
    "thus , for our model we ignore pathloss , i.e. @xmath122 , to allow any node s transmission to be heard by each of the other @xmath123 nodes .",
    "* delay model : the second assumption is that there is instantaneous coupling .",
    "this assumption is the same as setting @xmath124 .",
    "in such a situation we would use our pathloss only model . *",
    "synchronization pulses : the third key assumption made in  @xcite is that there is non - uniform coupling , meaning that each of the @xmath9 oscillators fire with strengths @xmath125 .",
    "we modify the parameters in our model by making node @xmath18 transmit with magnitude @xmath126 .",
    "they also assume that any two pulses transmitted at different times will be seen by an oscillator as two separate pulses . in our model",
    ", we may choose any pulse @xmath28 that has an arbitrarily short duration and each node will detect the pulse arrival time and pulse magnitude .",
    "* clock model : the fourth important assumption made by mirollo and strogatz is that the oscillators are identical but they start in arbitrary initial conditions . we simplify our clock model in  ( [ eq : clock ] ) by eliminating any timing jitter , i.e. @xmath127 , and making the clocks identical by setting @xmath128 for @xmath129 .",
    "we leave @xmath47 in the model to account for the arbitrary initial conditions .",
    "we also assume that the phase variable in the pulse - coupled oscillator model increases at the same rate as our clock .",
    "that is , the time it takes the phase variable to go from zero to one and the time it takes our clock to count from one integer value to the next are the same .",
    "now that we have identical system models , what remains is to modify our model to mimic the coupling action detailed in  @xcite .",
    "this is accomplished by defining a proper pulse - connection function @xmath119 .      to match the coupling action in  @xcite",
    ", we choose a pulse transmit time function @xmath130 that is a function of pulse receive times and also the time of node @xmath18 s @xmath131th pulse transmission time .",
    "@xmath132 is the time in terms of @xmath40 that node @xmath18 receives its @xmath65th pulse since its last pulse transmission at @xmath133 . in this case",
    ", @xmath119 will be a function that updates node @xmath18 s @xmath120th pulse transmission time each time node @xmath18 receives a pulse .",
    "let @xmath134 where it is node @xmath18 s @xmath120th pulse transmission time after observing @xmath65 pulses since its last pulse transmission .",
    "node @xmath18 will transmit its pulse as soon as @xmath135 where @xmath121 is node @xmath18 s current time .",
    "as soon as the node transmits a pulse at @xmath119 the function will reset and become @xmath136 .",
    "the node is now ready to receive pulses and at its first received pulse , the next transmission time will become @xmath137 .",
    "@xmath119 will thus be defined as @xmath138 , \\qquad k>0\\\\ x_{n , i}^{c_{i}}(0 ) & = & x_{n-1,i}^{c_{i}}+1 \\label{eq : pco_estimator2}\\end{aligned}\\ ] ] where the pulse received at @xmath132 is a pulse of magnitude @xmath139 and the function @xmath1\\to [ 0,1]$ ] is the smooth , monotonic increasing , and concave down function defined in  @xcite .",
    "equations  ( [ eq : pco_estimator ] ) and ( [ eq : pco_estimator2 ] ) fundamentally say that each time node @xmath18 receives a pulse , node @xmath18 s next transmission time will be adjusted .",
    "this is in line with the behavior of the coupling model described by mirollo and strogatz since each time an oscillator receives a pulse , its state variable is pulled up by @xmath140 thus adjusting the time at which the oscillator will next fire . to see how equations  ( [ eq : pco_estimator ] ) and ( [ eq : pco_estimator2 ] ) relate to the coupling model in  @xcite ,",
    "let us consider an example with two pulse coupled oscillators .",
    "consider two oscillators @xmath57 and @xmath141 illustrated in fig .",
    "[ fig : strogatzmodel ] . in fig .",
    "[ fig : strogatzmodel](a ) ,    we have that oscillator @xmath57 is at phase @xmath142 and oscillator @xmath141 is just about to fire . below the pulse - coupled oscillator model we have a time axis for node @xmath18 corresponding to our clock model going from time @xmath133 to @xmath143 . our time axis for node @xmath18 models the behavior of oscillator @xmath57 ,",
    "that is , we want node @xmath18 to behave in the same way as oscillator @xmath57 under the influence of oscillator @xmath141 .",
    "if oscillator @xmath141 did not exist , then the phase variable @xmath142 will match our clock in that @xmath142 reaches @xmath42 at the same time our clock reaches @xmath144 and oscillator @xmath57 will fire at the same time our model fires . in fig .",
    "[ fig : strogatzmodel](b ) , oscillator @xmath141 has fired and has pulled the state variable of oscillator @xmath57 up by @xmath140 .",
    "this coupling has effectively pushed the phase of oscillator @xmath57 to @xmath145 and decreased the time before @xmath57 fires .",
    "in fact , the time until oscillator @xmath57 fires again is decreased by @xmath56 .",
    "we can capture this coupling in our model since we can calculate the lost time @xmath56 .",
    "the time at which oscillator @xmath141 fires is @xmath146 and it is clear that @xmath147 .",
    "thus , if the time that oscillator @xmath57 will fire again is decreased by time @xmath56 due to the pulse of @xmath141 , then we adjust our node firing time by decreasing the firing time to @xmath148 .",
    "this is exactly the expression in  ( [ eq : pco_estimator ] ) for @xmath149 .",
    "this relationship between our model for calculating the node firing time and the pulse - coupled oscillator coupling model can be easily extended to @xmath9 oscillators .",
    "we can see then that the pulse - coupled oscillator model proposed by mirollo and strogatz in  @xcite is a special case of our model .",
    "our model generalizes this pulse - coupled oscillator model by considering timing jitter , pulses of finite width , propagation delay , non - identical clocks , and an ability to accommodate arbitrary coupling functions .",
    "just as we could specialize our model to the pulse - coupled oscillator model of mirollo and strogatz , we now specialize the model for our proposed synchronization technique .",
    "we start under the assumption of no propagation delay and develop the synchronization technique for this case .",
    "propagation delay is considered in section  [ sec : timedelay ] .",
    "we proceed in three steps . in section  [ sec : signal - reception ] , we specify the model for @xmath150 , the received waveform at any node @xmath29 .",
    "second , in section  [ sec : pulseproperties ] , we prove that given certain characteristics of the model , @xmath150 has very useful limiting properties .",
    "third , we show in section  [ sec : timesynchronization ] that estimators ( i.e. , the pulse connection function ) developed for our synchronization technique give @xmath150 the desired properties .      for our synchronization technique ,",
    "we specialize the general model by making the following assumptions on @xmath51 and @xmath52 for @xmath151 :    * a characterization of the @xmath152 is given by a known function @xmath153 with @xmath154 $ ] that gives the percentage of nodes with any given @xmath155 value .",
    "thus , the fraction of nodes with @xmath155 values in the range @xmath156 to @xmath157 can be found by integrating @xmath153 from @xmath156 to @xmath157 .",
    "we assume that @xmath158 , for some constant @xmath159 .",
    "we keep this function constant as we increase the number of nodes in the network ( @xmath37 ) .",
    "given any circle of radius @xmath95 that intersects the network , the nodes within that circle will have @xmath51 s that are characterized by @xmath153 .",
    "@xmath95 is the maximum @xmath56 such that @xmath160 .",
    "this means that the set of nodes that any node @xmath29 will hear from will have its @xmath51 s characterized by a known function .",
    "note that @xmath95 can be infinite , and in that case , any node @xmath29 hears from all nodes in the network .",
    "fundamentally , @xmath153 means that as we increase node density , the new nodes have @xmath155 parameters that are well distributed in a predictable manner .",
    "* @xmath52 is a zero mean gaussian process with samples @xmath161 , for any @xmath162 , and independent and identically distributed samples for any set of times @xmath163 $ ] , @xmath65 a positive integer .",
    "we assume @xmath164 and note that @xmath165 is defined in terms of the clock of node @xmath18 .",
    "we assume that @xmath52 is gaussian since the rms ( root mean square ) jitter is characterized by the gaussian distribution  @xcite .",
    "we maintain the full generality of the pathloss model from section  [ sec : prop - model ] .",
    "note that throughout this work we assume no transmission delay or time - stamping error .",
    "this means that a pulse is transmitted at exactly the time the node intends to transmit it .",
    "we make this assumption since there will be no delay in message construction or access time  @xcite because our nodes broadcast the same simple pulse without worrying about collisions .",
    "also , when a node receives a pulse it can determine its clock reading without delay since any time stamping error is small and can be absorbed into the random jitter .      for our proposed synchronization technique , the aggregate waveform seen by node @xmath29 at any time @xmath78 is @xmath166 where @xmath150 is the waveform seen at node @xmath29 written in the time scale of @xmath43 and @xmath167 for all @xmath18 .",
    "@xmath35 is the maximum transmit magnitude of a node .",
    "@xmath33 is the random timing offset suffered by the @xmath18th node , which encompasses the random clock jitter and estimation error .",
    "this model says that each node @xmath18 s pulse transmission occurs at the ideal transmit time @xmath32 plus some random error @xmath33 . in the next section , section  [ sec : pulseproperties ] ,",
    "we find properties for @xmath33 that will give us desirable properties in @xmath150 .",
    "then , in section  [ sec : timesynchronization ] , we show that our proposed steady - state synchronization technique and its associated pulse - connection function will give us the desired properties .",
    "there are two comments about ( [ eq : timesync - aggwaveform ] ) that we want to make .",
    "first , note that even though we sum the transmissions from all @xmath9 nodes in ( [ eq : timesync - aggwaveform ] ) , we do not assume that node @xmath29 can hear all nodes in the network .",
    "recall from the pathloss model that if we have a multi - hop network , then there will be a nonzero probability that @xmath168 .",
    "thus , node @xmath29 will not hear from the nodes whose transmissions have zero magnitude .",
    "second , it may be possible that the nodes are told that there are @xmath169 nodes in the network while the actual number of functioning nodes is @xmath9 . in which case",
    ", each node will transmit with signal magnitude @xmath170 and ( [ eq : timesync - aggwaveform ] ) will have a factor of @xmath171 .",
    "other than for this factor , however , the theoretical results that follow are not affected .    to model the quality of the reception of @xmath150 by node @xmath29",
    ", we model the reception of a signal by defining a threshold @xmath172 .",
    "@xmath172 is the received signal threshold required for nodes to perfectly resolve the pulse arrival time .",
    "if the maximum received signal magnitude is less than @xmath172 then the node does not make any observations and ignores the received signal waveform .",
    "we assume that @xmath173 .",
    "in our work we will assume that @xmath28 takes on the shape @xmath174 where @xmath175 is expressed in terms of @xmath43 .",
    "we assume @xmath176 for @xmath177 , @xmath178 only on @xmath179 , @xmath180 , and @xmath181 is uniformly continuous on @xmath182 .",
    "thus , we see that @xmath28 has at most three jump discontinuities ( at @xmath183 ) .",
    "@xmath184 should be chosen large compared to @xmath185 , i.e. @xmath186 , where @xmath187 is the value of @xmath165 translated from the time scale of @xmath40 to @xmath43 .",
    "this way , over each synchronization phase , with high probability a zero - crossing will occur . for each node",
    ", the duration in terms of @xmath43 of a synchronization phase will be @xmath188 .",
    "note that we assume @xmath184 is a value that is constant in any consistent time scale .",
    "this means that even though nodes have different clocks , identical pulses are transmitted by all nodes .",
    "we define a pulse to be transmitted at time @xmath78 if the pulse makes a zero - crossing at time @xmath78 .",
    "similarly , we define the _ pulse receive ( arrival ) time _ for a node as the time when the observed waveform first makes a zero - crossing .",
    "a _ zero - crossing _ is defined for signals that have a positive amplitude and then transition to a negative amplitude .",
    "it is the time that the signal first reaches zero .    for the exchange of synchronization pulses",
    ", we assume that nodes can transmit pulses and receive signals at the same time .",
    "this simplifying assumption is not required for the ideas presented here to hold , but simplifies the presentation .",
    "we mention a way to relax this assumption in section  [ sec : nosimulttxrx ] .    in ( [ eq : timesync - aggwaveform ] ) and in the discussions",
    "above , we have focused on characterizing the aggregate waveform for any one synchronization phase .",
    "that is , ( [ eq : timesync - aggwaveform ] ) is the waveform seen by any node @xmath29 for the synchronization phase centered around node @xmath42 s transmission at @xmath189 , @xmath32 a positive integer .",
    "we can , however , describe a synchronization pulse train in the following form , @xmath190 where @xmath191 is the integer value of @xmath78 at the @xmath192th synchronization phase , and @xmath193 is the error suffered by the @xmath18th node in the @xmath192th synchronization phase . we seek to create this pulse train with equispaced zero - crossings and use each zero - crossing as a synchronization event .",
    "an illustration of such a pulse train is shown in fig .",
    "[ fig : pulsetrain ] . for simplicity , however , most of the theoretical work is carried out on one synchronization phase .      in this section ,",
    "we characterize the properties of @xmath33 that give us desirable properties in the aggregate waveform . from ( [ eq : timesync - aggwaveform ] )",
    ", the aggregate waveform seen at each node @xmath29 in the network has the form @xmath194 we have dropped the @xmath29 and @xmath43 for notational simplicity since in this section we deal solely with the received waveform at a node @xmath29 in the time scale of @xmath43 . as we let the number of nodes grow unbounded ( @xmath37 ) , the properties of this limit waveform can be characterized by theorem  [ theorem : main ] .",
    "these properties will be essential for asymptotic cooperative time synchronization . as a note , in theorem  [ theorem : main ]",
    "we present the case for gaussian distributed @xmath33 but similar results hold for arbitrary zero - mean , symmetrically distributed @xmath33 with finite variance .",
    "[ theorem : main ] let @xmath28 be as defined in equation  ( [ eq : poft ] ) and @xmath195 with @xmath196 a constant and @xmath197 for all @xmath18 , @xmath141 a constant .",
    "also , let @xmath198 be defined as in section  [ sec : prop - model ] and be independent from @xmath33 for all @xmath18 .",
    "then , @xmath199 has the properties    * @xmath200 , * @xmath201 for @xmath202 , and @xmath203 for @xmath204 for some @xmath205 .",
    "* @xmath206 is odd around @xmath189 , i.e. @xmath207 for @xmath208 * @xmath209 is continuous .",
    "@xmath210    the properties outlined in theorem  [ theorem : main ] will be key to the synchronization mechanism we describe . the specific value of @xmath211 will be determined by our choice of the pulse - connection function .",
    "before we prove theorem  [ theorem : main ] in section  [ sec : theoremproof ] we develop and motivate a few important related lemmas .      at time @xmath212",
    ", we have that @xmath213 where @xmath214 .",
    "we have the mean of @xmath215 being @xmath216 where @xmath217 is the gaussian pdf @xmath218 it is clear that the @xmath215 s , for different @xmath18 s , do not have the same mean and do not have the same variance since the two quantities depend on the @xmath51 value . since the @xmath51 s are characterized by @xmath153 ( defined in section  [ sec : systemparameters ] ) , we write the gaussian distribution for @xmath8 as @xmath219 and @xmath215 is in fact a function of @xmath220 as well , denoted @xmath221 . using @xmath222 and @xmath221 ,",
    "the notation makes it clear that we can average over the @xmath51 s that are characterized by @xmath153 .",
    "we use the results of lemmas  [ lemma : polarity_positive ] and [ lemma : polarity_negative ] to prove the polarity result for @xmath206 in section  [ sec : theoremproof ] .",
    "[ lemma : polarity_positive ] given the sequence of independent random variables @xmath215 with @xmath223 , @xmath224 , and @xmath225 .",
    "then , for all @xmath18 , @xmath226 @xmath227 for some constants @xmath228 , @xmath229 , and @xmath230 and @xmath231 almost surely , where @xmath232    [ lemma : polarity_negative ] given the sequence of independent random variables @xmath215 with @xmath233 , @xmath224 , and @xmath225 . then , for all @xmath18 , @xmath234 @xmath235 for some constants @xmath228 , @xmath229 , and @xmath230 and @xmath236 almost surely , where @xmath237    the results of lemma  [ lemma : polarity_positive ] and lemma  [ lemma : polarity_negative ] are intuitive since given that @xmath28 is odd and the gaussian noise distribution is symmetric , it makes sense for @xmath206 to have properties similar to an odd waveform .",
    "since the proofs of the two lemmas are very similar , we only prove lemma  [ lemma : polarity_positive ] .",
    "the proof can be found in the appendix .    knowing only the polarity of @xmath206 is not entirely satisfying since we would also expect that the limiting waveform be continuous .",
    "the proof of lemma  [ lemma : continuity1 ] is once again left for the appendix .",
    "[ lemma : continuity1 ] using @xmath28 in ( [ eq : poft ] ) , @xmath238 is a continuous function of @xmath78 , where @xmath239      we can proceed in a straightforward manner to show that @xmath240 . for @xmath241 , @xmath242 where @xmath243 .",
    "since our goal is to apply some form of the strong law of large numbers , we first examine the mean of @xmath244 .",
    "we have that @xmath245 @xmath246 @xmath247 .",
    "furthermore , @xmath248 since @xmath249 is odd and @xmath217 is even because it is zero - mean gaussian .",
    "thus , @xmath250 .",
    "we next consider the variance of @xmath244 : @xmath251 where we have used the fact that @xmath252 and @xmath253 .    from the preceding discussion",
    "we see that the @xmath244 s are a sequence of zero mean , finite ( but possibly different ) variance random variables . from stark and woods  @xcite , we know that if @xmath254 , then we have strong convergence of the @xmath244 s : @xmath255 with probability-1 as @xmath37 .",
    "but it is easy to see that @xmath256 so the condition is satisfied . as a result ,",
    "@xmath257 as @xmath258 .",
    "we have that @xmath206 is continuous from lemma  [ lemma : continuity1 ] .",
    "thus , next we need to show that @xmath201 for @xmath259 , and @xmath203 for @xmath260 for some @xmath261 .",
    "we show the case for @xmath262 by simply applying lemma  [ lemma : polarity_positive ] .",
    "since lemma  [ lemma : polarity_positive ] holds for all @xmath223 , there clearly exists a @xmath263 such @xmath264 for @xmath259 .",
    "the case for @xmath265 comes similarly from lemma  [ lemma : polarity_negative ] .",
    "lastly , it remains to be shown that @xmath206 is odd around @xmath189 .",
    "this , however , is evident from the form of @xmath266 . since @xmath222 is even in @xmath267 about @xmath41 and @xmath249",
    "is odd about @xmath41 , it is clear that @xmath268 as a function of @xmath78 is odd about @xmath32 .",
    "thus , @xmath266 is odd around @xmath32 .",
    "this then completes the proof for theorem  [ theorem : main ] .",
    "in this work we want to show that as we let @xmath37 then we can recover deterministic parameters that allow for time synchronization . such a result would provide rigorous theoretical support for a new trade - off between network density and synchronization performance . to simplify the study , we focus on the steady - state time synchronization properties of asymptotically dense networks . in particular ,",
    "we develop a cooperative technique that constructs a sequence of equispaced zero - crossings seen by all nodes which allows the network to maintain time synchronization indefinitely given that the nodes start with a collection of equispaced zero - crossings . starting with",
    "a few equispaced zero - crossings allows us to avoid the complexities of starting up the synchronization process but still allows us to show that spatial averaging can be used to average out timing errors .",
    "if we are able to maintain indefinitely a sequence of equispaced zero - crossing using cooperative time synchronization , then it means that spatial averaging can average out all uncertainties in the system as we let node density grow unbounded .",
    "this recovery of deterministic parameters is our desired result . here",
    ", we overview the estimators needed for cooperative time synchronization .",
    "let @xmath269 be the time , with respect to clock @xmath270 , that the @xmath18th node sees its @xmath120th pulse . in dealing with the steady - state properties ,",
    "we start by assuming that each node @xmath18 in the network has observed a sequence of @xmath271 pulse arrival times , @xmath272 , that occur at integer values of @xmath78 , @xmath271 is an integer .",
    "recall that @xmath272 is defined as a set of @xmath271 pulse arrival times in the time scale of @xmath40 .",
    "therefore , even though @xmath272 occur at integer values of @xmath78 ( the time scale of @xmath43 ) , these values are not necessarily integers since they are in the time scale of @xmath40 .",
    "note also that in our model the pulse arrival time is a zero - crossing location . using these @xmath271 pulse arrival times",
    ", each node @xmath18 has two distinct , yet closely related tasks .",
    "the first task is time synchronization . to achieve time synchronization",
    ", node @xmath18 wants to use these @xmath271 pulse arrival times to make an estimate of when the next zero - crossing will occur . if it can estimate this next zero - crossing time",
    ", then it can effectively estimate the next integer value of @xmath78 .",
    "this estimator can then be extended to estimate arbitrary times in the future which gives node @xmath18 the ability to synchronize to node @xmath42 .",
    "the second task is that node @xmath18 needs to transmit a pulse so that the sum of all pulses from the @xmath9 nodes in the network will create an aggregate waveform that , in the limit as @xmath37 , will give a zero - crossing at the next integer value of @xmath78 .",
    "this second task is very significant because if the aggregate waveform gives the exact location of the next integer value of @xmath78 , then each node @xmath18 in the network can use this new zero - crossing along with @xmath273 to form a set of @xmath271 zero - crossing locations .",
    "this new set can then be used to predict the next zero - crossing location as well as node @xmath18 s next pulse transmission time .",
    "recall that determining the pulse transmission time is the job of the pulse - connection function @xmath119 .",
    "with such a setup , synchronization would be maintained indefinitely .",
    "the zero - crossings that always occur at integer values of @xmath78 would provide node @xmath18 a sequence of synchronization events and also illustrate how cooperation is averaging out all random errors .",
    "the waveform properties detailed in theorem  [ theorem : main ] play a central role in accomplishing the nodes task of cooperatively generating an aggregate waveform with a zero - crossing at the next integer value of @xmath78 . from  ( [ eq : waveformgeneralform ] ) , if the arrival time of any pulse at a node @xmath29 is a random variable of the form @xmath274 , where @xmath32 is the next integer value of @xmath78 and @xmath33 is zero - mean gaussian ( or in general any symmetric random variable with zero - mean and finite variance ) , then theorem  [ theorem : main ] tells us that the aggregate waveform will make a zero - crossing at the next integer value of @xmath78 .",
    "this idea is illustrated in fig .",
    "[ fig : example ] .",
    "thus , for achieving time synchronization in an asymptotically dense network we need to address two issues .",
    "first , we need to develop an estimator for the next integer value of @xmath78 given a sequence of @xmath271 pulse arrival times that occur at integer values of @xmath78",
    ". we will call this the _ time synchronization estimator _ and let us write @xmath275 as the time synchronization estimator that determines the time , in the time scale of @xmath40 , when node @xmath18 predicts it will see its @xmath120th zero - crossing .",
    "two , we need to develop the pulse - connection function @xmath119 such that node @xmath18 s transmitted pulse will arrive at a node @xmath29 with the random properties described in theorem  [ theorem : main ] .      here",
    "we establish the conditions for estimating the next pulse arrival time , or equivalently the next integer value of @xmath78 , given @xmath271 pulse arrival times .",
    "these conditions apply most directly to the time synchronization estimator @xmath275 since we want to synchronize in some desired manner .",
    "the problem of synchronization is the challenge of having the @xmath18th node accurately and precisely predict when the next integer value of @xmath78 will occur . in our setup",
    ", the reception of a pulse by node @xmath18 tells it of such an event .",
    "let us explicitly model the time at an integer value of @xmath78 in terms of the clock of node @xmath18 .",
    "assume @xmath32 is an integer value of @xmath78 and at this time , node @xmath18 will observe its @xmath120th pulse .",
    "thus , from ( [ eq : clock ] ) we have that @xmath276 the equation makes use of the clock model of node @xmath18 ( [ eq : clock ] ) to tell us the time at clock @xmath40 when node @xmath42 is at @xmath32 , where @xmath32 is an integer in the time scale of @xmath43 .",
    "we are also starting with the assumption that the zero - crossing that occurs at an integer value of @xmath78 is observed by node @xmath18 at this time .",
    "from ( [ eq : state - eqns ] ) we see that the pulse receive time at node @xmath18 , @xmath277 , is a gaussian random variable whose mean is parameterized by the unknown vector @xmath278 $ ] . thus , to achieve synchronization node @xmath18",
    "will try to estimate the random variable @xmath277 using a series of @xmath271 pulse receive times as observations ( recall that @xmath271 is known ) .",
    "note that the observations are also random variables with distributions parameterized by @xmath279 .",
    "we want the time synchronization estimator of node @xmath18 to make an estimate of @xmath277 , denoted @xmath280 which is a function of past observations @xmath281 , that meets the following criteria : @xmath282 = e_{\\vartheta}(t_{n , i}^{c_{i } } ) \\label{eq : opt1}\\ ] ] @xmath283 \\label{eq : opt2}\\ ] ] for all @xmath279 .",
    "the subscript @xmath279 means that the expectation is taken over the distributions involved given any possible @xmath279 .",
    "the first condition comes from the fact that given a finite @xmath271 , it is reasonable to want the expected value of the estimate to be the expected value of the random variable being estimated for all @xmath279 . as in the justification for unbiased estimators , this condition eliminates unreasonable estimators so that the chosen estimator will perform well , on average , for all values of @xmath279  @xcite .",
    "the second condition is the result of seeking to minimize the mean squared error between the estimate and the random variable being estimated for all @xmath279 .",
    "for the time synchronization estimator , node @xmath18 will seek to estimate @xmath277 given @xmath272 . from ( [ eq : state - eqns ] )",
    ", we see that @xmath284^{t}$ ] is a jointly gaussian random vector parameterized by @xmath279 .",
    "recall that we assume @xmath52 is a zero mean gaussian process with independent and identically distributed samples @xmath285 , for any @xmath78 . also , since we re assuming that the zero - crossings at node @xmath18 occur at consecutive integer values of @xmath78 , the random variable @xmath286 is gaussian with @xmath287 for some @xmath288 $ ] .",
    "we also notice that @xmath289 since each noise sample is independent , we see that the distribution of @xmath290 parameterized by @xmath279 can be written as @xmath291 where @xmath292\\ ] ] and @xmath293 .    as a result , for any @xmath271 consecutive observations",
    ", we can simplify notation by using the model @xmath294 where @xmath295^{t } = [ t_{n - m , i}^{c_{i } } \\quad t_{n - m+1,i}^{c_{i } } \\dots t_{n-1,i}^{c_{i}}]^{t}$ ] and @xmath296 = \\left [ \\begin{array}{c } \\alpha_{i}(\\tau_{0}-m-\\bar{\\delta}_{i})\\\\ \\alpha_{i } \\end{array } \\right]\\ ] ] with @xmath297^t\\ ] ] and @xmath298^{t}$ ] . since @xmath52 is a gaussian noise process , @xmath299 with @xmath293 .    using the simplified notation in ( [ eq : simple - obs ] ) , we want to estimate @xmath300 , where @xmath300 is jointly distributed with @xmath301 as @xmath302 \\sim { \\mathcal",
    "n } ( \\left [ \\begin{array}{c } { \\mathbf m}\\\\ \\theta_{1}+m\\theta_{2 } \\end{array } \\right ] , \\left [ \\begin{array}{cc } \\sigma & 0\\\\ 0 & \\sigma^{2 } \\end{array } \\right]).\\ ] ] using this notation , we can rewrite the synchronization criteria as : @xmath303=e_{\\theta}(y_{m+1})\\ ] ] @xmath304,\\ ] ] where @xmath305 is the estimator for @xmath300 .",
    "condition ( [ eq : opt1-simple ] ) implies that our estimate must be unbiased .",
    "condition ( [ eq : opt2-simple ] ) is equivalent to @xmath306.\\ ] ] to see this equivalence , note that @xmath307 } \\nonumber \\\\ & = & e_{\\theta}\\big[(\\hat{y}_{m+1}(y_{1 } , y_{2 } , \\dots , y_{m})-(\\theta_{1}+m\\theta_{2})-w_{m+1 } ) ^{2}\\big ] \\nonumber \\\\ & = & e_{\\theta}\\big[(\\hat{y}_{m+1}(y_{1 } , y_{2 } , \\dots , y_{m})- ( \\theta_{1}+m\\theta_{2 } ) ) ^{2}\\big]+e\\big [ w_{m+1}^{2}\\big],\\end{aligned}\\ ] ] where the last inequality follows from the independence of @xmath308 from all other noise samples .",
    "since the distribution of of @xmath308 is independent of @xmath309 , @xmath310 } \\nonumber \\\\ & = & \\textrm{argmin}_{\\hat{y}_{m+1 } } e_{\\theta}\\big[(\\hat{y}_{m+1}(y_{1 } , y_{2 } , \\dots , y_{m})- ( \\theta_{1}+m\\theta_{2 } ) ) ^{2}\\big ] \\nonumber.\\end{aligned}\\ ] ] with these two conditions , from  @xcite we see that the desired estimate for @xmath300 will be the uniformly minimum variance unbiased ( umvu ) estimator for @xmath311 .    using the above linear model , from  @xcite we know the maximum likelihood ( ml ) estimate of @xmath309 , @xmath312 ,",
    "is given by @xmath313 this estimate achieves the cramer rao lower bound , hence is efficient .",
    "the fisher information matrix is @xmath314 and @xmath315 .",
    "this means that @xmath312 is umvu .",
    "again from  @xcite , the invariance of the ml estimate tells us that the ml estimate for @xmath316 is @xmath317 .",
    "first , it is clear that @xmath318 , where @xmath319 $ ] . as a result",
    ", we first see that @xmath320 so @xmath321 is unbiased .",
    "next , to see that @xmath321 is also minimum variance we compare its variance to the lower bound .",
    "@xmath322 the extension of the cramer rao lower bound in  @xcite to a function of parameters tells us that @xmath323 with @xmath324 . in this case ,",
    "@xmath325 $ ] so the lower bound to the mean squared error is @xmath326 as a result , we see that @xmath321 is umvu .",
    "since @xmath321 is the desired estimate of where the next pulse arrival time will be , it is the time synchronization estimator .",
    "thus , @xmath327 note that @xmath328 has a variance that goes to zero as @xmath329 .",
    "we now need to develop the pulse - connection function so that the conditions for @xmath33 in theorem  [ theorem : main ] are satisfied .",
    "recall we are developing the synchronization technique under the assumption of no propagation delay , i.e. @xmath330 .",
    "given a sequence of @xmath271 pulse arrival times , the time synchronization estimator @xmath275 given in ( [ eq : timesync - estimator ] ) gives each node the ability to predict the next integer value of @xmath78 .",
    "what remains to be considered is the second part of the synchronization process : developing a pulse - connection function @xmath119 such that the aggregate waveform seen by a node @xmath29 will have the properties described in theorem  [ theorem : main ] .",
    "let us first consider the distribution of @xmath275 . from ( [ eq : timesync - estimator - distribution ] ) , we have that @xmath331 using ( [ eq : clock ] ) , we can translate @xmath332 into the time scale of @xmath43 as @xmath333 which gives @xmath334 this means that @xmath335 under our assumption of @xmath330 , any transmission by node @xmath18 will be instantaneously seen by any node @xmath29 . as a result",
    ", the random variable @xmath336 will be seen as the pulse arrival time at node @xmath29 , in the time scale of @xmath43 .",
    "due to the assumption of no propagation delay , defining @xmath337 will give us the desired properties in the aggregate waveform . to see this ,",
    "let us compare the distribution of @xmath338 to the assumptions of theorem  [ theorem : main ] . since @xmath32 is the ideal crossing time in the time scale of @xmath43 , we have @xmath339 therefore , we see that @xmath340 where @xmath211 from theorem  [ theorem : main ] is @xmath341 we have shown that using the pulse connection function @xmath337 satisfies the conditions of theorem  [ theorem : main ]",
    ". thus , all the results of the theorem apply .    as a result",
    ", we have established a time synchronization estimator @xmath336 and a pulse - connection function @xmath338 . in the case of @xmath330",
    ", we have that @xmath337 , or in the time scale of @xmath40 , @xmath342 .",
    "when each node in the network uses the pulse - connection function @xmath343 we have a resulting aggregate waveform that has a zero - crossing at the next integer value of @xmath78 as @xmath37 .",
    "this fact follows from applying theorem  [ theorem : main ] .",
    "thus , we have an asymptotic steady - state time synchronization method that can maintain a sequence of equispaced zero - crossings occurring at integer values of @xmath78 . an interesting feature of this synchronization technique is that no node needs to know any information about its location or its surrounding neighbors .      before ending this section ,",
    "let us comment on the assumption of simultaneous transmission and reception .",
    "one way to relax this assumption is to divide the network into two disjoint sets of nodes , say the odd numbered nodes and the even numbered nodes , where each set is still uniformly distributed over the area .",
    "then , the odd nodes and the even nodes will take turns transmitting and receiving .",
    "for example , the odd numbered nodes can transmit pulses at odd values of @xmath78 and the even numbered nodes will listen .",
    "the even numbered nodes will then transmit pulses at the even values of @xmath78 and the odd numbered nodes will listen .",
    "with such a scheme , nodes do not transmit and receive pulses simultaneously , but can still take advantage of spatial averaging .",
    "the odd numbered nodes will see an aggregate waveform generated by a subset of the even numbered nodes and the even numbered nodes will receive a waveform cooperatively generated by the odd numbered nodes . let us take a more detailed look at this scheme .    in fig .",
    "[ fig : nosimulttxrx ] we assume that @xmath32 is an even integer value of @xmath78 and use @xmath344",
    ". each even numbered node will use the aggregate signals occurring at @xmath345 , @xmath346 , and @xmath347 to estimate @xmath32 and cooperatively the even nodes will generate the aggregate signal at @xmath32 .",
    "the odd numbered nodes will then use the aggregate signals occurring at @xmath348 , @xmath349 , and @xmath32 to generate the aggregate signal at @xmath350 .",
    "therefore , the odd and even numbered nodes can take turns transmitting and receiving signals and nodes never need to simultaneously transmit and receive .",
    "of course , such a setup would require a modification of the estimators used by the nodes .",
    "nodes will receive a vector of @xmath271 observations @xmath351 with @xmath352 = \\alpha_{i}(\\tau_{0}+1 - 2(m - l)-\\bar{\\delta}_{i})+\\psi_{i}$ ] for @xmath353 .",
    "with such a mechanism , the @xmath354 matrix in equation ( [ eq : simple - obs ] ) would change to @xmath355^t\\ ] ] and @xmath309 becomes @xmath296 = \\left [ \\begin{array}{c } \\alpha_{i}(\\tau_{0}+1 - 2m-\\bar{\\delta}_{i})\\\\ \\alpha_{i } \\end{array } \\right].\\ ] ]    to estimate the location @xmath32 in the time scale of @xmath40 , we can proceed as in section  [ sec : timesyncestimator ] : @xmath356 will be distributed @xmath357 and @xmath312 is umvu .",
    "this leads to the umvu estimate @xmath358 , where @xmath359 $ ] , and @xmath360 . in this case",
    ", the variance of @xmath321 will be @xmath361 , and thus we have that @xmath362 converted to the time scale of @xmath43 we have @xmath363 comparing equations ( [ eq : comptonosimult ] ) and ( [ eq : nosimult ] ) , we see that they have the same form . as a result",
    ", we can again set @xmath342 and achieve cooperative time synchronization .",
    "we now extend the ideas of cooperative time synchronization to the situation where signals suffer not only from pathloss but also propagation delay .",
    "it turns out that the effect of propagation delay can also be addressed using the concept we have been using throughout this paper  averaging out errors using the large number of nodes in the network .    in this section ,",
    "we use the pathloss and propagation delay model detailed in section  [ sec : delay - model ] .",
    "we introduce a time delay function @xmath83 . for generality",
    ", we explicitly model a multi - hop network where we have a @xmath53 function that is zero for @xmath56 greater than some distance @xmath95 , i.e. @xmath364 for @xmath365 .",
    "such a model implies that the aggregate signal seen at any node @xmath29 is influenced only by the set of nodes inside a circle of radius @xmath95 centered at node @xmath29 . with this",
    "we can effectively divide the network into two disjoint sets , a set of _ interior nodes _ and a set of _ boundary nodes_. an interior node @xmath29 is defined to be a node whose distance from the nearest network boundary is greater than or equal to @xmath95 .",
    "a boundary node is thus defined to be a node that is a distance less than @xmath95 away from the nearest network boundary .",
    "we make this distinction since the synchronization technique for each set of nodes is different .",
    "please note that if a pathloss function where @xmath364 for @xmath365 is unreasonable , then we simply choose @xmath95 to be infinite and consider all nodes in the network to be boundary nodes .",
    "using the propagation delay model , @xmath116 will obviously modify the general received aggregate waveform seen at any node @xmath29 .",
    "in fact , equation ( [ eq : timesync - aggwaveform ] ) will now be written as @xmath366 for @xmath9 large , this model will give an accurate characterization of the aggregate waveform seen at node @xmath29 .      from equation ( [ eq : timesync - aggwaveform - withdelay ] )",
    ", it is clear that the aggregate waveform will not have a zero - crossing at @xmath32 for every node @xmath29 because of the presence of the @xmath116 random variables .",
    "therefore , to average out propagation delay , the idea we employ is to have each node introduce a _",
    "random _ artificial time shift that counteracts the effect of the time delay random variable .",
    "more precisely , we want to introduce another random variable @xmath367 such that @xmath368 will have zero mean and a symmetric distribution . at the same time , we assume each node knows @xmath97 and @xmath99 and will also introduce an artificial scaling factor @xmath369 to simplify the analysis of the aggregate waveform .",
    "this means that instead of using the scaling factor @xmath370 , each node @xmath18 will scale its transmitted pulse by @xmath371 . for",
    "the motivation in this section , let us assume that node @xmath29 is an interior node .    to find the distribution of @xmath367 , we consider the following .",
    "@xmath82 has density @xmath115 and let @xmath372 be the density of @xmath367 . since @xmath82 and @xmath367 are independent , we know that the density of @xmath373 , @xmath374 , will be the convolution of @xmath115 and @xmath372 .",
    "therefore , by the properties of the convolution function , if we set @xmath375 , then we have that @xmath374 is symmetric , i.e. @xmath376 . as well , since @xmath82 has finite expectation , it is easy to see that @xmath377 .    given a sequence of @xmath271 zero - crossings that we know to be occurring at integers of @xmath78 , we can still use @xmath336 ( from ( [ eq : timesync - estimator ] ) in the time scale of node @xmath42 ) as the time synchronization estimator .",
    "however , with propagation delay , the pulse - connection function will now be @xmath378 . with",
    "@xmath367 and @xmath379 included , we can rewrite equation ( [ eq : timesync - aggwaveform - withdelay ] ) as @xmath380 it is important to see that since @xmath82 has the same distribution for _ all _ interior nodes @xmath29 , equation ( [ eq : timesync - aggwaveform - withdelayandfix ] ) holds for every node @xmath29 that is an interior node .",
    "this means that for the network to cooperatively generate the waveform in ( [ eq : timesync - aggwaveform - withdelayandfix ] ) each transmit node @xmath18 needs to have the following additional knowledge : ( 1 ) the distribution of @xmath367 whose density is @xmath375 , where @xmath29 is an interior node , and ( 2 ) the functions @xmath97 and @xmath99 to generate @xmath379 . with this knowledge , we can use equation ( [ eq : timesync - aggwaveform - withdelayandfix ] ) to study the aggregate waveform seen at any interior node @xmath29 .",
    "in fact , we find that the aggregate waveform has limiting properties that are similar to those outlined in theorem  [ theorem : main ] .",
    "these properties are described in theorem  [ theorem : main - delay ] .",
    "[ theorem : main - delay ] let @xmath28 be as defined in equation  ( [ eq : poft ] ) and @xmath195 with @xmath196 a constant and @xmath197 for all @xmath18 , @xmath141 a constant . @xmath34 and @xmath116 are defined as in section  [ sec : delay - model ] and @xmath367 with density @xmath375 is independent from @xmath116 . @xmath369 and let @xmath116 , @xmath367 , and @xmath33 be mutually independent for all @xmath18 .",
    "then , for any interior node @xmath29 with @xmath381 as defined in ( [ eq : timesync - aggwaveform - withdelayandfix ] ) , @xmath382 has the properties    * @xmath383 , * @xmath384 is odd around @xmath189 , i.e. @xmath385 for @xmath208 .",
    "@xmath210    the proof of theorem  [ theorem : main - delay ] is left for the appendix .    from the arguments",
    "so far , it seems that time synchronization with delay , at least for interior nodes , can be solved simply by modifying the pulse - connection function @xmath386 and changing the scaling factor to @xmath371 .",
    "theorem  [ theorem : main - delay ] tells us that the limiting aggregate waveform makes a zero - crossing at the next integer value of @xmath78 and the waveform is odd .",
    "thus , we can use this zero - crossing as a synchronization event and maintain synchronization in a manner identical to the technique used in the situation without propagation delay .",
    "this , however , unfortunately is not the case . in order to implement the above concept , we need to find the random variable , @xmath387 , in the time scale of @xmath40 , that corresponds to @xmath367 such",
    "that @xmath388 this means that we need @xmath389 .",
    "however , each node @xmath18 can not find @xmath387 that satisfies this since it does not know its @xmath51 .",
    "since the @xmath18th node does not know its own value of @xmath51 , to do time synchronization with propagation delay we can have each node estimate its @xmath51 value .",
    "however , this estimate will not be perfect and we may no longer have the symmetric limiting aggregate waveform described by theorem  [ theorem : main - delay ] .",
    "this means that the center zero - crossing might occur some @xmath140 away from @xmath32 , @xmath32 an integer value of @xmath78 .",
    "however , steady - state time synchronization can be maintained if the network can use a sequence of @xmath271 equispaced zero - crossings that occur at @xmath390 , where @xmath32 is an integer value of @xmath78 , to cooperatively generate a limiting aggregate waveform that has a zero - crossing at @xmath391 .",
    "in such a situation , the network will be able to construct a sequence of equispaced zero - crossings and maintain the occurrence of these zero - crossings indefinitely .",
    "the idea is the same as in the case without propagation delay , but the only difference here would be that the zero - crossings do not occur at integer values of @xmath78 .",
    "let us give a more formal description of this idea .    using notation from section  [ sec : timesyncestimator ] , we start with the assumption that each interior node @xmath18 has a sequence of @xmath271 observations that has the form @xmath392 where @xmath393 and @xmath140 is known . to develop the time synchronization estimator @xmath394 and the pulse - connection function @xmath343",
    ", we consider the observations made by each node .",
    "if we assume that each node knows the value of @xmath140 , the vector of observations can be written as in ( [ eq : simple - obs ] ) @xmath395 where the matrix @xmath396 in this case is @xmath397^t.\\ ] ] using this model , we can follow the development in section  [ sec : timesyncestimator ] to find the the time synchronization estimator @xmath398 where @xmath399 $ ]",
    ". this estimator will give each node the ability to optimally estimate the next integer value of @xmath78 .",
    "note that the variance of the time synchronization estimator is @xmath400 using the time synchronization estimator , we can choose the pulse - connection function as @xmath401 where each time node @xmath18 makes the estimate @xmath402 it also estimates @xmath403 as @xmath404 @xmath405 $ ] .",
    "we find that @xmath406 .",
    "since , from section  [ sec : propdelay_motivation ] , we know we want @xmath389 , we have set @xmath407 . notice that since @xmath387 is simply a realization of @xmath367 multiplied by node @xmath18 s estimate of @xmath51 , node @xmath18 can use the realization of @xmath367 and find @xmath369 .    with our choice of @xmath343 in ( [ eq : pulse - connection - propdelay ] ) , we see that @xmath408 where @xmath409 , and @xmath410 .",
    "because of the random factor @xmath411 , we see that @xmath412 is no longer a symmetric distribution . as a result",
    ", the limiting aggregate waveform @xmath413 may not have a zero - crossing at @xmath189 .",
    "thus , if we can find an @xmath140 such that each node @xmath18 using a set of observations of the form ( [ eq : observation_form ] ) allows the network to cooperatively generate the waveform in ( [ eq : aggregate - waveform - timedelay ] ) that has its zero - crossing occurring at @xmath414 ( in the time scale of @xmath43 ) , then we have steady - state time synchronization .",
    "this is because the network would be able to use a sequence of @xmath271 observations to generate the next observation that gives the same information as any of the previous observations .",
    "thus , by always taking the @xmath271 most recent observations , the process can continue forever and maintain synchronization .",
    "each node @xmath18 would need to know distribution of @xmath367 , the value of @xmath140 , and the functions @xmath97 and @xmath99 .",
    "therefore , we find that steady - state time synchronization of the interior nodes is possible under certain conditions . as a note , no interior node needs to know any location information .      before we consider the synchronization of boundary nodes , we note that the key requirement for each boundary node @xmath18 is to have a pulse - connection function given in equation ( [ eq : pulse - connection - propdelay ] ) .",
    "the reason that this must be the pulse - connection for every boundary node @xmath18 is because the analysis for the interior nodes assumes that the aggregate waveform seen by any interior node @xmath29 is created by pulse transmissions occurring at a time determined by ( [ eq : pulse - connection - propdelay ] ) . since the aggregate waveform seen by some interior nodes are created by pulse transmissions from boundary nodes , each boundary node must have the appropriate pulse - connection function .",
    "this requirement , however , proves to be extremely problematic and reveals a limitation of the elegant technique of averaging out timing delay when we come to boundaries of the network .",
    "the problem comes because @xmath415 already does not have a symmetric distribution if @xmath29 is a boundary node .",
    "recall that @xmath416 when @xmath29 is an interior node and @xmath417 when @xmath29 and @xmath77 are both interior nodes .",
    "however , @xmath418 when @xmath29 is an interior node and @xmath77 is a boundary node . as a result ,",
    "@xmath415 is no longer symmetric if @xmath29 is a boundary node .",
    "in fact , it is clear that the distribution of @xmath415 is a function of node @xmath29 s location near the boundary .",
    "because of this additional asymmetry , let us assume for a moment that the sequence of zero - crossings observed by boundary node @xmath18 occur @xmath419 away from an integer value of @xmath78 .",
    "that is , if every node in the network , including the boundary nodes , transmitted a sequence of pulses where each pulse was sent according to ( [ eq : pulse - connection - propdelay ] ) , then boundary node @xmath18 would observe the sequence of observations @xmath420 where @xmath393 and @xmath419 is known .",
    "this boundary node @xmath18 could then use the time synchronization estimator given by ( [ eq : timesync - estimator - propdelay ] ) but where the matrix @xmath396 is now replaced with @xmath421 @xmath422^t.\\ ] ] thus , for this boundary node @xmath18 we have @xmath423 in this case , however , the variance of the time synchronization estimator depends on @xmath419 @xmath424 the fact that the variance depends on @xmath419 is the root of the problem .",
    "the pulse - connection function @xmath425 is _ not _ the same as that given by ( [ eq : pulse - connection - propdelay ] ) .    to correct for this",
    ", we can make the strong assumption that each boundary node @xmath18 knows is own @xmath51 .",
    "we address the reasoning behind this assumption in section  [ sec : propdelay_assumption ] .",
    "if we use this assumption , then each boundary node @xmath18 can get an observation sequence of the form ( [ eq : observation_form ] ) simply by adding @xmath426 to each of the @xmath271 observations of the form given in ( [ eq : observation_form_boundary ] ) , where we assume that node @xmath18 knows both @xmath140 and @xmath419 .",
    "with such an observation sequence , boundary node @xmath18 will have the time synchronization estimator ( [ eq : timesync - estimator - propdelay ] ) and , more importantly , the pulse - connection function ( [ eq : pulse - connection - propdelay ] ) .",
    "thus , maintaining time synchronization for the case of propagation delay would be possible .    what we have",
    "then is that boundary node synchronization would require only the boundary nodes to know their @xmath51 parameters . with this strong assumption only for the boundary nodes ,",
    "the network is effectively synchronized .",
    "even though the boundary nodes do not see the same zero - crossing as the interior nodes , they can calculate this time and thus have all the required synchronization information .",
    "the assumption that each boundary node @xmath18 knows @xmath51 is a strong assumption .",
    "even though the fraction of nodes that are boundary nodes is small for multi - hop networks requiring many hops to send information across the network , we believe that the assumption is still very artificial .",
    "there are two reasons that we make the assumption for the presentation of results on time synchronization with propagation delay .",
    "first , the assumption allows us to give an elegant presentation of the main concept of this paper which is to use high node density to average out errors in the network . throughout this work we have used high node density to average out inherent errors present in the nodes .",
    "we were able to average out random timing jitter that is present in each node and provide the network with a sequence of zero - crossings that can serve as synchronization events .",
    "we then applied this technique to averaging out the errors introduced by time delay .",
    "to this end we were partially successful in that the interior nodes can average out these errors assuming the boundary nodes have additional information .",
    "but this is of interest since the goal of this paper is to understand the theory of spatial averaging for synchronization and discover its fundamental advantages and limitations .",
    "second , the problem encountered at the boundaries is one that opens up an entirely new area of study which is the target of our future work .",
    "the issue that we encounter is that the waveform seen by some nodes in the network will have a zero - crossing that is shifted from the ideal location .",
    "this implies that different nodes will observe different zero - crossings .",
    "furthermore , these zero - crossings will now evolve in time since we do not have the same observations over the entire network .",
    "this problem is similar to what we encounter if we consider finite sized networks . for finite @xmath9",
    ", the zero - crossing location will be random and thus introduce another source of error .",
    "as well , different nodes will see different zero - crossing locations .",
    "therefore , we will turn our attention to the case of finite @xmath9 and develop a different set of tools that will be needed to understand what types of synchronization are achievable under the situation where zero - crossing locations evolve in time . using this understanding",
    ", we hope to return to the issue of propagation delay in asymptotically dense networks and characterize the behavior of the network .",
    "to conclude , we revisit the scalability issue under the light of work developed in this paper .      in the introduction ( section  [ sec : estimate - params ] ) , we mentioned that most existing proposals for time synchronization suffer from an inherent scalability problem .",
    "the problem with those existing proposals lies in the fact that synchronization errors accumulate : if node 2 can synchronize to node 1 with some small error , and node 3 can synchronize to node 2 with the same small error , these errors accumulate , and the synchronization of node 3 to node 1 is worse",
    ". therefore , synchronization error increases with the number of hops in the network , and this problem is especially apparent in the regime of high densities . to make these ideas precise",
    ", we first determine the maximum number of hops over which synchronization information must travel and then study how the error in a generic pairwise synchronization mechanism depends on this number of hops .      to obtain an estimate for the maximum number of hops @xmath427 in a network in the regime of high densities ( fixed area , @xmath37 ) , we approximate the transmission range of a node by the minimum required transmission distance , @xmath428 , to maintain a fully connected network with high probability . from  @xcite",
    ", we have that for @xmath9 nodes uniformly distributed over a @xmath429\\times [ 0,1]$ ] square , the graph is connected with probability-1 as @xmath37 if and only if each node s transmission distance @xmath428 is such that @xmath430 for some @xmath431 .",
    "let us , therefore , approximate @xmath428 as @xmath432 thus , @xmath433 , and thus @xmath434 as @xmath37 .",
    "now , we assume there are @xmath435 nodes arranged in a linear ordering , numbered @xmath42 to @xmath435 . to synchronize , each node @xmath18 forms an estimate of its own @xmath51 , based on @xmath271 pulses transmitted from node @xmath436 . as before",
    ", node @xmath42 will have the reference clock @xmath44 .",
    "node @xmath42 starts by sending @xmath271 pulses at times @xmath437 for @xmath393 . as a result ,",
    "node @xmath0 will get a vector of observations @xmath438 , where @xmath439 = \\alpha_{2}(\\tau_{1}-\\bar{\\delta}_{2})+\\psi_{2}$ ] and the @xmath440th element of @xmath438 is @xmath441=\\alpha_{2}(\\tau_{1}-\\bar{\\delta}_{2})+l\\alpha_{2}+\\psi_{2}$ ] .",
    "this is similar to the situation we had in ( [ eq : simple - obs ] ) and we can therefore estimate @xmath442 using @xmath443 where @xmath444 $ ] . we find that @xmath445 .",
    "node @xmath0 will now transmit @xmath271 pulses at times , in terms of @xmath446 , @xmath447 , for @xmath393 .",
    "note that @xmath448 is now a fixed value since node @xmath0 has estimated @xmath442 . in terms of @xmath43 , these pulses occur at @xmath449 for @xmath393 , where @xmath450 . thus ,",
    "if we translate these times into the time scale of @xmath451 , we will have the vector of observations , @xmath452 , made by node @xmath453 .",
    "we find that the @xmath440th element of @xmath452 is @xmath454 = \\alpha_{3}((\\tau_{2 } + l\\frac{\\hat{\\alpha}_{2}}{\\alpha_{2}}- \\frac{\\psi_{2}}{\\alpha_{2}})-\\bar{\\delta}_{3})+\\psi_{3 } \\sim { \\mathcal n}\\bigg(\\alpha_{3}(\\tau_{2}-\\bar{\\delta}_{3})+l\\alpha_{3}\\frac{\\hat{\\alpha}_{2}}{\\alpha_{2 } } , \\sigma^{2}\\big(\\frac{\\alpha_{3}^{2}}{\\alpha_{2}^{2}}+1\\big)\\bigg).\\ ] ] this vector of observations is of the form @xmath455 where @xmath456 = \\left [ \\begin{array}{c } \\alpha_{3}(\\tau_{2}-\\bar{\\delta}_{3})\\\\ \\alpha_{3}\\frac{\\hat{\\alpha}_{2}}{\\alpha_{2 } } \\end{array } \\right]\\ ] ] with @xmath297^t\\ ] ] and @xmath298^{t}$ ] . @xmath457 with @xmath458 .    with this vector of observations , we can use the estimator @xmath459 where @xmath444 $ ] .",
    "we find that @xmath460 if we continue this reasoning , we find that @xmath461 will be the estimate of node @xmath435 .    from the above analysis",
    ", we see that each node @xmath18 s estimate suffers from jitter variance of the same form .",
    "however , there is an accumulation of error because node @xmath18 s estimate has a mean that is dependent on node @xmath436 s estimate . as a result ,",
    "if node @xmath436 has some small error , then that error will propagate to the estimate of node @xmath18 . a good way to see",
    "this is if we consider the special case where @xmath462 .",
    "this is the case where the clock frequencies are the same , but nodes do not know this . in this case , we find that node @xmath435 s estimate can be written as @xmath463 where @xmath464 .",
    "this is intuitively obvious because node @xmath18 s estimate @xmath403 will be the mean of the gaussian random variable @xmath465 . therefore , it is obvious that the error variance grows linearly with the number of hops .",
    "in fact , this behavior is observed in experimental work . with reference broadcast synchronization ( rbs ) , from  @xcite",
    "the authors find that the synchronization error variance of an @xmath435 hop path is approximately @xmath466 , where @xmath165 is the one hop error variance .",
    "therefore , we have that the synchronization error between our two nodes will grow linearly as @xmath467 , which is strictly monotonically increasing . as a result , as @xmath37 , we have that synchronization error will grow unbounded .",
    "this scalability problem , however , can potentially be avoided using cooperative time synchronization as @xmath37 .",
    "this is because in the limit of infinite density , the cooperative time synchronization technique allows every node in the network to see a set of identical equispaced zero - crossings . as a result , in steady - state the synchronization error does not grow across the network .",
    "this comes about by using the high node density to average out random timing errors .",
    "thus , we find that cooperative time synchronization has very favorable scalability properties in the limit as @xmath37 .",
    "the cooperative synchronization technique described in this paper provides us deterministic parameters that we can use for time synchronization in the limit as node density grows unbounded .",
    "in fact , as the node density grows , the observations that can be used for synchronization improve .",
    "this means that our cooperative synchronization technique provides an effective trade - off between network density and synchronization performance .",
    "such a trade - off has not existed before and will provide network designers an additional dimension over which to improve network synchronization performance .",
    "the fundamental idea behind cooperative time synchronization is that by using spatial averaging , the errors inherent in each node can be averaged out . by using observations that are an  average \" of the information from a large number of surrounding nodes , synchronization performance can be improved due to the higher quality observations .    from this point of view , it is clear that the particular technique described in this paper is but one example of using spatial averaging to improve synchronization .",
    "other techniques can also be developed using spatial averaging .",
    "for example , nodes may not necessarily have to send odd - shaped pulses and use zero - crossing observations . even though this setup takes advantage of the superposition of pulses",
    ", it has its drawbacks . to keep the signals in phase ,",
    "the jitter variance will limit the maximum frequency at which signals can be sent .",
    "instead , nodes may transmit ultra wideband pulses .",
    "if the nodes surrounding a particular node @xmath29 each transmit an impulse at their estimate of an integer value of @xmath78 , then due to timing errors in the surrounding nodes , node @xmath29 will see a cluster of pulse arrivals around this integer value of @xmath78 .",
    "node @xmath29 can then take the sample mean of this cluster of pulses and use that as an observation , just like we used the zero - crossing as an observation in this paper .",
    "this idea is illustrated in fig .",
    "[ fig : pulsetraincluster ] .",
    "such a technique based on ultra wideband pulses will also provide similar scalability properties .",
    "as a result , cooperative time synchronization really describes a class of techniques that can take advantage of spatial averaging to improve synchronization performance .      with the goal of developing practical cooperative synchronization mechanisms , two keys areas of interest",
    "are cooperative synchronization in finite - sized networks and algorithm development .",
    "first , the analysis of performance for finite - sized networks is very important .",
    "determining when the asymptotic properties presented in this work are good predictors of performance in networks that may be large but still finite in size is important in terms of bridging the gap between our proposed ideas and practical systems .",
    "preliminary , simulation - based work along these lines can be found in  @xcite .",
    "second , developing practical techniques for cooperative time synchronization is essential for implementing spatial averaging in real networks . along these lines ,",
    "one area of interest is determining what types of pulses should be used , i.e. odd - shaped pulses or ultra wideband pulses .",
    "furthermore , the ideas in this paper suggest a few other areas of interest for future work .",
    "one is the issue of distributed modulation methods .",
    "if we have the ability to generate an aggregate waveform with equispaced zero - crossings , by controlling the location of these crossings we can modulate information onto this waveform and use it to communicate with a far receiver . preliminary work along these lines can be found in  @xcite .",
    "another issue is to study how the idea of spatial averaging that is so prevalent in this work contributes to synchronization that is observed in nature .",
    "* proof of lemma  [ lemma : polarity_positive ] . * to show  ( [ eqn : cond3a ] ) , we consider @xmath468 since @xmath223 , we have that @xmath469 implying that @xmath249 is shifted to the left and the zero - crossing of @xmath249 occurs at a negative value .",
    "@xmath249 is odd about its zero - crossing and @xmath217 is symmetric about zero and strictly monotonically increasing on @xmath470 $ ] for all positive finite variance values .",
    "thus , it is clear that @xmath471 which makes @xmath472 .",
    "now , the expectation will vary with the variance of @xmath33 and the variance will range from a positive upper bound of @xmath473 to a positive lower bound of @xmath474 , where recall that @xmath211 is a value determined by our choice of the pulse connection function .",
    "if we consider @xmath475 to be a function of the variance of @xmath33 , then we see that it is bounded and continuous on the compact domain @xmath476 $ ] .",
    "since we showed in the previous paragraph that @xmath472 whenever @xmath33 has a nonzero finite variance , clearly @xmath472 when @xmath477 $ ] .",
    "thus , it is clear that @xmath228 and @xmath229 exist and  ( [ eqn : cond3a ] ) is shown .    to show  ( [ eqn : cond3b ] )",
    ", we consider @xmath478 where the second to last inequality follows from the fact that @xmath479 is upper bounded by @xmath42 .",
    "the last inequality follows since @xmath480 by the fact that @xmath481 .",
    "thus , we have shown  ( [ eqn : cond3b ] ) .",
    "[ theorem : feller ] the convergence of the series @xmath484 implies that the strong law of large numbers will apply to the sequence of independent random variables @xmath215 .",
    "that is , again from  @xcite , for every pair @xmath485 , @xmath486 , there corresponds an @xmath9 such that @xmath487 for all @xmath488 .",
    "@xmath210    we have shown  ( [ eqn : cond3b ] ) so we have @xmath489 . thus @xmath490 and we have convergence by the direct comparison test .",
    "therefore , we can apply theorem  [ theorem : feller ] and get that for any pair @xmath485 , @xmath486 , we can find an @xmath9 such that @xmath491 for all @xmath488 .",
    "by  ( [ eqn : cond3a ] ) we have that @xmath492 .",
    "thus , we can clearly see that @xmath493 furthermore , since we keep the function @xmath153 constant as we increase the number of nodes in the network we get that @xmath494 converges to a constant @xmath495 given by @xmath496 the above expression comes from the fact that since each @xmath497 is a function of @xmath51 , @xmath494 will converge to the average of the @xmath498 over @xmath153 , the function that characterizes the set of @xmath51 s .",
    "therefore , given any @xmath140 , we can find an @xmath499 such that @xmath500 for all @xmath501 .",
    "note that since @xmath502 , we have that @xmath503 . since @xmath504 using ( [ eqn : slln ] ) and ( [ eq : means - converge ] ) we have @xmath505 for all @xmath488 , where @xmath506 .",
    "thus , we have @xmath507 almost surely .",
    "this completes the proof of lemma  [ lemma : polarity_positive ] . @xmath210",
    "* proof of lemma  [ lemma : continuity1 ] . *",
    "first , we start by finding an analytical expression for @xmath508 . from the proof of lemma  [ lemma : polarity_positive ] we have",
    "that @xmath509 therefore , @xmath508 can be written as @xmath510 f_{t}(\\psi , s ) f_{\\alpha}(s)d\\psi ds| \\\\ & \\leq & a_{max } \\int_{\\alpha_{low}}^{\\alpha_{up}}\\int_{-\\infty}^{\\infty } |p(t-\\tau_{o}-\\psi)-p(t_{o}-\\tau_{o}-\\psi)|f_{t}(\\psi , s ) f_{\\alpha}(s)d\\psi ds \\\\ & = &   a_{max } \\int_{\\alpha_{low}}^{\\alpha_{up}}\\int_{-\\tau_{nz}+t_{o}-\\tau_{0}-|t - t_{o}|}^{\\tau_{nz}+t_{o}-\\tau_{0}+|t - t_{o}| }    f_{t}(\\psi , s)f_{\\alpha}(s ) d\\psi ds,\\end{aligned}\\ ] ] where @xmath511 .",
    "the change in the limits of integration in the last equality comes from the fact that @xmath512 outside of @xmath513 $ ] .",
    "this is the maximum interval over which @xmath514 can be non - zero .",
    "there is no need to take the absolute value of @xmath222 and @xmath153 since they are always non - negative .",
    "our second step is to bound the inner integral . before doing so",
    ", we first show that the inside integral is in fact riemann integrable . for",
    "any given @xmath78 and @xmath515 , the inside integral is taken over a closed interval . over a closed interval ,",
    "we know from strichartz  @xcite that any bounded function that is continuous except at a finite number of points is riemann integrable .",
    "furthermore , also from  @xcite we know that the sums and products of continuous functions are continuous . as well , if a function is continuous then the absolute value of that function is also continuous .",
    "@xmath28 has at most @xmath516 locations at which it is discontinuous and over any open interval not containing a discontinuity , @xmath28 is uniformly continuous since @xmath181 is uniformly continuous .",
    "@xmath222 has @xmath517 discontinuities in @xmath267 for an given @xmath220 since it is gaussian for any @xmath220 . and",
    "since @xmath518 $ ] , @xmath519 for all @xmath267 and @xmath220 ( @xmath520 occurring when @xmath521 and @xmath522 ) .",
    "thus , since @xmath28 and @xmath222 are continuous except at a finite number of points , we see that for given @xmath220 , @xmath78 , and @xmath162 @xmath523 is also continuous in @xmath267 except at a finite number of points ( at most @xmath524 points ) .",
    "this function is also bounded since the product of two bounded functions is bounded . as a result , we see that the integral is riemann integrable over any closed interval .",
    "we now proceed to bound from above the value of this integral by first bounding the maximum value of the integral assuming no discontinuities and then introducing another term that bounds the maximum area contributed by the discontinuities .",
    "if we ignore the discontinuities and assume @xmath28 is uniformly continuous , for any @xmath525 there exists a @xmath526 such that @xmath527 for all @xmath78 and @xmath515 . as a result , @xmath514 can be made as small as desired by choosing the proper @xmath120 thus giving us @xmath528 for all @xmath267 for an appropriate choice of @xmath120 .",
    "furthermore , we note that @xmath529 because @xmath253 and @xmath519 .",
    "the maximum possible jump at a discontinuity in the function @xmath530 is thus @xmath531 and for any @xmath532 , the maximum area contributed by each discontinuity is @xmath533 . as a result , for all @xmath524 discontinuities , the maximum area contribution will be no more than @xmath534 .            for the third term we want @xmath546 this gives us @xmath547 since the only requirement is @xmath536 for @xmath120 chosen by any given @xmath525 , we can always choose @xmath532 as small as desired .",
    "thus , this condition can be satisfied .",
    "with the second term we want the condition @xmath548 which means that @xmath549 again , this condition can be satisfied since we can choose @xmath550 as large as we want and @xmath532 as small as we want as long as @xmath536 for a given @xmath550 .    thus , for any @xmath542 , we first choose @xmath551 .",
    "then , we find an @xmath552 such that @xmath553 implies that @xmath554 for all @xmath78 and @xmath515 if we remove the discontinuities in @xmath28 .",
    "then , if necessary , @xmath555 is increased to @xmath120 so that @xmath536 implies that @xmath556 and @xmath557 . if no increase is necessary , then @xmath558 . with this choice of @xmath526 , @xmath559 . as a result ,",
    "for any @xmath271 , we can find an @xmath120 such that @xmath536 implies that @xmath560 .",
    "thus , @xmath206 is continuous .",
    "* proof of theorem  [ theorem : main - delay ] .",
    "* let us start by writing ( [ eq : timesync - aggwaveform - withdelayandfix ] ) as @xmath561 where @xmath562 .",
    "recall that the dependence on @xmath220 comes from the fact that the density of @xmath33 is a function of @xmath51 which is characterized by @xmath153 .",
    "this notation is analogous to the notation used in section  [ sec : pulseproperties ] . following the steps in the proof of lemma  [ lemma : polarity_positive ]",
    ", we can quickly show that the limiting aggregate waveform at node @xmath29 will take on the form @xmath563 where @xmath564 with @xmath565 .",
    "therefore , we can prove theorem  [ theorem : main - delay ] in two steps :    * to show that @xmath266 is odd about @xmath32 , we need to show that @xmath566 is odd in @xmath78 about @xmath32 , i.e. @xmath567 for @xmath568 . * to show a zero - crossing at @xmath32 , show that @xmath569 .",
    "we first show that @xmath567 for @xmath208 . using the fact that @xmath570 and @xmath571 , we have the following : @xmath572)\\big ) \\\\ & \\stackrel{\\small{(a)}}{= } & -e\\big(a_{max}g(-d_{fix } ) g(d_{j , i } ) p(-\\xi+[t_{i}+d_{fix}+d_{j , i}])\\big ) \\\\ & = & -a_{max}\\int_{-\\infty}^{\\infty } \\int_{-\\infty}^{0 } \\int_{0}^{\\infty}g(-y)g(x)p(-\\xi+[\\psi+y+x])f_{d_{j}}(x ) f_{d_{fix}}(y ) f_{t}(\\psi , s)dx dy d\\psi \\\\ & \\stackrel{\\small{(b)}}{= } & a_{max}\\int_{\\infty}^{-\\infty } \\int_{\\infty}^{0 } \\int_{0}^{-\\infty}g(z)g(-u)p(-\\xi-[w+z+u])f_{d_{j}}(-u ) f_{d_{fix}}(-z ) f_{t}(-w , s)du dz dw \\\\ & \\stackrel{\\small{(c)}}{= } & -a_{max}\\int_{-\\infty}^{\\infty } \\int_{-\\infty}^{0 } \\int_{0}^{\\infty}g(-u)g(z)p(-\\xi-[w+u+z])f_{d_{j}}(z ) f_{d_{fix}}(u ) f_{t}(w , s)dz du dw \\\\ & = & -e\\big(a_{max}g(-d_{fix } ) g(d_{j , i } ) p(-\\xi-[t_{i}+d_{fix}+d_{j , i}])\\big ) \\\\ & = & -e(\\tilde{m}_{i}(\\tau_{0}-\\xi , s)),\\end{aligned}\\ ] ] where @xmath573 follows because @xmath574 and at @xmath575 we did a change of variables with @xmath576 , @xmath577 , and @xmath578",
    ". @xmath579 follows from @xmath580 and @xmath581 .",
    "we thus have @xmath567 for @xmath568 .",
    "an - swol hu was born in new york state and grew up in california .",
    "he received his b.s . in electrical engineering from stanford university in 2002 .",
    "currently he is a ph.d .",
    "candidate in the school of electrical and computer engineering at cornell university .",
    "his research interests include applied statistics and statistical signal processing , with applications to sensor networks .",
    "sergio d.  servetto was born in argentina , on january 18 , 1968 .",
    "he received a licenciatura en informatica from universidad nacional de la plata ( unlp , argentina ) in 1992 , and the m.sc .",
    "degree in electrical engineering and the ph.d .",
    "degree in computer science from the university of illinois at urbana - champaign ( uiuc ) , in 1996 and 1999 . between 1999 and 2001 , he worked at the ecole polytechnique federale de lausanne ( epfl ) , lausanne , switzerland . since fall 2001",
    ", he has been an assistant professor in the school of electrical and computer engineering at cornell university , and a member of the field of applied mathematics .",
    "he was the recipient of the 1998 ray ozzie fellowship , given to `` outstanding graduate students in computer science , '' and of the 1999 david j. kuck outstanding thesis award , for the best doctoral dissertation of the year , both from the dept .",
    "of computer science at uiuc .",
    "he is also the recipient of a 2003 nsf career award .",
    "his research interests are centered around information theoretic aspects of networked systems , with a current emphasis on problems that arise in the context of large - scale sensor networks ."
  ],
  "abstract_text": [
    "<S> _ the problem of time synchronization in dense wireless networks is considered . </S>",
    "<S> well established synchronization techniques suffer from an inherent scalability problem in that synchronization errors grow with an increasing number of hops across the network . in this work , a model for communication in wireless networks </S>",
    "<S> is first developed , and then the model is used to define a new time synchronization mechanism . </S>",
    "<S> a salient feature of the proposed method is that , in the regime of asymptotically dense networks , it can average out all random errors and maintain global synchronization in the sense that all nodes in the multi - hop network can see identical timing signals . </S>",
    "<S> this is irrespective of the distance separating any two nodes . _    </S>",
    "<S> ( 0,0 ) ( 0,78)to appear in the ieee transactions on information theory .    </S>",
    "<S> cooperation in networks , large network asymptotics , relay networks , scalability , sensor networks , time synchronization , wireless communications . </S>"
  ]
}