{
  "article_text": [
    "random matrix theory is of importance for both its conceptual and its predictive powers . at a conceptual level",
    ", there is the three fold way classification of global time reversal symmetries of hamiltonians for chaotic quantum systems @xcite , later extended to ten by the inclusion of chiral and topological symmetries @xcite . for each of the ten hamiltonians",
    "there is an ensemble of random hermitian matrices , which in turn are the hermitian part of the ten matrix lie algebras associated with the infinite families of symmetric spaces .",
    "the symmetric spaces themselves give rise to ten ensembles of random unitary matrices @xcite .    to see how the formulation of ensembles leads to a predictive statement , consider for definiteness the three fold way classification of hamiltonians for chaotic quantum systems .",
    "the basic hypothesis , initiated by wigner @xcite and dyson @xcite , and refined by bohigas et al .",
    "@xcite , is that a quantum mechanical system for which the underlying classical mechanics is chaotic , will , for large energies have the same statistical distribution as the bulk scaled eigenvalues of the relevant ensemble of hermitian matrices .",
    "the particular ensemble is determined by the presence or absence of a time reversal symmetry , with the former consisting of two subcases depending on the time reversal operator @xmath2 being such that @xmath3 , or @xmath4 ; see e.g.  ( * ? ? ?",
    "* ch .  1 ) .",
    "this becomes predictive upon the specification of the statistical distributions for the bulk scaled eigenvalues of the random matrix ensemble .",
    "thus , according to the hypothesis , these same distributions will be exhibited by the point process formed from the highly excited energy levels of a chaotic quantum system .",
    "the point process can be realised in laboratory experiments of nuclear excitations ( see e.g.  @xcite ) , and microwave billiards @xcite , amongst other examples .",
    "arguably the most spectacular example of both the conceptual and predictive powers of random matrix theory shows itself in relation to the riemann zeta function @xmath5 .",
    "the celebrated riemann hypothesis asserts that all the complex zeros of @xmath5 are of the form @xmath6 , with @xmath7 .",
    "the montgomery - odlyzko law asserts that for large @xmath8 these zeros  referred to as the riemann zeros  have the same statistical properties as the bulk eigenvalues of large hermitian random matrices with complex elements . but from the three fold way ,",
    "the latter is the ensemble of random hermitian matrices giving the statistical properties of the large energy levels of a chaotic quantum mechanical system without a time reversal symmetry .",
    "the implied relationship between the riemann zeros and quantum chaos is consistent with and extends the hilbert - plya conjecture @xcite asserting that the riemann zeros correspond to the eigenvalues of some ( unknown ) unbounded self - adjoint operator ; see @xcite for contemporary research on this topic .    to realise the predictive consequences of this link between two seemingly unrelated quantities  the riemann zeros and chaotic quantum hamiltonians without time reversal symmetry",
    " requires a list of the riemann zeros for large @xmath8 .",
    "such a list has been provided by odlyzko @xcite , who in a celebrated numerical computation has provided the high precision evaluation of the @xmath9-th riemann zero and over 70 million of its neighbours . from this data",
    "set the veracity of the montgomery - odlyzko law can be tested .",
    "primary statistical quantities for this purpose include the two - point correlation function @xmath10  which measures the density of zeros a distance @xmath11 from @xmath12 , with @xmath12 itself averaged over a window of zeros which itself is large , but still small relative to @xmath12  and the spacing distribution @xmath13 for the event that the @xmath14-th next ( in consecutive order ) neighbours - th next neighbour of the item @xmath15 is item @xmath16 . ]",
    "are a distance @xmath11 apart .",
    "as displayed in @xcite , at a graphical level the agreement between the riemann zero data and the predictions of random matrix theory is seemingly exact .",
    "although zeros of order @xmath9 are huge on an absolute scale , it turns out that convergence to random matrix predictions occurs on a scale where @xmath17 plays the role of @xmath1 , giving rise to potentially significant finite size effects .",
    "such effects were first considered in the work of keating and snaith @xcite in their study of the statistical properties of the value distribution of the logarithm of the riemann zeta function on @xmath18 with @xmath19 large .",
    "quite unexpectedly they showed that the finite size corrections could be understood by introducing as a model for the riemann zeros the eigenvalues of haar distributed unitary random matrices from u@xmath20 , instead of complex hermitian random matrices .",
    "it had been known since the work of dyson @xcite that the eigenvalues for haar distributed unitary random matrices from u@xmath20 and complex hermitian random matrices with gaussian entries have the same limiting statistical distribution .",
    "but for finite @xmath1 they are fundamentally different , with the former being rotationally invariant while the spectral density of the latter is given by the wigner semi - circle law and thus has edge effects .",
    "odlyzko s work on the computation of large riemann zeros is ongoing . in @xcite",
    "he announced a data set beginning with the @xmath21-nd zero and its next @xmath22 neighbours .",
    "taking advantage of the great statistical accuracy offered by this data set , the finite size correction for the deviation of the empirical nearest neighbour spacing distribution and the limiting random matrix prediction was displayed , and shown to have structure .",
    "to explain the functional form of this correction , in keeping with the work of keating and snaith , bogomolny and collaborators @xcite were able to present analytic evidence that the correction term could again be understood in terms of a model of eigenvalues from haar distributed u@xmath20 matrices .",
    "more explicitly , let @xmath23 refer to the spacing distribution between consecutive eigenvalues for haar distributed unitary random matrices , with the angles of the eigenvalues rescaled to have mean spacing unity .",
    "the study @xcite calls for the functional form of @xmath24 in the large @xmath1 expansion @xmath25 here the subscript  2 \" on the rhs is the label from dyson s three fold way in the case of no time reversal symmetry . as a straightforward application of the pioneering work of mehta @xcite and gaudin @xcite , dyson @xcite showed that @xmath26 where @xmath27 is the integral operator on @xmath28 with kernel @xmath29 twenty years later this fredholm determinant evaluation was put in the context of painlev theory by the kyoto school of jimbo et al .",
    "@xcite , who showed @xmath30 where @xmath31 satisfies the differential equation ( an example of the painlev v equation in sigma form ) @xmath32 with small @xmath33 boundary conditions @xmath34 note that the parameter @xmath35 introduced in ( [ ks ] ) only enters in the characterisation through the boundary condition ; we refer to  ( * ? ? ?",
    "8) for background theory relating to the painlev equations as they occur in random matrix theory .    in @xcite the leading correction term @xmath24",
    "was estimated using a numerical extrapolation from the tabulation of @xmath36 . in @xcite",
    "the task of finding analytic forms for @xmath24 was addressed .",
    "one first notes that analogous to the formula ( [ 2 ] ) one has , for finite @xmath1 , @xmath37 where @xmath38 is the integral operator on @xmath28 with kernel @xmath39 expanding now for large @xmath1 gives @xmath40 where the leading correction term in this expansion is given explicitly by @xmath41 it was observed in @xcite ( cf . also lemma  [ lem : folklore ] below ) that this expansion lifts to @xmath42 where @xmath43 is as in ( [ 3a ] ) and",
    "@xmath44 is the integral operator on @xmath28 with kernel @xmath45 ; the leading correction is now given by the operator expression @xmath46 which is _ linear _ in @xmath47 .",
    "substituting in ( [ 1a ] ) and comparing to ( [ 1 ] ) we read off that @xmath48 in section  [ sub : numerical ] of the present paper the problem addressed is how to use such formulae to provide a high precision numerical tabulation of @xmath49 . in the case @xmath50 we exhibit the resulting functional form in odlyzko s data set for the riemann zeros ; see section [ sect : riemann ] .    an expression for the large @xmath1 expansion of the fredholm determinant in ( [ 1a ] ) involving painlev transcendents",
    "was also given in @xcite .",
    "thus it was shown that @xmath51 as noted above , @xmath52 satisfies the particular painlev v equation in sigma form ( [ d1 ] ) with boundary condition ( [ d2 ] ) , with only the latter depending on @xmath35 .",
    "the transcendent @xmath53 was characterised as the solution of the second order , linear differential equation @xmath54 where , with @xmath55 , @xmath56 and fulfilling the @xmath57 boundary condition @xmath58 substituting ( [ 2.13d ] ) in ( [ 1a ] ) and comparing to ( [ 1 ] ) we read off that @xmath59 by using a nested power series method to solve the differential equation ( [ sig2 ] ) numerically , this expression was used in @xcite to determine the graphical form of @xmath24 , and also to determine its small and large @xmath11 expansions .",
    "however , the operator approach advocated in the present paper is simpler and more straightforward to use numerically .",
    "random unitary matrices from u@xmath20 chosen with haar measure form one of dyson s three circular ensembles of unitary random matrices coming from the considerations of the three fold way , and in this context is referred to as the circular unitary ensemble ( cue ) .",
    "the other two circular ensembles are the circular orthogonal ensemble ( coe ) of symmetric unitary matrices , and the circular symplectic ensemble ( cse ) of self dual unitary matrices .",
    "we will show that our methods can be adapted to provide a systematic investigation of the leading correction in the large @xmath1 expansion of spacing distributions for each of these examples .",
    "after some preparatory material on the expansion of operator determinants and numerical methods for evaluating the corresponding terms in section  [ sect : prep ] , we begin in section  [ sect : cue ] by extending the study initiated in @xcite on this problem as it applies to cue matrices .",
    "the first question addressed is the computation of the leading order correction term in the large @xmath1 expansion of @xmath60 , or equivalently @xmath61 , in terms of an integral operator formula extending ( [ tq1 ] ) .",
    "we then do the same in the circumstance that each eigenvalue has been deleted independently at random with probability @xmath62 .",
    "such a thinning procedure , well known in the theory of point processes ( see e.g.  @xcite ) , was introduced into random matrix theory by bohigas and pato @xcite , and has been applied to odlyzko s data set for the riemann zeros in @xcite . continuing with the point process perspective ,",
    "next we consider the setting of a translationally invariant one - dimensional point process , normalised to have average spacing unity , superimposed with a poisson point process .",
    "our interest is in the distribution of the minimum distance from each poisson point to a point in the original process . in an ensemble",
    "setting , this is equivalent to computing the minimum distance from the origin of a point in the original process . for cue matrices",
    "the distribution can be expressed in a form analogous to , which allows the statistic to be expanded for large @xmath1 . in the final subsection of section  [",
    "sect : cue ] , the statistic for the nearest neighbor spacing , that is , the minimum of the spacing distance between left and right neighbours in the cue is similarly studied . in section  [",
    "sect : riemann ] our results are compared against empirical findings from odlyzko s data set for the riemann zeros . there",
    "we will use a unique @xmath63 correction of the cue correlation kernel that was observed in the study @xcite to match the corresponding @xmath63 terms of the two- and three - point correlation functions . including this term in the numerical calculations",
    "systematically improves the fit to the empirical data .",
    "the study of spacing distributions for matrices from the coe and cse is more involved than for cue matrices .",
    "the reason is that the latter is based on the single integral operator @xmath64 with kernel ( [ 3 ] ) , whereas the pathway to tractable expressions in the case of the coe and cse makes use of inter - relations between gap probabilities .",
    "the necessary theory is covered in the first part of section  [ sect : coecse ] .",
    "in the second part of section  [ sect : coecse ] we give the leading correction term for the large @xmath1 expansion of @xmath65 where @xmath66 for the coe and @xmath67 for the cse , in terms of a characterisation analogous to ( [ 2.13d ] ) and ( [ sig2 ] ) .",
    "the parameter @xmath35 specifies the thinning probability .      in this paper",
    "we discuss finite size effects up to an error @xmath68 , with @xmath1 in the odlyzko data set of riemann zeros being effectively @xmath69 .",
    "we choose the same order of magnitude of @xmath1 for the simulations of the circular ensembles .",
    "now , by the law of large numbers , sampling is known to introduce a statistical error of about @xmath70 where @xmath71 denotes the sample size .",
    "hence , pushing the sampling error to the same order of magnitude as the remaining finite size error thus requires a sampling size of @xmath72 .",
    "this was actually the choice for our simulations and is well matched by the odlyzko data set of a little more than @xmath73 zeros .",
    "however , observing structure also in the @xmath68 remainder term would hence require to increase the sampling size by at least two to four orders of magnitude .",
    "this is only possible with parallel processing and a subtle memory management of the resulting gigantic data sets ( the raw material provided by odlyzko is already about 22 gb in size ) .",
    "the integral operator formulae of this paper are based on the following _ folklore _ lemma , which we prove here for ease of reference .",
    "[ lem : folklore ] let @xmath74 be a bounded interval and let @xmath75 , @xmath76 , @xmath77 be continuously differentiable kernels on @xmath78 .",
    "if the expansion @xmath79 holds uniformly up to the first derivatives as @xmath80 , then it lifts as an expansion @xmath81 of the induced integral operators on @xmath82 in trace - class norm .",
    "if @xmath83 , the operator determinant expands as    @xmath84    with the leading correction term given by is the frchet derivative of the map @xmath85 under the identification of the dual of the space of trace - class operators with the space of bounded operators , see ( * ? ? ?",
    "the derivative of that map in the direction of the bounded operator @xmath47 is thus given by @xmath86 . by analytic continuation",
    "this interpretation of the expression @xmath87 extends well to the case that @xmath88 . ]",
    "@xmath89    an expression that is linear in @xmath47 .    on _ bounded _",
    "intervals @xmath74 , continuously differentiable kernels @xmath76 induce integral operators @xmath90 on @xmath82 that are trace - class : using the fundamental theorem of calculus one can represent them straightforwardly as the sum of a rank - one operator and a product of two hilbert  schmidt operators , see , e.g. , @xcite . by the same construction the expansion lifts from kernels in @xmath91-norm to operators in trace - class norm .",
    "now , using the multiplicativity of the operator determinant we get first that @xmath92 truncating the series definition of the operator determinant in terms of exterior products , see , e.g. , ( * ? ?",
    "* eq .  ( 3.5 ) ) , @xmath93 at the second term we get next that @xmath94 which completes the proof .",
    "the computations for all figures of this paper are based on the numerical evaluation of operator terms such as @xmath95 or @xmath87 .",
    "in fact , there is an extension of the numerical method introduced in @xcite for the operator determinant that facilitates the efficient highly - accurate evaluation of such terms with exponential convergence such that the approximation error is @xmath96 where @xmath97 denotes the dimension parameter of the method ( e.g. , the number of quadrature points ) . ] if the kernels extend analytically into the complex domain . given a quadrature method @xmath98 with _ positive _ weights @xmath99 , we associate with an integral operator @xmath90 on @xmath82 with the kernel @xmath76 the _ nystrm matrix _",
    "@xmath100 for compact intervals @xmath74 the best choice for smooth @xmath101 is gauss  legendre quadrature , for which recently a super - fast algorithm of @xmath102 complexity has been found @xcite ; it converges exponentially fast if @xmath101 extends analytically into the complex domain .    as was shown in (",
    "6.2 ) , these convergence properties are inherited by the determinant of the nystrm matrix as an approximation of the operator determinant , namely @xmath103 where @xmath104 denotes the identity operator in @xmath82 on the left and the @xmath105 identity matrix on the right . in particular , the convergence is exponential if the kernel @xmath106 extends analytically into the complex domain .",
    "now , the same method of replacing the integral operator by the associated nystrm matrix applies to the approximation of quite general operator terms .",
    "we give four examples :    * the trace is approximated straightforwardly by the quadrature formula as @xmath107 * operator products are approximated by matrix products , that is , @xmath108 this follows from @xmath109 * the resolvent kernel @xmath110 of the operator @xmath111 satisfies the integral equation @xmath112 for all @xmath113 .",
    "application of the quadrature rule gives with @xmath114 @xmath115 that is @xmath116 and therefore @xmath117 .",
    "* by combining all the examples so far , we get @xmath118    in all the examples the convergence properties are inherited from the underlying quadrature formula ; in particular , the convergence is exponential if the kernels extend analytically to the complex domain .",
    "the proof is straightforward in the first two examples and follows from the theory of the nystrm method for integral equations in the third one ; the fourth is a combination of all the previous results .",
    "the numerical derivatives with respect to the @xmath11 and @xmath119 variables of the generating functions for the spacing distributions are computed in exactly the same fashion as discussed in @xcite , that is , based on chebyshev expansions with respect to @xmath11 and contour integration with respect to @xmath119 .",
    "the actual implementation and use of this methodology within the matlab toolbox of @xcite is described in the appendix of the present paper .",
    "the sequence of angles , to be referred to as eigen - angles , specifying the eigenvalues of a unitary random matrix from any of the three circular ensembles forms a point process on @xmath120 $ ] with uniform density @xmath121 . due to the rotational symmetry , the spacing distributions of the angles , @xmath122 with @xmath123 for the coe , cue , cse respectively , and @xmath124 ,",
    "are thus independent of the absolute location of the eigenvalues .",
    "if there is an eigen - angle at @xmath12 and at @xmath125 , we may rotate all the angles so that @xmath12 becomes the origin , and speak of a spacing of size @xmath11",
    ". let us do this , and also normalise the angles so that the mean spacing is unity .",
    "fundamental to the study of spacing distributions @xmath122 are the so - called gap probabilities @xmath126 .",
    "the latter specify the probability that an interval of size @xmath11 contains exactly @xmath127 eigen - angles for @xmath128 matrices .",
    "specifically , let us introduce the generating functions @xmath129 of course the naming on the lhs s represent an abuse of notation , due to the same functional forms also appearing on the rhs ; however the appearance of the generating function symbol @xmath119 is enough to distinguish the different quantities .",
    "we have the relationship between generating functions ( see e.g.  ( * ? ? ?",
    "8.1 ) ) @xmath130 or equivalently the formula @xmath131    also fundamental is the relationship between the generating function ( [ g2 ] ) and the @xmath14-point correlation functions @xmath132 .",
    "thus we have ( see e.g.  ( * ? ? ?",
    "9.1.1 ) ) @xmath133 the eigenvalues for the cue form a determinantal point process , while the eigenvalues for the coe and cse form pfaffian point processes ; see e.g.  ( * ? ? ?",
    "* chapters  5 and 6 ) .",
    "specifically , in the case of the cue we have @xmath134_{j , l=1,\\dots , k},\\ ] ] where @xmath135 is given by ( [ 3 ] ) , while the analogous formula for the coe and cse involves a pfaffian of a @xmath136 anti - symmetric kernel function .",
    "this structural difference distinguishes the case of the cue and thus makes it simpler .      substituting ( [ rk ] ) in ( [ er ] ) , and making use of a standard expansion formula in the theory of fredholm integral operators ( see e.g.  ( * ? ? ?",
    "* eq .  ( 3.14 ) ) ) gives @xmath137 now substituting the expansion ( [ tq0 ] ) in ( [ rk1 ] ) and substituting the result in ( [ g3 ] ) we read off the large @xmath1 expansion to second order .",
    "[ p1 ] we have @xmath138 where @xmath139 and @xmath140 in particular @xmath141 and @xmath142      the operation of thinning applied to a point process refers to the procedure of independently deleting each point in a sample with probability @xmath62 , @xmath143 . with the @xmath14-point correlation function before thinning being given by @xmath144 , the @xmath14-point correlation function after thinning is simply @xmath145 , due to the independence .",
    "it thus follows from ( [ er ] ) , that the generating function for the gap probability in the presence of thinning , @xmath146 say , is related to the generating function for the gap probability without thinning by @xmath147 specialising further to the cue we can substitute ( [ rk1 ] ) in the rhs of this expression to conclude @xmath148 the analogues of ( [ g3 ] ) and ( [ g4 ] ) for the spacing probabilities are @xmath149    using the first of these , together with ( [ rk1 ] ) and the expansion ( [ tq0 ] ) we can write down the analogue of proposition [ p1 ] .    [ p1a ] we have @xmath150 where @xmath151 and @xmath152 in particular @xmath153 and @xmath154    implementation of these formulae according to the method of section  [ sub : numerical ] will be carried out in section  [ sect : riemann ] , in the context of a comparison with the corresponding statistics for odlyzko s data set of the riemann zeros .    ) .",
    "left panel : a histogram of empirical data from @xmath155 with @xmath156 scaled to unit mean spacing , computed using a bin size of 0.01 and @xmath157 samples from @xmath155 , for each of which @xmath158 samples of a uniformly distributed random origin were drawn ( blue dots ) ; the large @xmath1 limit @xmath159 ( red solid line ) .",
    "right panel : the simulation data minus @xmath159 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath161 ( red solid line).,title=\"fig:\",scaledwidth=55.0% ] ) . left panel : a histogram of empirical data from @xmath155 with @xmath156 scaled to unit mean spacing , computed using a bin size of 0.01 and @xmath157 samples from @xmath155 , for each of which @xmath158 samples of a uniformly distributed random origin were drawn ( blue dots ) ; the large @xmath1 limit @xmath159 ( red solid line ) .",
    "right panel : the simulation data minus @xmath159 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath161 ( red solid line).,title=\"fig:\",scaledwidth=55.0% ]     but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]   but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]      the quantity @xmath163 is the probability that there are no eigenvalues in the interval @xmath164 of the scaled c@xmath165e .",
    "differentiating this quantity with respect to @xmath11 gives the probability density function @xmath166 for the scaled eigen - angle closest to the origin , @xmath167 in the case @xmath168 with thinning , it follows from ( [ th1 ] ) , as well as the translation invariance of the sine kernel , that @xmath169 use of ( [ 2.13d ] ) gives a characterisation of the leading two terms of the large @xmath1 expansion of this quantity .",
    "we have @xmath170 where in terms of integral operators @xmath171 alternatively , in terms of the transcendents @xmath172 and @xmath173 defined in @xmath174 and @xmath175    to simulate this quantity in translationally invariant empirical data such as the @xmath176 itself , one can actually draw the origin uniformly and independently within the interval for which the data are defined ( that is , one superimposes a poisson point process defining the origin ) . to prepare for corresponding computations within a large set of riemann zeros this was done , as a proof of concept , for cue matrices in figs .  [ fig:5 ] and figs .  [ fig:6 ] .",
    "a variant of the spacing distribution between consecutive eigenvalues is the spacing distribution between nearest neighbour eigenvalues @xcite . for this , at each eigenvalue one measures the smallest of the spacings to the eigenvalue immediately to the left , and the spacing immediately to the right . in a theoretical ensemble formulation ,",
    "the system is to be conditioned so that there is an eigenvalue at the origin .",
    "consider in particular the cue with eigen - angles scaled to have unit spacing . with @xmath177 denoting the @xmath97-point correlation function for the conditioned system in the presence of thinning , we have @xmath178 where the second line follows from ( [ rk ] ) and ( [ 3 ] ) , together with elementary row operations applied to the determinant .",
    "let the entry of the determinant in ( [ 2.25 ] ) be denoted by @xmath179 , and denote the corresponding integral operator supported on @xmath180 by @xmath181 .",
    "analogous to  ( [ 2.20a ] ) , the scaled nearest neighbour spacing in the presence of thinning is then @xmath182 by observing @xmath183 we can read off from ( [ 2.21a ] ) , upon expanding the kernel to order @xmath184 , integral operator formulae for the leading two terms analogous to ( [ 2.25x ] ) .    in terms of the notation and ,",
    "let @xmath185 denote by @xmath186 and @xmath187 the integral operators on @xmath188 with kernels @xmath189 and @xmath190 respectively .",
    "we have @xmath191 where @xmath192    in @xcite a painlev transcendent evaluation of @xmath193 has been given ; see also @xcite .",
    "-st next neighbour spacing : riemann zeros data vs. random - matrix based prediction with effective dimension @xmath194 , no thinning ( @xmath195 ) . left panel : a histogram of the odlyzko data set with bin size @xmath196 ( blue dots ) ; the large @xmath1 limit @xmath197 ( red solid line ) .",
    "right panel : the riemann zero data minus @xmath197 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath198 with interior rescaling ( red solid line ) , exterior rescaling ( thin black line ) and no rescaling ( dashed green line).,title=\"fig:\",scaledwidth=55.0% ] -st next neighbour spacing : riemann zeros data vs. random - matrix based prediction with effective dimension @xmath194 , no thinning ( @xmath195 ) . left panel : a histogram of the odlyzko data set with bin size @xmath196 ( blue dots ) ; the large @xmath1 limit @xmath197 ( red solid line ) .",
    "right panel : the riemann zero data minus @xmath197 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath198 with interior rescaling ( red solid line ) , exterior rescaling ( thin black line ) and no rescaling ( dashed green line).,title=\"fig:\",scaledwidth=55.0% ]    [ fig:1 ]",
    "starting with the 1973 seminal work of montgomery there have been significant developments on a deep ( conjectural ) connection between the statistics of the fluctuation properties of the zeros of the riemann zeta function on the critical axis @xmath18 and those of the eigen - angles of @xmath199 , supported by large - scale numerical calculations based on the extensive tables of riemann zeros provides by odlyzko , see , e.g. , @xcite and the literature cited therein . answering a question of odlyzko @xcite , who had posed the challenge of understanding the structure in the numerical difference graph between the riemann zeta spacing distribution for a set of zeros of large height and the ( conjectured ) asymptotics , finite size effects of this statistic",
    "were studied in  @xcite .",
    "this study gave a precise quantitative association of riemann zeros @xmath200 at height @xmath8 to a ( formal ) size @xmath1 of the corresponding @xmath199 .",
    "using the hardy  littlewood conjecture of the distribution of prime pairs , bogomonly and keating @xcite had earlier given an analytic expression for the pair correlation of the riemann zeros .",
    "the authors of @xcite expanded this for large height @xmath8 , with the local density normalized to unity , to obtain @xmath201 where @xmath202 denotes the smooth asymptotic density of zeros at @xmath8 and @xmath203 , @xmath204 are the following constants ( with @xmath205 the stieltjes constants and @xmath206 summation over the primes ) : ] and the method of @xcite to the sums over the primes . ]",
    "@xmath207 on the other hand , the pair correlation function @xmath208 of @xmath199 , normalized to mean spacing unity , expands by as @xmath209 by matching the first correction terms of and the authors of @xcite got as effective dimension @xmath1 of a @xmath199 at height @xmath8 @xmath210 this way one has the ( conjectural ) approximation @xmath211     but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]   but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]      as noted in @xcite a rescaling of the @xmath11-variable in the leading correction term of the @xmath212-expansion of the two - point functions absorbs the @xmath213 term , respectively the @xmath63 term : @xmath214 where @xmath215 that is , one gets an @xmath216 approximation of @xmath217 by expanding @xmath218 into powers of @xmath219 and rescaling the @xmath11-variable of the leading correction term by @xmath220 .",
    "it was suggested in @xcite to apply the same procedure , that is , @xmath220-rescaling the @xmath11-variable of the leading correction term of a @xmath199 based expansion , to improve the fit even for more general statistics , such as the spacing distribution originally considered by odlyzko . in @xcite",
    "it was successfully applied to improve the fit of the cue leading correction term to the spacing distribution in the presence of thinning .",
    ", no thinning ( @xmath195 ) . left panel : a histogram of the odlyzko data set with bin size @xmath196 ( blue dots ) , where the approximately @xmath22 zeros were broken into 1024 sets of nearly equal size , for each of which @xmath221 samples of a uniformly distributed random origin were drawn ; the large @xmath1 limit @xmath159 ( red solid line ) .",
    "right panel : the riemann zero data minus @xmath159 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath161 with interior rescaling ( red solid line ) , exterior rescaling ( thin black line ) and no rescaling ( dashed green line).,title=\"fig:\",scaledwidth=55.0% ] , no thinning ( @xmath195 ) .",
    "left panel : a histogram of the odlyzko data set with bin size @xmath196 ( blue dots ) , where the approximately @xmath22 zeros were broken into 1024 sets of nearly equal size , for each of which @xmath221 samples of a uniformly distributed random origin were drawn ; the large @xmath1 limit @xmath159 ( red solid line ) .",
    "right panel : the riemann zero data minus @xmath159 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath161 with interior rescaling ( red solid line ) , exterior rescaling ( thin black line ) and no rescaling ( dashed green line).,title=\"fig:\",scaledwidth=55.0% ]     but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]   but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]      the numerical data , physical arguments and mathematical conjectures surrounding the fluctuations of the riemann zeros indicate that their statistics is asymptotically well approximated , to more than just leading order , by some correlation kernel @xmath222 . consequently , to justify the mechanism of the exterior rescaling introduced in the last paragraph , @xcite suggested to pull - back the absorption of the @xmath213 term from the two - point function into the expansion of such an assumed kernel . in the present paper",
    "we will use such an expansion to improve systematically the @xmath199 fit of the fluctuation properties of the riemann zeros statistics from @xmath63 to @xmath68 .    by modifying the expansion   of the cue correlation kernel @xmath223 to include an @xmath63 term ,",
    "@xmath224 the task is thus to identify the unknown kernel @xmath225 from the @xmath63 term in . by translation invariance and symmetry of the kernel @xmath222 and by the normalization @xmath226 to mean spacing unity , we get the form @xmath227 of a convolution kernel with a _ symmetric _",
    "function @xmath228 satisfying @xmath229 . a brief calculation results in the corresponding two - point function @xmath230 matching with gives , cf . the first equality in ( * ? ? ?",
    "* eq .  ( 28 ) ) , @xmath231 in the appendix of @xcite it is shown that this expansion of the kernel allows to reproduce consistently a conjectural expansion of the three - point function ( which was obtained from a calculation published much later in @xcite ) .",
    "this is further evidence that the kernel expansion induces , quite generally , the @xmath232 correction terms in the determinantal point process fluctuations statistics .",
    "now , the correction kernel @xmath71 can be absorbed easily by an _ interior _ rescaling of the leading correction kernel @xmath45 , namely by introducing @xmath233 which expands as @xmath234 , where would be the same as @xmath220 . ]",
    "@xmath235 to summarize , we have @xmath236 and thus get the following recipe to go from the leading correction term of a @xmath199 fluctuation statistics to the corresponding one of the riemann zeros : simply replace the leading correction kernel @xmath45 by its interior rescaling @xmath237 .    in our experiments , the most pronounced difference between interior and exterior rescaling",
    "can be observed in the statistics shown in the right panel of fig .",
    "[ fig:4 ] .      the largest data set of riemann zeros currently provided by odlyzko , which was announced already in @xcite , consists of the @xmath238 consecutive zeros starting with zero number @xmath239 the first of them has height @xmath240 while the last one has height @xmath241 because of the logarithmic dependence on the height , even within that large data set the smooth density @xmath212 , the effective dimension @xmath1 and the scaling parameters @xmath220 , @xmath242 remain essentially _ constant _ to 15 digits precision , @xmath243    from this data set we extracted various spacing statistics ,- th next neighbour spacing can be found in ( * ? ? ? * figs .",
    "12 ) ( no thinning and no theoretical prediction of the leading correction term ) , in ( * ? ? ?",
    "13 ) ( no thinning , exterior rescaling only ) and in ( * ? ? ?",
    "910 ) ( exterior rescaling only ) .",
    "since in this case there is no difference visible between interior and exterior rescaling we refrained from showing the results once more . ] with ( @xmath162 ) and without ( @xmath195 ) thinning , and compared them up to the leading correction with the theoretical prediction in terms of operator determinants @xmath244 and their corrections @xmath87 as obtained in section  [ sect : cue ] for the cue . in figs .",
    "[ fig:1][fig:8 ] the riemann zero data are shown as blue dots , the leading order term as a red solid line , and the correction terms    * with interior rescaling @xmath245 as a red solid line , * with exterior rescaling @xmath246 as a thin black line , * without rescaling as a green dashed line .",
    "in particular , the following statistics of the riemann zeros are shown to be in excellent agreement up to the leading correction term with ( interior ) rescaling :    [ cols=\"^,^,^,^,^\",options=\"header \" , ]     here we denote by @xmath247 those probability densities for the riemann zeros that are defined analogously to the cue case @xmath248 .    , no thinning ( @xmath195 ) . left panel : a histogram of the odlyzko data set with bin size @xmath196 ( blue dots ) ; the large @xmath1 limit @xmath249 ( red solid line ) .",
    "right panel : the riemann zero data minus @xmath249 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath250 with interior rescaling ( red solid line ) , exterior rescaling ( thin black line ) and no rescaling ( dashed green line).,title=\"fig:\",scaledwidth=55.0% ] , no thinning ( @xmath195 ) . left panel : a histogram of the odlyzko data set with bin size @xmath196 ( blue dots ) ; the large @xmath1 limit @xmath249 ( red solid line ) .",
    "right panel : the riemann zero data minus @xmath249 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath250 with interior rescaling ( red solid line ) , exterior rescaling ( thin black line ) and no rescaling ( dashed green line).,title=\"fig:\",scaledwidth=55.0% ]     but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]   but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]",
    "as already mentioned , the fact that the eigenvalues of coe matrices form a pfaffian point process tells us that the counterpart to the formula ( [ rk ] ) involves a pfaffian of a @xmath136 anti - symmetric kernel function . substituting this in ( [ er ] ) , the pfaffian analogue of the identity implying ( [ rk1 ] ) ( see e.g.  ( * ? ? ?",
    "* eq .  ( 6.32 ) ) ) allows for a pfaffian analogue in the case of the coe to be given .",
    "however , the resulting formula is not of the same practical utility as ( [ rk1 ] ) since the @xmath136 kernel function is not analytic , which in turn means that the numerical quadrature methods of section  [ sub : numerical ] have poor convergence properties .",
    "fortunately , there is a second option .",
    "this presents itself due to fundamental inter - relations between gap probabilities for the coe and cue .",
    "these also involve the gap probabilities for haar distributed orthogonal matrices from the classical groups o@xmath251 and o@xmath252 . in reference to the latter , eigenvalues on the real axis and thus corresponding to @xmath253 or @xmath254 are to be disregarded , and only the eigenvalues with angles in @xmath255 are to be considered ( the remaining eigenvalues occur at the negative of these angles , i.e.  the complex conjugates ) .",
    "the first inter - relation of interest is between the generating functions for the gap probabilities in the cue , and in haar distributed real orthogonal matrices @xcite , ( * ? ? ?",
    "* eq .  ( 8.127 ) ) @xmath256 with me denoting a particular matrix ensemble , we have used the symbol @xmath257 instead of @xmath258 to indicate that in this expression no scaling of the eigen - angles has been imposed ; this convention will be followed below .",
    "to present the next inter - relation , introduce the generating functions @xmath259 with coe@xmath260coe denoting the point process of @xmath261 eigenvalues on the circle that results by superimposing the eigenvalue sequences of two independent coe matrices , a result conjectured by dyson @xcite and proved by gunson @xcite gives that @xmath262 where the operation  alt \" refers to the operation of observing every second eigenvalue only . as a consequence of this , one has that @xcite , @xcite @xmath263    according to ( [ w1 ] ) , it follows from ( [ w4 ] ) that the gap probabilities for the coe are related to those for o@xmath264 and o@xmath265 with @xmath97 suitably chosen , but this alone does not determine the former . to be able to do this , additional inter - relationships between generating functions are required . in the case @xmath266 and thus @xmath1 even , the additional inter - relationships have been given in @xcite according to the generating function identity @xmath267 note that ( [ w5 ] ) substituted in ( [ w4 ] ) is consistent with ( [ w1 ] ) in the case @xmath1 even .",
    "the identity ( [ w5 ] ) has very recently @xcite been shown to be a corollary of the identities between eigenvalue distributions @xmath268 here the notation @xmath269 refers to the eigenvalue distribution of @xmath270 coe matrices , while @xmath271 refers to the distribution in the circumstance that the eigenvalues with angles @xmath272 are reflected in the real axis by @xmath273 , and thus all eigenvalues have angles between 0 and @xmath254 .",
    "the operation even ( odd ) refers to observing only those eigenvalues that occur an even ( odd ) number of places from @xmath253 , reading anti - clockwise .    substituting ( [ w5 ] ) in ( [ w2 ] ) , and setting @xmath274 so that @xmath275 we obtain , after some minor manipulation , a closed formula for the gap probabilities of @xmath269 in terms of the gap probabilities for @xmath276 ( * ? ? ?",
    "* eq .  ( 8.150 ) ) @xmath277    the analogue of ( [ w6 ] ) for @xmath278 allows us to deduce the analogue of ( [ w7 ] ) .",
    "we have @xmath279    we read off from ( * ? ? ?",
    "7.1 ) that @xmath280 substituting in ( [ w2 ] ) and manipulating as in the derivation of ( [ w7 ] ) gives ( [ w8 ] ) .    with @xmath281 the cases and can be combined into a single formula that holds for both parities of @xmath1 : @xmath282 the eigenvalues for @xmath283 in @xmath255 form a determinantal point process with kernel ( see e.g.  ( * ? ? ?",
    "5.5.3 ) ) @xmath284 where @xmath285 scaling the eigen - angles of @xmath286 to have unit mean spacing by @xmath287 thus yields the following result :    [ cor : coe ] let @xmath288 denote the integral operator on @xmath28 with kernel and denote @xmath274 .",
    "we have @xmath289 as in thinning is expressed by @xmath290    we will now turn our attention to spacing probabilities for the cse .",
    "these follow from knowledge of the spacing distributions for the coe .",
    "thus one has the inter - relation @xcite @xmath291 and it follows from this that @xmath292 as noted in ( * ? ? ?",
    "* eq .  ( 8.158 ) ) , recalling the definition ( [ w2 ] ) , and making use too of  ( [ w5 ] ) , this gives @xmath293 as discussed before , the kernel of the determinantal point process formed by the eigenvalues of @xmath276 is given by @xmath294 scaling the eigen - angles of @xmath295 to have unit mean spacing by @xmath287 thus yields the following result , where we use to express the presence of thinning :    [ cor : cse ] let @xmath288 denote the integral operator on @xmath28 with kernel  .",
    "we have @xmath296     @xmath297-th next neighbour spacing : simulation vs. formulae from theory for finite size coe , no thinning ( @xmath195 ) .",
    "left panel : a histogram of empirical data from @xmath298 with @xmath156 scaled to unit mean spacing , computed using a bin size of 0.01 and @xmath157 samples ( blue dots ) ; the large @xmath1 limit @xmath299 ( red solid line ) .",
    "right panel : the simulation data minus @xmath299 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath300 ( red solid line).,title=\"fig:\",scaledwidth=55.0% ]   @xmath297-th next neighbour spacing : simulation vs. formulae from theory for finite size coe , no thinning ( @xmath195 ) . left panel : a histogram of empirical data from @xmath298 with @xmath156 scaled to unit mean spacing , computed using a bin size of 0.01 and @xmath157 samples ( blue dots ) ; the large @xmath1 limit @xmath299 ( red solid line ) .",
    "right panel : the simulation data minus @xmath299 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath300 ( red solid line).,title=\"fig:\",scaledwidth=55.0% ]    as in figure [ f8 ] but with thinning @xmath162 . ,",
    "title=\"fig:\",scaledwidth=55.0% ] as in figure [ f8 ] but with thinning @xmath162 .",
    ", title=\"fig:\",scaledwidth=55.0% ]      making use of the second equation in ( [ th2 ] ) we get the spacing distribution @xmath301 from which knowledge of the large @xmath1 expansion of the determinants in corollary  [ cor : coe ] will allow us to determine the terms in the corresponding expansion of the spacing .",
    "[ prop : coe ] let @xmath302 and @xmath303 denote the integral operators on @xmath28 with kernels @xmath304 and @xmath305 respectively .",
    "we have @xmath306 where , denoting @xmath307 , @xmath308 and @xmath309    the case @xmath310 of ( [ m1 ] ) is due to gaudin @xcite .    as an illustration and test of the above results",
    ", we took @xmath157 samples of @xmath286 ( @xmath156 , using the @xmath311 cmv sparse matrix model @xcite ) , and from this made an empirical determination of the spacing distribution scaled to unit mean spacing .",
    "this was then subtracted from the large @xmath1 limit @xmath299 and the difference compared against @xmath312 .",
    "both @xmath313 ( no thinning ) and @xmath162 were considered ; see figures [ f8 ] and [ f8a ] .    the analogue of ( [ sa1 ] ) , @xmath314 allows us to determine the first terms of the large @xmath1 expansion by expanding correspondingly the determinants in proposition  [ cor : cse ] .",
    "[ prop : cse ] with @xmath302 and @xmath303 as in proposition [ prop : coe ] we have @xmath315 where @xmath316 and @xmath317    the case @xmath310 of ( [ m2 ] ) is due to mehta and dyson @xcite .",
    "@xmath297-th next neighbour spacing : simulation vs. formulae from theory for finite size cse , no thinning ( @xmath195 ) .",
    "left panel : a histogram of empirical data from @xmath318 with @xmath156 scaled to unit mean spacing , computed using a bin size of @xmath196 and @xmath157 samples ( blue dots ) ; the large @xmath1 limit @xmath319 ( red solid line ) .",
    "right panel : the simulation data minus @xmath319 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath320 ( red solid line).,title=\"fig:\",scaledwidth=55.0% ] @xmath297-th next neighbour spacing : simulation vs. formulae from theory for finite size cse , no thinning ( @xmath195 ) . left panel : a histogram of empirical data from @xmath318 with @xmath156 scaled to unit mean spacing , computed using a bin size of @xmath196 and @xmath157 samples ( blue dots ) ; the large @xmath1 limit @xmath319 ( red solid line ) .",
    "right panel : the simulation data minus @xmath319 scaled by @xmath160 ( blue dots ) ; the leading correction term @xmath320 ( red solid line).,title=\"fig:\",scaledwidth=55.0% ]    as in figure [ f9 ] but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ] as in figure [ f9 ] but with thinning @xmath162.,title=\"fig:\",scaledwidth=55.0% ]    as was done for the coe , to illustrate and test the above results , we took @xmath157 samples of @xmath295 ( @xmath156 , again using the @xmath321 cmv sparse matrix model @xcite ) , and from this made an empirical determination of the spacing distribution scaled to unit mean spacing .",
    "this was then subtracted from the large @xmath1 limit @xmath319 and the difference compared against @xmath322 .",
    "both @xmath313 ( no thinning ) and @xmath162 were considered ; see figures [ f9 ] and [ f9a ] .",
    "alternatively to the integral operator characterisation of the expansion terms in propositions  [ prop : coe ] and [ prop : cse ] there is one in terms of painlev transcendents .",
    "such an expression in the case of the cue has been given in @xcite and restated in  above .",
    "to simplify we restrict ourselves to @xmath1 being even , writing @xmath323 for definiteness .",
    "we begin by noting that the joint eigenvalue pdf for the eigen - angles @xmath324 of @xmath276 matrices in the interval @xmath255 , after changing variables @xmath325 , is proportional to @xmath326 with @xmath327 , @xmath328 , which is an example of the jacobi unitary ensemble ( jue ) ; see e.g.  @xcite .",
    "hence the corresponding generating functions for the gap probabilities are related by @xmath329 the significance of this result for present purposes is that the rhs can be expressed as a @xmath31pvi transcendent @xcite .",
    "specifically , reading off from ( * ? ? ?",
    "( 8.71 ) , ( 8.75 ) , ( 8.76 ) ) we have @xmath330 where @xmath331 satisfies the particular @xmath31pvi equation @xmath332 subject to the boundary condition @xmath333    \\displaystyle { 2 n \\over \\pi } z t^{1/2 } ,   & a=-1/2 .",
    "\\end{array } \\right.\\ ] ] we therefore have @xmath334    to obtain an expansion consistent with ( [ sa ] ) we make the ansatz @xmath335 changing variables in ( [ sa3 ] ) @xmath336 , substituting ( [ ffa ] ) , and equating terms to leading order @xmath337 and to next leading order @xmath338 , we obtain characterisations in terms of differential equations of @xmath339 and @xmath340 .    the leading function @xmath339 in satisfies the particular @xmath341 equation ( _ with @xmath342 in the notation of ( * ?",
    "? ? * eq .  ( 8.15 ) )",
    "_ ) @xmath343 subject to the boundary condition @xmath344 \\displaystyle { z \\over \\pi } w^{1/2 } , & \\nu = - .",
    "\\end{array } \\right.\\ ] ] the function @xmath345 in satisfies the second order linear differential equation @xmath346 where the coefficients are given in terms of @xmath347 according to @xmath348 subject to the boundary condition @xmath349 which is thus the same in both cases . in terms of @xmath339 and @xmath340",
    "we have @xmath350    scaling the eigen - angles of @xmath269 to have unit mean spacing by @xmath351 , we can now substitute ( [ 3.31 ] ) into ; then  after using to add the presence of thinning ",
    "substitute the result in ( [ sa1 ] ) and compare with ( [ sa ] ) to obtain painlev transcendent characterisations of the expansion terms @xmath299 and @xmath312 .",
    "[ cc1 ] we have @xmath352 and @xmath353    [ r3.6 ] the case @xmath310 of ( [ cc1a ] ) agrees with the @xmath341 formula for @xmath354 ( no thinning ) reported in @xcite and @xcite .    the differential equations ( [ ffa1 ] ) and ( [ ffa3 ] ) can be used to successively generate terms in the series expansions of @xmath355 and @xmath356 about the origin , extending the boundary conditions ( [ ffa2 ] ) and ( [ ffa4 ] ) . substituting these into ( [ cc1a ] ) and ( [ cc1b ] ) then provides us with the small @xmath11 expansion of @xmath299 and @xmath312 .    [ c3.8 ] we have @xmath357 - \\frac{\\pi ^8 \\xi s^7 } { 90720 } + \\frac{\\pi ^8   ( \\xi     -2 ) ( 3 \\xi -32)\\xi s^8   } { 5292000 } + \\frac{\\pi ^{10 } \\xi s^9 } { 7983360 }    + \\operatorname{o}(s^{10 } )    \\end{gathered}\\ ] ] and @xmath358 + \\frac{\\pi ^8 \\xi s^7}{7560}-\\frac{\\pi ^8      ( \\xi -2 ) \\left(3 \\xi -32 \\right)\\xi s^8}{352800}-\\frac{\\pi^{10 } \\xi s^9}{435456 } + \\operatorname{o}\\left(s^{10}\\right ) .   \\end{gathered}\\ ] ]    we remark that setting @xmath195 in ( [ cc1c ] ) extends the expansion of @xmath359 given in ( * ? ? ?",
    "* eq .  ( 8.141 ) ) .",
    "for the analogous results in the case of the @xmath295 , scaling the eigen - angles to have unit mean spacing by @xmath287 , we substitute ( [ 3.31 ] ) into ( [ w6c ] ) ; then  after using to add the presence of thinning ",
    "substitute the result in ( [ sa16 ] ) and compare with ( [ sa7 ] ) .",
    "[ cc2 ] we have @xmath360 and @xmath361    as in remark [ r3.6 ] the case @xmath310 of ( [ cc2a ] ) agrees with the @xmath362 formula for @xmath363 ( no thinning ) reported in @xcite and @xcite .    as with corollary [ c3.8 ] we can use these characterisations to generate power series expansions about the origin .",
    "[ c3.9 ] we have @xmath364 \\nonumber r_{4,\\xi}(0;s ) & = -\\frac{4}{27 } \\pi ^4 \\xi s^4+\\frac{128   \\pi ^6 \\xi   s^6}{2025}-\\frac{128 \\pi ^8 \\xi s^8}{11025}+\\frac{17408   \\pi ^{10 } \\xi   s^{10}}{13395375}+ \\operatorname{o}(s^{12}).\\end{aligned}\\ ] ]    the expansions of corollaries [ c3.8 ] and [ c3.9 ] are consistent with the operator theoretic numerical evaluations of figures [ f8][f9a ] for small values of @xmath11 .",
    "the method of section  [ sub : numerical ] for numerically evaluating general terms of integral operators is most easily added to the matlab toolbox described in @xcite ; the basic code needed to run it is as follows :    [ source , numberlines ] ---- function [ val , err , n ] = operatorterm(term , varargin )    % operatorterm evaluates terms of integral operators that have a scalar value .",
    "% %    operatorterm(term , k1, ... ,km ) returns the value of the %    expression ' term(k1, ...",
    ",km ) ' for m discrete integral   %    operators k1, ... ,km ( that is , for nystrm matrices of %    a variable dimension n , which is chosen adaptively ) .",
    "%    the value to be returned must be scalar .",
    "tol = 5e-15 ; n = 7 ; n_max = 1000 ;    operators = cell(size(varargin ) ) ;    val0 = inf ; while n <",
    "n_max      n = floor(1.41*n ) ;      for k = 1:length(varargin )          operators{k } = varargin{k}(n ) ;      end      val = term(operators { : } ) ;      err = abs(val - val0 ) ;      if err < tol ; break ; end      val0 = val ; end ----    from the user perspective this command is called with a considerable symbolic look and feel .",
    "for example , the leading order term in , that is , @xmath365 evaluates for @xmath366 to the following value :    [ source , numberlines ] ---- s = 1 ; k = op(@(x , y ) sinc(pi*(x - y)),[0,s ] ) ; i = @(k ) eye(size(k ) ) ; lead = @(k ) det(i(k ) - k ) ; [ val , err , n ] = operatorterm(lead , k ) ; printcorrectdigits(val , err ) ;        0.170217421379185     ----    and the leading correction term in , that is , @xmath46 evaluates for @xmath366 to the following value :    [ source , numberlines ] ---- l = op(@(x , y ) pi*(x - y).*sin(pi*(x - y))/6,[0,s ] ) ; corr = @(k , l ) -det(i(k)-k)*trace((i(k)-k)\\l ) ; [ val , err , n ] = operatorterm(corr , k , l ) ; printcorrectdigits(val , err ) ;        -0.075241982465122 ----    since the estimated error has been taken into account when printing these values , they are good to about 15 digits ; in both cases the adaptively chosen number of gauss  legendre quadrature points ( that is , the dimension of the nystrm matrices representing the integral operators ) was as small as @xmath367 , which is a clear sign of the exponential convergence of the method .",
    "cpu time is about a millisecond .",
    "we are grateful to a.  odlyzko for providing us with the riemann zero data set .",
    "the research of f.b . was supported by the dfg - collaborative research center , trr 109 , `` discretization in geometry and dynamics . ''",
    "the research of p.j.f .",
    "and a.m. is part of the program of study supported by the arc centre of excellence for mathematical & statistical frontiers .",
    "to3em , _ a method for calculating spectral statistics based on random - matrix universality with an application to the three - point correlations of the riemann zeros _ , j. phys .",
    "a * 46 * ( 2013 ) , 305203 , 17pp .",
    "to3em , _ the @xmath371-nd zero of the riemann zeta function _ , dynamical , spectral , and arithmeitc zeta functions ( m.  van frankenhuysen and m.l .",
    "lapidus , eds . ) , contemporary math .",
    "290bb , amer .",
    "soc , providence , ri , 2001 , pp ."
  ],
  "abstract_text": [
    "<S> according to dyson s three fold way , from the viewpoint of global time reversal symmetry there are three circular ensembles of unitary random matrices relevant to the study of chaotic spectra in quantum mechanics . </S>",
    "<S> these are the circular orthogonal , unitary and symplectic ensembles , denoted coe , cue and cse respectively . for each of these three ensembles and their thinned versions , </S>",
    "<S> whereby each eigenvalue is deleted independently with probability @xmath0 , we take up the problem of calculating the first two terms in the scaled large @xmath1 expansion of the spacing distributions . it is well known that the leading term admits a characterisation in terms of both fredholm determinants and painlev transcendents . </S>",
    "<S> we show that modifications of these characterisations also remain valid for the next to leading term , and that they provide schemes for high precision numerical computations . in the case of the cue </S>",
    "<S> there is an application to the analysis of odlyzko s data set for the riemann zeros , and in that case some further statistics are similarly analysed . </S>"
  ]
}