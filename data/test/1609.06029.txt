{
  "article_text": [
    "statistical inference for time series stemming from stationary functional processes has attracted considerable interest during the last decades and progress has been made in several directions .",
    "estimation and testing procedures have been developed for a wide range of inference problems and for large classes of stationary functional processes ; see bosq ( 2000 ) , hrmann and kokoszka ( 2012 ) and horvth and kokoszka ( 2012 ) .",
    "however , the asymptotic results derived , typically depend in a complicated way on difficult to estimate , infinite dimensional characteristics of the underlying functional process .",
    "this restricts considerably the implementability of asymptotic approximations when used in practice to judge the uncertainty of estimation procedures or to calculate critical values of tests . in such situations",
    ", bootstrap methods can provide useful alternatives .",
    "bootstrap procedures for hilbert space - valued time series proposed so far in the literature , are mainly attempts to adapt , to the infinite dimensional functional set - up , of bootstrap methods that have been developed for the finite dimensional ( i.e. , mostly univariate ) time series case .",
    "politis and romano ( 1994 ) considered applications of the stationary bootstrap to functional , hilbert - valued time series and showed its validity for the sample mean for functional processes satisfying certain mixing and boundeness conditions .",
    "dehling et al .",
    "( 2015 ) considered applications of the non - overlapping block bootstrap to u - statistics for so called near epoch dependent functional processes and sharipov et al .",
    "( 2016 ) to change point analysis .",
    "franke and nyarigue ( 2016 ) and zhou and politis ( 2016 ) developed some theory for a residual - based bootstrap applied to a first order functional autoregressive process .",
    "notice that the transmission of other bootstrap procedures for real - valued time series to the functional set - up , like for instance of the autoregressive - sieve bootstrap , kreiss ( 1988 ) and kreiss et al .",
    "( 2011 ) , seems to be difficult mainly due to problems associated with the estimation ( of an with sample size increasing number ) of infinite dimensional autoregressive operators .",
    "applications of bootstrap procedures to certain inference problems in functional time series analysis have been also considered in the literature .",
    "for instance , for the construction of prediction intervals , fernndez de castro et al .",
    "( 2005 ) used an approach based on resampling pairs of functional observations by means of kernel - driven resampling probabilities .",
    "the same authors also apply a parametric , residual - based bootstrap approach using an estimated first order functional autoregression with i.i.d .",
    "resampling of appropriately defined functional residuals . for the same prediction problem ,",
    "hyndman and shang ( 2009 ) applied different bootstrap approaches including bootstrapping the functional curves by randomly disturbing the forecasted scores using residuals obtained from univariate autoregressive fits .",
    "aneiros - perez et al . (",
    "2011 ) considered the nonparametric functional autoregressive models , while mingotti et al .",
    "( 2015 ) the case of the integrated functional autoregressive model .",
    "apart from the lack of theoretical justification , the aforementioned bootstrap applications do not provide a general bootstrap methodology for functional time series as they are designed for and their applicability is restricted to the particular inference problem considered ; see also mcmurry and politis ( 2012 ) and shang ( 2016 ) for an overview .    in this paper a general and easy to implement bootstrap procedure for functional time series",
    "is proposed which generates bootstrap replicates @xmath0 of an observed functional time series @xmath1 and is applicable to a large class of stationary functional processes .",
    "the procedure avoids the explicit estimation of process operators and exploits some basic properties of the stochastic process of fourier coefficients ( scores ) appearing in the well - known karhunen - love expansion of the functional random variables .",
    "it is in particular shown , that under quite general assumptions , the stochastic process of fourier coefficients obeys a so - called vector autoregressive representation and this representation plays a key role in developing a bootstrap procedure for the functional time series at hand .",
    "more specifically , to capture the essential driving functional parts of the underlying infinite dimensional process , the first @xmath2 functional principal components are used and the corresponding @xmath2-dimensional time series of fourier coefficients is bootstrapped using a @xmath3th order vector autoregression fitted to the vector time series of sample fourier coefficients . in this way ,",
    "a @xmath2-dimensional pseudo - time series of fourier coefficients is generated which imitates the temporal dependence structure of the vector time series of sample fourier coefficients . using the ( truncated ) karhunen - love expansion , these pseudo - fourier coefficients",
    "are then transformed to functional bootstrap replicates of the main driving , principal components , of the observed functional time series .",
    "adding to these replicates an appropriately resampled functional noise , leads finally to the bootstrapped functional pseudo - time series @xmath4 .    in a certain sense",
    ", our bootstrap procedure works by using a finite rank ( i.e. , @xmath2-dimensional ) approximation of the infinite dimensional structure of the underlying functional process and a @xmath3th order vector autoregressive approximation of its infinite order temporal dependence structure . to achieve consistency and to capture appropriately the entire infinite dimensional structure of the functional process",
    ", the number @xmath2 of functional principal components used as well as the order @xmath3 of the vector autoregression applied , are allowed to increase to infinity ( at some appropriate rate ) as the sample size @xmath5 increases to infinity .",
    "this double sieve property justifies the use of the term  sieve bootstrap \" for the bootstrap procedure proposed .",
    "we show that under quite general conditions , this bootstrap procedure succeeds in imitating correctly the entire infinite dimensional autocovariance structure of the underlying functional process .",
    "notice that apart from the problem that instead of the unknown true scores , the time series of estimated scores is used , the asymptotic analysis of our bootstrap procedure faces additional challenges which are caused by the fact that vector autoregressions of increasing order and of increasing dimension are considered and that the lower bound of the corresponding spectral density matrix approaches zero as the dimension of the vector time series of scores used , increases to infinity .",
    "we apply the proposed sieve bootstrap procedure to the problem of estimating the distribution of the functional fourier transform which is fundamental in a multitude of applications and has attracted interest in the functional time series literature ; see cerovecki and hrmann ( 2015 ) for some recent developments . a basic bootstrap central limit theorem is then established which shows validity of the functional sieve bootstrap for this important class of statistics , which includes the sample mean as a special case .    using",
    "the time series of fourier coefficients in the context of functional time series analysis has been considered by many authors in a variety of applications . among others we mention hyndman and shang ( 2009 ) who , for functional autoregressive models and for the sake of prediction , used univariate autoregressions fitted to the scalar time series of scores . in the same context and more related to the approach proposed in this paper ,",
    "a multivariate approach of prediction has been proposed by aue et al .",
    "( 2014 ) which works by fitting a vector autoregressive model to the multivariate time series of scores .",
    "the paper is organized as follows .",
    "section 2 derives some basic properties and discuss the autoregressive representations of the vector process of fourier coefficients appearing in the karhunen - love expansion of the functional process .",
    "apart from being useful for bootstrap purposes , these properties are of interest on their own .",
    "the functional sieve bootstrap procedure proposed is described in section 3 where some properties of the bootstrap functional pseudo - time series are also discussed .",
    "asymptotic validity of the new bootstrap procedure for finite fourier transforms is established in section 4 .",
    "section 5 presents some numerical simulations which investigate the finite sample performance of the functional sieve bootstrap and comparisons with the performance of three popular block bootstrap methods are given . technical proofs and auxiliary lemmas",
    "are deferred to section 6 .",
    "we consider a ( functional ) stochastic process @xmath6 where for each @xmath7 ( interpreted as time ) , @xmath8 is a random element of the separable hilbert space @xmath9,\\re)$ ] with parametrization @xmath10 for @xmath11 $ ] . as usual",
    "we denote by @xmath12 the inner product in @xmath13 and by @xmath14 the induced norm defined for @xmath15 as @xmath16}x(t)y(t)dt\\big)^{1/2}$ ] and @xmath17 respectively .",
    "furthermore , for a matrix @xmath18 we denote by @xmath19 its frobenius norm , while for an operator @xmath20 , @xmath21 denotes its operator norm and @xmath22 its hilbert - schmidt norm , if @xmath20 is a hilbert - schmidt operator .    for the underlying functional process",
    "@xmath23 it is assumed that its dependence structure satisfies the following assumption .",
    "* assumption 1 *  @xmath24 is a purely non deterministic , @xmath25-@xmath26 approximable process .",
    "the general notion of @xmath27 approximability refers to stochastic process @xmath28 with @xmath29 taking values in @xmath30 , @xmath31 , and where the random element @xmath32 admits the representation @xmath33 . here the @xmath34 s are i.i.d .",
    "random elements in @xmath13 and @xmath35 some measurable function @xmath36 . if for @xmath37 an independent copy of @xmath38 , the condition @xmath39 is satisfied , where @xmath40 , then @xmath23 is called @xmath27 approximable .",
    "@xmath41 approximability is a notion of weak dependence which applies to many commonly used functional time series models , like linear functional processes , functional arch processes , etc . ; see hrmann and kokoszka ( 2010 ) for more details .",
    "let @xmath42 be the mean of @xmath23 which by stationary is independent of @xmath43 and for which we assume @xmath44 for simplicity .",
    "we denote by @xmath45 the autocovariance operator @xmath46 at lag @xmath47 defined by @xmath48 .",
    "associated with the covariance operator is the covariance function @xmath49\\times[0,1 ] \\rightarrow \\re$ ] with @xmath50 , @xmath51 $ ] , that is , @xmath52 is an integral operator with kernel function @xmath53 .",
    "assumption 1 implies that @xmath54 and that for every @xmath55 the spectral density operator @xmath56 is well defined , continuous in @xmath57 , selfadjoint and trace class , hrmann et al .",
    "( 2015 ) ; see also panaretos and tavakoli ( 2013 ) for similar properties under different weak dependence conditions which require summability of functional cumulants . in what follows",
    "we will strengthen somehow the assumption on the norm summability of the autocovariance operator to the following requirement .",
    "* assumption 2 *   @xmath58 for some @xmath59 .",
    "furthermore , we will assume that the spectral density operator @xmath60 satisfies the following condition .",
    "* assumption 3 *   for all @xmath61 $ ] , the operator @xmath62 is of full rank , i.e. , @xmath63 . for real - valued univariate processes , @xmath63 is equivalent to the condition that the spectral density is everywhere in @xmath64 $ ] strictly positive while for multivariate process to the non - singularity of the spectral density matrix for every frequency @xmath61 $ ] .",
    "notice that all eigenvalues @xmath65 , @xmath66 of @xmath67 are positive , while @xmath68 by the trace class property of @xmath60 .",
    "since @xmath69 , the positivity of @xmath60 implies that the covariance operator @xmath70 has full rank , that is , its eigenvalues @xmath71",
    "satisfy @xmath72 for all @xmath73 and the corresponding eigenfunctions @xmath74 form a complete orthonormal basis in @xmath30 . by the symmetry and compacteness of @xmath75 , the random element",
    "@xmath32 admits the well known karhunen - love representation @xmath76 where @xmath77 , @xmath78 , are the orthonormalized eigenfunctions that correspond to the eigenvalues @xmath79 , @xmath80 , of @xmath75 . for @xmath81 ,",
    "let @xmath82 , @xmath73 , and consider any subset of indices @xmath83 with @xmath84 , @xmath85 .",
    "later on , we will concentrate on the specific set @xmath86 which will be the set of the @xmath2 largest eigenvalues of the covariance operator @xmath70 .",
    "consider now the @xmath2-dimensional process @xmath87 .",
    "observe that @xmath88 is strictly stationary , purely non deterministic and has mean zero , @xmath89 .",
    "furthermore , its autocovariance matrix function @xmath90 , @xmath91 , is given by @xmath92 and satisfies by assumption 2 , @xmath93 note that the bound on the right hand side above is independent of the set @xmath94 and that although by construction it holds true that @xmath95 for @xmath96 , the random variables @xmath97 and @xmath98 may be correlated for @xmath99 . the summability property ( [ eq.gammasum ] )",
    "implies that the @xmath2-dimensional vector process @xmath88 possesses a continuous spectral density matrix @xmath100 which is given by @xmath101 moreover , @xmath102 satisfies the following boundeness conditions .",
    "[ le.eigen ] under assumption 1 and 3 and assumption 2 with @xmath103 , the spectral density @xmath104 satisfies @xmath105$},\\ ] ] where @xmath106 and @xmath107 are real numbers ( @xmath108 depends on the set @xmath94 ) , such that @xmath109 and @xmath110 is the @xmath111 unity matrix .",
    "the continuity and the boundeness properties of the spectral density matrix @xmath112 stated in lemma [ le.eigen ] , imply that the process @xmath88 obeys a so called vector autoregressive representation ; cheng and pourahmadi ( 1983 ) , see also wiener and masani ( 1957 ) and ( 1958 ) .",
    "that is , there exist an infinite sequence of @xmath113-matrices @xmath114 and a full rank @xmath2-dimensional white noise process @xmath115 , such that @xmath116 where the coefficients matrices satisfy @xmath117 and @xmath118 is a zero mean white noise innovation process , that is @xmath119 and @xmath120 , with @xmath121 if @xmath122 , @xmath123 otherwise and @xmath124 a full rank @xmath113 covariance matrix .",
    "we stress here the fact that ( [ eq.arxi ] ) does not describe a model for the process of fourier coefficients @xmath125 and should not be confused with the so - called linear , infinite order vector autoregressive ( var(@xmath126 ) ) process driven by independent , identically distributed ( i.i.d . )",
    "in fact , representation ( [ eq.arxi ] ) is the autoregressive analogue of the well - known ( moving average ) wold representation of @xmath125 with respect to the same white noise innovation process @xmath127 .",
    "this autoregressive representation is valid for any stationary and purely non deterministic process the spectral density matrix of which is continuous and satisfies the boundness conditions ( [ eq.fbounds ] ) ; see also cheng and pourahmadi ( 1983 ) and pourahmadi ( 2001 ) for details .",
    "in contrast to the wold representation , the autoregressive representation ( [ eq.arxi ] ) seems to be more appealing for statistical purposes , since it express the vector time series of fourier coefficients @xmath128 as a function of its ( in principle ) observable past values @xmath129 , @xmath66 .    in what follows",
    "we assume that the eigenvalues are in descending order , i.e. , @xmath130 and we consider the set @xmath86 of the @xmath2 largest eigenvalues of @xmath75 .",
    "the corresponding normalized eigenfunctions ( principal components ) are denoted by @xmath77 , @xmath131 and are ( up to a sign ) uniquely identified .",
    "furthermore , by parseval s identity , the quantity @xmath132 describes the proportion of the variance of @xmath32 captured by the first @xmath2 functional principal components . to simplify notation",
    "we surpass in the following the upper index @xmath133 and write simple @xmath134 for @xmath128 keeping in mind that the @xmath135th component @xmath136 of @xmath137 corresponds to the @xmath138th largest eigenvalue @xmath71 of @xmath75 , @xmath139 .",
    "furthermore , we write @xmath140 , @xmath141 , @xmath142 and @xmath143 for @xmath144 , @xmath145 , @xmath106 and @xmath146 , respectively .",
    "the basic idea of our procedure is to generate pseudo - replicates @xmath4 of the functional time series at hand by first bootstrapping the @xmath2-dimensional time series of fourier coefficients @xmath147 , @xmath148 , corresponding to the first @xmath2 principal components .",
    "this @xmath2-dimensional time series of fourier coefficients is bootstrapped using the autoregressive representation of @xmath149 discussed in section 2.2 .",
    "the generated @xmath2-dimensional pseudo - time series of fourier coefficients is then transformed to functional principal pseudo - components by means of the truncated karhunen - love expansion @xmath150 . adding to this an appropriately resampled functional noise leads to the functional pseudo - time series @xmath4 . however , since the @xmath149 s are not observed , we work with the time series of estimates scores . this idea is precisely described in the following functional sieve bootstrap algorithm .    * * step 1 * :  select a number @xmath151 of functional principal components and an autoregressive order @xmath152 , both finite and depending on @xmath5 . * * step 2 * :  let @xmath153 be the @xmath2-dimensional time series of estimated fourier coefficients , where @xmath154 , @xmath139 are the estimated eigenvectors corresponding to the estimated eigenvalues @xmath155 of the sample covariance operator @xmath156 with @xmath157 . * * step 3 * :   let @xmath158 and define functional residuals as @xmath159 , @xmath160 . *",
    "* step 4 * :   fit a @xmath161th order vector autoregressive process to the @xmath2-dimensional time series @xmath162 , @xmath160 , denote by @xmath163 , the estimates of the autoregressive matrices and by @xmath164 the residuals , @xmath165 different estimators @xmath166 , @xmath167 can be used , like for instance , yule - walker estimators ; cf .",
    "brockwell and davis ( 1991 ) . * * step 5 * :   generate a @xmath2-dimensional pseudo time series of scores @xmath168 , @xmath169 , as @xmath170 where @xmath171 , @xmath160 are i.i.d .",
    "random vectors having as distribution the empirical distribution of the centered residual vectors @xmath172 , @xmath173 and @xmath174 . *",
    "* step 6 * :   define the pseudo - functional time series @xmath175 by @xmath176 where @xmath177 are i.i.d .",
    "random functions obtained by choosing with replacement from the set of centered functional residuals @xmath178 , @xmath160 and @xmath179 .",
    "some remarks concerning the above algorithm are in order .",
    "note that @xmath4 are functional pseudo - random variables and that the autoregressive representation of the vector time series of fourier coefficients is solely used as a vehicle to bootstrap the @xmath2 main functional principal components of the time series at hand .",
    "in fact , it is this autoregressive representation which allows the generation of pseudo - time series of fourier coefficients @xmath180 , in step 4 and step 5 , in a way that imitates the dependence structure of the sample fourier coefficients @xmath181 and which are used in the ( m - truncated ) karhunen - love representation .",
    "this together with the additive functional noise @xmath182 , lead to the new functional pseudo - observations @xmath183 .",
    "notice that the estimated eigenvectors @xmath184 may point in an opposite direction than the eigenvectors @xmath185 . in asymptotic derivations this is commonly taking care off by considering the sign corrected estimator @xmath186 , where the ( unobserved ) random variable @xmath187 is given by @xmath188 . however , since adding this sign correction will not affect the asymptotic results derived , we assume for simplicity throughout this paper , that @xmath189 , for @xmath190 .",
    "some modifications of the above basic bootstrap algorithm are possible which concern the resampling schemes used to generate the vector of pseudo - innovations @xmath171 and/or the bootstrap functional noise @xmath191 . to elaborate , and as we will see in the sequel , the applied i.i.d .",
    "resampling of the innovations @xmath171 in step 5 , suffices in order to capture the entire , infinite dimensional second order structure of the underlying functional process @xmath24 . a modification of this i.i.d .",
    "resampling scheme may be needed , however , if higher order characteristics of the underlying functional process beyond those of order two , should also be correctly mimicked by the functional pseudo - time series @xmath4 . in such a case , the i.i.d .",
    "resampling used to generate the @xmath171 s in step 5 can be replaced by other resampling schemes ( i.e. , block bootstrap schemes ) that are able to capture higher order dependence characteristics of the white noise series @xmath192 s as well .",
    "it should be mentioned that if @xmath24 is a stationary functional autoregressive ( far ) process , i.e. , if @xmath193 , where @xmath194 are autoregressive operators and @xmath34 an i.i.d .",
    "sequence in @xmath30 , see bosq ( 2000 ) for stability conditions of the far process , then the infinite dimensional vector process @xmath195 of scores satisfies @xmath196 , where @xmath197 , @xmath198 , are @xmath199 dimensional matrices and @xmath200 is an infinite dimensional vector of i.i.d . innovations .",
    "that is , in this case the vector process of scores is generated by a linear , ( infinite dimensional ) autoregressive process of order @xmath3 . in this case and under some obvious modifications ,",
    "the sieve bootstrap procedure proposed in this paper provides an alternative way to bootstrap the far(p ) process which circumvents the problem of estimating explicitly the autoregressive operators @xmath201 , @xmath202 .",
    "asymptotic validity of such a bootstrap procedure will then require that the truncation parameter @xmath2 increases to infinity ( at some appropriate rate ) with the sample size @xmath203 .      as usual",
    ", all considerations made regarding the bootstrap procedure are made conditionally on the observed functional time series @xmath204 .",
    "the generation mechanism of the pseudo - time series @xmath4 , enables us to consider the bootstrap functional process @xmath205 , where for @xmath206 , @xmath207 , with @xmath208 generated as @xmath209 , and , where the @xmath210 s are i.i.d .",
    "functional random variable taking values in the set @xmath211 with probability @xmath212 . in the above notation @xmath213",
    "is the @xmath2-dimensional vector @xmath214 , where the unity appears in the @xmath135th position .",
    "it is easy to see that @xmath215 is a strictly stationary functional process with mean function @xmath216 for all @xmath81 , and , autocovariance operator @xmath217 given , for @xmath91 , by @xmath218 where @xmath219 is the @xmath220 autocovariance matrix at lag @xmath221 of @xmath222 .",
    "@xmath223 is a hilbert - schmidt operator since it is , for @xmath224 , a finite rank operator while for @xmath225 it is the sum of a finite rank operator and of the ( hilbert - schmidt ) empirical covariance operator of the pseudo - innovations @xmath226    if the ( estimated ) vector autoregressive process used to generate the time series of pseudo - scores @xmath227 is stable , then the dependence structure of the bootstrap process @xmath215 can be more precisely described .",
    "this is stated in the following proposition .",
    "notice that the required stability condition of the estimated autoregressive polynomial is fulfilled , if for instance , @xmath228 , @xmath229 , are the yule - walker estimators ; cf .",
    "brockwell and davis ( 1991 ) , ch .",
    "[ pr.lp_m ] if the estimator @xmath228 , @xmath167 , used in step 4 of the functional sieve bootstrap algorithm is such that @xmath230 for all @xmath231 , where @xmath232 , @xmath233 , then , conditionally on @xmath204 , the bootstrap process @xmath215 is @xmath234 approximable .",
    "the @xmath234 approximability of @xmath215 implies the norm summability @xmath235 , see hrmann et al .",
    "( 2015 ) , which can be also easily verified since @xmath236 furthermore , and because of the @xmath234 approximability property , the bootstrap process @xmath237 possesses for every @xmath55 a spectral density operator @xmath238 defined by @xmath239    @xmath240 and @xmath241 are essentially finite rank approximations of the corresponding population operators @xmath45 and @xmath242 respectively .",
    "thus and in order for the bootstrap process @xmath237 to capture the infinite dimensional structure of the underlying functional process and the infinite order dependence structure of the vector time series generating the scores , the dimension @xmath2 as well as the autoregressive order @xmath3 , used in the functional sieve bootstrap algorithm , have to increase to infinity ( at an appropriate rate ) as the sample size @xmath5 increases to infinity . this rate should take into account the fact that the true scores and eigenfunctions appearing in the karhunen - love expansion are not observed and , therefore , sample estimates are used instead .",
    "furthermore , not only the order @xmath3 but also the dimension @xmath2 of the fitted autoregressive process has to increase to infinity with the sample size which makes the asymptotic analysis more involved .",
    "finally , the lower bound @xmath243 of the spectral density matrix @xmath244 of the scores approaches zero as the sample size @xmath203 increases to infinity .",
    "this is due to the fact that the eigenvalues @xmath245 of the spectral density operator @xmath60 converge to zero as @xmath246 .",
    "these conditions impose several restrictions regarding the behavior of @xmath2 and @xmath3 with respect to the sample size @xmath5 which are summarized in the following assumption .",
    "* assumption 4 *   the sequences @xmath247 and @xmath248 satisfy @xmath249 and @xmath250 as @xmath251 such that ,    1 .",
    "@xmath252 2 .",
    "@xmath253 , where @xmath254 and @xmath255 for @xmath256 .",
    "@xmath257 , where @xmath243 is the lower bound of the spectral density matrix @xmath258 given in ( [ eq.fbounds ] ) .",
    "@xmath259 , where @xmath260 , @xmath167 denote the same estimator as @xmath228 , @xmath167 , based on the true vector time series of scores @xmath181 instead of their estimates @xmath261 and @xmath262 , @xmath263 are the coefficient matrices of the best ( in the mean square sense ) linear predictor of @xmath149 based on @xmath264 , @xmath167 .    assumption 4(ii ) is mainly imposed in order to control the error made by the fact that the bootstrap procedure is based on estimated scores and eigenfunctions instead on the unobserved true quantities in a context where the dimension @xmath2 and the autoregressive order @xmath3 , both , increase to infinity .",
    "part ( iii ) relates the rate of increase of the autoregressive order @xmath3 to the lower bound of the spectral density matrix @xmath258 and the decay of the norm of the autoregressive matrices to zero .",
    "part ( iv ) is a requirement on the estimator @xmath265 , @xmath167 based on the true scores .",
    "this is essentially a requirement on the estimator @xmath228 applied , after ignoring the error caused by the fact that the estimated scores are used .",
    "notice that assumptions on the estimators of the autoregressive parameters are common in the autoregressive - sieve bootstrap literature for real valued - random variablees ; see kreis et al .",
    "( 2011 ) and meyer and kreiss ( 2015 ) .",
    "however , the situation here is different since in our context , not only the order @xmath3 but also the dimension @xmath2 of the vector autoregression has to increase to infinite with the sample size .",
    "this justifies the additional factor @xmath266 appearing in ( iv ) .    under the condition that @xmath2 and @xmath161 increase to infinity at an appropriate rate with @xmath5 such",
    "that assumption 4 is satisfied , the following proposition can be established which shows that the spectral density operator @xmath267 of the bootstrap process @xmath215 converges , in hilbert - schmidt norm , to the spectral density operator @xmath268 of the underlying functional process @xmath24 .",
    "[ pr.f ] under assumptions 1 , 3 and 4 and assumption 2 with @xmath103 , we have , that , as @xmath251 , @xmath269}\\|{\\mathcal f}^\\ast _ { \\omega , m } - { \\mathcal f } _ \\omega\\|_{hs } \\",
    "\\rightarrow \\ 0,\\ ] ] in probability .    from the above proposition and the inversion formulae of fourier transforms",
    ", we immediately get for the covariance operators @xmath270 and @xmath52 of the bootstrap process @xmath237 and of the underlying process @xmath24 , that @xmath271 in probability as @xmath272 .",
    "thus the bootstrap process @xmath215 , imitates asymptotically correct the entire infinite dimensional autocovariance structure of the functional process @xmath24 .",
    "this allows for the use of the bootstrap functional time @xmath273 to approximate the distribution of statistics based on the functional time series @xmath204 .",
    "examples of such statistics are discussed in the next section .",
    "in this section we investigate the validity of the functional sieve bootstrap applied in order to approximate the distribution of some statistic @xmath274 of interest , when the bootstrap analogue @xmath275 is used .",
    "consider the distribution of the functional fourier transform @xmath276,\\ ] ] and notice that the sample mean @xmath277 is a special case of ( [ eq.fft ] ) . in order to investigate the limiting distribution of @xmath278",
    ", we fix some notation .",
    "we say that a random element @xmath279 , follows a complex gaussian distribution with mean @xmath280 and covariance @xmath281 , we write @xmath282 , if @xmath283    under a range of different weak dependence assumptions on the functional process @xmath23 , it has been shown that @xmath284 as @xmath251 . for @xmath285 , such a limiting behavior has been established for linear functional processes by merlevde et al .",
    "( 1997 ) and for @xmath286 approximable processes by horvth et al .",
    "panaretros and tavakoli ( 2013 ) derived the above limiting distribution of @xmath287 for @xmath61 $ ] , under a summability condition of the functional cumulants , while more general results for the same statistic and under weaker conditions , have been recently obtained by cerovecki and hrmann ( 2015 ) .",
    "the following theorem establishes asymptotic validity of the functional sieve bootstrap procedure for the class of functional fourier transforms , when the bootstrap statistic @xmath288 is used to approximate the distribution of the statistic @xmath289 .",
    "[ th.th_main ] under assumptions 1 , 3 and 4 and assumption 2 with @xmath290 , we have for @xmath291 $ ] , that , as @xmath272 , @xmath292 in probability .",
    "in order to investigate the finite sample behavior of the functional sieve bootstrap ( fsp ) we have performed numerical simulations using time series stemming from a first order functional moving average process given by @xmath293 to specify the operator @xmath294 we adopted the simulation set - up of aue et al .",
    "( 2015 ) and set @xmath295 , where @xmath296 , @xmath297 with @xmath298 , @xmath299 and @xmath300 fourier basis functions on the interval @xmath301 $ ] . for @xmath302 where @xmath303 with @xmath304 , the operator @xmath305 considered , acts as follows : @xmath306 . furthermore , the i.i.d .",
    "innovations @xmath34 in ( [ eq.ma1sim ] ) are obtained as @xmath307 , where the random variables @xmath308 are i.i.d .",
    "gaussian with mean zero and standard deviation equal to @xmath309 .",
    "we are interested in estimating the standard deviation of the sample mean @xmath310 , calculated for time series of length @xmath311 observations and for @xmath312 , @xmath313 , @xmath314 , equidistant time points in the interval @xmath301 $ ] .",
    "the exact standard deviation of the sample mean is estimated using 20,000 replications of the moving average model structure ( [ eq.ma1sim ] ) considered .",
    "the finite sample performance of the fsb is also compared with that of three other bootstrap procedures , the moving block bootstrap ( mbb ) , the tapered block bootstrap ( tbb ) and the stationary bootstrap ( sb ) .",
    "all estimates presented are based on @xmath315 replications and @xmath316 bootstrap repetitions .",
    "although the development of a data driven procedure that automatically selects @xmath3 and @xmath2 is a problem of future research , we experimented with several values of @xmath2 and @xmath3 where we found that for this model and for the sample size considered , a vector autoregression of order @xmath317 describes appropriately the temporal dependence of the vector time series of scores .",
    "table 1 shows the fsb estimates obtained using different values of the bootstrap parameters @xmath2 and @xmath3 . in figure 1",
    "the results obtained using the fsb procedure are compared with those of the three aforementioned block bootstrap methods .",
    "in particular , figure 1 shows the fsb estimates of the standard deviation of the sample mean for @xmath318 and @xmath317 and the corresponding estimates of the mbb , of the tbb and of the sb .",
    "the bootstrap parameters of these block bootstrap procedures have been selected as follows . for the mbb we calculated the corresponding estimates for a range of values of the block size @xmath319 in the set @xmath320 and we selected the block size",
    "@xmath319 which minimizes the overall relative bias given by @xmath321 , where @xmath322 denote the moving block bootstrap estimator of the standard deviation using the block size @xmath319 and @xmath323 the corresponding estimated exact standard deviation .",
    "the block size for the mbb selected according to this procedure was equal to @xmath324 .",
    "the same procedure has been applied in order to choose the bootstrap parameters for the other two block bootstrap methods , that is of the tbb and of the sb procedure . for the tbb",
    "the block size selected according to this criterion was @xmath325 , while the same criterion delivered a probability of @xmath326 for the geometric distribution involved in the sb procedure .",
    "thus the corresponding block bootstrap estimator presented in figure 1 are , in the described sense , the ( overall ) less biased block bootstrap estimators .",
    "* please insert table 1 and figure 1 about here *    as table 1 shows the fsb estimates are quite good even for functional time series consisting of @xmath311 observations and seem not to be very sensitive with respect to the different choices of the parameter @xmath2 used to truncate the karhunen - love expansion . notice that as @xmath2 increases the variability of the fsb estimates increases too .",
    "this is expected since the number of parameters to be estimated for the vector autoregression fitted to the time series of scores equals @xmath327 .",
    "the good finite sample behavior of the fsb method is also demonstrated in figure 1 where comparisons of the fsb estimates with those obtained using the three different block bootstrap methods are given .",
    "as this figure shows , between the three bootstrap estimators considered , the mbb estimator seems to behave better that the sb estimator , while both estimators are more biased compared to the tbb estimator .",
    "the later method performs best among the three different block bootstrap methods considered .",
    "however , all block bootstrap estimates are quite biased and they are clearly outperformed by the fsb estimates for all time points @xmath328 in the interval @xmath301 $ ] considered .",
    "[ le.a1 ] let assumption 1 , 2 and 3 be satisfied .",
    "denote by @xmath329 , @xmath78 , the coefficients matrices of the power series @xmath330 , where @xmath331 , @xmath231 , and let @xmath332 .",
    "then ,        * proof : *   consider ( i ) and ( ii ) .",
    "let @xmath336 be the class of all @xmath220 matrix - valued functions on @xmath337 $ ] with @xmath338-valued fourier coefficient matrices @xmath339 satisfying the condition @xmath340 , where @xmath341 is independent of @xmath2 .",
    "then , @xmath342 since the autocovariance matrix function of @xmath343 satisfies @xmath344 , see ( [ eq.gammasum ] ) . furthermore , @xmath345 , with @xmath346 the optimal factor of @xmath347",
    "; see cheng and pourahmadi ( 1993 ) , p. 116 . from the boundeness conditions it follows that @xmath348 for all @xmath349 , and , therefore , @xmath350 is invertible with inverse denoted by @xmath351 .",
    "notice that @xmath352 . according to wiener and masani ( 1958 ) , theorem 5.5 and theorem 5.7",
    ", there exist sequences @xmath353 and @xmath354 which are independent of @xmath7 such that for all @xmath81 , @xmath355 and @xmath356 , where @xmath357 and the infinite sums are @xmath358-convergent .",
    "the coefficients in the autoregressive and the wold representation are obtained by setting @xmath359 , @xmath360 and @xmath361 , where @xmath362 , @xmath363 and @xmath364 , @xmath365 , are the fourier coefficients of @xmath346 and @xmath351 , respectively . since @xmath352 , we get that @xmath366 and @xmath367 are bounded uniformly in @xmath2 . in ( iii )",
    "the lower bound follows from the regularity of the infinite dimensional process of scores @xmath368 which in turn follows from the regularity of @xmath23 . for the upper bound , let @xmath369 , @xmath263 , be the ( positive ) eigenvalues of @xmath370 .",
    "then , since @xmath371 we have @xmath372 .",
    "@xmath373    the following version of baxter s inequality is very useful in our setting because it relates the approximation error of the coefficient matrices of the finite predictor and of the autoregressive - representation of the @xmath2-dimensional process of scores to the lower bound of the spectral density matrix @xmath374 .",
    "it is an immediate consequence of lemma  [ le.eigen ] and theorem 3.2 of meyer et al .",
    "( 2016 ) .",
    "[ le.a2 ] let assumption 1 , 2 and 3 be satisfied .",
    "then there exists a constant @xmath375 which does not depend on @xmath2 , such that for all @xmath376 , @xmath377 where @xmath243 is given in lemma  [ le.eigen ] .",
    "the following lemma provides a useful bound between the estimated matrices of the autoregressive parameters based on the vector of scores @xmath134 and on the vector of their estimates @xmath162 , @xmath148 .",
    "it deals with the case of the yule - walker estimators and can be established for other estimators , like least squares , by similar arguments .",
    "* proof : *   we first show that @xmath382 where @xmath383 , @xmath384 , @xmath385 , @xmath386 and @xmath387 , @xmath388 . since @xmath389 it suffices to consider only one of the two terms on the right hand side of the last bound . by the triangular and the cauchy - schwarz inequality we have @xmath390 with the @xmath391 term uniformly in @xmath221 .",
    "the assertion follows because by assumption 1 , @xmath392 ; see hrmann and kokoszka ( 2010 ) .",
    "we next proof the assertion for @xmath393 . for this",
    "recal that @xmath394 and @xmath395 .",
    "furthermore , @xmath396 and using the analogue expression for @xmath397 we get @xmath398 where the last equality follows using ( [ eq.difgamma ] ) and the bound @xmath399 . by the above arguments and using expression ( [ eq.difgamma ] ) we obtain @xmath400 extension of the assertion for @xmath401",
    "follows using the above bound for @xmath402 , equation ( [ eq.difgamma ] ) and durbin - levinson s recursion formulae for the yule - walker estimators ; see brockwell and davis ( 1991 ) , ch . 11.4 .",
    "@xmath373    [ le.a4 ] let assumption 1 and 2 ( with @xmath103 ) be satisfied and @xmath403 , @xmath233 .",
    "there exists @xmath404 and a positive constant @xmath341 which does not depend on @xmath2 such that for @xmath405 and all @xmath406 , @xmath407    * proof : *   we first show that the assertion is true for @xmath231 . since @xmath408 for @xmath231 it follows by the minimum modulus principle for holomorphic functions that @xmath409 .",
    "now , recall that for @xmath410 $ ] , @xmath411 .",
    "let @xmath412 be the largest eigenvalue of @xmath413 , we then have @xmath414 for some constant @xmath415 independent of @xmath2 .",
    "notice that the first inequality follows by lemma  [ le.a1](iii ) and the last by the fact that @xmath416 is bounded uniformly in @xmath2 ; see lemma  [ le.eigen ] .",
    "thus @xmath417 } |det ( a_{p , m}(e^{-i\\omega})|^2 \\geq   c m^{-1}$ ] which implies that @xmath418 with some constant @xmath375 independent of @xmath2 .",
    "extension of this lower bound to the slightly larger region @xmath419 and for all @xmath406 for some @xmath404 , follows then exactly along the same lines as the proof of lemma 3.2 of meyer and kreiss ( 2015 ) ; see also lemma 2.3 of kreiss et al .",
    "@xmath373    to state the next lemma we first fix the following notation .",
    "@xmath420 , @xmath421 , @xmath422 and @xmath423 @xmath78 denote the coefficient matrices in the power series expansions of @xmath330 , @xmath424 , @xmath425 and @xmath426 , respectively , @xmath231 .",
    "we set @xmath427 .",
    "furthermore , @xmath428 , @xmath429 , @xmath430 and @xmath431 , while @xmath432 and @xmath433 with @xmath434 and @xmath435 where @xmath436 denotes expectation with respect to the measure assigning probability @xmath437 to each @xmath438 , @xmath439 .",
    "* proof : *   to see ( i ) let @xmath446 be the @xmath447th element of a matrix @xmath448 and notice that by cauchy s inequality for holomorphic functions we have @xmath449 with an obvious notation for @xmath450 and @xmath451 . by theorem 2.12 of ipsen and rehman ( 2008 ) we get that @xmath452 where @xmath453 and @xmath454 denotes the spectral norm ( i.e. , the largest singular value ) of the matrix @xmath448 . since @xmath455 and using the bound @xmath456 for the largest singular value of a non - singular matrix @xmath448 , see merikoski and kumar ( 2005 ) , p. 373",
    ", we get by straightforward calculations and in view of lemma  [ le.a4 ] and the constant @xmath341 appearing there , that @xmath457 since @xmath458 and @xmath459 uniformly in @xmath2",
    ". thus @xmath460 and assumption 4(iv ) lead to the bound @xmath461 from which we derive using ( [ eq.det-bound ] ) that @xmath462 and by lemma  [ le.a4 ] that @xmath463 furthermore , by lemma  [ le.a4 ] and the bound ( [ eq.det-bound ] ) we get @xmath464 thus and using equation ( [ eq.cauchy ] ) , we conclude that @xmath465 by assumption 4 .",
    "consider ( ii ) so we have , @xmath466 with an obvious notation for @xmath467 , @xmath468 .",
    "we show that all three terms converge to zero in probability . by the triangular inequality and in order to show @xmath469 , it suffices to show that @xmath470 . for this",
    "we use the bound @xmath471 since by straightforward calculations it yields that @xmath472 , we get by assumption 4(iv ) and cauchy - schwarz s inequality that @xmath473 for the second term on the right hand side of ( [ eq.bound1 ] ) we get by replacing @xmath474 by @xmath475 and using lemma  [ le.a2 ] , that @xmath476 by assumption 4 . finally and by the same assumption , we get for the third term of ( [ eq.bound1 ] ) using @xmath477 which converges to zero in probability .    since the term @xmath478 is easier to deal with using similar arguments as for the term @xmath479 , we consider the term @xmath480 . using @xmath481",
    "we have that @xmath482 since @xmath483 uniformly in @xmath2 and by similar arguments as above , we have @xmath484 thus we conclude using assumption 4 , that @xmath485 .    consider ( iii ) . by",
    "( i ) it suffices to show that @xmath486 . for this notice that @xmath487 by lemma  [ le.a3 ] and by cauchy s inequality for holomorphic functions we get for the @xmath447th element of the matrices @xmath423 and @xmath488 , that @xmath489 and @xmath490 from the above bound and by lemma  [ le.a3 ] and lemma  [ le.a4 ] , we get by similar arguments as those leading to the bound ( [ eq.det-bound ] ) , that , uniformly in @xmath138 , @xmath491 that is @xmath492 from which we get @xmath493 by assumption 4 ( ii ) .    to establish ( iv ) notice that using ( ii ) it suffices to show that @xmath494 . by the triangular inequality it suffices to show that @xmath495\\big(\\widehat{e}_{t , p}(m)-\\widetilde{e}_{t , p}(m)\\big)\\| \\stackrel{p}{\\rightarrow } 0.\\ ] ] since the above term can be bounded by @xmath496 we show that both terms above converge to zero in probability .",
    "we use the bound @xmath497 from lemma  [ le.a3 ] we get by straightforward calculations that , @xmath498 , @xmath499 and @xmath500 similar arguments yield @xmath501 and @xmath502 .",
    "* proof of lemma [ le.eigen ] : *   expression ( [ eq.gammasum ] ) imediately leads , for all @xmath61 $ ] , to an upper bound of @xmath503 . to derive a lower bound ,",
    "recall that @xmath504 and observe that @xmath505 let @xmath506 , @xmath139 , be the eigenvalues of @xmath507 ( including multiplicity ) .",
    "it suffices to show that @xmath508 for all frequencies @xmath509 $ ] , i.e. , that the eigenvalues of the spectral density matrix @xmath510 are uniformly ( in @xmath57 ) bounded away from zero . for this",
    "let @xmath511 be the corresponding normalized eigenvectors . then for every @xmath512",
    ", we have @xmath513 by the positivity of @xmath60 , where @xmath514 and @xmath515 . because of the norm summability of the autocovariance matrix function @xmath516 , the eigenvalues @xmath517 , @xmath263 , are continuous functions of @xmath518 .",
    "let @xmath519 and notice that @xmath520 is continuous in @xmath57 and @xmath521 for all @xmath61 $ ] .",
    "define @xmath522}\\delta_m(\\omega)$ ] which is positive by the continuity of @xmath523 .",
    "hence @xmath524 for all @xmath509 $ ] . @xmath373",
    "* proof of proposition  [ pr.lp_m ] : * recall the definition of @xmath525 and observe that @xmath526 , where @xmath527 and the power series @xmath528 converges for @xmath231 .",
    "write @xmath529 and define @xmath530 where for each @xmath81 , @xmath531 is an independent copy of @xmath532 .",
    "notice that @xmath533 by minkowski s inequality we have @xmath534 and evaluating the first expectation term we get using @xmath535 and the submultiplicative property of the frobenius matrix norm , that @xmath536 where @xmath537 .",
    "an identical expression appears for the second expectation term on the right hand side of ( [ eq.l2mapp ] ) . applying minkowski s inequality again we get by the exponential decay of @xmath538 , that @xmath539 @xmath373    * proof of proposition  [ pr.f ] : *   recall that the spectral density operator @xmath67 can be expressed as @xmath540 . define for @xmath405 , @xmath541 and verify that since @xmath542 , the following expression is also valid for @xmath543 , @xmath544 where @xmath545 , @xmath231 .",
    "let @xmath546 where @xmath547 , @xmath231 . finally recall that @xmath548 then , @xmath549 the first term on the right hand side above is bounded by @xmath550 furthermore , @xmath551 where @xmath552 are i.i.d .",
    "random variables taking values with probability @xmath553 in the set @xmath554 and @xmath555 .",
    "then @xmath556 in probability , since @xmath557 and the operator @xmath70 is hilbert - schmidt .",
    "furthermore , @xmath558 in probability , where the last equality follows by straightforward calculations and using @xmath559 .",
    "similarly , and by the same arguments as above and using lemma  [ le.a5 ] , we get @xmath560      consider next the second term on the right hand side of ( [ eq.speczer ] ) . for this term",
    "we get @xmath563 , i.e. , @xmath564 converges to zero in probability by lemma  [ le.a5](v ) and ( vi ) . for the third and last term on the right hand side of ( [ eq.speczer ] )",
    "we obtain @xmath565 as @xmath249 , since @xmath566 is a complete orthonormal basis of @xmath567 .",
    "@xmath373    * proof of theorem  [ th.th_main ] * let @xmath568 where @xmath569 , @xmath160 with @xmath570 , where @xmath571 , @xmath167 are the estimators of the autoregressive parameter matrices based on the vector time series of true scores @xmath149 , @xmath148 and @xmath572 are obtained by i.i.d .",
    "resampling from the centered residuals @xmath573 , @xmath439 .",
    "that is , the pseudo - variable @xmath574 is obtained using the true eingefunctions @xmath77 and the true scores @xmath575 instead of their estimates @xmath184 and @xmath576 respectively .",
    "decompose then @xmath577 as @xmath578 with an obvious notation for @xmath579 , @xmath580 , @xmath581 and @xmath582 .",
    "notice that the terms @xmath580 and @xmath583 are due to the fact that , in the bootstrap procedure , the unknown scores and eigenfunctions are replaced by their sample estimates , while @xmath584 is due to the @xmath2-dimensional approximation of the infinite dimensional structure of the underlying process .",
    "the assertion of the theorem follows then from lemma  [ le.le1th_main ] ,  [ le.le2th_main ] ,  [ le.le3th_main ] and  [ le.le4th_main ] and slutsky s lemma .",
    "@xmath373      * proof : *   note that @xmath586 using @xmath587 , see hrmann and kokoszka ( 2010 ) , we get @xmath588 where the last equality follows because @xmath589 . furthermore , @xmath590 follows using similar arguments and since @xmath591 , where @xmath592 .",
    "@xmath373      * proof : *   we have @xmath594 with an obvious notation for @xmath595 and @xmath596 .",
    "we consider @xmath597 only since @xmath598 can be handled similarly .",
    "for this term we have @xmath599\\widetilde{\\psi}_{l+s - t , p}(m)^\\top { \\bf 1}_j \\end{aligned}\\ ] ] and , using lemma  [ le.a1 ] and  [ le.a5 ] , we get for the first term on the right hand side of ( [ eq.dnm1 ] ) , that , this term is bounded by @xmath600 in probability . the second term of ( [ eq.dnm1 ] ) is bounded by @xmath601 which converges to zero in probability , because @xmath602 in probability .",
    "this can be seen using @xmath603 we then have @xmath604 furthermore , @xmath605 where the last equality follows using lemma  [ le.a1 ] and  [ le.a3 ] . finally , @xmath606 in probability , since @xmath607 and @xmath608 by similar arguments we get @xmath609 , in probability . @xmath610",
    "* proof : * write @xmath615 where @xmath616 with @xmath617 , @xmath618 , a random element in @xmath13 .",
    "notice that @xmath619 , while using @xmath620 , @xmath621 , we get @xmath622 with an obvious notation for @xmath623 . it is easily seen that @xmath624 and therefore @xmath625 in probability , by lemma  [ le.a5 ] .",
    "hence and using @xmath626 as @xmath627 , we get that @xmath628 in probability , as @xmath251 .",
    "let @xmath629 , define @xmath630 and @xmath631 .",
    "it easily follows by simple algebra and using lemma  [ le.a5 ] that @xmath632 , in probability , that is @xmath633 .",
    "thus to prove the assertion of the lemma it suffices to show that @xmath634 . for this",
    "we show that the assumptions of theorem 2 of cerovecki and hrmann ( 2015 ) are satisfied , that is , using the notation @xmath635 , we show that the following two conditions are fulfilled , in probability . @xmath636 and @xmath637 where the operator @xmath638 is defined as @xmath639 and @xmath640 . toward this",
    "we first define @xmath641 , where @xmath642 if @xmath643 and @xmath644 if @xmath645 with @xmath646 a copy of @xmath572 which is independent of @xmath647 for @xmath648 .",
    "we show that @xmath649 where the @xmath650 term is independent of @xmath2 and @xmath3 .",
    "notice first that by minkowski s inequality @xmath651 thus @xmath652 now , since by lemma  [ le.a1](ii ) , @xmath653 is bounded uniformly in @xmath2 , and , by lemma  [ le.a5](ii ) and ( vi ) and lemma  [ le.a1](iii ) , @xmath654 is bounded in probability , where the bound is independent of @xmath3 and @xmath2 , assertion ( [ eq.uo ] ) follows .",
    "consider next condition ( [ th2.cond1 ] ) . for positive integers",
    "@xmath655 we have that @xmath656 recall the definition of @xmath657.then we have , since @xmath658 , that @xmath659 hence @xmath660 as @xmath661 because of ( [ eq.uo ] ) .",
    "50 aneiros - prez , g. , cao , r. and vilar - fernanz , j. m. ( 2011 ) .",
    "functional methods for time series prediction : a nonparametric approach . _ journal of forecasting _ , * 30 * , 377 - 392 .",
    "aue , a. , dubart , d. n. and hrmann , s. ( 2015 ) . on the prediction of stationary functional time series .",
    "_ journal of the american statistical association _ ,",
    "* 110 * , 378 - 392 .",
    "bosq , d. ( 2000 ) .",
    "_ linear process in function spaces_. springer , berlin - heidelberg - new york .",
    "cerovecki , c. and hrmann , s. ( 2015 ) . on the clt for discrete fourier transforms of functional time series .",
    "_ preprint_. cheng , r. and pourahmadi , m. ( 1993 ) .",
    "baxter s inequality and convergence of finite predictors of multivariate stochastic processes .",
    "_ probability theory and related fields _ , * 95 * , 115 - 124 .",
    "dehling , h. , sharipov , o. s. and wendler , m. ( 2015 ) . bootstrap for dependent hilbert space valued random variables with application to von mises statistics .",
    "_ journal of multivariate analysis _ , * 133 * , 200 - 215 .",
    "fernndez de castro , b. , guillas , s. and gonzlez manteiga , w. ( 2005 ) . functional samples and bootstrap for predicting sulfur dioxide levels .",
    "_ technometrics _ , * 47 * , 212 - 222 .",
    "franke , j. and nyarigue , e. ( 2016 ) .",
    "residual - based bootstrap for functional autoregressions .",
    "_ preprint_. hrmann , s. and kokoszka , p. ( 2010 ) .",
    "weakly dependent functional data .",
    "_ annals of statistics _ , * 38 * , 1845 - 1884 .",
    "hrmann , s. and kokoszka , p. ( 2012 ) .",
    "functional time series .",
    "_ handbook of statistics : time series analysis - methods and applications _ , 157 - 186 .",
    "hrmann , s. , kidziski , l. and hallin , m. ( 2015 ) .",
    "dynamic functional principal components .",
    "_ journal of the royal statistical society : series b _ , * 77 * , 319 - 348 .",
    "horvth , l. and kokoszka , p. ( 2012 ) .",
    "_ inference for functional data with applications_. springer , berlin - heidelberg - new york .",
    "hyndman , r. j. and shang , h. l. ( 2009 ) .",
    "forecasting functional time series .",
    "_ journal of the korean statistical society _ ,",
    "* 38 * , 199 - 211 .",
    "ipsen , i. c. f. and rehman , r. ( 2008 ) .",
    "perturbation bounds for determinants and characteristic polynomials .",
    "_ siam journal of matrix analysis and applications _ , * 30 * , 762 - 776 .",
    "kreiss , j .-",
    "asymptotic statistical inference for a class of stochastic processes .",
    "universitt hamburg .",
    "kreiss , j .-",
    "p . , paparoditis , e. and politis , d. n. ( 2011 ) . on the range of validity of the autoregressive sieve bootstrap .",
    "_ annals of statistics _ , * 39 * , 2103 - 2130 .",
    "mcmurry , t. and politis , d. n. ( 2011 ) .",
    "resampling methods for functional data . _",
    "the oxford handbook of functional data analysis _ , ( f. ferraty and y. romain , eds . ) 189 - 209 .",
    "oxford university press .",
    "merikoski , j. k. and kumar , r. ( 2005 ) .",
    "upper bounds for singular values . _ linear algebra and its applications _ , 401 , 371 - 379 .",
    "merlevede , f. , peligrad , m. and utev , s. ( 1997 ) .",
    "sharp conditions for the clt of linear processes in a hilbert -space . _ journal of theoretical probability _ , * 10 * , 681 - 693 .",
    "meyer , m. and kreiss , j .-",
    "( 2015 ) . on the vector autoregressive sieve bootstrap .",
    "_ journal of time series analysis _ , * 36 * , 377 - 397 .",
    "meyer , m. , jentsch , c. , and kreiss , j .-",
    "baxter s inequality and sieve bootstrap for random fields .",
    "_ bernoulli _ , to appear .",
    "mingotti , n. , lillo , r. e. and romo , j. ( 2015 ) . a random walk test for functional time series .",
    "uc3 m working papers , statistics and econometrics . panaretos , v. and tavakoli , s. ( 2013 ) . fourier analysis of stationary time series in function spaces . _",
    "annals of statistics _ , * 41 * , 568 - 603 .",
    "politis , d. n. and romano , j. ( 1994 ) .",
    "limit theorems for weakly dependent hilbert space valued random variables with applications to the stationary bootstrap .",
    "_ statistica sinica _ , * 4 * , 461 - 476 .",
    "pourahmadi , m. ( 2001 ) .",
    "_ foundation of time series analysis and prediction theory_. john - wiley : new york .",
    "sharipov , o. , tewes , j. and wendler , m. ( 2016 ) . sequential block bootstrap in a hilbert space with application to change point analysis .",
    "_ the canadian journal of statistics _ , forthcoming .",
    "wiener , n. and masani , p. ( 1957 ) .",
    "the prediction theory of multivariate stochastic processes , i. _ acta mathematica _ , * 98 * , 111 - 150 .",
    "wiener , n. and masani , p. ( 1958 ) .",
    "the prediction theory of multivariate stochastic processes , ii . _",
    "acta mathematica _ ,",
    "* 99 * , 93 - 137 .",
    "shang , l. h. ( 2016 ) .",
    "resampling methods for dependent functional data .",
    "_ preprint_. zhou , t. and politis , d. n. ( 2016 ) .",
    "kernel estimation of first - order nonparametric functional autoregression model and its bootstrap approximation .",
    "_ preprint_.         * table 1 : * estimated exact ( @xmath663 ) and functional sieve bootstrap ( fsb ) estimates of the standard deviation of the sample mean @xmath664 for different values of @xmath665 $ ] and for different parameters @xmath666 and @xmath3 .",
    "@xmath667 refers to the mean , while @xmath668 to the standard deviation of the fsb estimates obtained for @xmath669 replications .       for different values of @xmath665 $ ] .",
    "bullets refer to the estimated exact standard deviation , while the mean estimates of the standard deviation of the fsb ( @xmath670 ) are presented by circles , of the tbb ( @xmath325 ) , by diamonds , of the mbb ( @xmath324 ) , by triangles and of the sb @xmath671 , by  + \" .,title=\"fig:\",width=566 ] +"
  ],
  "abstract_text": [
    "<S> a bootstrap procedure for functional time series is proposed which exploits a general vector autoregressive representation of the time series of fourier coefficients appearing in the karhunen - love expansion of the functional process . </S>",
    "<S> a double sieve - type bootstrap method is developed which avoids the estimation of process operators and generates functional pseudo - time series that appropriately mimic the dependence structure of the functional time series at hand . </S>",
    "<S> the method uses a finite set of functional principal components to capture the essential driving parts of the infinite dimensional process and a finite order vector autoregressive process to imitate the temporal dependence structure of the corresponding vector time series of fourier coefficients . by allowing the number of functional principal components as well as the autoregressive order used to increase to infinity ( at some appropriate rate ) as the sample size increases , </S>",
    "<S> a basic bootstrap central limit theorem is established which shows validity of the bootstrap procedure proposed for functional finite fourier transforms . </S>",
    "<S> some numerical examples illustrate the good finite sample performance of the new bootstrap method proposed .    </S>",
    "<S> = cmr8 at 8 . </S>",
    "<S> truept 2u^n+12 2n+12 _ </S>",
    "<S> ht_h    </S>",
    "<S> p + r_*^+ ii ||||    [ section ] [ section ] [ section ] [ section ] [ section ] [ lemma]notation [ lemma]definition [ lemma ]    22.25 cm 17.5 cm    plus 1pt plus 2pt minus 2pt    = cmss12 = cmr7 </S>"
  ]
}