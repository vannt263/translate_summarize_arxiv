{
  "article_text": [
    "pricing financial derivatives generally boils down to numerically compute an expectation , at least for european type contracts . basically , there are two ways of doing so : either solving a partial differential equation or resorting to monte carlo techniques .",
    "monte carlo integration is known to provide better results when the dimension of the problem increases but for reasonably small dimensional problems , its efficiency is not that clear . however",
    ", alternative numerical integration techniques may help in such situations . in the black - scholes framework ,",
    "the pricing of vanilla options reduces to a numerical integration problem over @xmath0 , where @xmath1 is the number of underlying assets .",
    "this problem has some specificities coming from the properties of the function to integrate .",
    "first , the integrand decreases quickly away from the origin and hence we can consider that the integration domain is a hypercube @xmath2^{d}$ ] with @xmath3 relatively small .",
    "second , the integrand is clearly not a smooth function in the whole domain as it is only continuous at the interface between the area where the function vanishes and the area where it is positive .",
    "moreover , this interface is neither known and nor located at the boundary of the hypercube so there is no hope of using techniques like the periodisation method @xcite to increase the smoothness of the integrand .",
    "finally , the integrand is a muldimensional function in a dimension @xmath1 , which can be large , so one also has to deal with the curse of dimensionality .",
    "hence , it seems quite natural to use monte carlo or quasi - monte carlo @xcite methods to face such a difficult problem .",
    "in fact a crude use of these methods is not necessarily sufficient to reach a good accuracy .",
    "besides the usual variance reduction methods , one needs to develop adaptive methods to make them really competitive . in many situations ,",
    "the function to integrate or to approximate may have completely different behaviors in terms of variations or even in terms of regularity in different parts of the domain @xmath4 in those cases , it might be more efficient to adaptively split @xmath5 in subregions according to error indicators based on quadrature points .",
    "the most famous adaptive monte carlo integration routines are miser @xcite and vegas @xcite .",
    "they rely on stratified and importance sampling and error indicators based on the empirical variance , respectively .",
    "quasi - monte carlo versions of these two algorithms have been introduced in @xcite .",
    "more recently , adaptive approaches have been developed for stratified sampling @xcite and for importance sampling @xcite .",
    "the idea of adaptive algorithms is to make use of past simulations to help better leading future ones . in the case of stratified sampling , both the number of samples in each strata and the boundaries of the strata can be learnt inline .",
    "the idea remains quite similar for adaptive importance sampling , which consists in adaptively learning the optimal change of measure from the already drawn samples .",
    "following the methodology of @xcite , two of the authors have developed an adaptive integration algorithm @xcite based on quasi - monte carlo quadratures , which proved to be efficient for very smooth but also for less smooth functions @xcite .",
    "this algorithm has already been tested on the pricing of basket options achieving excellent results in dimension two but loosing most of its efficiency for larger dimensions .",
    "the loss of accuracy is mainly due to the difficulty to capture the interface between the two regions of interest .",
    "our goal is to improve this algorithm in order to use it in higher dimensions , for the pricing of more general options like digital or put on minimum options and also for the computations of sensitivities with respect to the parameters of the black - scholes model .",
    "the improvements of the algorithm will consist in a new splitting criterion and on a dimension reduction using a principal components analysis combined with control variates .",
    "the rest of the paper is organized as follows . in section 2",
    ", we describe the different kinds of options considered in the black - scholes framework and we discuss the type of sensitivities we are interested in . in section 3 ,",
    "we recall the adaptive algorithm developed in @xcite and introduce a new criterion based on very simple geometric considerations like the ones used in mesh refinement for finite element methods . in section 4",
    ", we compare the new criterion to the old one on the pricing of different types of options in low dimensions .",
    "we focus on examples in dimension two in order to emphasize the quality of the mesh refinement .",
    "section 5 is devoted to sensitivity analysis .",
    "we compute the delta of the different derivatives using standard deterministic techniques like polynomial interpolation allowed by the high accuracy of our adaptive pricing method .",
    "the last section deals with higher dimensional models . the adaptive method is coupled with dimension reduction via a principal component analysis to derive a variance reduction method based on control variates .",
    "we consider a black - scholes model in dimension @xmath1 in which each asset is supposed to follow the standard one dimensional dynamics given under the risk neutral measure by @xmath6 with @xmath7 and where @xmath8 denotes a vector of correlated standard brownian motions .",
    "the volatility @xmath9 is a vector in @xmath0 , the instantaneous interest rate is @xmath10 and @xmath11 is the vector of spot values .",
    "the covariance structure of these correlated brownian motions is supposed to be defined by @xmath12 where @xmath13 is a positive definite matrix with all its diagonal terms equal to one . in the numerical examples considered in the next sections , we assume that @xmath14 where the parameter @xmath15-\\frac{1}{d-1},1[$ ] to ensure that the matrix @xmath13 remains positive definite .",
    "we introduce the cholesky decomposition @xmath16 of @xmath13 ( such that @xmath17 and denote by @xmath18 its @xmath19 row for @xmath20 . the black - scholes model can be rewritten @xmath21 where now @xmath22 is a standard @xmath23dimensional brownian motion .    in this model",
    ", we want to price options with payoffs written as functions of the asset price at a maturity time @xmath24 .",
    "hence , the price is given by the discounted expectation @xmath25 where the function @xmath26 characterizes the option type . in the following ,",
    "we consider three different multidimensional options for    * basket options with payoffs @xmath27 * digital basket options with payoffs @xmath28 * put on minimum options with payoffs @xmath29    the vector @xmath30 represents the weight of the different assets within the basket .",
    "these weights may be negative to allow to consider exchange options .",
    "the variable @xmath31 denotes the strike price and the vector @xmath32 corresponds to an upper barrier on the asset price at maturity time @xmath24 . most of the time , the expectation @xmath33 needs to be computed numerically by means of monte carlo methods . in order to use a systematic approach ,",
    "the expectation @xmath33 is usually rewritten as @xmath34 where @xmath35 is a standard normal random vector in @xmath0 and @xmath36 is a measurable and integrable function . to use our adaptive method described in the next section , we need to transform the computation of @xmath34 into the numerical computation of @xmath37^{d}}\\phi(x)p(x)dx\\ ] ] where @xmath38 is the density of @xmath35 and @xmath39",
    "is chosen large enough to have a good approximation of @xmath34 by @xmath40      when selling a financial derivative , the price of the option is obviously of a primary interest but one should keep in mind that the original definition of an option price goes back to the replicating theory .",
    "the price is actually defined as the value at time @xmath41 of the replicating portfolio .",
    "hence , the price becomes fairly useless if we do not know how to implement the replicating portfolio ; hopefully , we precisely know how many stocks the portfolio should carry on at any time @xmath42 and this quantity is given by the famous _",
    "delta _ of an option defined as the gradient of the option price with respect to the spot vector @xmath43",
    "there are several numerical methods for computing the delta of an option .",
    "the most commonly used method is based on a finite difference approach because of its automatic application .",
    "however , when coupled with a monte carlo method it often yields a poor accuracy unless a very large number of samples is used .",
    "any adaptive integration method relies on a quadrature rule designed for the non - adaptive case .",
    "while monte carlo or quasi - monte carlo methods can deal with integrands with no or little regularity , usual quadrature rules like gauss product rules are built for functions having a given regularity or belonging to particular bases .",
    "these quadratures should not be too sensitive to the dimensional effect and thus quadrature formulae based on interpolation or approximation on different reduced size bases are considered . in the case of @xmath23dimensional fourier bases on periodic smooth functions , korobov spaces @xcite",
    "are built using that the fourier coefficients @xmath44 verify @xmath45 where @xmath46 and @xmath47 is linked to the regularity of the integrand .",
    "the corresponding quadrature formulae are lattice rules @xcite which are exact for the most significant fourier coefficients according to this decay .",
    "non - periodic but smooth functions can be periodized @xcite to still use these quadratures but with an increasing constant of decay .    in the case of polynomial approximations ,",
    "novak and ritter @xcite have obtained quadrature formulae , which are exact for polynomials with total degree less than a given value .",
    "based on the use of the control variates method on piecewise interpolation polynomials , atanassov and dimov @xcite built a numerical method reaching an optimal rate of convergence for multivariate smooth functions with a fixed degree of differentiation .",
    "the previous quadratures give highly accurate results for smooth functions but they can yield a really poor accuracy for non - smooth functions .",
    "monte carlo methods are somehow more stable because they are not sensitive to the smoothness of the integrand .",
    "the quadratures developed in @xcite combine the approximation on reduced tchebychef polynomial basis and the use of quasi - monte carlo points to build this approximation .",
    "they are especially efficient for very smooth functions but they can also handle pretty well only continuous functions .",
    "they have been obtained after successive improvements of an initial adaptive monte carlo method @xcite via quasi - random sequences @xcite and the introduction of tchebychef polynomial basis of korobov type @xcite .",
    "we recall these formulae for a multivariate function defined on the hypercube @xmath48^{d}$ ] . for @xmath49 ,",
    "let @xmath50 .",
    "we introduce the set @xmath51 which corresponds to the level @xmath52 of approximation .",
    "the reduced tchebychef polynomial approximation writes @xmath53 where the @xmath54 coefficients @xmath55",
    "verify @xmath56 for a @xmath57 function . to compute the numerical approximation of the coefficients @xmath58",
    "we fit the model @xmath59 to the observations of the function @xmath60 at some quadrature points @xmath61 with @xmath62 the choice of the points @xmath63 is obviously crucial for the condition number @xmath64 of the least - square matrix @xmath3 .",
    "we have proved in @xcite that if these points are independent random variables distributed according to the multidimensional tchebychef density @xmath65}(x_{i})\\ ] ] then @xmath64 goes to 1 when @xmath66 at a monte carlo speed @xmath67 . moreover",
    "the variance @xmath68 is bounded by one for any set @xmath69 . an even better choice to represent the density",
    "@xmath70 is to use quasi - monte carlo points or quantization points @xcite .",
    "we compute numerically the inverse of the matrix @xmath3 in order to obtain once and for all quadrature formulae for each of the coefficients @xmath55 and finally a quadrature formula for the integral itself . in the following ,",
    "the quadrature points are built using @xmath71 halton points with one additional point at each corner of the domain for a total of @xmath72 points . in most situations ,",
    "the parameter @xmath73 is chosen equal to @xmath74 which is sufficient to ensure a small value for @xmath64 .",
    "the corner points are control points to detect a possible change of regularity of the function @xmath60 .",
    "nevertheless , we will see in section 4 , that more quadrature points may be necessary to detect this change of regularity on the difficult example of digital options . the approximation of @xmath75^{d}}f(x)dx\\ ] ] is given by the quadrature formula @xmath76 which is obtained thanks to the corresponding approximations @xmath77 of the coefficients @xmath55 and the integration of the approximation model .",
    "we also denote by @xmath78 and @xmath79 the relative quadrature formulae on a given rectangle @xmath80 which will be used in the adaptive integration algorithm .",
    "we keep the same error indicators than the one used in our previous paper @xcite .",
    "they rely on hierarchical quadratures for the integral of @xmath60 but also for some of the coefficients of its weighted mean - square approximation .",
    "we select two sets @xmath81 and @xmath82 with @xmath83 , the corresponding quadrature formulae @xmath84 and @xmath85 for the integral of @xmath60 and also the quadrature formulae for some of the leading coefficients in the approximation model .",
    "these coefficients are the @xmath86 coefficients belonging to the set @xmath87 of the coefficients @xmath55 for which all the indexes @xmath88 are equal to zero or only one is non - zero and equal to one .",
    "our error indicator @xmath89 is @xmath90 on a given hyperrectangle @xmath91 this indicator is more robust than the usual indicator based on the comparison between only @xmath92 and @xmath93 .",
    "indeed , it is less likely to happen that all the estimators of the leading coefficients are close to each other but all wrong .",
    "the approximate value of the integral on a given hyperrectangle is @xmath93 and the approximate integral of @xmath60 is the sum of the integrals over all the hyperrectangles .",
    "now , we describe the splitting strategies used in the numerical experiments . at each step of the algorithm ,",
    "the list of all the remaining hyper - rectangles involved in the algorithm is stored and these hyperrectangles are sorted according to their error indicator .",
    "once the splitting is performed , the hyperrectangle @xmath80 with the largest error indicator is removed from the list and the hyperrectangles @xmath94 and @xmath95 are inserted in the list according to their error indicators @xmath96 and @xmath97 .",
    "the first strategy named fas is fully adaptive .",
    "it consists in trying the @xmath1 possible ways to divide the hyper - rectangle @xmath80 with largest error indicator in two equal size pieces @xmath94 and @xmath95 along one of the axes and keeping only the best splitting .",
    "the best splitting is the one for which @xmath98 is minimum among the @xmath1 possible choices .",
    "each step of this algorithm requires @xmath99 evaluations of the function @xmath60 .",
    "the computational cost of the method should also take into account the cost of inserting the two newly created hyperrectangles into the list of all hyperrectangles .",
    "this can be done efficiently by an insertion sort which has a complexity of @xmath100 for our algorithm with @xmath101 steps . in most practicals examples ,",
    "the evaluation of the function @xmath60 requires a lot of atomic computations and hence it makes sense to neglect the cost the sort compared to the number of function evaluations .",
    "the fas requires @xmath1 trials to find the optimal splitting .",
    "it is mainly interesting when the integrand has variations different from several degrees of magnitude from one coordinate to another like for instance for the two dimensional function @xmath102 when pricing vanilla options , this kind of situation is unlikely to happen . furthermore and maybe more importantly , we have noticed in our previous work @xcite that the convergence problems of our algorithm came from a too fine splitting in one direction near the interface between the regions where the regularity changes .",
    "we propose another strategy named geometrical random splitting ( grs ) in order to reduce the computational costs and to solve the convergence problems by finding more precisely this interface . at each step of the algorithm",
    ", we divide the hyperrectangle with the largest error criterion in two equal size pieces @xmath94 and @xmath95 uniformly at random among the admissible directions .",
    "the admissible directions are the ones having the larger length among the axis of the hyperrectangle .",
    "the initial hyperrectangle is always a hypercube which means that we can never have a ratio more than two between the different lengths of the axis of the hyperrectangles occurring in the mesh .",
    "the cost of the algorithm is @xmath103 and it is stochastic which enables to compute some statistics on its results .",
    "in this section , we compare the fas and the grs for pricing vanilla options on several examples already treated in @xcite and also on examples from the general model . on all numerical examples , the same quadrature formulae will be used for the two methods .",
    "the number of iterations of the algorithm will be @xmath104 for the fas and consequently @xmath1 times more for the grs in order to keep the same complexity .",
    "let us focus a little on basket options .",
    "the price of such options , with payoffs only depending on the asset price at maturity time @xmath24 , can be expressed as an expectation @xmath105 .",
    "when the random vector @xmath106 has a density @xmath107 with respect to the lebesgue measure , computing this expectation is easily turned into a numerical integration problem @xmath108^d } \\psi(x ) f_s(x ) dx.\\ ] ] when @xmath109 , there is no need of a numerical integration as a closed formula exists . in the black ",
    "scholes framework , we know that @xmath110 where @xmath35 is a random normal vector with values in @xmath111 . hence , @xmath112^d }    \\psi\\left(s_{0}^{i}\\exp\\left\\{(r-\\frac{\\sigma_{i}^{2}}{2})t+\\sigma_{i}c_{i }    \\sqrt{t } \\ ; x\\right\\ } , 1 \\le",
    "i \\le d \\right ) \\frac{1}{(2\\pi)^{d/2 } }   e^{-|x|^2/2 } dx.\\end{aligned}\\ ] ] for the particular case of a call basket option , the payoff @xmath26 writes down @xmath113 therefore , if we denote by @xmath114 the price of the call basket option , we can write @xmath115^d } \\left ( \\sum_{i=1}^d \\lambda_i s_{0}^{i}\\exp\\left\\{(r-\\frac{\\sigma_{i}^{2}}{2})t+\\sigma_{i}c_{i } \\sqrt{t } \\ ; x\\right\\ } - k\\right)_+   e^{-|x|^2/2 } dx.\\ ] ] using the equality @xmath116 and letting the price of the corresponding put basket option be @xmath117 , we obtain the so  called call put parity relationship @xmath118    in general , this formula is used to obtain the hardest price to compute ( in terms of variance ) between the call or the put option prices from the other . here , we independently compute the call and put option prices and use this formula as a criterion of accuracy .",
    "the infinite integral is truncated and we let @xmath119^d } \\left ( \\sum_{i=1}^d\\lambda_i s_{0}^{i}\\exp\\left\\{(r-\\frac{\\sigma_{i}^{2}}{2})t+\\sigma_{i}c_{i } \\sqrt{t } \\ ; x\\right\\ } - k\\right)_+   e^{-|x|^2/2 } dx\\ ] ] be the truncated estimation of @xmath114 .",
    "the truncated approximation of the put basket option price @xmath120 is defined in a similar way .",
    "note that these multi  dimensional integrals are truncated on a square domain .",
    "in all the following examples dealing with basket options , we fix the weights of the basket as @xmath121 so that the baskets are all homogeneous and their weights sum up to one .      the numerical tests considered in this paragraph are very similar to the ones treated in @xcite .",
    "three different values for the strike price are tested , one at the money @xmath122 one out @xmath123 and one completely out @xmath124 these examples were already studied in @xcite and the conclusion was that the fas was outperforming monte carlo and quasi - monte carlo integration .",
    "hence , we only compare the grs to the fas .",
    "moreover , the new algorithm is only run once as we have a deterministic error criterion based on the call - put parity formula .    the grs is used with quadrature formulae of degrees @xmath125 and @xmath126 .",
    "the latter corresponds to a number of function evaluations of @xmath127 we give in tables [ tab_2dbasket_ex1 ] and [ tab_2dbasket_ex2 ] , the values of the truncated estimations for @xmath128 and @xmath129 .",
    "we also compute @xmath130 for these reference values and denote by @xmath131 the same error indicator using the fas . truncating",
    "the domain of a real valued standard normal random variable to @xmath132 $ ] may seem far too large .",
    "this is true from a monte - carlo point of view and we have actually also run some tests with more conventional values such as @xmath133 .",
    "these tests were already showing a far better accuracy than a crude monte carlo ; the results obtained on the examples of table  [ tab_2dbasket_ex1 ] already had @xmath134 accurate digits .",
    "however , since we are targeting to compute sensibilities , we need a better accuracy , which explains the choices of the parameter @xmath3 .",
    ".basket option with parameters @xmath135 , @xmath136 , @xmath137 @xmath138 , @xmath139 [ cols=\"^,^,^,^,^\",options=\"header \" , ]",
    "in this paper , we have developed a new numerical integration algorithm based on a geometrical random splitting .",
    "this new algorithm has been successfully applied to the pricing of vanilla options in dimensions up to five . in particular",
    ", this new algorithm efficiently handles the difficult problems of pricing and hedging digital options . in most situations ,",
    "the accuracies we have obtained were out of reach for a crude monte carlo approach . for higher dimensions",
    ", we have shown that the grs can be used as a control variate when associated to a principal component analysis .",
    "the resulting variance reduction was quite impressive especially for very correlated assets .",
    "one important issue would be the development of other dimension reduction techniques that could be coupled with the grs .",
    "the grs itself can obviously have many other applications for instance in computer experiment or in the adaptive approximation of partial differential equations .",
    "the grs algorithm proposed in this paper is very satisfactory on most examples studied .",
    "c. de luigi , s. maire , adaptive integration and approximation over hyper - rectangular regions with applications to basket option pricing , monte carlo methods and applications , 16 , ( 3 - 4 ) , pp.265 - 282 , 2010 ."
  ],
  "abstract_text": [
    "<S> we develop a numerical method for pricing multidimensional vanilla options in the black - scholes framework . in low dimensions , we improve an adaptive integration algorithm proposed by two of the authors by introducing a new splitting strategy based on a geometrical criterion . in higher dimensions , this new algorithm is used as a control variate after a dimension reduction based on principal component analysis . </S>",
    "<S> numerical tests are performed on the pricing of basket , put on minimum and digital options in dimensions up to ten .    </S>",
    "<S> option pricing , adaptive numerical integration , control variate    65c05 , 65d30,91g60 </S>"
  ]
}