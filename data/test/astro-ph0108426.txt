{
  "article_text": [
    "in astronomical data analysis , one develops models of physical processes in the spectral , spatial , and/or temporal domains , then fits these models to observed data",
    ". these data may be of arbitrary dimension , and/or they may have been collected using an arbitrary number of telescopes that observe in different wavelength bands .",
    "_ sherpa _ , the modeling and fitting application of the _ chandra interactive analysis of observations ( ciao ) _ software package,@xcite is designed to tackle such complex multi - dimensional , multi - wavelength analyses .",
    "free of hard - wired instrument details , _ sherpa _ is outfitted with a wide variety of models , fit statistics , and methods of optimization , model comparison , and parameter estimation , and it offers powerful embedded visualization , scripting , and data manipulation capabilities .",
    "it can thus be used to analyze energy- or wavelength - space data from , _",
    "e.g. _ , ground - based telescopes , _ iso _ ,",
    "_ hubble _ , _ xmm _ , and the _ chandra x - ray observatory _ , as well as from next - generation projects such as the virtual observatory .",
    "in this paper we present a basic overview of _",
    "sherpa_. in ",
    "[ sect : code ] , we describe the application itself , while in  [ sect : func ] we describe _ sherpa _",
    "s capabilities using a typical _ sherpa _ session as a framework , from reading in data to determining the 1@xmath0 errors on the best - fit model parameters . in ",
    "[ sect : examples ] we provide brief examples of how one may use _",
    "sherpa_. for more information , the reader may consult the on - line _ sherpa _",
    "the authors have developed _ sherpa _ using the object - oriented c++ programming language.@xcite in object - oriented programming , objects encapsulate related data and functions ; thus , classes ( from which objects are instantiated ) can be written that more closely model the problem domain . for a modeling and fitting application",
    ", classes containing fitting methods , statistics , models , and data organize the code in a way that more intuitively mirrors the concepts underlying the fitting process .",
    "_ sherpa _ is an interactive application , using a lex / yacc - based parser to interpret commands .",
    "_ sherpa _ accepts input via the command - line interface or ascii script files .",
    "the _ ciao _ package also contains a number of other programs and libraries that enhance _ sherpa _ s capabilities .",
    "data i / o is provided by the _",
    "ciao _ data model library.@xcite the data model gives a higher - level , abstract view of astronomical data files and provides transparent access to the most common astronomical file formats ( fits , _ iraf _ imh , _ iraf _ qpoe ) .",
    "the data model provides a uniform interface so that the application need no longer use i / o functions specific to particular file formats .",
    "the data model also has a sophisticated filtering and binning syntax that allows the extraction of selected portions of data contained in a file",
    ".    for all visualization needs , _ sherpa _ uses _ chips _ , the _ chandra imaging and plotting system_.@xcite as the name indicates , _ chips _ provides an interface to plotting and imaging applications ( currently _ sm_,@xcite _ saods9_,@xcite and _ saotng_@xcite ) .",
    "_ chips _ is both a stand - alone , interactive application and a c++ library ( which is how it is used by",
    "_ sherpa_it passes commands and data to _ chips _ ) .",
    "_ sherpa _ can access _ chips _ functions through the _ chips _ api , but it is also possible for _ chips _ commands to be input directly at the _ sherpa _ command - line .",
    "as of _ ciao 2.1 _ , the s  lang interpreted scripting language@xcite has been embedded in _",
    "ciao_. its features include :    * global and local interpreted variables , and multidimensional arrays ( up to seven dimensions ) ; * branching and looping , and programmability with user - defined functions ; * string and numeric data types , structures , and a limited form of pointers ; * built - in arithmetic and mathematical functions , which operate transparently on arrays ; and * extensibility  the ability to create new functionality for _ ciao _ applications ( _ e.g. _ guide ; see  [ sect : chgrating ] ) .",
    "s  lang is accessed through a supplementary library layer , dubbed variables , math , and macros ( varmm),@xcite which gives the user additional capability to define structured variables directly from disk files , as well as enabling existing _ ciao _ applications to access s  lang variables and other features with a bare minimum of new development effort .",
    "the capabilities of _ sherpa _ can be best described by following the steps of a typical analysis session . in such a session",
    ", the user would :    * read in ( source and/or background ) data ( and set filters , _ etc . _ ) ; * build models that describe these data ( as well as the telescope / detector combination ) ; * choose a statistic that quantifies how well these models describe the data ; * fit the models to the data , determining the minimum value of the chosen statistic ; * compare best - fit results achieved with different models to select one best - fit model ; and * estimate the errors for each parameter of the best - fit model .",
    "below , we discuss each of these items in turn . we note that a typical session would also include _ chips _ visualization ( of the source data , or of the background fit , _ etc . _ ) ; while we do not discuss it specifically in this section , we provide examples of visualization in  [ sect : examples ] .",
    "data input marks the beginning of a _ sherpa _ analysis session .",
    "the data may be input from either a file on disk or an interpreted s  lang variable . in table",
    "[ tab : io ] , we list data types that may be input into _ sherpa _ , while in table [ tab : iotypes ] we list currently supported file formats .",
    "( instrument characteristics , such as the point - spread function , or psf , may also be contained in files that are read in when an instrument model is specified ; see  [ sect : inst ] . )",
    "[ ht ]        ' '' ''    data & source data +    ' '' ''    back & background data +    ' '' ''    ( b)errors & source or background errors +    ' '' ''    ( b)errors system & source or background systematic errors +    ' '' ''    filter & specification of which bins of a given dataset are to be analyzed +    ' '' ''    weight & statistical weights for each datum +    ' '' ''    groups & specification of how data are to be binned +    [ ht ]        ' '' ''    ascii & ascii data +    ' '' ''    fitsbin & fits binary table +    ' '' ''    fits & fits image +    ' '' ''    imh & _ iraf _ imh image +    ' '' ''    pha & type i & ii pha data +    ' '' ''    qp & _ iraf _ qpoe image +    one only needs to read in source data to start an analysis session ; other data types ( such as background ) are not required",
    ". however , some types of data may be input automatically when source data are read ; for instance , a pha file can have columns that specify the statistical and systematic errors ( stat_err and sys_err , respectively ) and the data grouping ( grouping ) , and it can have a keyword ( backfile ) specifying the background dataset . also , one can specify statistical and systematic errors , filters , and statistical weights via the command - line interface .",
    "if statistical errors are not input or specified , they are estimated by _ sherpa _ during fitting ; see  [ sect : stat ] .    an arbitrary number of datasets may be input into _ sherpa _ , and arbitrary subsets of these data may be jointly analyzed .",
    "since current standard processing of _ chandra _ grating data includes the extraction of background spectra from regions on either side of the source extraction region , one may also specify up to two background datasets per source dataset .",
    "these data may be fit simultaneously with the source data ( see  [ sect : srcback ] ) , or they may be subtracted from the source data on a channel - by - channel basis prior to a fit : @xmath1 \\,.\\ ] ] @xmath2 is the source datum in bin @xmath3 , @xmath4 is the background datum in bin @xmath3 of background set @xmath5 , @xmath6 is the observation time , and @xmath7 is the  backscale \" ( the backscal header keyword value in a pha file ) , typically defined as the ratio of data extraction area to total detector area .    at any time during an analysis session , quantities like the background - subtracted data , convolved model amplitudes , or fit residuals may be output to files using the write command .",
    "( the files may be saved in any of the formats listed in table [ tab : iotypes ] . )",
    "a user may also save ( and later restore ) the state of a _ sherpa _ analysis session using a model descriptor list ( mdl ) .",
    "the mdl is a record of all information relevant to a sherpa fitting session : the names of all input data files and associated filters ; all defined source and instrument models , with model parameter settings ; the choices of optimization method and fit statistic ; and the fluxes and identification of emission / absorption lines that the user may have identified ( see  [ sect : chgrating ] )",
    ". the mdl may be either saved to disk or instantiated as an s  lang variable .",
    "once source and/or background data are input , the next step is to create model expressions reflecting one s knowledge of the physical processes which gave rise to those data .",
    "( the user can also build model expressions that represent the observing instruments .",
    "[ sect : inst ] . ) _ sherpa _ currently provides nearly 40 of its own one- and two - dimensional models and 90 one - dimensional _",
    "xspec_@xcite models that may be arbitrarily combined to build complex composite models , as we show below .",
    "note that a user can also define a model and compile it into the libascfituser.so shared - object library , where it can be accessed by",
    "_ sherpa_.    [ [ sherpa - model - language . ] ] sherpa model language .",
    "+ + + + + + + + + + + + + + + + + + + + + +    the _ sherpa _ model language resolves ambiguity by allowing the user to give a unique name or alias to each instance of a model . for example , if two datasets are entered , and each is to be fit with a gaussian model , but with different parameters , one might type :    .... sherpa > gauss1d[g1 ] sherpa > gauss1d[g2 ] sherpa > source 1 = g1 sherpa > source 2 = g2 ....    whereas if each is to be fit with the same gaussian model , one might type :    .... sherpa > gauss1d[g1 ] sherpa > source 1:2 = g1 ....    [ [ linking - parameters - to - other - parameters - or - to - models . ] ] linking parameters to other parameters or to models .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one can link an individual model parameter to another model parameter , so that their values are correlated .",
    "for instance , if a particular atomic line is observed by two different detectors , it could be modeled with two gaussian functions whose centroids are linked :    .... sherpa > source 1 = gauss1d[g1 ] sherpa > source 2 = gauss1d[g2 ] sherpa > g1.pos = > g2.pos ....    ( note that simple arithmetic relations are also possible , _ e.g. _  g1.ampl = > 2*g2.ampl . ) at this point , g1.pos is no longer a free parameter of the fit .",
    "it can be made free again with the command unlink g1.pos .",
    "one can also link an individual model parameter to a model , to describe how a parameter s value will vary as a function of position in parameter space .",
    "for instance , one can model emission from an accretion disk using a blackbody function whose temperature is a function of radius :    .... sherpa > source = bb sherpa >",
    "temperature = poly sherpa > bb.kt = > temperature ....    [ [ nesting - model - expressions . ] ] nesting model expressions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    a model may be nested within another , _",
    "i.e. _ one may specify a model expression of the form g(f(x ) ) . in this example",
    ", the input data axis is transformed to log - space using _ sherpa _ s log model , and a blackbody model is evaluated in that space :    .... sherpa > logenergy = shlog sherpa > source = bb{logenergy } ....    [ [ multi - dimensional - model - expressions . ] ] multi - dimensional model expressions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one can specify completely different models that are to be evaluated along different axes of a multi - dimensional dataset , as in this example , where two - dimensional spectral - radius data are modeled with a combination of lorentzian and power - law models :    .... sherpa > lorentz[spatial ] sherpa > pow[spec ] sherpa > source = spatial{x1}*spec{x2 } ....    x1 and x2 represent the first and second axes of the input image , respectively .",
    "instrument models are used to quantify characteristics , such as effective area , a detector s energy response , or a mirror s point - spread function .",
    "they provide a mapping from photon space ( where source and background models are evaluated ) to counts space ( where fit statistics are computed ) .",
    "the instrument model class is the key element which makes _ sherpa _ a mission - independent application , permitting analysis of data observed by any telescope , regardless of whether it is ground - based or space - based .",
    "currently , _",
    "sherpa _ defines three instrument model classes : ( 1 ) rsp , in which an evaluated one - dimensional model is multiplied by an ancillary response ( arf , _",
    "i.e. _  an effective area ) on a bin - by - bin basis , then folded through a response matrix ( rmf ) ; ( 2 ) psffromfile , in which the evaluated one- or two - dimensional model is convolved with a numeric kernel ; and ( 3 ) psffromtcd , in which the evaluated one- or two - dimensional model is convolved with an analytic kernel ( _ e.g. _  gaussian ) defined within _ ciao _ s transformation , convolution , and deconvolution ( tcd ) library .",
    "future versions of _ sherpa _ may include new classes to treat , _",
    "e.g. _ , two - dimensional exposure maps .",
    "the @xmath8 statistic is appropriate for the analysis of gaussian - distributed data .",
    "it is defined as @xmath9 where @xmath10 is the ( source or background ) data in bin @xmath3 , @xmath11 is the ( convolved source or background ) model predicted amplitude in bin @xmath3 , and @xmath12 is the estimated error for the @xmath13 datum ( the square root of the variance of the distribution from which that datum had been sampled ) .",
    "as noted in  [ sect : io ] , one may specify the errors via a file or the command - line ; if this is done , the @xmath8 statistic is used as shown above .",
    "otherwise , the data are assumed to be poisson - distributed , with the errors for each datum estimated during analysis .",
    "the large array of error estimators that _ sherpa _ provides is one of its key features ; these are listed in table [ tab : stat ] .",
    "note that the entries in this table are only correct if the background data have not been subtracted from the source data ; otherwise errors are propagated in the standard manner ( @xmath14 ) .",
    "also note that error estimates based on model amplitudes are inappropriate to use in the analysis of background - subtracted data , as they generally underestimate the true error .",
    "using a @xmath8-based statistic to analyze counts data is generally only valid in the gaussian ( high - counts ) limit ( @xmath15 5 counts in _ each _ bin ) .",
    "this is because the approximations that must be made to derive the @xmath8 statistic from poisson log - likelihood @xmath16 break down otherwise .",
    "the chi gehrels@xcite and chi primini@xcite statistics are designed to work with low - count data ; note that the former it is not generally sampled from the @xmath8 distribution and thus the derived best - fit statistic may appear to be  too good \" ( @xmath17 1 , where @xmath18 is the number of degrees of freedom in the fit ) , in the low - counts limit .",
    "the poisson likelihood function is @xmath19 _ sherpa _ features two statistics based on this function : cash and bayes .    the version of the cash statistic@xcite used by _",
    "sherpa _ is derived from @xmath20 by ( 1 ) taking its logarithm , ( 2 ) dropping the factorial term ( which remains constant during fits to given datasets ) , ( 3 ) multiplying by two , and ( 4 ) changing the sign ( so that the statistic may be minimized , like @xmath8 ) : @xmath21 \\,,\\ ] ] in the high - counts limit , @xmath22 , so that in principle one can use @xmath23 instead of @xmath24 in model comparison tests ( see  [ sect : modcomp ] ) .",
    "[ ht ]        ' '' ''    statistic & variance @xmath25 +    ' '' ''    chi dvar & @xmath10 +    ' '' ''    chi gehrels ( _ sherpa _ default ) & @xmath26 ^ 2 $ ] +    ' '' ''    chi mvar & @xmath11 +    ' '' ''    chi parent & @xmath27 +    ' '' ''    chi primini & @xmath11 from previous best - fit +    the bayes statistic@xcite is based on bayesian statistical methodology and is appropriate to use when a background is input and the rate of background accumulation may be taken as the same in both the background and source extraction regions .",
    "this statistic takes into account uncertainty in the ( implicitly defined ) background amplitudes via marginalization : @xmath28 where @xmath29 represents the set of source model parameters and @xmath30 is the background amplitude in the @xmath13 bin .",
    "( note that the above equation has an analytic solution that we do not reproduce here . )",
    "note that because the cash and bayes statistics are based on the likelihood function , they should not be applied to background - subtracted data .",
    "also , there is no  goodness - of - fit \" measure associated with cash and bayes , as there is of @xmath8-based statistics .",
    "such a measure can , in principle , be computed by performing monte carlo simulations : one would repeatedly sample new datasets from the best - fit model , fit them , and note where the observed statistic lies within the derived distribution of statistics .",
    "optimization is the act of minimizing @xmath8 or @xmath31 by varying the thawed parameters of the defined model .",
    "_ sherpa _ provides a number of optimization methods , which can be classified in two broad categories : those which find a local minimum of the statistical surface in parameter space by moving along the local gradient of that surface , and those which examine large ( hyper-)volumes of parameter space in a search for the global minimum ( see table [ tab : opt ] ) .",
    "below , we discuss the three optimization methods appropriate for finding local minima : powell , simplex , and levenberg - marquardt .",
    "users should be acquainted with the ( dis)advantages of each so as to make the best use of them .",
    "( for more information about _",
    "sherpa s _ other optimization methods , consult the _ sherpa _ manual@xcite and , _",
    "e.g. _ , press _ et al .",
    "_  1992@xcite . )",
    "powell , a direction - set method in which the chosen statistic is minimized by varying each member of an ( initially orthogonal ) set of parameter - space vectors in turn , is _",
    "sherpa s _ default optimizer .",
    "its advantages include the fact that no gradient calculations are required , and that it is a robust method , capable of finding minima even on complex statistical surfaces .",
    "( also , unlike levenberg - marquardt , is can be used effectively with likelihood - based statistics . )",
    "its primary disadvantage is that it is relatively slow .",
    "[ ht ]        ' '' ''    local minimum & powell , simplex , levenberg - marquardt +    ' '' ''    global minimum & grid(-powell ) , monte(-powell ) , simulated annealing +    in simplex optimization , the fit statistic is calculated at the @xmath32 vertices of a simplex in a @xmath18-dimensional parameter space , with the vertices being moved until the local minimum is bracketed .",
    "its advantages include the fact that no gradient calculations are required , it can find minima of complex statistical surfaces , and it requires fewer model evaluations than powell . however , it is not as robust as powell .",
    "the simplex method is best - used when one starts the optimization close to the local minimum ; for instance , it is a good optimizer to use in parameter estimation ( see  [ sect : parest ] ) .    in levenberg - marquardt optimization ,",
    "the local minimum is approached by taking steps in parameter space whose magnitudes @xmath33 are computed by solving the set of linear equations @xmath34 where @xmath35~~{\\rm and}~~\\beta_i~=~-\\frac{1}{2}\\frac{{\\partial}\\chi^2}{{\\partial}x_i } \\,,\\end{aligned}\\ ] ] and @xmath36 is a matrix with non - zero diagonal elements whose magnitudes are inversely proportional to @xmath33 .",
    "the primary advantage of levenberg - marquardt optimization is speed , while its disadvantages include the fact that a gradient computation is required , that it is appropriate for use with @xmath8-based statistics only , and that it is less robust when applied to optimization on a complex statistical surface .",
    "( to circumvent the third issue , we have introduced the option that the optimization method may be switched from levenberg - marquardt to simplex close to the minimum , where the disadvantages of levenberg - marquardt become more readily apparent . )      often , a user will fit more than one parametrized model to a given dataset , and will wish to compare the best - fit results of each . for instance",
    ", one may fit two continuum models to data , and need to decide whether the improvement in the fit statistic that is observed when using the more complex model is attributable to chance . to make this decision ,",
    "one uses a model comparison test to yield either : ( 1 ) the frequentist test significance , @xmath37 , which is the probability of selecting the alternative ( more complex ) model @xmath38 when in fact the null hypothesis @xmath39 is correct ; or ( 2 ) the bayesian odds , the ratio of model posterior probabilities for @xmath38 and @xmath39 .",
    "if the prior probability distribution for a model s parameter values is constant , then its posterior probability is proportional to the integral of the likelihood function @xmath20 over parameter space .",
    "the model comparison test that is currently available to the _ sherpa _ user is the @xmath8 goodness - of - fit ( gof ) test , an alternative - free test .",
    "the next version of _ sherpa _ will also contain the maximum likelihood ratio ( mlr ) test and the @xmath40-test .",
    "methods of model comparison that may be included in future versions of _ sherpa _ include : using simulations to determine model comparison test statistics numerically when the conditions for using an analytic test are not fulfilled ; computing the bayesian odds using the laplace approximation@xcite ; and computing the bayesian odds via numerical integration .",
    "we note that these new techniques , in addition to assisting the comparison of models , would also be useful for parameter estimation .      once one has selected a best - fit model , the next question is : what are the errors on the model parameters , _",
    "i.e. _  what are the confidence intervals associated with each model parameter ? in general , a frequentist statistician can determine possible intervals by repeatedly simulating data from the best - fit model , fitting these data , and determining the distribution of best - fit values for each model parameter .",
    "the central 68% of each distribution can then be deemed the 1@xmath0 confidence interval .",
    "however , simulations are computationally expensive , and if : ( 1 ) the @xmath8 or @xmath16 surface is approximately shaped like a multi - dimensional paraboloid ( _ i.e. _  contours of constant @xmath8 or @xmath16 appear ellipsoidal in two - dimensional plots ) , and ( 2 ) the best - fit point is sufficiently far from parameter space boundaries , then confidence intervals may be estimated by examining the statistical surface itself .",
    "_ sherpa _ currently features three parameter estimation methods appropriate for use when the statistical surface is  well - behaved \" : uncertainty , projection , and covariance .",
    "( in addition , one can make one- or two - dimensional plots showing the fit statistic value as a function of parameter value[s ] . ) with uncertainty , the error for a particular thawed parameter is estimated by varying its value ( while holding all other parameter values fixed to their best - fit values ) until the fit statistic increases by a preset amount from its minimum value ( _ e.g. _  @xmath24 = 1 for 1@xmath0 ) .",
    "projection is similar to uncertainty , except that the values of all other parameters are allowed to float to new best - fit values . with covariance ,",
    "errors are estimated by calculating the covariance matrix , the inverse of the matrix of statistical surface second derivatives at the best - fit point .",
    "each of these methods has distinct ( dis)advantages : for example , uncertainty , while fast , will generally underestimate an interval s size if the parameter is correlated with other parameters ; and projection provides a means to visualize the surface and can be used even if the model parameters are correlated , but is in the strictest statistical sense no more accurate than the much faster covariance method ( which is itself not useful for visualization ) .",
    "in this section , we present four examples of _ sherpa _ analyses . we note that space limitations prevent us from showing all but a few commands that are used in these analyses ; for full scripts , plus scripts showing other analyses , please consult the _ sherpa _ analysis threads.@xcite      in this example , we analyze flux data ( log@xmath41 $ ] ) of re j1034 + 396,@xcite a low - redshift , narrow - line seyfert 1 galaxy .",
    "the data were collected by the william herschel 4.2 m telescope , _ hst _ , and _",
    "bepposax_. because the data are not sampled from a poisson distribution , the errors must be input or specified ; here , we assume that the error on the flux is 1% :           we would like to thank mark birkinshaw , william joye , malin ljungberg , and michael noble for past and present contributions to _ sherpa _ s development .",
    "we would also like to thank holly jessop for her tireless work maintaining the _ sherpa _ manuals and threads .",
    "the _ sherpa _",
    "project is supported by the _ chandra _ x - ray center under nasa contract nas8 - 39073 .",
    "s.  doe , m.  ljungberg , a.  siemiginowska , & w.  joye ,  fitting and modeling of axaf data with the asc fitting application , \" in _ astronomical data analysis software and systems vii _ , r.  albrecht , r.  n.  hook , & h.  a.  bushouse , ed . , pp .  157160 , asp , san francisco , 1998 .",
    "s.  doe , m.  noble , & r.  smith ,  interactive analysis and scripting in ciao 2.0 , \" in _ astronomical data analysis software and systems x _ , f.  r.  harnden , f.  a.  primini , & h.  e.  payne , ed . ,",
    "_ in press _ , asp , san francisco , 2001 .",
    "k.  kearns , f.  primini , & d.  alexander , `` bias - free parameter estimation with few counts , by iterative chi - squared minimization , '' in _ astronomical data analysis software and systems iv _",
    ", r.  a.  shaw , h.  e.  payne , & j.  j.  e.  hayes , ed . , pp .",
    "331334 , asp , san francisco , 1995 .",
    "t.  j.  loredo & d.  q.  lamb , `` establishing the existence of lines in gamma - ray bursts , '' in _ gamma - ray bursts : observations , analyses , and theories _",
    ", c.  ho , r.  epstein , & e.  fenimore , ed . ,",
    "pp .  414415 , cambridge university press , cambridge , 1992 .",
    "r.  k.  smith , n.  s.  brickhouse , d.  a.  liedahl , & j.  c.  raymond , `` collisional plasma models with apec / aped : emission line diagnostics of hydrogen - like and helium - like ions , '' _ ap .",
    "j.  lett .",
    "_ , _ in press _ , 2001"
  ],
  "abstract_text": [
    "<S> the ever - increasing quality and complexity of astronomical data underscores the need for new and powerful data analysis applications . </S>",
    "<S> this need has led to the development of _ sherpa _ , a modeling and fitting program in the _ ciao _ software package that enables the analysis of multi - dimensional , multi - wavelength data . in this paper , </S>",
    "<S> we present an overview of _ sherpa _ s features , which include : support for a wide variety of input and output data formats , including the new model descriptor list ( mdl ) format ; a model language which permits the construction of arbitrarily complex model expressions , including ones representing instrument characteristics ; a wide variety of fit statistics and methods of optimization , model comparison , and parameter estimation ; multi - dimensional visualization , provided by _ chips _ ; and new interactive analysis capabilities provided by embedding the s  lang interpreted scripting language . </S>",
    "<S> we conclude by showing example _ sherpa _ analysis sessions . </S>"
  ]
}