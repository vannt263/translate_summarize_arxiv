{
  "article_text": [
    "network systems  @xcite typically display a modular organization , reflecting the existence of special affinities among vertices in the same module , which may be a consequence of their having similar features or the same roles in the network .",
    "such affinities are revealed by a considerably larger density of edges within modules than between modules .",
    "this property is called community structure or graph clustering  @xcite : detecting the modules ( also called _ clusters _ or _ communities _ ) may uncover similarity classes of vertices , the organization of the system and the function of its parts .",
    "the community structure of complex networks is still rather elusive .",
    "the definition of community is controversial , and should be adapted to the particular class of systems / problems one considers .",
    "consequently it is not yet clear how scholars can test and validate community detection methods , although the issue has lately received some attention  @xcite .",
    "also , in order to deliver possibly more reliable results , methods should ideally exploit all features of the system , like edge directedness and weight ( for directed and weighted networks , respectively ) , and account for properties of the partitions , like hierarchy  @xcite and community overlaps  @xcite . very few methods are capable to take all these factors into consideration  @xcite .",
    "another important barrier is the computational complexity of the algorithms , which keep many of them from being applied to networks with millions of vertices or larger .    in this paper",
    "we focus on another major problem affecting clustering techniques .",
    "most of them , in fact , do not deliver a unique answer .",
    "the most typical scenario is when the seeked partition or individual clusters correspond to extrema of a cost function  @xcite , whose search can only be carried out with approximation techniques , with results depending on random seeds and on the choice of initial conditions .",
    "allegedly deterministic methods may also run into similar difficulties .",
    "for instance , in divisive clustering methods  @xcite the edges to be removed are the ones corresponding to the lowest / highest value of a variable , and there is a non - negligible chance of ties , especially in the final stages of the calculation , when many edges have been removed from the system . in such cases",
    "one usually picks at random from the set of edges with equal ( extremal ) values , introducing a dependence on random seeds .    in the presence of several outputs of a given method ,",
    "is there a partition more representative of the actual community structure of the system ?",
    "if this were the case , one would need a criterion to sort out a specific partition and discard all others .",
    "a better option is combining the information of the different outputs into a new partition .",
    "exploiting the information of different partitions is also very important in the detection of communities in dynamic systems  @xcite , a problem of growing importance , given the increasing availability of time - stamped network datasets  @xcite .",
    "existing methods typically rely on the analysis of individual snapshots , while the history of the system should also play a role  @xcite . therefore",
    ", combining partitions corresponding to different time windows is a promising approach .",
    "consensus clustering  @xcite is a well known technique used in data analysis to solve this problem .",
    "typically , the goal is searching for the so - called _ median _ ( or _ consensus _ ) _ partition _ ,",
    "i.e. the partition that is most similar , on average , to all the input partitions .",
    "the similarity can be measured in several ways , for instance with the normalized mutual information ( nmi )  @xcite . in its standard formulation",
    "it is a difficult combinatorial optimization problem .",
    "an alternative greedy strategy  @xcite , which we explore here , uses the _ consensus matrix _ ,",
    "i.e. a matrix based on the cooccurrence of vertices in clusters of the input partitions .",
    "the consensus matrix is used as an input for the graph clustering technique adopted , leading to a new set of partitions , which generate a new consensus matrix , etc .",
    ", until a unique partition is finally reached , which can not be altered by further iterations .",
    "this procedure has proven to lead quickly to consistent and stable partitions in real networks  @xcite .",
    "we stress that our goal is not finding a better optimum for the objective function of a given method .",
    "consensus partitions usually do not deliver improved optima . on the other hand , global quality functions , like modularity  @xcite , are known to have serious limits  @xcite , and their optimization is often unable to detect clusters in realistic settings , not even when the clusters are loosely connected to each other . in this respect , insisting in finding the absolute optimum of the measure would not be productive .",
    "however , if we buy the popular notion of communities as subgraphs with a high internal edge density and a comparatively low external edge density , the task of any method would be easier if we managed to further increase the internal edge density of the subgraphs , enhancing their cohesion , and to further decrease the edge density between the subgraphs , enhancing their separation .",
    "ideally , if we could push this process to the extreme , we would end up with a set of disconnected cliques , which every method would be able to identify , despite its limitations .",
    "consensus clustering induces this type of transformation ( fig . 1 ) and",
    "therefore it mitigates the deficiencies of clustering algorithms , leading to more efficient techniques .",
    "the situation in a sense recalls spectral clustering  @xcite , where by mapping the original network in a network of points in a euclidean space , through the eigenvector components of a given matrix ( typically the laplacian ) , one ends up with a system which is easier to clusterize .",
    "in this paper we present the first systematic study of consensus clustering .",
    "we show that the consensus partition gets much closer to the actual community structure of the system than the partitions obtained from the direct application of the chosen clustering method .",
    "we will also see how to monitor the evolution of clusters in temporal networks , by deriving the consensus partition from several snapshots of the system .",
    "we demonstrate the power of this approach by studying the evolution of topics in the citation network of papers published by the american physical society ( aps ) .",
    "in order to demonstrate the superior performance achievable by integrating consensus clustering in a given method , we tested the results on artificial benchmark graphs with built - in community structure .",
    "we chose the lfr benchmark graphs , which have become a standard in the evaluation of the performance of clustering algorithms  @xcite .",
    "the lfr benchmark is a generalization of the four - groups benchmark proposed by girvan and newman , which is a particular realization of the planted @xmath0-partition model by condon and karp  @xcite .",
    "lfr graphs are characterized by power law distributions of vertex degree and community size , features that frequently occur in real world networks .",
    "the clustering algorithms we used are listed below :    * _ fast greedy modularity optimization_. it is a technique developed by clauset et al .",
    "@xcite , that performs a quick maximization of the modularity by newman and girvan  @xcite .",
    "the accuracy of the estimate for the modularity maximum is not very high , but the method has been frequently used because it has been one of the first techniques able to analyze large networks .",
    "we label it here as _",
    "clauset et al._. * _ modularity optimization via simulated annealing_. here the maximization of modularity is carried out in a more exhaustive ( and computationally expensive ) way .",
    "simulated annealing is a traditional technique used in global optimization problems  @xcite .",
    "the first application to modularity has been devised by guimer et al .",
    "in contrast to the standard design , we start at zero temperature .",
    "this is necessary because if the method is very stable there is no point in using the consensus approach : if the algorithm systematically finds the same clusters , the consensus matrix @xmath1 would consist of @xmath2 disconnected cliques and the successive clusterization of @xmath1 would yield the same clusters over and over . for the method we use the label _ sa_. * _ louvain method_. the goal is still the optimization of modularity , by means of a hierarchical approach .",
    "first one partitions the original network in small communities , such to maximize modularity with respect to local moves of the vertices .",
    "this first generation clusters turn into supervertices of a ( much ) smaller weighted graph , where the procedure is iterated , and so on , until modularity reaches a maximum .",
    "it is a fast method , suitable to analyze very large graphs .",
    "however , like all methods based on modularity optimization , including the previous two , it is biased by the intrinsic limits of modularity maximization  @xcite .",
    "we refer to this method as to _ louvain_. * _ label propagation method_. this method  @xcite simulates the spreading of labels based on the simple rule that at each iteration a given vertex takes the most frequent label in its neighborhood .",
    "the starting configuration is chosen such that every vertex is given a different label and the procedure is iterated until convergence .",
    "this method has the problem of partitioning the network such that there are very big clusters , due to the possibility of a few labels to propagate over large portions of the graph .",
    "we considered asynchronous updates , i.e. we update the vertex memberships according to the latest memberships of the neighbors .",
    "we shall refer to this method as _ lpm_. * _ infomap_. the idea behind this method is the same as in cartography : dividing the network in areas , like counties / states in a map , and recycling the identifiers / names of vertices / towns among different areas .",
    "the goal is to minimize the description of an infinitely long random walk taking place on the network  @xcite . when the graph has recognizable clusters , most of the time the walker will be trapped within a cluster .",
    "that way , the additional cost of introducing new labels to identify the clusters is compensated by the fact that such labels are seldom used to describe the process , as transitions between clusters are unfrequent , so the recycling of the binary identifiers for the vertices among different clusters leads to major savings in the description of the random walk",
    ". we shall refer to this method as _ infomap_. * _ oslom_. the method relies on the concept of statistical significance of clusters .",
    "the idea here is that , since random graphs are not supposed to have clusters , the subgraphs of a network that are deemed to be communities should be very different from the subgraphs one observes in a random graph with similar features as the system at study .",
    "the statistical significance is then estimated through the probability of finding the observed clusters in a random network with identical expected degree sequence  @xcite .",
    "clusters are identified by maximizing locally such probability .",
    "we shall refer to this method as _",
    "oslom_.    all the above techniques can be applied to weighted networks , a necessary requisite for our implementation of consensus clustering ( see methods ) .        in fig .",
    "2 we show the results of our tests .",
    "each panel reports the value of the normalized mutual information ( nmi ) between the planted partition of the benchmark and the one found by the algorithm as a function of the mixing parameter @xmath3 , which is a measure of the degree of fuzziness of the clusters .",
    "low values of @xmath3 correspond to well - separated clusters , which are fairly easy to detect ; by increasing @xmath3 communities get more mixed and clustering algorithms have more difficulties to distinguish them from each other . as a consequence ,",
    "all curves display a decreasing trend .",
    "the nmi equals @xmath4 if the two partitions to compare are identical , and approaches @xmath5 if they are very different . in fig 2a and 2b",
    "the benchmark graphs consist of @xmath6 and @xmath7 vertices , respectively .",
    "each point corresponds to an average over @xmath8 different graph realizations . for every realization we have produced @xmath9 partitions with the chosen algorithm .",
    "the curve `` original '' shows the average of the nmi between each partition and the planted partition .",
    "the curve `` consensus '' reports the nmi between the consensus and the planted partition , where the former has been derived from the @xmath9 input partitions .",
    "we do not show the results for infomap and oslom because their performance on the lfr benchmark graphs is very good already  @xcite , so it could not be sensibly improved by means of consensus clustering ( we have verified that there still is a small improvement , though ) .",
    "the procedures to set the number of runs and the value of the threshold @xmath10 for each method are detailed in the appendix . in all cases ,",
    "consensus clustering leads to better partitions than those of the original method .",
    "the improvement is particularly impressive for the method by clauset et al . :",
    "the latter is known to have a poor performance on the lfr benchmark  @xcite , and yet in an intermediate range of values of the mixing parameter @xmath3 it is able to detect the right partition by composing the results of individual runs .",
    "for @xmath3 small the algorithm delivers rather stable results , so the consensus partition still differs significantly from the planted partition of the benchmark . in the appendix",
    "we give a mathematical argument to show why consensus clustering is so effective on the lfr benchmark .",
    "another major advantage of consensus clustering is the fact that it leads to stable partitions  @xcite .",
    "here we verify how stability varies with the number of input runs @xmath11 .",
    "vertices and @xmath12 edges . ]     and the ones cited by them . ]    in figs . 3 and 4 we present stability plots for two real world datasets : the neural network of _",
    "c. elegans_@xcite ( @xmath13 vertices , @xmath12 edges ) ; the citation network of papers published in journals of the american physical society ( aps ) ( @xmath14 vertices , @xmath15 directed edges ) .",
    "each figure shows two curves : the average nmi between best partitions ( circles ) ; the average nmi between consensus partitions ( squares ) .",
    "both the best and the consensus partition are computed for @xmath11 input runs , and the procedure is repeated for @xmath16 sequences of @xmath11 runs .",
    "so we end up having @xmath16 best partitions and @xmath16 consensus partitions .",
    "the values reported are then averages over all possible pairs that one can have out of @xmath16 numbers .",
    "each of the six panels corresponds to a specific clustering algorithm . to derive the consensus partitions we used the same values of the threshold parameter @xmath10 as in the tests of fig .",
    "2a ( for infomap and oslom @xmath17 ) .",
    "as `` best '' partition for louvain , sa and clauset et al .",
    "we take the one with largest modularity .",
    "this sounds like the most natural choice , since such methods aim at maximizing modularity .",
    "for the lpm there is no way to determine which partition could be considered the best , so we took the one with maximal modularity as well .",
    "on the other hand , both infomap and oslom have the option to select the best partition out of a set of @xmath11 runs .    in fig .",
    "3 we show the stability plot for _ c. elegans_. for all methods the consensus partition turns out to be more stable of the input than the best partition .",
    "the only exception is the method by clauset et al . , but the two curves are rather close to each other .",
    "we remark that increasing the number of input runs does not necessarily imply more stable partitions . in the cases of lpm and oslom , for instance ,",
    "the best partitions of the method get more unstable for @xmath18 . on the other hand ,",
    "the stability of the consensus partition is monotonically increasing for all six algorithms .    in fig .",
    "4 we see the corresponding plot for the aps dataset .",
    "the analysis of the full dataset is too computationally expensive , so we focused on a subset , that of papers published in @xmath19 , along with the papers cited by them .",
    "the resulting network has @xmath20 vertices and @xmath21 edges .",
    "again , we see that the stability of the consensus partition grows monotonically with the number of input runs @xmath11 , and it remains higher than that of the best partition .    in the appendix",
    "we show that the consensus partition is not only more stable , but it also has higher fidelity than the individual input partitions it combines ( figs . s5 and s6 ) .",
    "consensus clustering is a powerful tool to explore the dynamics of community structure as well .",
    "here we show that it is able to monitor the history of the citation network of the aps , and to follow birth , growth , fragmentation , decay and death of scientific topics .",
    "the procedure to derive the consensus partitions out of time snapshots of a network is described in the methods .        the evolution of the aps dataset is shown in fig .",
    "the system is too large to be meaningfully displayed in a single figure , so we focused on the evolution of communities of papers in statistical physics .",
    "for that , we selected only the clusters whose papers include _ criticality _ , _ fractal _ , _ ising _ , _ network _ and _ renormalization _ among the @xmath22 most frequent words in their titles .",
    "each vertical bar corresponds to a time window of @xmath23 years ( see methods ) , its length to the size of the system .",
    "the time ranges from @xmath24 until @xmath25 .",
    "the evolution is characterized by alternating phases of expansion and contraction , although in the long term there is a growing tendency in the number of papers .",
    "this is due to the fact that the keywords we selected were fashionable in different historical phases of the development of statistical physics , so some of them became obsolete after some time ( i.e. , there are less papers with those keywords ) , while at the same time others become more fashionable .",
    "communities are identified by the colors .",
    "pairs of matching clusters in consecutive times are marked by the same color .",
    "clusters of consecutive time windows sharing papers are joined by links , whose width is proportional to the number of common papers .",
    "we mark the clusters corresponding to famous topics in statistical physics , indicating the most frequent words appearing in the titles of the papers of each cluster .",
    "one can spot the emergence of new fields , like _ self - organized criticality _ , _ spin glasses _ and _ complex networks_.    in fig .",
    "5b we consider only papers with the words _ network _ or _ networks _ among the @xmath22 most frequent words in their titles . here",
    "we can observe the genesis of the fields _ neural networks _ and _ complex networks_. in order to have clearer pictures , in fig .",
    "5a we only plotted clusters that have at least 50 papers , while in fig . 5b",
    "the threshold is 10 papers .    .",
    "the two panels show the results obtained with infomap ( left ) and oslom ( right ) .",
    "the data are aggregated in four bins , according to the maximum size reached by the cluster .",
    "the phases of growth and decay of fields appear rather symmetric . ]    for a quantitative assessment of the birth , evolution and death of topics , we keep track of each cluster matching it with the most similar module in the following time frame ( see methods ) .",
    "this allows us to compute one sequence for each cluster , which reports its size for all the years when the community was present . in fig .",
    "6 we computed the statistics of these sequences , centering them on the year when the cluster reached its peak ( reference year @xmath5 ) . to obtain smooth patterns ,",
    "clusters are aggregated in bins according to their peak magnitude .",
    "6 shows the average cluster size for each bin as a function of the years from the peak .",
    "we computed the curves using infomap ( left ) and oslom ( right ) . around the peak ,",
    "the cluster sizes are highly heterogeneous , with some important topics reaching almost @xmath6 papers at the peak ( for infomap ) .",
    "the rise and decline of topics take place around 10 years before and after the peak , with a remarkably symmetric pattern with respect to the maximum .",
    "consensus clustering is an invaluable tool to cope with the stochastic fluctuations in the results of clustering techniques .",
    "we have seen that the integration of consensus clustering with popular existing techniques leads to more accurate partitions than the ones delivered by the methods alone , in artificial graphs with planted community structure .",
    "this holds even for methods whose direct application gives poor results on the same graphs . in this way it is possible to fully exploit",
    "the power of each method and the diversity of the partitions , rather than being a problem , becomes a factor of performance enhancement .",
    "finding a consensus between different partitions also offers a natural solution to the problem of detecting communities in dynamic networks . here one combines partitions corresponding to snapshots of the system , in overlapping time windows .",
    "results depend on the choice of the amplitude of the time windows and on the number of snapshots combined in the same consensus partition .",
    "the choice of these parameters may be suggested by the specific system at study .",
    "it is usually possible to identify a meaningful time scale for the evolution of the system . in those cases both the size of the time windows and",
    "the number of snapshots to combine can be selected accordingly . as a safe guideline one should avoid merging partitions referring to a time range which is much broader than the natural time scale of the network .",
    "a good policy is to explore various possibilities and see if results are robust within ample ranges of reasonable values for the parameters .",
    "additional complications arise from the fact that the evolution of the system may not be linear in time , so that it can not be followed in terms of standard time units . in citation networks ,",
    "like the one we studied , it is known that the number of published papers has been increasing exponentially in time .",
    "therefore , a fixed time window would cover many more events ( i.e. published papers and mutual citations ) if it refers to a recent period than to some decades ago . in those cases , a natural choice could be to consider snapshots covering time windows of decreasing size .",
    "* the consensus matrix*. let us suppose that we wish to combine @xmath26 partitions found by a clustering algorithm on a network with @xmath27 vertices .",
    "the consensus matrix @xmath28 is an @xmath29 matrix , whose entry @xmath30 indicates the number of partitions in which vertices @xmath31 and @xmath32 of the network were assigned to the same cluster , divided by the number of partitions @xmath26 .",
    "the matrix @xmath33 is usually much denser than the adjacency matrix @xmath34 of the original network , because in the consensus matrix there is an edge between any two vertices which have cooccurred in the same cluster at least once . on the other hand ,",
    "the weights are large only for those vertices which are most frequently co - clustered , whereas low weights indicate that the vertices are probably at the boundary between different ( real ) clusters , so their classification in the same cluster is unlikely and essentially due to noise .",
    "we wish to maintain the large weights and to drop the low ones , therefore a filtering procedure is in order . among the other things , in the absence of filtering the consensus matrix would quickly grow into a very dense matrix , which would make the application of any clustering algorithm computationally expensive .",
    "we discard all entries of @xmath33 below a threshold @xmath10 .",
    "we stress that there might be some noisy vertices whose edges could all be below the threshold , and they would be not connected anymore .",
    "when this happens , we just connect them to their neighbors with highest weights , to keep the graph connected all along the procedure .",
    "next we apply the same clustering algorithm to @xmath33 and produce another set of partitions , which is then used to construct a new consensus matrix @xmath35 , as described above .",
    "the procedure is iterated until the consensus matrix turns into a block diagonal matrix @xmath36 , whose weights equal @xmath4 for vertices in the same block and @xmath5 for vertices in different blocks .",
    "the matrix @xmath36 delivers the community structure of the original network . in our calculations",
    "typically one iteration is sufficient to lead to stable results .",
    "we remark that in order to use the same clustering method all along , the latter has to be able to detect clusters in weighted networks , since the consensus matrix is weighted .",
    "this is a necessary constraint on the choice of the methods for which one could use the procedure proposed here .",
    "however , it is not a severe limitation , as most clustering algorithms in the literature can handle weighted networks or can be trivially extended to deal with them .",
    "we close by summarizing the procedure , step by step .",
    "the starting point is a network @xmath37 with @xmath27 vertices and a clustering algorithm @xmath34 .    1 .",
    "apply @xmath34 on @xmath37 @xmath26 times , so to yield @xmath26 partitions .",
    "compute the consensus matrix @xmath33 , where @xmath30 is the number of partitions in which vertices @xmath31 and @xmath32 of @xmath37 are assigned to the same cluster , divided by @xmath26 .",
    "all entries of @xmath33 below a chosen threshold @xmath10 are set to zero .",
    "4 .   apply @xmath34 on @xmath33 @xmath26 times , so to yield @xmath26 partitions .",
    "5 .   if the partitions are all equal , stop ( the consensus matrix would be block - diagonal ) .",
    "otherwise go back to 2 .",
    "0.5 cm * consensus for dynamic clusters*. in the case of temporal networks , the dynamics of the system is represented as a succession of snapshots , corresponding to overlapping time windows .",
    "let us suppose to have @xmath2 windows of size @xmath38 for a time range going from @xmath39 to @xmath40 .",
    "we separate them as @xmath41 $ ] , @xmath42 $ ] , @xmath43 $ ] , ... , @xmath44 $ ] .",
    "each time window is shifted by one time unit to the right with respect to the previous one .",
    "the idea is to derive the consensus partition from subsets of @xmath11 consecutive snapshots , with @xmath11 suitably chosen .",
    "one starts by combining the first @xmath11 snapshots , then those from @xmath45 to @xmath46 , and so on until the interval spanned by the last @xmath11 snapshots . in our calculations for the aps citation network we took @xmath47 ( years ) ,",
    "@xmath48 .",
    "there are two sources of fluctuations : 1 ) the ones coming from the different partitions delivered by the chosen clustering technique for a given snapshot ; 2 ) the ones coming from the fact that the structure of the network is changing in time .",
    "the entries of the consensus matrix @xmath30 are obtained by computing the number of times vertices @xmath31 and @xmath32 are clustered together , and dividing it by the number of partitions corresponding to snapshots including both vertices .",
    "this looks like a more sensible choice with respect to the one we had adopted in the static case ( when we took the total number of partitions used as input for the consensus matrix ) , as in the evolution of a temporal network new vertices may join the system and old ones may disappear .",
    "once the consensus partitions for each time step have been derived , there is the problem of relating clusters at different times .",
    "we need a quantitative criterion to establish whether a cluster @xmath49 at time @xmath50 is the evolution of a cluster @xmath51 at time @xmath52 . the correspondence is not trivial : a cluster may fragment , and thus there would be many `` children '' clusters at time @xmath50 for the same cluster at time @xmath52 . in order to assign to each cluster @xmath51 of the consensus partition at time @xmath52 one and only one cluster of the consensus partition @xmath53 at time @xmath50 we compute the jaccard index  @xcite between @xmath54 and every cluster of @xmath53 , and pick the one which yields the largest value .",
    "the jaccard index @xmath55 between two sets @xmath56 and @xmath57 equals @xmath58 in our case , since the snapshots generating the partitions refer to different moments of the life of the system and may not contain the same elements , the jaccard index is computed by excluding from either cluster the vertices which are not present in both partitions .",
    "the same procedure is followed to assign to each cluster @xmath59 of the consensus partition at time @xmath50 one and only one cluster of the consensus partition @xmath60 at time @xmath52 . in general ,",
    "if cluster @xmath56 at time @xmath52 is the best match of cluster @xmath57 at time @xmath50 , the latter may not be the best match of @xmath56 .",
    "if it is , then we use the same color for both clusters .",
    "otherwise there is a discontinuity in the evolution of @xmath56 , which stops at @xmath52 , and its best match at time @xmath50 will be considered as a newly born cluster .",
    "for any implementation of our method there are two parameters that need to be set before starting the computation : 1 ) the number @xmath11 of partitions to be combined in the consensus matrix ( see methods ) ; 2 ) the threshold @xmath10 used to filter the entries of the consensus matrix , to avoid that the latter becomes too dense , slowing down the procedure . in figs . 7 and 8",
    "we show how these numbers are chosen .",
    "7 displays the normalized mutual information ( nmi ) between the consensus partition and the planted partition of the benchmark graphs used for fig .",
    "1 , for different values of @xmath11 and a specific value of the mixing parameter @xmath3 . each curve corresponds to a different value for the threshold @xmath10 , which equals @xmath5 , @xmath61 and @xmath62 .",
    "each panel presents the result of a different clustering algorithm ; the value of @xmath3 varies for each method because consensus is the most effective the more diverse the input partitions are .",
    "therefore we picked the value of @xmath3 at which the original method starts failing ( @xmath63 for louvain , @xmath64 for the lpm , @xmath65 for sa and @xmath66 for clauset et al .. from fig .",
    "7 we deduce that for @xmath67 one reaches an optimal partition with consensus clustering , which remains stable for larger values .",
    "this seems to hold regardless of the value of the threshold parameter @xmath10 .",
    "therefore , in our tests of fig .",
    "1 we have taken @xmath11 between @xmath68 and @xmath8 .",
    "[ figs1 ] .",
    "each panel reports the nmi between the planted partition of the lfr benchmark graphs used for fig .  1 , at a given @xmath3 ( see text ) , as a function of the number of runs for a specific method .",
    "the symbols refer to three different choices for the threshold parameter @xmath10 : @xmath5 ( circles ) , @xmath61 ( squares ) , @xmath62 ( diamonds).,title=\"fig : \" ]    [ figs2 ] .",
    "each panel reports the nmi between the planted partition of the lfr benchmark graphs used for fig .  7 , as a function of @xmath10 for a specific method .",
    "the symbols refer to two different choices for the number of runs @xmath11 : @xmath16 ( squares ) , @xmath68 ( diamonds).,title=\"fig : \" ]    in fig .",
    "8 we show instead how the threshold @xmath10 affects the results .",
    "we use the same benchmark graphs as in fig . 7 , and two values for the number of runs @xmath11 : @xmath16 and @xmath68 .",
    "the y - axis reports again the value of the nmi between the consensus and the planted partition of the benchmark .",
    "we see that the ranges of optimal values for @xmath10 depend on the clustering technique adopted . for louvain",
    ", it is best to choose a low threshold , for the lpm @xmath10-values in the range @xmath69 $ ] give optimal results , for sa the best value span a shorter range ( from @xmath61 to @xmath62 ) and for clauset et al .",
    "the best results are obtained for fairly high values of the threshold .",
    "to understand why consensus clustering is so effective at detecting the clusters of the lfr benchmarks , we discuss here a simpler model which resembles the lfr benchmarks .",
    "we focus on modularity optimization because it is easier to understand how consensus improves the method .",
    "we consider a graph with @xmath70 cliques of @xmath71 vertices each .",
    "the cliques are connected by placing @xmath72 edges between randomly chosen pairs of vertices , where the vertices of each pair belong to different cliques .",
    "it can be proven that for this kind of graph , the modularity function is optimal for a partition of @xmath73 modules of equal size , where @xmath74 is the number of edges .",
    "this result has been proved for a ring of cliques , but it is straightforward to verify that the same proof can be extended to this case .    since there is a high number of combinations to group the cliques together in order to reach the optimal number of modules ,",
    "we expect that , on average , each clique will be joined to some of its neighboring cliques with roughly equal probability .",
    "if we call @xmath75 the average number of neighboring cliques , the probability that two neighboring cliques are found in the same cluster is simply @xmath76 ( we recall that we placed @xmath72 links ) .",
    "if @xmath77 and @xmath78 is small enough so that the network of cliques is sparse , there will be a very small number of edges between the cliques grouped in the same module .",
    "the smallest number of edges necessary to keep @xmath27 vertices connected is @xmath79 ( which gives a tree - like structure ) , and in such a case every vertex has an average degree @xmath80 , when @xmath81 . in the case of a tree",
    ", we would have that @xmath82 .",
    "the probability for two cliques to be connected if their distance in the clique network is @xmath83 , will be , in general ,    @xmath84    fig .",
    "9 shows that this approximation is not bad especially for high values of @xmath70 . in the following plots we considered @xmath85 , @xmath86 .",
    "eventually , we might expect that choosing a value of the threshold @xmath87 , the consensus matrix will consist of @xmath70 disconnected cliques .",
    "modularity optimization instead would always merge cliques together in larger clusters .",
    "indeed , the nmi between the planted partition and the input partitions is much lower than the nmi between the planted and the consensus partition already for @xmath88 ( fig .",
    "10 ) .    .",
    "we consider two values for the number of cliques of the model network , @xmath89 and @xmath90 . ]",
    "in figs . 3 and 4 we have shown that the consensus partitions are more stable than the best partitions .",
    "however trivial partitions , like the one where all vertices are together in the same cluster , would be the most stable possible , although they would be completely unrelated to the input partitions . to prove that the consensus partitions are actually very close to the input ones , fig .",
    "11 shows the normalized mutual information of the input partitions among themselves ( the average value of nmi among all pairs of different partitions ) and the average value of nmi between the input partitions and the consensus partition , for different values of the threshold @xmath10 , for the neural network of _ c. elegans_. fig .",
    "12 shows the same plot for the aps citation network of papers published in 1960 . indeed the consensus partition is often even closer to the input partitions than the latter are to each other , with the additional advantage of being more stable . this does not hold only when the threshold is too high , because in this case the consensus partition is made of small clusters , since too many connections carry a weight under the threshold and are deleted .",
    "otherwise this should explain why the consensus partition is more representative than the input . in figs .",
    "11 and 12 we considered @xmath68 input partitions , but the results are practically the same if we take @xmath8 of them ."
  ],
  "abstract_text": [
    "<S> the community structure of complex networks reveals both their organization and hidden relationships among their constituents . </S>",
    "<S> most community detection methods currently available are not deterministic , and their results typically depend on the specific random seeds , initial conditions and tie - break rules adopted for their execution . </S>",
    "<S> consensus clustering is used in data analysis to generate stable results out of a set of partitions delivered by stochastic methods . here </S>",
    "<S> we show that consensus clustering can be combined with any existing method in a self - consistent way , enhancing considerably both the stability and the accuracy of the resulting partitions . </S>",
    "<S> this framework is also particularly suitable to monitor the evolution of community structure in temporal networks . </S>",
    "<S> an application of consensus clustering to a large citation network of physics papers demonstrates its capability to keep track of the birth , death and diversification of topics . </S>"
  ]
}