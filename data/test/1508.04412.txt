{
  "article_text": [
    "a fundamental task in quantum optics is the reconstruction of the state of the light field , the complete description of which is contained in the density matrix .",
    "close to the boundary between quantum and classical regions the density matrix is conveniently studied in phase space representation , e.g. , through the wigner function @xcite , since this allows the investigation of the transition between the two regimes .",
    "there is a wealth of techniques @xcite to measure the wigner function , most of which require many copies of the state and many measurement shots .",
    "producing many copies , however , is not always possible or efficient . in systems just crossing the classical - to - quantum boundary such as nanomechanical resonators @xcite , for example , data can be so noisy and prone to drift that the required number of experimental runs with nominally identical parameters is not possible .",
    "often , this laborious task of full quantum state tomography is also asking a too general or too unspecific question .",
    "in many cases , it is sufficient to approximate the state by estimating a few parameters characterizing it . this is the case , _",
    "e.g. _ , in the simple and _ prima facie _ classical task of measuring both the quadrature amplitude @xmath2 and phase arg(@xmath1 ) of a weak ac signal , for example , in the microwave range .",
    "these signals are represented as coherent quantum states @xmath3 , with @xmath4 photon number eigenstate with @xmath5 photons .",
    "estimating coherent states is an important stepping stone for the characterization of more complicated quantum states of light because many such states , e.g. , a schrdinger cat state @xmath6 @xcite , a so - called voodoo cat state @xmath7 @xcite , and a compass state @xmath8 @xcite , can be presented as superpositions of coherent states .",
    "direct applications of quadrature measurements include , for example , cosmic microwave background detection @xcite and the search for dark matter axions @xcite .",
    "estimation of an optical phase alone , at fixed coherent state amplitude @xcite , is the basis of many metrological applications , e.g. , in magnetometry @xcite , detection of gravitational waves @xcite , and clock synchronization @xcite .",
    "phase estimation is also an indispensable component of several algorithms in quantum information processing @xcite .",
    "since it is difficult to define the concept of phase measurement for a single mode only , the usual approach is to consider two - mode measurements in an interferometer ( see fig .  1 in @xcite ) .",
    "the ultimate limit set by quantum mechanics to the precision of phase measurements is due to complementarity between photon number and phase .",
    "this translates to a so - called heisenberg limit , phase variance scaling as @xmath9 with @xmath10 the total number of photons that pass through the interferometer .",
    "note that inverse phase variance describes the fisher information ( variance of the score ) @xcite of the phase estimate .",
    "optimal measurements for phase estimation have been identified theoretically in @xcite but not realized experimentally ; it is not possible to perform them with photodetections at the output of the interferometer .",
    "input states and measurements with an error scaling close to optimum ( but with a different prefactor ) have been proposed optimizing adaptively the next measurement in the series of measurements @xcite ( local optimization ) .",
    "adaptive measurements have also been designed attempting to optimize the whole series of measurements @xcite ( global optimization ) .",
    "the input state to the interferometer considered in @xcite , however , is not separable between photon number eigenstates in the output arms of the interferometer and its creation is currently an open question .",
    "beating the standard quantum limit has , however , been demonstrated using simpler entangled input states @xcite . here",
    ", we are going beyond bare phase estimation in addressing simultaneous adaptive estimation of both phase and amplitude of @xmath1 . in terms of density operators",
    ", we thus estimate the state within a family @xmath11",
    ".    the most popular approach to quantum state estimation has been maximum likelihood estimation ( mle ) @xcite . given measurement settings @xmath12 and corresponding data @xmath13 , it seeks for a physical state @xmath14 that maximizes the likelihood functional @xmath15 , with @xmath16 the probability to obtain the measurement outcome @xmath17 given the state @xmath14 and measurement setting @xmath18 .",
    "however , mle does not deliver confidence intervals for the estimates .",
    "moreover , a basic problem with mle is that it tends to assign vanishing values for certain eigenvalues of @xmath14 @xcite .",
    "this is unreasonable since it is not possible to completely rule out some measurement outcomes with a finite amount of data .",
    "more advanced approaches based on bayesian inference do not suffer from these shortcomings .",
    "bayesian inference techniques have been developed , e.g , for phase @xcite , state @xcite , and hamiltonian @xcite estimation . for certain one - parameter estimation problems it is possible to perform local bayesian optimization of the measurement settings",
    "analytically @xcite .",
    "for a larger number of unknown parameters , however , finding optimal measurement settings adaptively becomes generally analytically intractable . to perform the bayesian updates numerically ,",
    "a sequential monte - carlo approach @xcite has recently undergone a strong development .",
    "bayesian reasoning provides a general framework to assign a probability distribution for system parameters given certain data .",
    "the nature of the data , however , depends on the measurement settings chosen by the experimenter .",
    "in general it is more effective to choose the measurement settings adaptively so that they depend on the data that has been collected .",
    "generally , the specific set of rules , also called a policy , according to which the measurement setting @xmath19 is to be updated , has to be developed separately for each problem at hand .",
    "this is true also for the recently developed technique called self - guided quantum tomography ( sgqt ) @xcite .",
    "sgqt searches the estimate of a quantum state by making measurements in the directions close to the estimate , approaching it as a power law as a function of adaptive iteration steps .",
    "the optimal prefactors in the related power laws ( as well as certain coefficient added to the base of an exponential ) , however , depend on the problem and parameter region .",
    "for definiteness , we consider measurement of the mode using an ideal vacuum detector @xcite .",
    "a vacuum detector provides a click if there is more than zero photons in the cavity but does not give any indication of the photon number beyond that .",
    "such detectors have been realized in optics in the strongly coupled regime . at microwave frequencies ,",
    "the recently realized @xcite josephson photomultiplier @xcite has been shown theoretically @xcite to reach this ideal vacuum detector limit at weak tunneling and long interaction time .",
    "in contrast to a standard mach - zender interferometric scheme for phase measurements , photon number resolving detectors or beam splitters are not needed , and there is no entanglement involved .",
    "this technology is also suited for the measurement of a qubit state and should allow better scalability to larger circuits than that based on superconducting amplifiers .",
    "the latter requires a strong auxiliary microwave pump tone that must be isolated from the qubit circuitry with bulky cryogenic isolators , which with the former technology can be eliminated .    .",
    "the microwave source emits a pulse that displaces the coherent state by @xmath20 in phase space .",
    "the cavity is capacitively coupled to a josephson photomultiplier ( jpm ) that registers one of two possible measurement outcomes : the displaced state is either vacuum or a state containing photons.,scaledwidth=50.0% ]    in the measurement with a vacuum detector , different points in phase space may be accessed by injecting an additional drive pulse to the input signal , cf .",
    "[ fig : fig1 ] . appropriately normalized , the drive pulse @xmath21 displaces the coherent state by an amount @xmath22 in phase space , i.e. , it turns @xmath0 into @xmath23 , hence allowing one to measure the husimi @xmath24-function @xmath25 , with @xmath26 .    in terms of a positive operator - valued measure ( povm ) , a measurement setting is thus characterised by a set of operators @xmath27 , with @xmath28 given by the pulse parameter . the set @xmath29 is defined by @xmath30 , where @xmath31 indexes the possible measurement outcomes , a vacuum state or a state containing photons . here , we only need the operators @xmath32 and @xmath33 .    in @xcite and @xcite , respectively , the states of a superconducting resonator and a nanomechanical resonator were characterized .",
    "the tomographic method used in these papers is analogous to the measurement model above , since it consists of displacing the resonator state by a microwave pulse and then performing a projective measurement of the qubit . in @xcite",
    "a nonadaptive tomographic scheme based on semidefinite programming was presented for the characterization of noon states in resonators coupled to qubits .",
    "this type of measurements can be contrasted to probing of the wigner function by full photon counting with number resolution @xcite .",
    "the basic difference between frequentist and bayesian approaches to parameter estimation is that the latter allow one to assign an initial prior probability distribution @xmath34 to describe an unknown state @xmath0 .",
    "it quantifies the experimenters _ a priori _ conception of the state and its uncertainty .",
    "once the initial prior is set and given a suitable policy , one can take advantage of the information contained in the prior in choosing the measurement setting @xmath19 .",
    "the policies used in this paper are described in sec .  v. bayesian inference proceeds by iteratively applying bayes theorem @xmath35 as illustrated in fig .",
    "[ fig : fig2 ] .",
    "here @xmath36 , referred to as likelihood , is the probability to obtain data @xmath31 ( here , @xmath37 ) in the state @xmath0 , given the measurement setting @xmath19 . using the notation of povm in sec .",
    "ii , it is related to the hermitian operators @xmath38 through born s rule @xmath39 .",
    "the normalization factor @xmath40 is obtained by integrating the likelihood over all possible states @xmath41 .",
    "the probability distribution @xmath42 for @xmath0 given data @xmath31 and measurement setting @xmath19 is called the posterior .",
    "the posterior can be set as the prior for the next measurement which allows iterative application of eq .",
    "( [ eq : bayes_theorem ] ) @xmath43=\\nonumber\\\\ & \\frac{p(d_{m+1}|\\alpha , s_{m+1})p[\\alpha|(d , s)]}{\\int p(d_{m+1}|\\alpha , s_{m+1})p[\\alpha|(d , s)]d\\alpha},\\nonumber \\\\ & ( d , s)=\\{(d_{m},s_{m})\\ldots , ( d_{1},s_{1})\\}. \\label{eq : iterative_bayes}\\end{aligned}\\ ] ] once a sufficient amount of data has been collected and the posterior is narrow enough , the estimate @xmath44 is obtained from its mean value .",
    "the functional form of our likelihood function @xmath36 as well the rules to choose the measurement settings @xmath19 are described in sec .",
    "the sequential monte - carlo method @xcite delivers an efficient numerical method to perform the updates of the posterior .",
    "the posterior is approximated by keeping track of its value in @xmath45 moving grid points , or `` particles , '' @xmath46\\approx \\sum_{n=1}^{n_{\\rm p}}w_n\\delta(\\alpha-\\alpha_n)$ ] . here",
    "@xmath47 are the locations of the particles while @xmath48 are their relative probabilities or weights that can be updated through bayes theorem , @xmath49 here , @xmath50 are the weights evaluated after the @xmath51th measurement shot . equation ( [ eq : w_update ] )",
    "ensures the norming @xmath52 and the conservation of probability .    in the following ,",
    "the key quantities are the mean @xmath44 and the covariance matrix @xmath53 of @xmath1 over the posterior .",
    "numerically , these are readily approximated through @xmath54 .",
    "\\label{eq : mean_cov}\\end{aligned}\\ ] ]    a fixed grid would limit the achievable precision of the estimate , but we make use of an adaptive grid @xcite which makes it possible to focus the particles in the regions where the probability distribution concentrates . here , @xmath45 locations @xmath47 are first chosen following the discrete probability distribution @xmath55 .",
    "the particles are then assigned new locations @xmath56 by sampling from the normal distribution @xmath57 , \\label{eq : resampling}\\ ] ] with the mean @xmath58 and the covariance matrix @xmath59 . here",
    ", @xmath60 is a parameter that we set to @xmath61 @xmath62 .",
    "finally all the weights are set to @xmath63 .",
    "the artificial dynamics induced by eqs .",
    "( [ eq : resampling ] ) and ( [ eq : mui ] ) conserves by construction the covariance matrix @xmath64    in our calculations we choose @xmath65 . to compare different policies ,",
    "we apply them on simulated samples with randomly chosen true values @xmath1 .",
    "we choose @xmath1 from a uniform distribution on the region @xmath66 , with @xmath67 [ see fig .  [",
    "fig : fig3](a ) ] . note that @xmath68 is related to the maximum expectation value of the photon number operator through @xmath69 .",
    "the initial prior was chosen to coincide with the aforementioned probability distribution .",
    "while here , this prior exactly incorporates what is known about estimated quantities before data collection , it has to be noted that in an actual experimental situation there is no unique and objective way to assign the initial prior , but choosing it necessarily involves certain arbitrary or subjective elements .     in phase space .",
    "( a ) uniform initial prior within the disk @xmath66 . here , @xmath67 .",
    "( b ) posterior after ten measurement shots .",
    "the `` holes '' at positions @xmath70 have been created by photon detections with pulse parameters @xmath71 .",
    "( c ) posterior after the first detection of a vacuum state ( here the 11th measurement shot ) .",
    "the weight of the posterior is concentrated near @xmath72 , with @xmath73 the pulse parameter corresponding to the first vacuum detection.,scaledwidth=50.0% ]",
    "our measurement setting @xmath19 is defined by the pulse parameter @xmath20 .",
    "we consider an ideal vacuum detector with the likelihood functions for the detections of vacuum ( v ) and a state containing photons ( p ) , respectively @xmath74 in the beginning of the experiment , the first detection of a vacuum state narrows the posterior @xmath75 significantly more than detection of a photon . in the latter case the posterior only changes in the proximity of @xmath76 , where its value considerably decreases",
    "[ see fig .",
    "[ fig : fig3](b ) ] .",
    "however , in the former case the weight of the posterior is concentrated near @xmath76 , while outside this region the posterior is exponentially decreased [ see fig .",
    "[ fig : fig3](c ) ] .",
    "we therefore start the experiment by choosing the displacement pulse @xmath20 randomly from a probability distribution @xmath77 such that @xmath78 $ ] equals the posterior ( here the argument @xmath1 has to be replaced by @xmath20 ) .",
    "this makes measurements with similar values of @xmath20 unlikely .",
    "after the first detection of vacuum we adjust the support of @xmath77 in the proximity of @xmath79 , with @xmath80 the measurement setting with which vacuum is detected . before the first vacuum detection , the measurements are thus relatively uninformative , whereas most of the vacuum detections take place within a region with a radius @xmath81 in phase space ( see below ) .",
    "hence , compared to nonadaptive schemes , focusing the adaptive measurements in the correct region makes the number of required measurement shots smaller approximately by a factor @xmath82 or the area describing the initial uncertainty of @xmath1 in phase space .",
    "specifically , we choose the measurement settings @xmath20 according to the following policy @xcite @xmath83\\quad { \\rm if}\\ c = 0,\\\\ \\frac{1}{\\pi r^2(c)r_{\\alpha}^2}\\ { \\rm for } \\",
    "|\\beta+\\tilde{\\alpha}|<r(c)r_\\alpha\\ \\ { \\rm if}\\ c \\ge 1 , \\\\ 0\\ { \\rm otherwise}\\quad { \\rm if}\\ c \\ge 1 .",
    "\\end{cases } \\label{eq : policy}\\end{aligned}\\ ] ] here , @xmath84 is the number of measurement shots that have detected the vacuum state , @xmath44 is the current mean of the posterior , and @xmath85 describes the width of the region where the weight of the likelihood function is concentrated .",
    "more precisely , we define @xmath86+\\frac{1}{2}}}$ ] , with @xmath53 the covariance matrix for the bayesian probability distribution of @xmath1 [ see eq .",
    "( [ eq : mean_cov ] ) ] .",
    "after the first detection of vacuum , @xmath87 is chosen to be a uniform probability distribution on a disk with a radius @xmath88 .",
    "we have carried out extensive numerical calculations to search an optimal @xmath89 in the form of a power law @xmath90 with @xmath60 and @xmath91 constants .",
    "the pair @xmath92 parametrizes the space within which we search for a near - optimal policy .    ) .",
    "the vertical and horizontal axes describe the number of vacuum detections and the number of measurement shots performed after the first vacuum detection , respectively .",
    "different regions ( i)-(iv ) correspond the actions on the first to the fourth row of eq .",
    "( [ eq : re_policy ] ) , respectively.,scaledwidth=30.0% ]    since with a single vacuum detection the posterior concentrates near @xmath76 , the policy ( [ eq : policy ] ) is not robust against readout errors in the experiment .",
    "however , it can be made robust against such errors by confirming that an absence of a detector click is due to vacuum state rather than a readout error .",
    "this can be achieved through repetition . in the presence of readout errors we search policies of the form ( see fig .  [",
    "fig : fig4 ] ) @xmath93\\quad { \\rm if}\\ c = 0,\\\\ \\beta=\\beta_1,m'\\rightarrow m'+1 \\quad { \\rm if}\\ c \\ge 1 , m'<m'_{\\rm max},\\\\ \\beta=\\beta_1 , m'\\rightarrow 0 , c\\rightarrow 0 \\quad { \\rm if}\\ c_t > c \\ge 1 , m'=m'_{\\rm max},\\\\ p_{\\beta}=\\frac{1}{\\pi r^2(c)r_{\\alpha}^2}\\ { \\rm for } \\",
    "|\\beta+\\tilde{\\alpha}|<r(c)r_\\alpha,\\ 0\\ { \\rm otherwise}\\\\ \\hspace{4.5 cm } { \\rm if}\\ c \\ge c_t , m ' = m'_{\\rm max}. \\end{cases } \\label{eq : re_policy}\\end{aligned}\\ ] ] here , the measurements are repeated @xmath94 times at the setting @xmath73 that indicates vacuum state ( possibly a readout error ) .",
    "the variable @xmath95 counts the measurement shots performed after the vacuum detection .",
    "should after @xmath94 shots the number of vacuum detections @xmath84 be less than the threshold value @xmath96 , the variables @xmath95 and @xmath84 are set back to value 0 . if after @xmath94 shots @xmath84 is greater or equal to the threshold value @xmath96 , the remaining measurement settings are chosen as in policy ( [ eq : policy ] ) .",
    "similarly as in policy ( [ eq : policy ] ) , we look for an optimal policy with @xmath89 of the form eq .",
    "( [ eq : ab ] ) . here , we set @xmath97 , @xmath98 . in our computations",
    "we assume that the probability of misidentifying a vacuum state as a photon state and vice versa is @xmath99 .",
    "in the absence of readout errors , we find that for an optimal policy , @xmath100 and @xmath101 only weakly depends on @xmath84 ( see fig .  [",
    "fig : fig5 ] ) .",
    "for instance , for the policy @xmath102 that minimizes the median of the normalized squared error @xmath103 after @xmath104 measurement shots , we find @xmath105 and @xmath106 . here",
    ", the width of the plateau obtained with a low number of measurement shots depends on the degree of the initial parameter uncertainty or the radius @xmath68 . by a crude estimate",
    ", one expects that the first detection of a vacuum state takes place after @xmath107 measurement shots and that the error is then rapidly reduced to @xmath108 , corresponding to the width of the likelihood function [ cf .",
    "[ fig : fig3](c ) ] .",
    "this is consistent with the fact that approximately after 50 measurement shots the plateau shape of the curves crosses over to a rapid decrease .",
    "up to the level where the normalized median squared error reaches the value @xmath109 , the different curves overlap since until this point only the first line in eq .",
    "( [ eq : policy ] ) is executed , and the policy thus does not depend on @xmath101 .",
    "the curve shape following the expected first vacuum detection ( rapid decrease of the error ) is universal .",
    "interestingly , we find that the curves with different values of @xmath101 cross , which means that the globally best policy can not be found by local optimization .     calculated from an ensemble of @xmath110 simulated samples ( see text ) through the policies of eq .",
    "( [ eq : policy ] ) .",
    "different curves are for different radii @xmath101 denoted in the inset .",
    "black curve is for @xmath89 calculated through eq .",
    "( [ eq : ab]).,scaledwidth=50.0% ]    with @xmath111 , the boundary of the disk mentioned above coincides with the steepest slope of the likelihood function @xmath112 of eq .",
    "( [ eq : vplikelihood ] ) .",
    "such a disk contains approximately 39 @xmath113 of the weight of @xmath114 .",
    "one might expect that policies attempting to search for the steepest slope of the likelihood function , with @xmath115 , would be effective , but this is not the case .",
    "the policies with smaller values of @xmath60 are able to find a crude estimate faster . in the region",
    "@xmath116 the likelihood of detecting a photon @xmath117 is quadratically small .",
    "therefore with @xmath100 , once a crude estimate has been found , most measurement shots detect vacuum and confirm the estimate . however",
    ", since the relative rate of change @xmath118 increases with decreasing @xmath119 , the rare detections of photons can effectively make a distinction between different possible values of @xmath1 in the region @xmath120 .",
    "the relative rate of change above describes how much , due to bayes theorem ( [ eq : bayes_theorem ] ) , a detection of a photon changes the relative posterior probabilities of two possible values , @xmath1 and @xmath121 , when @xmath122 is fixed . putting all together ,",
    "measurement settings with @xmath116 are , somewhat unexpectedly , more effective than those with larger values of @xmath119 .",
    "even though for optimal policies we have @xmath100 , the optimal choice is not @xmath123 .",
    "indeed , the policy at @xmath123 corresponds to choosing @xmath124 equal to the mean of the posterior , somewhat similarly with a simple , relatively ineffective , policy in the context of bare phase estimation where the control phase is chosen to coincide with the mean of the posterior ( see eq .",
    "( 6.2 ) in @xcite ) .",
    "policies where the measurement strategy is changed after a certain number of measurement shots have been developed for phase @xcite and hamiltonian @xcite estimation .",
    "on the second line of eq .",
    "( [ eq : policy ] ) , rather than on the number of all the measurement shots , we expect a possible dependence on the number of shots that take place after the first detection of a vacuum state .",
    "we therefore count in eq .",
    "( [ eq : policy ] ) the number of shots in which a vacuum state is detected .",
    "calculated from an ensemble of @xmath110 simulated samples ( see text ) through the policies of eq .",
    "( [ eq : re_policy ] ) when the probability of a readout error is @xmath99 .",
    "different curves are for different radii @xmath101 denoted in the inset.,scaledwidth=50.0% ]    in the presence of readout errors , we find that the optimal value for @xmath60 is larger than in the absence of these errors and the settings are therefore more spread around their mean .",
    "the dependence of @xmath101 on @xmath84 should still be weak so that @xmath125 ( see fig .  [ fig : fig6 ] ) .",
    "for the policy @xmath126 that minimizes the relative median squared error after @xmath104 measurement shots , we find @xmath127 and @xmath128 .",
    "for each simulated ensemble we obtain some samples that we refer to as `` outliers '' for which the error significantly exceeds the median and the width of the posterior probability distribution .",
    "our policies can be made robust against such outliers through repetition as follows .",
    "after @xmath129 measurement shots we set the prior back to the initial prior .",
    "we thereafter perform another @xmath129 measurement shots .",
    "we then compare the estimates after @xmath129 and @xmath130 measurement shots .",
    "if their difference is smaller than a set threshold , we conclude that we have found a correct estimate , otherwise we start a new search of the estimate . for the new search",
    "we choose a prior that again coincides with the original prior .",
    "tables i and ii summarize the performance of the policies @xmath131 and @xmath132 in the absence and presence of readout errors , respectively .",
    "these correspond to the policies @xmath102 and @xmath126 supplemented with the outlier correction scheme .",
    "outliers are defined as the samples with the squared error @xmath133 larger than threshold @xmath134 .",
    "the outlier correction scheme appears to eliminate the outliers with an acceptable overhead .",
    ".number of outliers per @xmath129 simulated samples with @xmath135 for the policy @xmath131 ( see text ) .",
    "rows correspond to the number of outliers with normalized squared error larger than @xmath134 after a given number of measurement shots ( indicated by the columns ) . [",
    "cols=\"<,^,^,^,^,^,^\",options=\"header \" , ]     [ table1 ]",
    "based on bayesian inference , we have delivered powerful methods for adaptive characterization of coherent states . for",
    "larger photon numbers @xmath136 , the adaptive schemes discussed here reduce the number of measurement shots required to achieve a certain level of accuracy by a factor proportional to the area describing the initial uncertainty of @xmath1 in phase space . in terms of measurement shots",
    ", we expect that efficiency can be quite generally improved by several orders of magnitude which motivates making experiments adaptively . for more complicated quantum states of light in a superposition @xmath137 ,",
    "our results are readily applicable for estimating @xmath138 . for full identification of @xmath139 ,",
    "our policies have to be supplemented with methods to obtain relative weights @xmath140 of different components as well as their relative phases .",
    "our work thus constitutes a building block that opens up an avenue for efficient estimation of multicomponent schrdinger - cat states of light .",
    "we acknowledge l. c. g. govia , e. m. leonard jr . , r. mcdermott , i. pechenezhskiy , g. j. ribeill , s. f. taylor , and t. thorbeck for discussions .",
    "this work was supported by the european union through scaleqit .",
    "it is unlikely but possible that vacuum is not detected even though a large number , @xmath141 , of measurement shots is carried out . due to limited numerical accuracy",
    ", this can lead to a drastic failure of the estimation if the particles do not converge close to the true value . therefore , in case vacuum has not been detected after @xmath141 measurement shots , we switch the first line of eq .",
    "( 2 ) to a uniform probability distribution @xmath142 on the region @xmath143 .",
    "we set @xmath144 and @xmath67 ."
  ],
  "abstract_text": [
    "<S> we present methods for efficient characterization of an optical coherent state @xmath0 . </S>",
    "<S> we choose measurement settings adaptively and stochastically , based on data while it is collected . </S>",
    "<S> our algorithm divides the estimation into two distinct steps : ( i ) before the first detection of a vacuum state , the probability of choosing a measurement setting is proportional to detecting vacuum with the setting , which makes using too similar measurement settings twice unlikely ; and ( ii ) after the first detection of vacuum , we focus measurements in the region where vacuum is most likely to be detected . in step ( i ) [ ( ii ) ] the detection of vacuum ( a photon ) has a significantly larger effect on the shape of the posterior probability distribution of @xmath1 . compared to nonadaptive schemes , our method makes the number of measurement shots required to achieve a certain level of accuracy smaller approximately by a factor proportional to the area describing the initial uncertainty of @xmath1 in phase space . while this algorithm is not directly robust against readout errors , we make it such by introducing repeated measurements in step ( i ) . </S>"
  ]
}