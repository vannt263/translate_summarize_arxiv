{
  "article_text": [
    "this paper is concerned with the complexity of networks .",
    "many features of biological , social and technological systems can be described in terms of networks .",
    "examples include gene networks , friendship networks , citation networks , the power grid , the internet and the world wide web  @xcite . although the systems that generate these networks are extremely complex , the networks themselves may or may not evidence this complexity . in many cases the networks generated by complex systems",
    "are approximately scale free .",
    "barabasi and albert  @xcite ( ba ) showed that scale free networks can be generated by rules for network growth that embody the intuitively plausible idea of preferential attachment . in their model",
    ", the network grows by the addition of one node at a time and each node creates one new connection to an existing node .",
    "existing nodes in the network that already have many connections are more likely to gain the new connection from the new node added to the network . the growing network model seems to incorporate a history dependent process , albeit simplified , into the generation of the network .",
    "one of the essential markers of complexity is a long history .",
    "complex systems can not arise instantaneously but require a long sequence of interactions to develop .",
    "neither `` complexity '' nor `` long history '' are well - defined concepts but an appropriate proxy for these ideas can be formulated within computational complexity theory .",
    "computational complexity theory is concerned with the resources required to solve problems .",
    "although there are various resources required to solve computational problems , here we focus on parallel time or depth .",
    "depth is the number of computational steps needed by a parallel computer to solve a problem . in our case ,",
    "the problem is to generate a statistically correct representation of the network .",
    "if the depth of the computation needed to generate the network is large , even using the most efficient algorithm , we say that the network has a long history and can not be generated quickly .",
    "if , on the other hand , only a few parallel steps are needed to generate the network , then it can not be complex .",
    "the growing network model would appear to have substantial depth since nodes are added to the network one at a time and the preferential attachment rule uses knowledge of the existing state of the network to decide where each new node will attach . if the model captures the mechanism for the scale free behavior found in real world networks then perhaps one can conclude that some of the complexity or history dependence of the social , biological or technological system that generated the network is embodied in the network .",
    "one of the main conclusions of this paper is that growing network models do not actually embody much history dependence .",
    "what we show is that there is a fast parallel algorithm that generates growing networks with @xmath4 nodes in @xmath5 steps .",
    "the model has a linear preferential attachment rule .",
    "krapivsky , redner and leyvraz  @xcite introduced a generalization of the model in which the probability to connect to a node is proportional to a power , @xmath6 of its number of connections .",
    "the original model is the case @xmath7 while @xmath8 is a random network .",
    "the class of models @xmath9 is analyzed in refs .",
    "@xcite and it is seen that @xmath7 marks a `` phase transition '' between a  high temperature phase \" for @xmath10 where no node has an extensive number of connections and a `` low temperature phase '' for @xmath11 where a single node has almost all connections in the large @xmath4 limit .    we show that distinct but related parallel algorithms are needed to efficiently simulate the @xmath10 and @xmath11 regimes so that there is a discontinuous transition in the computational complexity of simulating the model at @xmath7 .",
    "for @xmath12 the parallel time for generating a network of size @xmath4 scales logarithmically in @xmath4 while for @xmath13 there is a constant time algorithm .",
    "exactly at @xmath7 yet a third algorithm is most efficient with parallel running time that is @xmath14 .",
    "a number of non - equilibrium models in statistical physics defined by sequential rules have been shown to have fast parallel dynamics .",
    "examples include the eden model , invasion percolation , the restricted solid - on - solid model  @xcite , the bak - sneppen model  @xcite and internal diffusion - limited aggregation  @xcite all of which can be simulated in parallel in polylogarithmic time . on the other hand ,",
    "no polylog time algorithm is known for generating diffusion - limited aggregation clusters and there is evidence that only powerlaw speed - ups are possible using parallelism  @xcite .",
    "phase transitions in computational complexity have been the object of considerable recent study , for example , see ref .",
    "most of the attention has been focused on * np*-hard combinatorial optimization problems .",
    "growing networks and many other physically motivated models are naturally related to problems in the lower class * p * ( problems solvable in polynomial time ) .",
    "one of the purposes of this paper is to provide an example of a transition in computational complexity at this lower level of the complexity hierarchy .",
    "the paper is organized as follows .",
    "in the next section we define and describe the class of preferential attachment network growth to be studied . in sec .",
    "[ sec : comp ] we give a brief review of relevant features of parallel computational complexity theory .",
    "section [ sec : alg ] presents efficient parallel algorithms for sampling growing network models and related systems , sec .",
    "[ sec : eff ] analyzes the efficiency of these algorithms and sec .",
    "[ sec : sim ] presents results from numerical studies of the efficiency of one of the algorithms .",
    "the paper ends with a discussion .",
    "in this section we describe growing network models with preferential attachment first considered by barabasi and albert @xcite and later generalized by krapivsky , redner and leyvraz  @xcite .",
    "consider a graph with @xmath4 ordered nodes , each having one outgoing link , constructed by the addition of one node every time step so that at time @xmath15 in the construction , node @xmath15 is attached to a previous node , @xmath16 through @xmath17 .",
    "the probability @xmath18 of attaching node @xmath15 to node @xmath19 is given by @xmath20 where @xmath21 is the degree ( number of connections ) of @xmath22 , at time t , @xmath23 is some function and @xmath24 is the normalization given by @xmath25 we require that @xmath26 is a non - decreasing function of @xmath27 .",
    "notice that , in general , @xmath18 is a function not only of @xmath21 but also of @xmath28 for all @xmath29 because of the normalization , @xmath24 .",
    "the attachment probabilities depend on all the node degrees unless @xmath30 is a function of @xmath31 alone .",
    "this simpler form holds if and only if @xmath23 is a linear function , @xmath32 . in the latter case , @xmath33 since @xmath34 .    the linear homogeneous case",
    ", @xmath35 corresponds to the original barabasi - albert model  @xcite and leads to a scale free network where the degree distribution , @xmath36 , has a power law tail , @xmath37 . more generally , if @xmath26 is asymptotically linear , @xmath38 where @xmath39 is tunable to any value @xmath40  @xcite .",
    "the asymptotically linear attachment kernel is a marginal case and marks a `` phase transition '' between regimes with qualitatively different behavior .",
    "consider the homogeneous models , @xmath41 studied in detail in ref .  @xcite . in the sublinear case , @xmath12 the degree distribution has a stretched exponential form and the node with the maximum degree has polylogarithmically many connections .",
    "the limiting case of @xmath8 is a random network where each connection is randomly and independently chosen .",
    "there is an analogy between @xmath6 and temperature in a thermodynamic system with the range @xmath42 like a high temperature phase .",
    "the order parameter is the maximum degree in the system divided by @xmath4 and the order parameter vanishes for @xmath43 . in the superlinear or low temperature phase ,",
    "@xmath44 there is a single , `` gel '' node that has almost all connections and the order parameter is unity .",
    "the phase transition then has a discontinuous character despite the fact that the @xmath7 state is scale free .",
    "another indication that the transition is discontinuous is seen by looking at the entropy . using the kolmogorov - chaitin definition of entropy as the minimum number of bits required to describe a system state  @xcite",
    ", it is clearly seen that the entropy per node is positive for all @xmath45 but that for @xmath11 the entropy per node vanishes since almost all nodes connect to the gel node and it is only necessary to specify the connections for those nodes that do not connect to the gel node .",
    "thus , the entropy per node is also discontinuous at @xmath7 .",
    "computational complexity theory is concerned with the scaling of computational resources needed to solve problems as a function of the size of the problem .",
    "an introduction to the field can be found in ref .",
    "here we focus on parallel computation and choose the standard _ parallel random access machine _ ( pram ) as the model of computation  @xcite .",
    "the main resources of interest are _ parallel time _ or _",
    "depth _ and number of processors .",
    "a pram consists of a number of simple processors ( random access machines or rams ) all connected to a global memory .",
    "although a ram is typically defined with much less computational power than a real microprocessor such as pentium , it would not change the scaling found here to think of a pram as being composed of many microprocessors all connected to the same random access memory .",
    "the processors run synchronously and each processor runs the same program .",
    "processors have an integer label so that different processors follow different computational paths .",
    "the pram is the most powerful model of classical , digital computation .",
    "the number of processors and memory is allowed to increase _ polynomially _",
    "( i.e.  as an arbitrary power ) in the size of the problem to be solved .",
    "communication is non - local in that it is assumed that any processor can communicate with any memory cell in a single time step .",
    "obviously , this assumption runs up against speed of light or hardware density limitations .",
    "nonetheless , parallel time on a pram quantifies a fundamental aspect of computation .",
    "any problem that can be solved by a pram with @xmath46 processors in parallel time @xmath47 could also be solved by a single processor machine in a time @xmath48 such that @xmath49 since the single processor could sequentially run through the tasks that were originally assigned to the @xmath46 processors .",
    "the single processor time , @xmath48 is sometimes referred to as the computational work . on the other hand , it is not obvious whether the work of a single processor can be re - organized so that it can be accomplished in a substantially smaller number of steps by many processors working independently during each step .",
    "an example of where exponential speed - up can be achieved through parallelism is adding @xmath4 numbers .",
    "addition can be done by a single processor in a time that scales linearly in @xmath4 . on a pram with @xmath50 processors addition",
    "can be carried out in @xmath51 parallel time using a binary tree . for simplicity ,",
    "suppose @xmath4 is a power of @xmath52 .",
    "in the first step , processor one adds the first and second numbers and puts the result in memory , processor two adds the third and fourth numbers and puts the result in memory and so on .",
    "after the first step is concluded there are @xmath50 numbers to add and these are again summed in a pairwise fashion by @xmath53 processors . the summation is completed after @xmath54 steps .",
    "addition is said to have an _ efficient _ parallel algorithms in the sense that they can be solved in time that is a power of the logarithm of the problem size , here @xmath4 , that is , _",
    "polylog _ time . on the other hand",
    ", it is believed that there are some problems that can be solved in polynomial time using a single processor but can not be efficiently parallelized .",
    "it is believed that p - complete problems  @xcite have this property and can not be solved in polylog time with polynomially many processors .",
    "the main concern of this paper is the complexity of generating networks defined by preferential attachment growth rules .",
    "since these networks grow via a stochastic process , we envision a pram model equipped with registers containing random numbers .",
    "the essential question that we seek to answer is the depth ( number of pram steps ) required to convert a set of independent random bits into a statistically correct network .",
    "at first glance , it seems that growing networks have a strong history dependence .",
    "it would appear that to connect some node @xmath31 appropriately one must first connect all nodes prior to @xmath31 in order to compute the connection probabilities for @xmath31 according to eq .",
    "[ eq : pat ] .",
    "surprisingly , one can construct a statistically correct network using an iterative parallel process that converges in far fewer than @xmath31 steps .",
    "the strategy is to place progressively tighter lower bounds on the connection probabilities based on connections made in previous parallel steps in the process .",
    "a simple example of the general strategy is instructive . consider a biased coin toss with memory such that the number of heads on the first @xmath31 coin tosses modifies the probability of a head on toss @xmath55 .",
    "suppose that more heads on previous tosses increases the probability of a head on the current toss according to some function @xmath56 where @xmath57 is the probability of a head on the @xmath58 coin toss and @xmath59 is the fraction of heads on all the coins tossed before @xmath31 .",
    "suppose that @xmath60 is a non - decreasing function of its argument and that @xmath61 .",
    "note that the special case @xmath62 is a polya urn problem and is discussed in sec .",
    "[ sec : redirect ] .",
    "the goal is to simulate a sequence of @xmath4 coin tosses .",
    "it would appear that we can not decide coin @xmath31 until we have decided all its predecessors .",
    "nonetheless , we can proceed in parallel by successively improving lower bounds on the probability that a given coin toss is a head .",
    "let , @xmath63 , @xmath64 be an estimated lower bound on the probability that the @xmath58 coin toss is a head on the @xmath65 step of the algorithm where @xmath66 is the fraction of tosses determined to be heads at the beginning of iteration @xmath67 .",
    "the starting assumption is that none of the tosses have been determined , @xmath68 for all @xmath31 , and this assumption is used to compute how many coins become heads on the first iteration .",
    "thus , @xmath69 and , on the first iteration , coin @xmath31 becomes a head with this probability .",
    "once a coin becomes a head , it stays a head while coins that are not heads remain undecided . on the second iteration ,",
    "we make use of the heads decided in the first iteration to recompute the fraction determined to be heads , @xmath70 and from these obtain the new bounds @xmath71 . for each coin @xmath31 that is not yet determined to be a head",
    "we declare it a head with conditional probability @xmath72 that it will become a head on this step given that it is not yet a head , @xmath73 .",
    "some new coins are declared heads and these are then used to compute @xmath74 . in general ,",
    "if coin @xmath31 is not yet determined by step @xmath67 , it becomes a head with probability @xmath75 where @xmath76 is the conditional probability of coin @xmath31 becoming a head on step @xmath67 given it was undecided up to step @xmath67 .",
    "the expression for the conditional probability follows from the observation that the denominator is the marginal probability of being undecided after step @xmath77 and the numerator is the probability of becoming a head on step @xmath67 .",
    "the algorithm stops on step @xmath47 when there is no change from one step to the next , @xmath78 for all @xmath31 , and the lower bounds equal the true probabilities @xmath79 . at the end of the simulation ,",
    "every coin that is not a head is declared to be a tail .",
    "for every @xmath31 , @xmath80 so that @xmath81 thus the procedure is well - defined and we can decide in stages whether coin @xmath31 will be a head .    in the following two sections",
    "we show how to generalize this strategy to the case of preferential attachment growing network models .",
    "this section describes a parallel algorithm for constructing a network with a sublinear or linear attachment rule , @xmath82 where @xmath83 or , more generally , the case where the attachment weight @xmath26 is a non - decreasing , convex function of @xmath27 . as in the coin toss example , on intermediate parallel steps we have nodes whose connections are not yet determined . in this algorithm",
    "we lump all of these connections into a `` ghost '' node whose in - degree is equal to the number of nodes that have not yet been determined . on every parallel time step , @xmath84 , the algorithm attempts to connect every node that is currently connected to the ghost node to a real node according to lower bounds on the connection probabilities determined by connections that have been made in previous steps .    in the initialization ,",
    "@xmath85 step of the algorithm , a ghost node is created and all real nodes are connected to it , except node zero , which connects to itself , and node one , which also connects to node zero .",
    "thus , for @xmath85 and every sequential time @xmath86 , every real node @xmath87 has in - degree 0 and out - degree 1 , except the zero node which has both in- and out - degree equal to 1 .",
    "the ghost node has in - degree @xmath88 for @xmath89 .",
    "let @xmath90 be the number of nodes connecting to the ghost node at the beginning of parallel step @xmath84 and sequential time t so that @xmath91 for @xmath89 .",
    "in the first , @xmath92 step of the algorithm the connection probability lower bound for node @xmath31 to connect to node @xmath93 , @xmath94 is given by @xmath95 while the connection probability , @xmath96 for the ghost node is taken to be proportional to its number of connections , @xmath97 with the normalization given by @xmath98 the constant @xmath99 is discussed below .",
    "these are the connection probabilities that would arise if each real node has one connection and the ghost node has an attachment probability proportional to its degree . on the first step of the algorithm , each node @xmath31",
    "is connected to one of its predecessors or the ghost node according to the probabilities given above .    as in the case of the coin toss model described in the previous section , on successive steps",
    "we recompute the bounds on the connection probabilities @xmath100 for the real nodes and the ghost node @xmath101 . for general @xmath84 , @xmath31 and @xmath93 these probabilities",
    "are given by @xmath102 with the normalization given by @xmath103    on step @xmath84 of the algorithm , the conditional probability , @xmath104 of connecting node @xmath31 to node @xmath93 , given that node @xmath31 has not yet connected to a real node on an earlier step , is given by the difference between the probability bounds on successive steps divided by the marginal probability of being undetermined ( connected to the ghost node ) before step @xmath67 , @xmath105 note that the denominator can be written as @xmath106 on step @xmath84 of the algorithm each node @xmath31 that was still connected to the ghost node after step @xmath107 is connected with probability @xmath104 to real node @xmath87 or , with probability , @xmath108 , @xmath109 still connected to the ghost node .",
    "the algorithm is finished after @xmath47 steps when there are no more nodes connected to the ghost node and the bounds of eq .",
    "[ eq : wat ] saturate to the correct probabilities of eq .",
    "[ eq : pat ] .",
    "note that at least one node must connect in each parallel step since the lowest numbered node that is still unconnected will have no weight allotted to it in the ghost node .    for the conditional probabilities @xmath104 to be positive",
    ", the probability bounds must be non - decreasing for all @xmath93 and @xmath31 , @xmath110 these inequalities imply a bound on @xmath99 as follows .",
    "since @xmath26 is a non - decreasing function of @xmath27 and @xmath111 is a non - decreasing of @xmath84 it is sufficient to require that @xmath112 is a non - increasing function , @xmath113 , or , since , @xmath114 we require that @xmath115 this inequality is satisfied term by term if @xmath116 is non - increasing which holds if @xmath117 since the algorithm will finish fastest if the ghost node has the smallest possible weight , we set @xmath99 equal to its lower bound . in particular , for the power law case , @xmath118 with @xmath119 , the maximum occurs for @xmath120 yielding @xmath121      for the superlinear case , a gel node develops to which almost all nodes connect as @xmath122 . when @xmath123 all but a finite number of nodes connect to the gel node .",
    "the parallel algorithm described here takes advantage of the fact that the vast majority of connections are to the gel node and the gel node plays a role similar to that of the ghost node in the sublinear and linear cases .",
    "the basic structure of the algorithm is as follows . in the initialization",
    "@xmath85 phase the sequential algorithm is run so that all nodes @xmath124 are properly connected .",
    "@xmath125 is chosen so that a single gel node is firmly established by the time all nodes @xmath124 are connected .",
    "the gel node is firmly established if the probability that a different node ultimately becomes the gel node is less than some small value @xmath126 .",
    "when @xmath0 is large @xmath125 is small , but as @xmath0 approaches 1 , for fixed @xmath126 , @xmath125 diverges . after the initialization phase",
    ", it is tentatively assumed that all nodes @xmath127 are connected to the gel node .",
    "the gel node serves as a repository for all connections that are not yet determined . in successive steps",
    ", the connection probabilities of all nodes @xmath127 are modified according to the number of connections that possible destination nodes , @xmath87 received in the previous step and lower bounds on connection probabilities are recalculated .",
    "the difference between old and new probability bounds are used to find conditional probabilities for moving a connection from the gel node to some other node .",
    "this process is repeated until no connections are moved from the gel node to any other node .",
    "the nodes that have not been moved away from the gel node are then determined to be connected to the gel node .",
    "following the general strategy , lower bounds on the connection probabilities for @xmath128 are determined for each parallel step , @xmath129 where the normalization is given by @xmath130 note that the connection probabilities are calculated in the same way for the gel node and the other nodes in contrast to the sublinear case .    in the first parallel step , @xmath92",
    ", the algorithm connects every node , @xmath128 to some node , @xmath93 according to the connection probabilities @xmath131 . in successive , steps , @xmath132",
    ", it attempts to re - connect only those nodes @xmath128 that are still connected to the gel node .",
    "the conditional probability @xmath133 for connecting @xmath128 to @xmath134 on step @xmath67 is given by @xmath135 the numerator is the probability that @xmath31 connects to @xmath93 on step @xmath84 and the denominator is the probability that @xmath31 is undetermined after step @xmath107 . the conditional probability that @xmath31 is undetermined after step @xmath84 , given that it was undetermined after step @xmath107 , is @xmath136 the algorithm is finished after step @xmath47 if no changes occur from step @xmath137 to step @xmath47 . on step @xmath47",
    "nodes that are connected to @xmath138 are considered to be determined and actually connected to the gel node .",
    "the algorithm is valid if eq .",
    "[ eqn : mono ] holds for all @xmath128 and @xmath134 .",
    "since @xmath26 is non - decreasing , we require that @xmath139 is a non - increasing function of @xmath84 . from eq .",
    "[ eqn : norm ] we must show that the change in @xmath24 from one parallel step to the next is either constant or decreasing for all @xmath31 and @xmath84 . we can write the requirement for the validity of the algorithm as @xmath140 \\leq 0.\\ ] ] it is useful to take the gel node term out of the sum , as its behavior is different @xmath141.\\ ] ] at each parallel step connections are switched from the gel node to other nodes . for every connection that is lost by the gel node exactly one connection",
    "is gained by another node .",
    "we also note that because @xmath23 is a concave function with a continuously increasing derivative , we can say that for any positive @xmath142 @xmath143 since @xmath144 is decreasing with @xmath84 and @xmath145 is increasing with @xmath84 we can rewrite eq .",
    "[ eqn : zdecrease2 ] , absorbing the contribution of the gel node into the sum to describe the entire rewiring of @xmath146 connections from the gel node to another node .",
    "we use eq .",
    "[ eqn : deltak ] to put an upper bound on the change in size , the rhs of eq .",
    "[ eqn : zdecrease2 ]    @xmath147[f^{\\prime}(k_m^{\\t})-f^{\\prime}(k_g^{\\t})].\\ ] ]    the term on the rhs in the first square brackets is non - negative . if @xmath148 then the term in square brackets is always negative because @xmath149 is a strictly increasing function of @xmath27 .",
    "this argument shows that eq .",
    "[ eqn : zdecrease ] holds and thus the algorithm is valid if the gel node remains the largest node until the end of the simulation .",
    "the value of @xmath126 and , thus , the choice of @xmath125 determines the error rate of the algorithm since the algorithm fails if and only if the gel node loses it status as having the most connections .",
    "this section explores the method proposed by krapivsky and redner@xcite for the case of a linear attachment kernel .",
    "we show that this method can be used to generate the network in @xmath5 steps .",
    "the method works as follows : at sequential time @xmath31 , node @xmath31 is connected to any node @xmath150 with equal probability . with probability @xmath151 ,",
    "however , this node is redirected to the `` ancestor '' of @xmath22 , the node that @xmath22 connects to .",
    "as krapivsky and redner show , when @xmath152 , this procedure exactly reproduces the model ( @xmath35 ) . for other values of @xmath151 , @xmath26 is asymptotically linear and the connectivity distribution scales as @xmath153 where @xmath154 .",
    "it is easy to see why redirection is equivalent to a linear kernel .",
    "a node that already has @xmath27 connections has @xmath27 ways to be connected from a new node since each of the @xmath27 connections can serve as a redirection point for the new node . for @xmath155",
    "it is clear that @xmath156 so this case corresponds to homogeneous network .",
    "this redirection process can be simulated in @xmath14 parallel time as follows .",
    "first , randomly connect every node to one of its predecessors .",
    "once this is done , for every connection , with probability @xmath151 , make that connection a redirectable ( r ) connection , otherwise , make it a terminal ( t ) connection .",
    "all that remains is to trace every path of r connections until a t connection is reached .",
    "this can be accomplished using a standard parallel connectivity algorithm or by the following simple approach . for every node , @xmath31",
    ", if its outgoing connection is type t make no change to the connection .",
    "if its outgoing connection is type r , then it is redirected .",
    "suppose @xmath31 connects to @xmath157 by an r connection and that @xmath157 connects to @xmath158 , then after the parallel step , @xmath31 connects to @xmath158 .",
    "furthermore , if the @xmath157 to @xmath158 connection is type t then the new connection from @xmath31 to @xmath158 is type t , otherwise it is an r connection .",
    "when all of the connections are type t , the program is done and the network is correctly wired .",
    "it is clear that this procedure require a number of steps that scales as the logarithm of the longest chain of redirections . on average ,",
    "the longest chain of redirections will behave as the logarithm of the system size .",
    "each connection redirects with probability @xmath151 .",
    "the average length of the longest chain of redirections , @xmath159 , is estimated by @xmath160 where @xmath4 is the number of possible starting points and @xmath161 is the probability of a chain of length @xmath159 .",
    "thus @xmath162 so @xmath163 .",
    "note that the chain length saturates at @xmath164 rather than diverges as @xmath165 .",
    "even if @xmath165 each connection will typically halve the distance to the origin so that there are @xmath166 connections in the longest chain .",
    "a chain of connections of length @xmath159 , can be traced in @xmath167 steps , because each step will halve the length of the chain .",
    "thus the algorithm will finish in @xmath168 steps .",
    "the polya urn model is closely related to the growing network model and the redirection method can be applied to efficiently sample its histories in parallel . in the simplest version of the model ,",
    "an urn initially contains two balls , one red and one black . on each time",
    "step a ball is randomly selected from the urn and then replaced along with a new ball of the same color .",
    "thus , after @xmath4 steps the urn contains @xmath169 balls .",
    "the urn model has the unusual property that it can have any limit law .",
    "for large @xmath4 the fraction of red balls approaches a constant but , with equal probability , that constant can be any value from zero to one .",
    "the limit law is thus determined by the initial choices .",
    "the urn model can be viewed as a network where each ball is a node and the connection from one node to a predecessor represents the fact that the color of the later node was determined by the earlier node . to find the color of a given ball or node ,",
    "the connections are traced back to one of the two initial balls .",
    "this representation shows that the urn model is identical to the linear network model in the limit that the redirection probability is unity .",
    "the typical longest path of connections back to the origin is @xmath166 since each connection will typically halve the distance to the origin .",
    "thus the depth of sampling the history of an urn model is @xmath5 .",
    "in this section we argue that for a system of size @xmath4 , when @xmath83 , the parallel algorithm will finish in @xmath170 parallel steps and we estimate the prefactor of the logarithm .",
    "the starting point is an equation for the expected number of connections to the ghost node on the @xmath171 step given the number of connections on steps @xmath84 and @xmath107 , @xmath172\\a_g^{\\t}(t^{\\prime}).\\ ] ] the quantity in the square brackets is 1 if @xmath173 is connected to the ghost node on step @xmath84 and 0 otherwise while @xmath174 , defined in eq .",
    "[ eq : ghostprob ] is the conditional probability that @xmath173 connected to the ghost node after step @xmath84 if it is connected to the ghost node before step @xmath84 .",
    "equation [ eq : kgvs ] holds for @xmath175 .",
    "initially , @xmath176 . specializing to the case that the attachment kernel is a pure power law with exponent @xmath0 and ignoring constants that are irrelevant in the large @xmath31 limit we have @xmath177 this result follows from the fact that the probability that node @xmath31 will still be connected to the ghost node after the first step is , according to eqs .",
    "[ eq : initghostprob ] and [ eq : normdef ] , approximately @xmath178 . the far rhs of the expression is obtained from eq .",
    "[ eq : cvalpha ] .    to proceed",
    "further we make two approximations .",
    "first , we ignore fluctuations and replace @xmath179 by its average value on the rhs of eq .",
    "[ eq : kgvs ] , @xmath180 \\frac{k_g^{\\t}(t^{\\prime } ) } { k_g^{\\t-1}(t^{\\prime } ) } \\frac { \\zt^{\\t-1}(t^{\\prime})}{\\zt^{\\t}(t^{\\prime})}\\ ] ] where the notation is simplified in this equation by interpreting @xmath179 as the average number of connections to the ghost node and where eqs .",
    "[ eq : gwat ] and [ eq : ghostprob ] have been used to expand @xmath181 .    for the case of a linear attachment kernel , @xmath182 and",
    "the normalization @xmath183 is independent of @xmath84 .",
    "the ratio of normalizations thus drops out of the equation and we obtain , @xmath184 \\frac{k_g^{\\t}(t^{\\prime } ) } { k_g^{\\t-1}(t^{\\prime } ) } \\ ] ] for sublinear kernels , the choice of @xmath99 insures that the ratio @xmath185 is less than one as discussed at the end of sec .",
    "[ sec : subalg ] .",
    "our second approximation , is to assume that this ratio is unity for the entire sublinear regime .",
    "note that both @xmath186 and @xmath187 are proportional to @xmath31 .",
    "it follows from eq .",
    "[ eq : kgvs2 ] that @xmath188 is is proportional to @xmath31 for all @xmath84 and we write @xmath189 .",
    "this substitution reduces eq .",
    "[ eq : kgvs2 ] to @xmath190 given our approximations , the ratio @xmath191 for all @xmath84 and the solution is @xmath192 .",
    "the estimate for the number of steps , @xmath47 needed to complete the algorithm is such that the ghost node is expected to have fewer than one node , @xmath193 .",
    "this requirement leads to the result @xmath194 this result is compared to the numerical simulations in sec .",
    "[ sec : sim ] .      in this section",
    "we show that the @xmath196 algorithm finishes in constant time independent of @xmath4 although this constant diverges as @xmath197 .",
    "the key fact @xcite about superlinear networks is that there is a cut - off @xmath198 such that only a finite number of nodes have more than @xmath199 connections . by choosing @xmath125 sufficiently large , no nodes @xmath200",
    "will have more than @xmath199 connections .",
    "we will show that the running time of the parallel part of the algorithm is roughly @xmath199 steps .",
    "consider what happens on the first step of the algorithm .",
    "all nodes @xmath128 are initially connected to the gel node so the leading behavior of the normalization is @xmath201 and the leading behavior of the connection probabilities , defined in eq .  [ eq : prob ] , is @xmath202 for @xmath134 .",
    "summing over all @xmath134 we find that on the first step , the probability that node @xmath31 will connect away from the gel node behaves as @xmath203 .",
    "the expected change in the number of nodes connecting to the gel node during step one is obtained by summing over all nodes @xmath204 , with the result @xmath205 if @xmath206 no changes are expected to occur in the first step of the algorithm and we are done .",
    "this result is consistent with the fact that for @xmath206 , there are only a finite number of nodes with more than one connection and these are all determined before @xmath125 .",
    "for @xmath207 additional steps are needed before @xmath208 is less than one and the algorithm is done .",
    "we make the ansatz that @xmath209 and look for a self - consistent solution for @xmath210 .",
    "the running time , @xmath47 is obtained by solving for the least @xmath47 such that @xmath211 .    on the second and later steps of the algorithm , the conditional connection probabilities , defined in eqs .",
    "[ eq : prob ] to [ eq : conprob ] , can be written to leading order and for @xmath134 as , @xmath212 there are two ways for @xmath104 to be non - zero .",
    "the first is for there to have been a new connection from @xmath173 to @xmath93 , with @xmath213 , in step @xmath107 .",
    "the expected number of nodes , @xmath93 that received new connections in step @xmath107 is just @xmath214 .",
    "since @xmath215 for all @xmath84 , the leading behavior of @xmath104 is @xmath216 and the overall probability that @xmath31 will connect away from the gel node by this mechanism scales as @xmath217 .",
    "the second way for @xmath104 to be non - zero is for the ratio @xmath218 to exceed unity .",
    "this possibility applies for all target nodes , @xmath87 , @xmath134 .",
    "the leading behavior of this ratio is given by @xmath219 so that the leading behavior of @xmath104 is @xmath220 .",
    "since there are @xmath31 target nodes , the total probability that @xmath31 will connect away from the gel node by this mechanism again scales as @xmath221 .    combining both of the above mechanisms for @xmath31 to connect away from the gel node and summing over all",
    "@xmath31 , @xmath222 ( and still connected to the gel node ) we obtain an expression for @xmath223 , the expected number of nodes directed away from the gel node on step @xmath84 , @xmath224 using the ansatz of eq .",
    "[ eq : ansatz ] we obtain the recursion relation , @xmath225 the recursion relation and the initial condition @xmath226 , eq .",
    "[ eq : deltak2 ] , has the solution , @xmath227 the running time of the algorithm is obtained from the least @xmath47 for which @xmath228 is negative , @xmath229 or , from , eq .",
    "[ eq : kmax ] , @xmath230 this result can be understood in terms of the following sequence of events for creating connections for nodes beyond @xmath125 . in the first parallel step almost all nodes with two connections",
    "are generated . in the second parallel step a small fraction of these nodes",
    "develop a third connection and a comparable number of nodes with one connection get a second connection . on the third step ,",
    "an even smaller number of nodes with three connections get a fourth connection and so on until nothing happens .",
    "note that the analysis of the algorithm reproduces the results in @xcite for the scaling of the number of nodes with @xmath231 connections .",
    "in sec .  [ sec : effsub ] we argued that the algorithm for the sublinear kernel requires logarithmic parallel time to generate a network and in eq .",
    "[ eq : subtheory ] we estimate the coefficient of the logarithm . in this section",
    "we support these conclusions with a simulation of the parallel algorithm on a single processor workstation . in the simulation",
    "the work of each processor on the pram is done in sequence making sure not to update the database describing the network until a parallel step is completed .",
    "we generated 1000 networks for each value of @xmath6 and for each system size .",
    "values of alpha ranged from 0 to 1 , in increments of 0.05 and system sizes from 50 nodes to 12,800 nodes with each size separated by a factor of two .",
    "figure [ fig : timevsize ] shows the average number of parallel steps vs.  system size for @xmath232 0.25 , 0.5 , 0.75 and 1.0 .",
    "the figure demonstrates the logarithmic dependance of average running time , @xmath47 on system size , @xmath4 for all values of @xmath6 and the full range of system sizes so that that , to good approximation , @xmath233 .",
    "figure [ fig : coeffvalpha ] shows a plot of the coefficient @xmath234 as a function of @xmath0 .",
    "the results are plotted for @xmath83 .",
    "the prediction of eq .",
    "[ eq : subtheory ] is shown on the same figure .",
    "although not perfect , the approximation of eq .",
    "[ eq : subtheory ] captures the general trend of the data and is within a few percent of the numerical results for @xmath235 .",
    "the larger fluctuations in connectivity near @xmath7 may explain why the `` mean field '' assumption underlying the theoretical curve loses accuracy there .",
    "the theoretical estimate does appear to correctly predict that @xmath236 approaches zero with infinite slope as @xmath237 .     to generate a network as a function of system size @xmath4 for @xmath238 , @xmath239 , @xmath240 and @xmath241 , from bottom to top , respectively.,width=288 ]     of the leading logarithmic term in the running time versus @xmath0 .",
    "the points are the results of the simulation and the solid line is the theoretical approximation , eq .",
    "[ eq : subtheory].,width=288 ]",
    "we have examined the parallel computational complexity of generating networks obeying preferential attachment growth rules .",
    "we demonstrated that these networks can be sampled in parallel time that is much less than the size of the network .",
    "this result is surprising because the defining rules for generating these networks are sequential with nodes added to the network one at a time depending on the present state of the network .",
    "nonetheless , we have bounded the depth of sampling growing networks by exhibiting efficient parallel algorithms for the three cases , @xmath242 , @xmath7 and @xmath243 .",
    "the average parallel running time for the @xmath242 algorithm is logarithmic , the algorithm for the scale free network runs in @xmath14 time and for @xmath243 the algorithm runs in constant time .",
    "growing networks thus provide an example of a discontinuous phase transition in complexity as a function of @xmath6 at @xmath7 .",
    "it is not surprising that a complexity transition occurs at @xmath7 since this is where the structural properties of the system also undergo a discontinuous transition from a high temperature ( @xmath10 ) regime where no nodes have a finite fraction of the connections to a low temperature ( @xmath11 ) regime where there is a single gel node with almost all connections .",
    "it is noteworthy that parallel time is the proper resource to observe this transition .",
    "the more common complexity measure of sequential time or computational work has no transition since it requires @xmath244 time to give an explicit description of the network for any @xmath6 .",
    "our results set upper bounds on the depth of sampling growing networks but we can not rule out the existence of yet faster parallel algorithms .",
    "for example , if a constant time algorithm exists for @xmath242 , it would modify the conclusion that there is a discontinuous complexity transition at @xmath7 .",
    "there are few rigorous lower bounds in computational complexity theory , so , in general , conclusions concerning the depth of sampling and the existence of complexity transitions in statistical physics must be considered tentative .",
    "in this paper we have presented a general strategy for parallelizing a broad class of sequential stochastic processes , exemplified by the coin toss with memory .",
    "we have applied the general method to create algorithms that efficiently parallelize preferential attachment network models .",
    "the general method should be more broadly applicable to growing network models with more complicated rules .",
    "to give one example , hajra and sen  @xcite extend the preferential attachment model to include an aging factor ( @xmath26 becomes @xmath245 ) so that older nodes are either favored or avoided depending on a parameter .",
    "our algorithm can be modified to efficiently handle this class of models .",
    "it is also instructive to examine a growing network model where our general method is not efficient .",
    "if @xmath246 , a case examined by onody and decastro  @xcite , the general method can be applied but will not be efficient .",
    "the problem is that lower bounds on connection probabilities are typically extremely small and the algorithm will connect only a few nodes in each parallel step .",
    "we are currently investigating methods to efficiently parallelize @xmath246 networks .",
    "the fact that preferential attachment growing networks have no more than logarithmic depth indicates that they are not particularly complex objects .",
    "on the other hand , very complex biological and social systems generate networks with similar properties .",
    "if growing network models accurately describe the networks generated by these systems one most conclude that the complexity and history dependence of the systems generating the networks are not manifest in the networks themselves .",
    "an alternative possibility is that the real networks are themselves complex but that growing network models lack some essential statistical properties of the real networks ."
  ],
  "abstract_text": [
    "<S> the parallel computational complexity or depth of growing network models is investigated . </S>",
    "<S> the networks considered are generated by preferential attachment rules where the probability of attaching a new node to an existing node is given by a power , @xmath0 of the connectivity of the existing node . </S>",
    "<S> algorithms for generating growing networks very quickly in parallel are described and studied . </S>",
    "<S> the sublinear and superlinear cases require distinct algorithms . as a result </S>",
    "<S> , there is a discontinuous transition in the parallel complexity of sampling these networks corresponding to the discontinuous structural transition at @xmath1 , where the networks become scale free . for @xmath2 networks can be generated in constant time while for @xmath3 logarithmic parallel time is required . </S>",
    "<S> the results show that these networks have little depth and embody very little history dependence despite being defined by sequential growth rules . </S>"
  ]
}