{
  "article_text": [
    "tail - biting trellises are perhaps the simplest instances of decoding graphs with cycles .",
    "a tail - biting trellis has a tanner graph  @xcite with a single cycle and usually approximate algorithms are used for decoding , as exact algorithms are believed to be too expensive .",
    "these approximate algorithms iterate around the trellis until either convergence is reached , or for a preset number of cycles .",
    "to the best of our knowledge , no _ exact _ decoding algorithms other than the brute force algorithm have been proposed so far for the general case , though there are several _ approximate _",
    "algorithms for maximum - likelihood decoding  @xcite and exact algorithms for bounded distance decoding  @xcite .",
    "the problem of maximum a - posteriori probability(map ) decoding is not addressed here .",
    "we propose an _",
    "exact _ recursive algorithm , which exhibits very good average case behavior .",
    "the algorithm exploits the fact that a linear tail - biting trellis can be viewed as a coset decomposition of the group corresponding to the linear code with respect to a specific subgroup and is based on the @xmath0 algorithm  @xcite .",
    "we also propose two approximate variants that always converge , and observe their performance on tail - biting trellises for the ( 24,12 ) extended golay code and two convolutional codes of rate 1/2 and memory of 4 and 6 respectively .",
    "the performance of the first approximate variant is indistinguishable from that of the exact algorithm in terms of bit error rate for the two convolutional codes , and it is guaranteed to update each node in the tail - biting trellis at most twice i.e it performs a computation equivalent to at most two rounds on the trellis .",
    "section  [ related ] briefly mentions related work .",
    "section  [ sec : background ] provides some background .",
    "section  [ algo ] describes the algorithm , while section  [ analysis ] analyses the algorithm .",
    "section  [ approx ] describes the approximate algorithm and provides an analysis for its good performance .",
    "section  [ simulations ] reports the results of simulations on an awgn channel and section  [ conclusion ] concludes the paper .",
    "aji et al .  @xcite have shown that iterative maximum - likelihood ( ml ) decoding on tail - biting trellises will asymptotically converge to exact maximum likelihood decoding for certain codes .",
    "they provide experimental evidence that practically ml decoding is achieved for the @xmath1 hamming code with five rounds of the tail - biting trellis .",
    "the presence of _ pseudocodewords _ sometimes results in sub - optimal decoding and it is also possible to have situations where the iterative message passing algorithm does not converge .",
    "several maximum likelihood decoding algorithms on tail - biting trellises have been proposed without a theoretical analysis  @xcite , but with good experimental results .",
    "most of these are sub - optimal algorithms in that they may not produce the exact maximum - likelihood result on termination .",
    "anderson and hladik  @xcite have given an algorithm that is optimal for bounded distance decoding .",
    "the @xmath0 algorithm  @xcite has been used for maximum likelihood soft decision decoding on conventional trellises for block codes  @xcite . in  @xcite han",
    "propose the use of the @xmath0 algorithm for ml decoding of block codes on their conventional trellises and report significant experimental gains in decoding complexity for signal to noise ratios ranging from 5 db to 8 db .",
    "this algorithm has been analyzed in @xcite and shown to be efficient for many practical communication systems . in @xcite",
    "a modified algorithm is proposed which searches through error patterns instead of codewords and similar gains are reported .",
    "heuristic search algorithms are proposed in @xcite which combine previously proposed algorithms and are able to outperform other practical decoders . a tutorial paper on the application of the @xmath0 algorithm to soft decision decoding appears in @xcite . sorokine and kschischang  @xcite propose a metric called the variable bias term that is used in an @xmath0 algorithm , which has low computational complexity .",
    "aguado and farrell @xcite discuss modified sequential algorithms on conventional trellises for block codes , which offer reduced complexity in comparison with the original stack algorithm @xcite for sequential decoding .",
    "han et al .",
    "@xcite propose a trellis based ml soft - decision decoder for convolutional codes which uses a stack and a metric that ensures ml decoding .",
    "we first present some background on tail - biting trellises .",
    "tail - biting trellises for convolutional codes were introduced in @xcite .",
    "minimal tail - biting trellises for block codes have been discussed in  @xcite .    a _ tail - biting trellis _ @xmath2 of depth",
    "@xmath3 is an edge - labeled directed graph with the property that the set @xmath4 can be partitioned into @xmath3 vertex classes @xmath5 such that every edge in @xmath6 is labeled with a symbol from the alphabet @xmath7 , and begins at a vertex of @xmath8 and ends at a vertex of @xmath9 , for some @xmath10 .",
    "we identify @xmath11 the set of time indices with @xmath12 , the residue classes of integers modulo @xmath3 .",
    "an interval of indices @xmath13 $ ] represents the sequence @xmath14 if @xmath15 , and the sequence @xmath16 if @xmath17 .",
    "every cycle in @xmath6 starting at a vertex of @xmath18 defines a vector @xmath19 which is an _ edge - label sequence_. we assume that every vertex and every edge in the tail - biting trellis lies on some cycle , that is the tail - biting trellises we are dealing with are _ reduced _ @xcite .",
    "the trellis @xmath6 represents a block code @xmath20 over @xmath7 if the set of all edge - label sequences in @xmath6 is equal to @xmath20 .",
    "let @xmath21 denote the code represented by a trellis @xmath6 .",
    "a linear tail - biting trellis , for an @xmath22 linear block code @xmath20 over @xmath7 can be constructed as a _ trellis product _",
    "@xcite of the representation of the individual trellises ( called _ elementary _ trellises ) corresponding to each of the @xmath23 rows of the generator matrix @xmath24 for @xmath20  @xcite .",
    "let @xmath25 and @xmath26 be the component trellises .",
    "the set of vertices @xmath27 of the product trellis @xmath28 at time index @xmath29 , is just the cartesian product of the vertices of the component trellises .",
    "thus @xmath30= @xmath31 .",
    "consider @xmath32 , and interpret an element @xmath33 in this product , where @xmath34 are vertices and @xmath35 edge labels , as the edge @xmath36 where @xmath37 denotes addition in the field @xmath7 . if we define the @xmath38 section as the set of edges connecting the vertices at time index @xmath29 to those at time index @xmath39 , then the edge count in the @xmath38 section is the product of the edge counts in the @xmath38 section of the individual trellises .",
    "let @xmath40 be the rows of a generator matrix @xmath24 for the linear code @xmath20 .",
    "each vector @xmath41 generates a one - dimensional subcode of @xmath20 , which we denote by @xmath42 .",
    "therefore @xmath43 , and the trellis representing @xmath20 is given by @xmath44 , where @xmath45 is the trellis for @xmath46 .",
    "to specify the component trellises in the trellis product above , we will need to introduce the notions of linear@xcite and circular spans@xcite and elementary trellises  @xcite .",
    "given a codeword @xmath47 , the _ linear span _ of @xmath48 , is the smallest interval @xmath13 \\in i= \\{1,2,\\ldots n\\ } , i\\leq j$ ] which contains all the non - zero positions of @xmath48 .",
    "circular span _ has exactly the same definition with @xmath17 .",
    "note that for a given vector , the linear span is unique , but circular spans are not they depend on the runs of consecutive zeros chosen for the complement of the span with respect to the index set @xmath49 . for a vector @xmath50 over the field @xmath7 and a specified span @xmath13 $ ]",
    ", there is a unique _ linear elementary trellis _ representing @xmath51  @xcite .",
    "this trellis has @xmath52 vertices at time indices @xmath29 to @xmath53 mod @xmath3 , and a single vertex at other positions . consequently ,",
    "@xmath45 in the trellis product mentioned earlier , is the elementary trellis representing @xmath42 for some choice of span ( either linear or circular ) .",
    "koetter and vardy  @xcite have shown that any linear trellis , conventional or tail - biting can be constructed from a generator matrix whose rows can be partitioned into two sets , those which have linear span , and those taken to have circular span . the trellis for the code is formed as a product of the elementary trellises corresponding to these rows .",
    "we will represent such a generator matrix as @xmath54 $ ] , where @xmath55 is the submatrix consisting of rows with linear span , and @xmath56 the submatrix of rows with circular span .",
    "[ def : zerorun ] for a vector @xmath57 of circular span @xmath58 $ ] in @xmath56 , the interval @xmath59 mod @xmath60 mod @xmath61 $ ] is called the _",
    "zero run _ of the vector .",
    "the path in the trellis corresponding to this vector shares all states at time indices in the zero run with the path corresponding to the all - zero codeword in the product trellis .",
    "+ for example , consider the codeword @xmath62 with circular span @xmath63 $ ] .",
    "this has zero run @xmath64 $ ] .",
    "the elementary trellis corresponding to this vector has state cardinality profile @xmath65 .",
    "( recall the time indices are numbered from 0 to @xmath66 where @xmath3 is the length of the code ) .    as an example we display a tail - biting trellis for a binary @xmath67 hamming code .",
    "though this is not a minimal trellis for the code , it serves to illustrate some of the definitions above .",
    "the spans of the rows are shown alongside the rows .",
    "all spans @xmath13 $ ] with @xmath29 greater than @xmath68 are circular spans .",
    "[ ex : overlay2 ] let @xmath20 be a @xmath69 hamming code a with a product generator matrix @xmath70 defined as @xmath71 \\begin{array}{c } \\lbrack 1,6 \\rbrack \\\\",
    "\\lbrack 3,7 \\rbrack \\\\",
    "\\lbrack 6,2 \\rbrack \\\\",
    "\\lbrack 7,4 \\rbrack \\end{array}\\ ] ]    the product tail - biting trellis for this generator matrix is given in figure  [ fig : hamming - overlay ] .",
    "a subtrellis of a tailbiting trellis consists of a start node at time index zero and all edges and nodes which can be traversed in any cycle of the graph that begins and ends at this start node .",
    "let @xmath72 denote the minimum conventional trellis for the code generated by @xmath55 .",
    "clearly @xmath72 is a subtrellis of the tail - biting trellis .",
    "if @xmath73 is the number of rows of @xmath24 with linear span and @xmath74 the number of rows of circular span , the tail - biting trellis constructed using the product construction will have @xmath75 start states .",
    "each such start state defines a subtrellis whose codewords form a coset of the subcode corresponding to the subtrellis containing the all 0 codeword .",
    "the coset structure is well known and has been reported in @xcite .",
    "each vector in the circular span can be considered to be a coset leader .",
    "the set of zero runs , of the coset leaders determines the structure of the tail - biting trellis in the following way .",
    "if a coset leader has zero run @xmath13 $ ] then the subtrellis associated with that coset shares all states at time indices in the interval @xmath13 $ ] with the subtrellis corresponding to the subcode defined by vectors of linear span .",
    "further , we recall , the _ coset leader _ shares all states in the interval @xmath13 $ ] with the states corresponding to the all - zero codeword .",
    "the four subtrellises of the tail - biting trellis of figure  [ fig : hamming - overlay ] are shown in figures  [ fig : subtrellis0 ] ,  [ fig : subtrellis1 ] ,  [ fig : subtrellis2]and  [ fig : subtrellis3 ] along with their associated coset leaders and zero runs .",
    "if subtrellises @xmath76 and @xmath26 share states from time indices @xmath29 to @xmath68 then the interval @xmath13 $ ] is called the _ merging _ interval of @xmath25 and @xmath26 .",
    "it is easy to see that two subtrellises do not share any states outside their merging interval .",
    "+ a tail - biting trellis is said to satisfy the _ intersection property _ if the intersection of all the zero runs of the members of @xmath56 is non - empty .",
    "the tail - biting trellis for the hamming code given in example  [ ex : overlay2 ] satisfies the intersection property as the interval @xmath77 $ ] is contained in the intersection of all the zero runs of @xmath56 .",
    "the decoding algorithm proposed here is different from the sub - optimal algorithms mentioned in section  [ related ] , that go round and round the tail - biting trellis updating all the nodes of the trellis in every round .",
    "it makes one round of the tail - biting trellis and subsequently judiciously uses the information gathered to further update as few nodes as it can before it closes in on the most likely codeword .",
    "our algorithm has two phases . in the first phase a viterbi algorithm",
    "is performed on the tail - biting trellis .",
    "this phase performs computations at _ every _ node of the tail - biting trellis . in the second phase however , _ only one path _",
    "is tracked at a time , this being the most likely path .",
    "the initial estimate of the most likely path is obtained from the first phase .",
    "this path is present in some subtrellis and is followed until the algorithm decides that some other path ( perhaps in another subtrellis ) looks more promising based on some metric .",
    "when such a situation is encountered , computation on this path is suspended and the more promising path is taken up . while this strategy at first glance looks like the stack algorithm @xcite for decoding convolutional codes , it differs from it because it has the property that it _ always _ delivers the optimal path as the metric used satisfies the property required by the @xmath0 algorithm .",
    "( we will prove this property formally ) .    for purposes of decoding we use the unrolled version of the trellis with start states @xmath78 and final states @xmath79 where @xmath73 is the number of subtrellises .",
    "an @xmath80 path is a path from start vertex @xmath81 to final vertex @xmath82 , and is consequently a codeword path in trellis @xmath45 , whereas an @xmath83 path for @xmath84 is a non codeword path as it starts in subtrellis @xmath45 and ends in subtrellis @xmath85 . for purposes of our discussion we term the label sequence along such a path as a _",
    "semicodeword_.    maximum - likelihood decoding for a tail - biting trellis is equivalent to finding the codeword closest to the received sequence measured in terms of a soft decision metric .",
    "assume that the channel is modeled as an additive white noise gaussian(awgn ) channel and that antipodal signaling is used for communication .",
    "a binary code digit 0 is mapped into @xmath86 and a 1 is mapped into @xmath87 where @xmath88 is the signal energy per bit entering the channel . for a discrete additive white gaussian noise(awgn ) channel",
    "we have @xmath89 where @xmath90 is the received signal at time @xmath91 , @xmath92 is the transmitted signal and @xmath93 is the value of a white gaussian noise random variable with variance @xmath94 where @xmath95 is the noise spectral density . without loss of generality we can assume that @xmath96 .",
    "the signal - to - noise ratio or snr is the quantity @xmath97 .",
    "the decoder uses the received vector @xmath98 to determine which codeword was transmitted .",
    "it forms an estimate @xmath99 of the codeword @xmath100 that was transmitted .",
    "a decoding error occurs if @xmath101 .",
    "the maximum likelihood decoding rule is to decode the received sequence @xmath98 to codeword @xmath102 whenever @xmath103 for all @xmath104 , where @xmath105 is the conditional probability of @xmath98 given @xmath102 .",
    "let @xmath106 be the signal vector corresponding to the codeword @xmath100 .. if @xmath107 is the euclidean distance between @xmath108 and @xmath98 , then the maximum likelihood decoding rule for decoding binary linear block codes transmitted over the awgn channel using antipodal signaling is to decode @xmath98 into codeword @xmath102 whenever @xmath109 for all @xmath110 .",
    "the decoding algorithm is thus cast as a shortest path problem in which each path is associated with a _",
    "metric _ , and the problem is to find a codeword path with minimum metric .",
    "the @xmath0 algorithm is used to cut down the search space .",
    "it does so by using a node metric which is the sum of the length of the shortest path from the source to a node and an _ underestimate _ of the length of the shortest path from the node to the goal node to guide the search .",
    "as mentioned earlier , only one path is explored at a time and the algorithm derives it s advantage from the fact that if the estimates used are close to the actual values then the search space that yields the optimal path is greatly reduced .",
    "we give the algorithm below .",
    "the algorithm maintains two sets of vertices , @xmath111 and @xmath112 .",
    "the set @xmath111 is the set of _ closed _ nodes and represents nodes to which the shortest paths have been finalized . at any iteration ,",
    "the set @xmath112 is the set of candidate nodes the best of which will be closed in the succeeding iteration .",
    "these are called the _ open _ or _ visited _ nodes .",
    "an operation of _ expanding _ a node consists of the following three steps : + 1 .",
    "getting all the immediate successors of the node .",
    "checking for each immediate successor if this successor has been visited before .",
    "if the successor has been visited then _ updating _ the minimum cost path to the successor by taking the minimum of the cost of the previous path and the cost of this one .",
    "all the expanded nodes are put into the closed set and the visited nodes are put into the open set . when the goal node is reached an optimal path has been found .",
    "+ the following is a formal description of the algorithm .",
    "line 1 performs the initialization of the sets and the costs and paths .",
    "line 3 selects the vertex to be expanded .",
    "line 4 puts the selected vertex into the closed set and deletes it from the open set .",
    "line 5 detects if the algorithm has completed ; lines 6 through 9 perform an expansion of a node .",
    "they update the cost of an immediate successor as well as the best path to that successor and mark the successor as visited by putting it into the open set . +",
    "* algorithm @xmath113 * + * input :* a trellis @xmath114 where @xmath4 is the set of vertices , @xmath115 is the set of edges and @xmath116 for edge @xmath117 in @xmath115 , a source vertex @xmath118 and a destination vertex @xmath119 , and an estimate @xmath120 for the shortest path from @xmath121 to @xmath119 for each vertex @xmath122 . +",
    "* output :* the shortest path from @xmath118 to @xmath119 .",
    "+ / * @xmath123 is the cost of the current shortest path from @xmath118 to @xmath121 and @xmath124 is a current shortest path from @xmath118 to @xmath121 * / + _ begin _ + @xmath125 ; + _ repeat _ + .",
    "let u be the vertex in @xmath112 with minimum value of @xmath126 .",
    "@xmath127 ; + . _ if _ @xmath128 _ then _ _ return _ @xmath129 ; + .",
    "_ for _ each @xmath130 _ do _",
    "_ if _ @xmath131 _ then _ + . _",
    "begin _ + .",
    "@xmath132 ; + _ if _ @xmath133 _ then _ append @xmath117 to @xmath124 to give @xmath134 ; + .",
    "@xmath135 ; + .",
    "_ end _ + .",
    "_ forever _ + _ end _ + the @xmath0 algorithm is guaranteed to output the shortest path if the following two conditions hold : let @xmath136 be the shortest path length from @xmath121 to @xmath119 in @xmath6 .",
    "let @xmath120 be any lower bound such that @xmath137 , and such that @xmath120 satisfies the following inequality , i.e , for @xmath121 a predecessor of @xmath138 , @xmath139 .",
    "if both the above conditions are satisfied , then the algorithm @xmath113 , on termination , is guaranteed to output a shortest path from @xmath118 to @xmath119 .",
    "+ the algorithm proposed here is a variant of the @xmath0 algorithm , which at any given instant , is executing an @xmath0 algorithm on exactly one of the subtrellises , with perhaps suspended executions of the algorithm on a set of other subtrellises .",
    "the subtrellis on which the algorithm is curently executing , appears the best in its potential to deliver the minimal cost path .",
    "since the algorithm is not straightforward , we first give an informal explanation of how it works .",
    "the algorithm has two phases .",
    "the first phase performs a viterbi algorithm on the tail - biting trellis and examines surviving paths , called _",
    "survivors _ here , at all states of the tail - biting trellis .",
    "the first phase is described below .",
    "let @xmath140 denote the initial vertex of edge @xmath141 .",
    "let @xmath142 denote the vertex entered via edge @xmath141 .",
    "+ * algorithm first phase * + * input : * an unrolled tail - biting trellis with start nodes @xmath143 , final nodes @xmath144 for the @xmath73 subtrellises , and an edge cost @xmath145 associated with each edge @xmath141 of the tail - biting trellis . + * output : * the cost @xmath146 of a least cost path to each node @xmath138 from any start node .",
    "+  * begin *   +  * for *   each node @xmath138 in the tail - biting trellis initialize @xmath147 ; +  * for *   @xmath29 = 1 to @xmath3  * do *   +  * for *   each vertex @xmath138 at time index @xmath29  * do *   + @xmath148 +  * for *   @xmath68 = 1 to @xmath73  * do *   + @xmath149 +  * end *     at the end of the first phase therefore we have a set of survivors at final nodes @xmath144 some of which may not correspond to codewords . the costs of these paths are taken as initial estimates for the second phase .",
    "we first informally describe the second phase below and then describe a recursive version in more detail . + * algorithm second phase * + * input : * the initial metrics @xmath150 computed in the first phase for the @xmath73 subtrellises and the costs @xmath146 of the survivors at all vertices @xmath138 of the tail - biting trellis . + * output : * the maximum likelihood path .",
    "+ sort the metrics @xmath150 in increasing order ; if the lowest metric is that of a codeword path then output that path as the ml path and return , else go to next step .",
    "+ @xmath151 = cost of lowest codeword survivor if there is one , otherwise , otherwise @xmath152 .",
    "+ if any of the metrics @xmath153 is greater than @xmath151 then discard subtrellis @xmath85 from the set of participants in the second phase .",
    "+ @xmath154-@xmath155 = set of all non - discarded trellises with non - codeword survivors ; + create a set @xmath112 of the initial vertices along with metrics , of all residual trellises , and let the start node @xmath118 of the @xmath0 algorithm be the start node of the residual trellis with a minimum initial metric ; + execute lines 2 to 11 of algorithm @xmath0 modifying statement in line 11 as * if * @xmath156 * then * @xmath157 and statement @xmath158 in line 5 by @xmath159 + if the open set @xmath160 becomes empty before a final node is reached , then the codeword with cost @xmath151 is output as the decoder s estimate of the transmitted codeword . + the algorithm above is therefore different from the standard @xmath0 algorithm in the following ways :    1 .",
    "it may switch from one subtrellis to another depending on which subtrellis the node with minimum metric is located in .",
    "each shared node in a subtrellis is regarded as a distinct node for purposes of the algorithm .",
    "thus there will be as many distinct copies of a given node of the tail - biting trellis as there are residual subtrellises sharing that node .",
    "3 .   before adding an element to the open set",
    ", we check to see that its metric is less than that of the best codeword survivor stored in @xmath151 . in the traditional algorithm",
    "there is no such check .",
    "if the open set @xmath112 becomes empty before a final node is reached then the codeword with cost @xmath151 is output .",
    "we need to define the estimate @xmath120 in line 3 of algorithm @xmath0 . recall that this has to be an _ underestimate _ of the path length from node @xmath121 to the final node if the ml path is to be output .",
    "the estimate we use for node @xmath138 in subtrellis @xmath85 is the difference between the _ initial _",
    "metric for trellis @xmath85 computed in the first phase and the cost of the _ survivor _ at node @xmath138 in the first phase .",
    "we will prove later that this is _ indeed _ an underestimate and therefore guarantees that the ml path is output on termination .",
    "we implement the open set @xmath112 as a _ heap _  @xcite .",
    "this ensures that the minimum element can be retrieved in _ constant _ time and that whenever an element is _ inserted _ into the heap , restructuring it in order to preserve the property of constant time access to the minimum element , has complexity logarithmic in the size of the heap .",
    "+ we now describe the second phase of the algorithm more formally beginning with the notation used",
    "variable @xmath161 is the estimate obtained for the shortest path from the start to the final node in subtrellis @xmath45 in the first phase .",
    "variable @xmath162 is the estimate for the shortest path from node @xmath138 to node @xmath82 in subtrellis @xmath45 which is computed when an update occurs at node @xmath138 .",
    "this is the difference between the initial estimate at @xmath81 in trellis @xmath45 , and the cost of the survivor at node @xmath138 in the first phase .",
    "variable @xmath163 is a pointer to a structure representing a node in the trellis ; @xmath164 is the state , @xmath165 indicates which trellis that state belongs to ; @xmath166 stores the current metric which is the sum of the length of the path from the start node in trellis @xmath165 to @xmath167 and the estimate of the path length from @xmath167 to the final node in that trellis .",
    "variable @xmath168 is a pointer to the successor of a node ; @xmath169 and @xmath170 have meanings that can be deduced from 3 above .",
    "variable @xmath171 refers to the time index and takes on values from 0 to @xmath66 where @xmath3 is the length of the code .",
    "variable @xmath172 is a unique number associated with a subtrellis .",
    "function @xmath173 inserts a node into the heap ; function @xmath174 extracts the node with minimum value of metric from the heap .",
    "function @xmath175 returns a boolean value which is true if the heap is empty and false otherwise .",
    "variable @xmath176 represents the actual cost of the path from the start state of a subtrellis that ends at the node @xmath177 .",
    "variable @xmath178 represents the cost of the survivor in the first phase at that node .",
    "variable @xmath179 is the updated metric at a successor of a node in a trellis using function @xmath180 , which is called when that node is closed using @xmath181 .",
    "variable @xmath182 is the sequence of nodes representing the winning path at the state @xmath183 .",
    "variable @xmath151 is the cost of the lowest cost @xmath80 path in the first phase .",
    "variable @xmath184 is used to detect whether the winning path is the one identified in the first or second phase .",
    "it is initialized to 0 .",
    "if the heap becomes empty without reaching a final node in the second phase then the lowest cost @xmath80 path is output as flag remains 0 .",
    "else the path that first reaches a final node in the second phase is the winning path .",
    "* function *  @xmath185 + / * begin with @xmath186 residual trellises whose metrics have been sorted in increasing order , and with variable @xmath151 which stores the metric of the best codeword survivor*/ +  * begin *   + / * first create a heap @xmath187 with these @xmath186 metrics ; each element of the heap is a record containing the trellis number , the node , the time index , and the metric*/ +  * for *   @xmath188  * to *   @xmath186  * do *   + @xmath189 +  * endfor *   + @xmath190 ; +  * while *   @xmath191  * false *   * and *   @xmath192  * do *   + @xmath193 + @xmath194 /*add @xmath167 to the set of closed nodes*/ + @xmath195 / * expand @xmath167*/ +  * endwhile *   +  * if *   @xmath196  * then *   output the codeword with metric @xmath151 ;  * return *   +  * end *   +  * function *  @xmath197 + 1 .",
    "* begin *   + 2 .  * if *   @xmath198  * then *   @xmath199 ; output @xmath182 ;  * return *   + 3 .",
    "* else *   + 4 .  * for *   each successor @xmath168 of @xmath183  * do *   + 5 .",
    "@xmath200 + 6 .",
    "* if *   @xmath201  * then *  @xmath202 + 7 .",
    "@xmath203 + 8 .",
    "* else *   + 9 .  *",
    "if *   @xmath204 + 10 .",
    "* then *  @xmath205 + 11 .  * endif *   + 12 .  * endif *   + 13 .  * endfor *   + 14 .  * endif *   + 15 .  *",
    "end *   +  * function *  @xmath206 ; +  * begin *   + @xmath207 + @xmath208 +  * if *   @xmath209  * then *   + @xmath210 / * update the current shortest path to @xmath211*/ + @xmath212 / * update the cost of the current shortest path to node 2*/ + @xmath213/ * update the metric at @xmath211 ; @xmath214 is the cost of the survivor in the first phase*/ +  * endif *   +  * end *",
    "we first prove that on termination the algorithm always outputs the optimal path    each survivor at a node @xmath121 has a cost which is a lower bound on the cost of the least cost path from @xmath215 to @xmath121 in an @xmath216 path passing through @xmath121 .",
    "assume that @xmath121 is an arbitrary node on an @xmath216 path and that path @xmath217 is the survivor at @xmath121 in the first phase .",
    "there are two cases .",
    "either @xmath217 is a path from @xmath215 to @xmath121 or @xmath217 is a path from @xmath218 to @xmath121 , @xmath219 .",
    "if the latter is the case , then the cost of @xmath217 is less than the cost of the path from @xmath215 to @xmath121 ; hence the cost of the survivor at @xmath121 is a lower bound on the cost of the least cost path from @xmath215 to @xmath121 .",
    "[ properties ] the quantity @xmath220 defined in the algorithm satisfies the following two properties :    1 .",
    "@xmath221 2 .",
    "@xmath222 where @xmath117 is an edge .    1 .",
    "@xmath223 + also @xmath224 , from which the result follows .",
    "2 .   to prove : @xmath225 + lhs @xmath226 + @xmath227 + if survivor at @xmath138 is survivor at @xmath121 concatenated with edge @xmath117 , then + lhs @xmath228 + @xmath229 + on the other hand if survivor at @xmath138 is not a continuation of the survivor at @xmath121 , + @xmath230 + @xmath231 + or , @xmath232 + or , @xmath233 + therefore , @xmath225    lemma  [ properties ] , and the fact that all estimates on trellises on which execution is suspended are underestimates , assures us that _ if the final node is reached in any subtrellis then this is indeed the shortest path in the tail - biting trellis or in other words the ml codeword .",
    "we first make a few observations about the algorithm . during any point in the second phase",
    ", the algorithm is exploring some path in a candidate subtrellis called the _",
    "current _ trellis even though it may do so in discontinuous steps .",
    "this path is called the _ current path _ in that subtrellis .",
    "the metric which it uses to decide whether to continue on the current path on the current trellis , say @xmath45 , or forsake it in favour of another path either in the current trellis or on another candidate trellis is initially @xmath161 .",
    "we have the following lemma specifying how the metric changes along the path .    [ update ] during the second phase ,",
    "if the current path updates a node @xmath138 using function @xmath180 , where the survivor in the first phase was not in the current subtrellis then the metric becomes @xmath234 where @xmath235 is the difference between the cost of the least cost path ending at @xmath138 in the current trellis and the survivor at @xmath138 during the first pass .",
    "we know that @xmath236 and @xmath237 the metric is just the sum of the two lefthand sides of the previous two equations . thus if the survivor is the current path then @xmath238 and the lemma follows .",
    "if the survivor is not the current path then the metric is increased by the difference between the length of the current path up to @xmath138 and the survivor at @xmath138 .",
    "a critical node on a path in a subtrellis is one at which the metric for a subtrellis reaches its final value(i.e .",
    "the actual cost of the path ) .",
    "[ lem : critical ] during the second phase , once a critical node is closed in a subtrellis , the algorithm goes on to reach the final node in that subtrellis without switching trellises , and outputs an ml path .",
    "the critical node was closed because it had the minimum metric .",
    "the metric represents the _ actual _ cost of the path at a critical node .",
    "this is no greater than the metrics of all other visited nodes which are _ underestimates _ of the costs of all other paths .",
    "thus once a critical node is closed , the metric does not change along the continuation of this winning path to the final node .",
    "therefore line 6 of function @xmath181 is always true at some successor andno trellis switching takes place .",
    "the following properties hold for the metric .",
    "let @xmath239 denote the metric in subtrellis @xmath29 at node @xmath240 :    [ predecessor ] let an @xmath241 path be the winner at @xmath82 in the first phase and let it win over an @xmath80 path at node @xmath242",
    ". then @xmath243 and @xmath244 for any proper predecessor @xmath245 of @xmath242 .",
    "since the @xmath241 path was the overall winner at @xmath82 its length will be the metric at the start node of trellis @xmath45 and by lemma  [ update ] , the metric on the path in @xmath45 will rise by the appropriate amounts @xmath246 at each node @xmath68 where the path was overtaken by a path from some other subtrellis .",
    "when it reaches node @xmath242 , which is a critical node , the metric will reach its final value , namely @xmath247 . since @xmath245 is a predecessor of @xmath242 and the metric _ rises _ at @xmath242 , @xmath244 .    for each shortest path in a subtrellis @xmath29 ,",
    "the nodes where it was overtaken by paths originating at the start nodes of other subtrellises in the first phase , are the nodes where its metric will rise during the second phase .",
    "these nodes are called _ rising points_. thus the node at the final rising point in a subtrellis is the critical node .",
    "[ share ] let subtrellises @xmath45 and @xmath85 share a node @xmath240 and between them , let @xmath45 be the first to close the node in the second phase",
    ". then @xmath248 .    since @xmath45 is the first to close the node it closes it either before @xmath85 was first opened or after .",
    "if the former was the case , then @xmath249 . if the latter was the case the least current metric of @xmath85 is greater than the metric @xmath239 of @xmath45 from which the result follows as the metric can only increase .",
    "[ segment ] for nodes @xmath242 and @xmath245 let @xmath250 be a path segment in the merging interval of @xmath45 and @xmath85 and let @xmath251",
    ". then @xmath252 .",
    "since at @xmath242 , @xmath251 and thereafter all updates to the metrics in trellises @xmath45 and @xmath85 until node @xmath245 is reached will be identical as the survivors at those node in the first phase will be the same for both trellises @xmath45 and @xmath85 , @xmath252 .",
    "we next show that any path from an arbitrary start node to any final node represents a vector in a vector space . for the sake of simplicity",
    "we restrict our arguments to binary codes .",
    "[ vectorspace ] the set of all labels from an arbitrary start node to any final node is a vector space .",
    "assume that each of the @xmath74 vectors in the submatrix @xmath56 of the generator matrix is of the form @xmath253 $ ] where @xmath254 has circular span @xmath255 $ ] , where @xmath256 stands for the sequence of symbols from the first , up to and including the @xmath257 symbol and is called the _",
    "head _ , and @xmath258 stands for the sequence of symbols from positions @xmath68 to @xmath66 and is called the _",
    "tail _ ; @xmath259 represents the run of zero symbols in between the head and the tail , spanning the appropriate number of codeword indices .",
    "( this run may be empty if @xmath260 . )",
    "let @xmath261 be the vectors of @xmath56 .",
    "then the matrix @xmath262 defined as @xmath263 $ ] , where @xmath264 consists of @xmath265 rows of the form @xmath266,[{{\\mathbf 0}},{{\\mathbf t_i } } ] , 1\\leq i \\leq c$ ] , ( where the number of zeroes in @xmath259 makes up a total of @xmath3 elements for the row ) generates the set of labels of all paths from any start node to any final node .",
    "this set has @xmath267 elements .",
    "this can be verified from the product construction .",
    "the set of elements of this vector space consists of _ semicodewords _ and codewords .",
    "each semicodeword is the label of an @xmath83 path @xmath84 .",
    "the matrix @xmath262 corrresponding to the matrix @xmath70 for the hamming ( 7,4 ) code of example  [ ex : overlay2 ] is displayed below .",
    "+ @xmath268\\ ] ]    it can be observed that the semicodeword 1100110 formed by adding rows 1 and 3 of @xmath262 traces a path from start vertex @xmath269 to final vertex @xmath270 in the tail - biting trellis of figure  [ fig : hamming - overlay ] .    [ not - close ] the algorithm will not close any node whose metric exceeds the cost of the ml path .",
    "the lemma follows from lines 6 and 7 of function @xmath181 and the observation that calling function @xmath181 on a node is equivalent to closing the node .",
    "the test ensures that only nodes with metric value less than the current metric are closed . since the current metric is a lower bound on the cost of the ml path the lemma follows .",
    "we use a result of tendolkar and hartmann  @xcite stated below .",
    "[ tendolkar ] let @xmath187 be the parity check matrix of the code and let a codeword @xmath100 be transmitted as a signal vector @xmath106 .",
    "let the binary quantization of the received vector @xmath271 be denoted by @xmath272 .",
    "let @xmath273 and @xmath274 .",
    "then ml decoding is achieved by decoding a received vector @xmath98 into the codeword @xmath275 where @xmath276 is a binary vector that satisfies @xmath277 and has the property that if @xmath278 is any other binary vector such that @xmath279 then @xmath280 where @xmath281 is the inner product .",
    "a direct consequence of lemma  [ tendolkar ] is the following result .",
    "[ ml - codeword ] if the all - zero codeword is the ml codeword for an error pattern @xmath276 then@xmath282 for any non - zero codeword @xmath48 .",
    "since the space explored by the algorithm , namely the space of semicodewords and codewords is a vector space , we can analyse the algorithm assuming that the ml codeword is the all 0 codeword .",
    "[ semicodewords ] assume the all 0 codeword is the ml codeword . let @xmath276 be the binary quantization of the received vector .",
    "for the error pattern @xmath276 the second phase of the decoding algorithm will close the start nodes of only those subtrellises whose initial metric corresponds to a semicodeword @xmath283 satisfying @xmath284    we first note that at the start of the second phase the metrics at the start nodes of all residual subtrellises correspond to the costs of vectors in the vector space of codewords and semicodewords , i.e. the vector space defined by the generator matrix @xmath262 . from lemma  [ vectorspace ] we have @xmath285 where @xmath286 is the parity check matrix corresponding to the matrix @xmath262 . from lemma  [ tendolkar ] maximum likelihood decoding on the set of semicodewords",
    "will initially choose @xmath283 , a semicodeword , which satisfies the inequality of the lemma and the algorithm will close the start node of the subtrellis with that initial metric . as the algorithm proceeds with updating metrics it may close start nodes of other subtrellises .",
    "however by lemma  [ not - close ] it will never close the start node of any trellis @xmath85 whose initial metric exceeds that of the ml codeword , which implies that the all-0 codeword is more likely than the semicodeword survivor in @xmath85 , thus implying equation  [ equ : weights ] .",
    "the properties of the algorithm proved in this section will be used to explain the good performance of the approximate algorithms described in the following section .",
    "recall that each shared node is treated as a distinct node in the second phase of the algorithm .",
    "we now propose an approximate variant of the exact algorithm which closes a shared node _ at most once _ in the second phase .",
    "we term this algorithm @xmath287 .",
    "+ assume we replace line 5 of function @xmath181 by +  * if *   @xmath288  * then *   @xmath200  * else *   continue + what this ensures is that each shared node is closed _ at most once _ , that is , by at most one subtrellis , in the second phase .",
    "therefore the total number of viterbi updates in the first phase and expansions in the second phases is at most @xmath289 where @xmath4 is the number of states in the tail - biting trellis . since a node",
    "is closed by at most one subtrellis , it is conceivable that a shared node that is on the ml path is closed by a subtrellis that does not contain the ml codeword . in such a case the result produced will not be the ml codeword .",
    "we now analyse the conditions under which this happens .",
    "the symbols are the same as those defined for lemma  [ semicodewords ] .",
    "the following theorem gives the conditions under which the approximate algorithm produces a non - ml output .",
    "recall that the intersection property requires that the intersection of all the zero runs of vectors in @xmath264 be non - empty .",
    "[ explanation ] if the tail - biting trellis satisfies the intersection property , the approximate algorithm produces a non - ml output for error patterns @xmath276 satisfying equation  [ equ : weights ] whenever @xmath283 is a semicodeword which is formed as a linear combination of rows of @xmath262 that contain at least one non - zero multiple of a vector from @xmath55 .",
    "let us assume that the all - zero codeword is the ml codeword but that it is not the output of the approximate algorithm @xmath287 .",
    "therefore some trellis say @xmath45 must close a node @xmath240 on the all 0 path ( so that @xmath290 never gets to close it , as only one closure is allowed , and therefore can not output the all 0 path ) .",
    "clearly node @xmath240 must be in the merging interval of @xmath290 and @xmath45 .",
    "since @xmath45 is a residual trellis(otherwise it would have not participated in the second phase ) , let the survivor at @xmath82 in the first phase be an @xmath241 path that overtakes the @xmath291 path at node @xmath242 , in other words , @xmath242 is the critical node for trellis @xmath45 .    * case 1 .",
    "* suppose node @xmath242 is a predecessor of node @xmath240 .",
    "by lemma  [ predecessor ] , @xmath292 , and since @xmath242 is a critical node , by lemma  [ lem : critical ] , @xmath45 would have gone on to win in the exact algorithm and therefore the all - zero codeword could not have been the ml codeword giving a contradiction .    * case 2 .",
    "* suppose node @xmath242 is a successor of @xmath240 _ within _ the merging interval of @xmath45 and @xmath290 .",
    "by lemma  [ predecessor ] @xmath243 .",
    "since @xmath259 is the ml codeword @xmath293 implying that @xmath294 .",
    "since subtrellis @xmath45 closed node @xmath240 , by lemma  [ share ] , @xmath295 . by the property of the metric @xmath296",
    "implying that @xmath297 .",
    "since @xmath242 is in the merging interval of @xmath290 and @xmath45 by lemma  [ segment ] @xmath298 giving a contradiction .",
    "therefore we conclude that if subtrellis @xmath45 closes @xmath240 and @xmath242 is a successor of @xmath240 , then @xmath242 can not be in the merging interval of @xmath45 and @xmath290 .",
    "+ we thus conclude that @xmath242 is beyond the merging interval of @xmath290 and @xmath45 , and hence the @xmath299 path does not touch the all - zero path .",
    "since the intersection property is satisfied , any path which is a linear combination of vectors of @xmath264 alone must have at least one node on the all - zero path .",
    "hence the semicodeword corresponding to the @xmath299 path can not be formed as a linear combination of rows only in @xmath264 and therefore it is formed as a linear combination of vectors with at least one member of @xmath55 .",
    "theorem  [ explanation ] and lemmas  [ ml - codeword ] and  [ semicodewords ] provide an explanation of the experimental observation that decoding differences between the exact and the approximate algorithm are infrequent , so much so , that the bit error rate curves are practically indistinguishable .",
    "lemma  [ semicodewords ] tells us that in order for a subtrellis to be opened it must contain a semicodeword satisfying equation  [ equ : weights ] , being the most likely semicodeword among the possible candidates .",
    "theorem  [ explanation ] establishes the condition that if a node on the all - zero path is closed by some trellis @xmath45 other than @xmath290 when the all - zero codeword was transmitted , then the initial metric of @xmath45 must be that of a semicodeword of pretty high weight ( because it is a linear combination of vectors which contain at least one vector in @xmath55 ) .",
    "further , the error @xmath276 which caused the cost of this high weight semicodeword to drop significantly enough to satisfy equation  [ equ : weights ] , should not cause the weight of any non - zero _ codeword _ to drop by an amount enough to violate equation  [ equ : ml ] . since semi - codewords share prefixes and suffixes with codewords",
    ", such events may be quite infrequent .",
    "+ one could get an even better approximation by allowing a node to be closed at most twice .",
    "we have experimented with this and observe that the bit error rate for this approximation is indistinguishable from that of the exact algorithm at all values of signal to noise ratio for all the three codes on which we have run the simulations .",
    "the significance of this is that the time complexity can be explicitly bounded by the complexity of at most three computations for each node of the tail - biting trellis , one update in the first viterbi decoding phase and at most two expansions in the second phase .",
    "we now estimate the time complexity of the approximate algorithm . the following bound on the complexity of the viterbi algorithm is well known@xcite .",
    "[ viterbi ] the complexity of the first phase of the decoding algorithm is @xmath300 where @xmath115 is the number of edges in the tail - biting trellis .",
    "the next lemma is a statement of a well known result on heap data structures@xcite .",
    "[ heap ] each insertion into the heap has complexity @xmath301 where @xmath187 is the number of elements in the heap .",
    "[ approx1 ] the algorithm @xmath287 has complexity bounded by @xmath302 where @xmath4 is the number of states in the tail - biting trellis .",
    "the number of vertices that are updated is at most @xmath289 as each vertex is expanded at most once in the second phase .",
    "each time a vertex is expanded it results in computations on every edge leaving it and at most a constant number of elements being visited and inserted into the heap @xmath112,(as this number is bounded by the field size assumed to be a constant ) .",
    "the complexity of each insertion phase is @xmath303 where @xmath187 is the size of the heap . since this size is proportional to @xmath4 the complexity of the second phase is @xmath304 .",
    "the sorting operation at the end of the first phase has complexity @xmath305 where @xmath18 is the number of states at time index @xmath306 .",
    "the complexity is dominated by the @xmath302 term and hence the theorem .    to reduce the overheads ,",
    "the heap is implemented as @xmath307 separate heaps if there are @xmath307 residual trellises , with a separate heap of pointers , each element of which points to the root of a distinct subtrellis heap .",
    "the individual heap sizes are small in practice and the algorithm is practically linear in the size of the trellis . in the next section we present results from profiling the program which bear out the claim that the overheads of heap operations are negligible .    an argument similar to that in theorem  [ approx1 ]",
    "estalishes the complexity of algorithm @xmath308 as @xmath302 .",
    "we next look at the space complexity of the algorithm .",
    "+    [ lem : space - complexity ] the space requirement for algorithm @xmath287 is @xmath309 bits .",
    "the algorithm requires @xmath310 space to store the estimates at each state in the first phase .",
    "the additional space required to store the heap is also @xmath310 as each expanded node can put at most all its successors on the heap .",
    "the bit vectors that store trellis membership are of size @xmath18 where @xmath18 is the number of start nodes of the tail - biting trellis .",
    "the space requirements for the bit vectors is therfore @xmath311 bits .",
    "the space requirements for storing the current cost at each node is @xmath310 .",
    "this follows from the fact that each shared node is closed at most once .",
    "this means that at most one copy of a shared node updates its succesors .",
    "this in turn means that each successor has at most one update along each of its incoming edges .",
    "since the number of incoming edges is a constant which is at most the size of the field , a constant number of costs are associated with each node in the tail - biting trellis from which the result follows .",
    "we have coded the exact and approximate algorithms and show the results of simulations on minimal tail - biting trellises for the 16 state tail - biting trellis  @xcite for the extended ( 24,12 ) golay code on an awgn channel with antipodal signaling , and tail - biting trellises for two rate 1/2 convolutional codes with memory 6 , circle size 48 ( which is the same as the ( 554,744 ) convolutional code experimented with in  @xcite , and memory 4 , circle size 20 ( which is the same as the ( 72,62 ) convolutional code used in  @xcite respectively .",
    "we show the variation of both , the average as well as the maximum number of node computations ( counting viterbi updates in the first phase and expansions in the second phase ) with the signal to noise ratio for our exact algorithm , and compare this with the number of viterbi updates needed for the brute force approach .",
    "note that this number is indicative of the _ time complexity _ of the algorithm .",
    "the results are encouraging and are displayed in tables  [ tab : expansions1 ] ,  [ tab : expansions2 ] and  [ tab : expansions3 ] respectively for the golay code and the two convolutional codes .",
    "_ on the average , the number of updates to get the exact ml result requires fewer than two computations at each node of the tail - biting trellis at all values of signal to noise ratio , one in the first pass and one in the second_. the maximum number of node computations for the algorithm @xmath287 is obviously bounded by twice the number of nodes in the tail - biting trellis .",
    "we also display the bit error - rate performance of the approximate algorithms closing nodes at most once for the first approximation @xmath287 , and at most twice for the second approximation , @xmath308 in figures  [ fig : golay - ber ] ,  [ fig : conv1-ber ] ,  [ fig : conv2-ber ] and and find that there is virtually no difference in the bit error rates for the second approximation and the exact ml algorithm .",
    "_ thus we get virtually ml performance for an explicit linearly bounded update complexity at all values of signal to noise ratio_.     * average node computations * + 0.0 & 285 & 602 & 245.2 + 0.5 & 294 & 688 & 235.3 + 1.0 & 311 & 709 & 225.7 + 1.5 & 273 & 637 & 217.7 + 2.0 & 271 & 580 & 210.6 + 2.5 & 256 & 576 & 204.8 + 3.0 & 289 & 643 & 200.1 + 3.5 & 242 & 557 & 197.2 + 4.0 & 192 & 480 & 195.1 + 4.5 & 152 & 423 & 193.8 + 5.0 & 135 & 396 & 193.0 +     * average node computations * + 0.0 & 13064 & 22311 & 4414.1 + 0.5 & 15698 & 24958 & 4051.4 + 1.0 & 13161 & 20369 & 3738.5 + 1.5 & 12926 & 18981 & 3487.9 + 2.0 & 9948 & 16162 & 3330.0 + 2.5 & 7492 & 11700 & 3233.5 + 3.0 & 5743 & 11175 & 3175.0 + 3.5 & 3354 & 7163 & 3138.2 + 4.0 & 2781 & 6447 & 3115.0 + 4.5 & 1526 & 5104 & 3099.5 + 5.0 & 1059 & 4693 & 3088.2 +     * average node computations * + 0.0 & 701 & 1437 & 426.9 + 0.5 & 784 & 1447 & 405.4 + 1.0 & 824 & 1554 & 384.9 + 1.5 & 749 & 1426 & 367.6 + 2.0 & 623 & 1214 & 353.5 + 2.5 & 563 & 1179 & 342.7 + 3.0 & 578 & 1162 & 334.6 + 3.5 & 503 & 984 & 329.5 + 4.0 & 412 & 918 & 326.2 + 4.5 & 292 & 718 & 323.7 + 5.0 & 241 & 660 & 322.3 +",
    "we have proposed an exact algorithm for ml decoding on tail - biting trellises and also experimented on two approximate variants .",
    "the average time complexity of the exact algorithm is seen to be quite low .",
    "the approximate variants perform as well as the exact one in terms of the bit error rate at an explicitly bounded update complexity equivalent to two , or sometimes three rounds on the tail - biting trellis .",
    "the algorithm does not suffer from the effects of limit cycles or pseudocodewords which current iterative algorithms are subject to . profiling measurements carried out on the program are displayed in table  [ tab : profile ] . the execution time",
    "was averaged over 10,000 runs of the decoder .",
    "the percentage of execution time taken up by each of the five major operations in the decoding process , namely , the initializations of all the arrays , the first pass , the sorting operation at the end of the first pass , the second pass , and the heap operations is displayed . it can be observed that heap operations incur an overhead of only 11 % of the program running time at 0 db and are negligible for higher values of signal to noise ratios .     & * initializations * & * phase 1 * & * sorting * & * phase 2 * & * heap operations * + & & & & & + 0.0 & 14.75% & 34.09% & 5.88% & 31.38% & 11.12% + 1.0 & 8.34% & 46.95% & 8.34% & 24.94% & 6.61% + 2.0 & 6.07% & 58.84% & 10.20% & 17.62% & 2.74% + 3.0 & 3.21% & 69.02% & 10.79% & 12.68% & 0.92% + 4.0 & 1.13% & 74.23% & 11.49% & 9.62% & 0.23% + 5.0 & 0.52% & 75.70% & 11.59% & 8.425% & 0.09% +      the results of simulations on the extended ( 24,12 ) golay code , a rate 1/2 , memory 6 convolutional code with a circle size of 48(which is the same as the ( 554,744 ) convolutional code used for experiments in @xcite and a rate 1/2 memory 4 convolutional code with a circle size of 20(which is the same as the ( 72,62 ) rate 1/2 convolutional used for experimentation in @xcite ) have been reported .",
    "it is seen that the second approximate variant has a bit error rate which is indistinguishable from that of the exact algorithm for all values of signal to noise ratio .",
    "+   * acknowledgement * the authors gratefully acknowledge discussions with aditya nori .",
    "they would also like to thank the anonymous referees for their comments which greatly improved the presentation of the paper .",
    "+    99 l.e .",
    "aguado and p. g. farrell , on hybrid stack decoding algorithms for block codes , _ ieee trans .",
    "inform . theory _",
    ", january 1998 , pp 398 - 409 .",
    "a. aho , j.e .",
    "hopcroft and j.d .",
    "ullman , _ data structures and algorithms _ , addison - wesley , reading , ma . 1983 .",
    "s. aji , g. horn , r. mceliece and m. xu , iterative min - sum decoding of tail - biting codes , _ proceedings of information theory workshop _ ,",
    "killarney , ireland , june 22 - 26 , pp .",
    "68 - 69 .",
    "anderson and s.m .",
    "hladik , an optimal circular viterbi decoder for the bounded distance criterion , _ ieee transactions on communications _ , * 50*(11 ) , november 2002 .",
    "anderson and s.m .",
    "hladik , tail - biting map decoders,_ieee journal in selected areas in communication _ , * 16*(2 ) , february 1998 .",
    "calderbank , g.d .",
    "forney , jr . , and a. vardy , minimal tail - biting trellises : the golay code and more , _ ieee trans .",
    "inform . theory _",
    ", * 45*(5 ) , july 1999 , pp .",
    "1435 - 1455 .    r.v .",
    "cox and c.v .",
    "sundberg , an efficient adaptive circular viterbi algorithm for decoding generalized tailbiting convolutional codes , _ ieee transactions on vehicular technology _ * 43*(1 ) , february 1994 , pp 57 - 68 .",
    "kaustubh deshmukh , priti shankar , amitava dasgupta , and b.  sundar rajan . on the many faces of block codes . in _",
    "symposium on theoretical aspects of computer science(stacs ) _ , pages 5364 , 2000 .",
    "l. ekroot and s. dolinar , @xmath0 decoding of block codes , _ ieee trans .",
    "_ * 44 * ( 9 ) , september 1996 , pp 1052 - 1056 .",
    "han , c.r.p .",
    "hartmann and c .- c .",
    "chen , efficient priority - first search maximum - likelihood soft - decision decoding of linear block codes , _ ieee trans .",
    "inform . theory _",
    "* 39 * ( 5 ) september 1993 , pp 1514 - 1523 .",
    "han , c.r.p .",
    "hartmann , and k.g .",
    "mehrotra , decoding linear block codes using a priority first search : performance analysis and suboptimal version , _ ieee trans .",
    "inform . theory _ * 44*(7 ) , november 1998 , pp 3091 - 3096 .",
    "han , a new treatment of priority - first search maximum - likelihood soft - decision decoding of linear block codes , _ ieee trans .",
    "inform . theory _ *",
    "44*(7 ) november 1998 , pp 3091 - 3096 .",
    "n . chen and h. -b .",
    "wu , a maximum - likelihood soft - decision sequential decoding algorithm for binary convolutional codes , _ ieee trans .",
    "* 50 * ( 2 ) , february 2002 , pp 173 - 178 .",
    "han , c.r.p .",
    "hartmann and k.g .",
    "mehrotra , decoding linear block codes using a priority - first search : performance analysis and suboptimal version , _ ieee trans .",
    "inform . theory _ * 44*(3 ) , may 1988 , pp 1233 - 1246 .",
    "f. jelinek , a fast sequential decoding algorithm using a stack , _ ibm j. res . devel _ * 13 * , 1969 , pp 675 - 685 .",
    "r. koetter and a. vardy , on the theory of linear trellises , _ information , coding and mathematics _ ( m. blaum , editor ) ,",
    "boston : kluwer , may 2002 .",
    "kschischang and v. sorokine , on the trellis structure of block codes , _ ieee trans .",
    "inform . theory _",
    ", * 41*(6 ) , nov 1995 , pp . 1924 - 1937 .",
    "kschischang and v. sorokine , a sequential decoder for linear block codes with a variable bias term metric , _ ieee trans .",
    "inform . theory _",
    "january 1998 , pp 410 - 411 .",
    "kudryashov , decoding of block codes obtained from convolutional codes , _ problemy peredachi",
    "informatsii_,*26*(2 ) , pp 18 - 26 , april - june 1990(in russian ) .",
    "english translation , plenum publishing corporation , oct 1990 .",
    "mceliece , on the bcjr trellis for linear block codes , _ ieee trans .",
    "inform . theory _ ,",
    "* 42 * ( 4 ) , july 1996 , pp 1072 - 1092 .",
    "j.h.ma and j.k.wolf , on tail - biting convolutional codes , _ ieee trans .",
    "commun._,*34*,february 1986 , pp 104 - 111 .",
    "nilsson , principles of artificial intelligence , tioga publishing co. , palo alto , ca , 1980 .",
    "p. shankar , a. dasgupta , k. deshmukh and b.s .",
    "rajan , on viewing block codes as finite automata , theoretical computer science , * 290*(2003 ) 1775 - 1797 .",
    "p. shankar , p.n.a .",
    "kumar , k. sasidharan and b.s .",
    "rajan , ml decoding of block codes on their tail - biting trellises , in _ proc .",
    "2001 ieee int .",
    "symposium on information theory _",
    ", ieee press , 2001 , pp .",
    "c.shih , c.r .",
    "wulff , c.r.p .",
    "hartmann and c.k .",
    "mohan , efficient heuristic search algorithms for soft - decision decoding of linear block codes , _ ieee trans .",
    "inform . theory _ ,",
    "november 1998 , pp 3023 - 3038 .",
    "g.solomon and h.c.a .",
    "van tilborg , a connection between block and convolutional codes , _",
    "siam j. appl .",
    "_ , * 37 * , october 1979 , pp 358 - 369 .",
    "m. tanner , a recursive approach to low complexity codes , _ ieee trans .",
    "inform . theory _ * 27 * , pp 533 - 547 , 1981 .",
    "tendolkar and c.r.p .",
    "hartmann , generalization of chase algorithms for soft decision decoding of binary linear codes , _ ieee trans .",
    "inform.theory,_*30*(5 ) , september 1984,pp 714 - 721 ."
  ],
  "abstract_text": [
    "<S> an algorithm for exact maximum likelihood(ml ) decoding on tail - biting trellises is presented , which exhibits very good average case behavior . </S>",
    "<S> an approximate variant is proposed , whose simulated performance is observed to be virtually indistinguishable from the exact one at all values of signal to noise ratio , and which effectively performs computations equivalent to at most two rounds on the tail - biting trellis . </S>",
    "<S> the approximate algorithm is analyzed , and the conditions under which its output is different from the ml output are deduced . </S>",
    "<S> the results of simulations on an awgn channel for the exact and approximate algorithms on the 16 state tail - biting trellis for the ( 24,12 ) extended golay code , and tail - biting trellises for two rate 1/2 convolutional codes with memories of 4 and 6 respectively , are reported . </S>",
    "<S> an advantage of our algorithms is that they do not suffer from the effects of limit cycles or the presence of pseudocodewords .    </S>",
    "<S> [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] </S>"
  ]
}