{
  "article_text": [
    "the problem addressed in this paper is rather elementary in statistics .",
    "it is best described as the following : suppose one who knows nothing about english language was given a sequence of english letters , which was actually obtained by taking off all the interwords delimiters among a sample of english text , how could he recover the words of the text by choosing to insert spaces between adjacent letters ?",
    "note that the only thing he can consult is the statistical properties of the sequence ?",
    "any two adjacent letters can be chosen to belong to the same word ( keep adjacent ) as well as belong to separate words ( be separated by space ) .",
    "suppose the sequence length is @xmath0 .",
    "any choice on the connectivity between @xmath1 pairs of adjacent letters is called a segmentation .",
    "there are a total of @xmath2 possible segmentations .",
    "the word segmentation problem is to find ways to distinguish the correct segmentation  in the sense that adjacent letters in the original text keep adjacent while letters separated by spaces and/or punctuation marks in the original text are separated by spaces in the segmentation  from others .",
    "although the problem seems toy - like , its fundamental importance for statistical linguistics is evident .",
    "we study on it , however , also for practical purposes .",
    "noncoding sequences in the genomes of species play essential rule on the regulation of gene expression and function  @xcite .",
    "however the development of computational methods for extracting regulatory elements is far behand dna sequencing and gene finding  @xcite .",
    "one reason is the lack of efficient way to discriminate large amount of sequence signals in noncoding dna sequences . through linguistic study",
    "it has been shown that noncoding sequences in eukaryotic genomes are structurally much similar to natural and artificial language  @xcite .",
    "thus many may expect to  read \" the noncoding sequences as a  text \" .",
    "actually , efforts have been given to build a dictionary for genomes  @xcite .",
    "li et al .",
    "@xcite showed the connection between regulatory elements prediction and word segmentation in noncoding dna sequences of eukaryote genomes .",
    "we expect that progress on word segmentation problem may help to deepen our knowledge on noncoding regions of eukaryote genomes .",
    "besides , word segmentation is an important issue for asian languages ( e.g. , chinese and japanese ) processing  @xcite , because they lack interword delimiters .",
    "to tackle word segmentation problem , we first consider a problem under constraints , so that one important concept  segmentation entropy  can be introduced .",
    "the constraints will be released at the end of this paper .",
    "suppose we have known that there are @xmath3 words of length @xmath4 @xmath5 in the original text . obviously , @xmath6 under these constraints  words length constraints wlc  there are totally @xmath7 segmentations . for example , for the following story , there are totally @xmath8 segmentations , while the number under wlc is about @xmath9 .    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _   _ the fox and the grapes _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    following least effort principle  @xcite , it is appreciable in natural languages to combine existing words to express different meaning .",
    "shannon  @xcite pointed out the importance of redundancy in natural languages long ago : generally speaking , nearly half of the letters in a sample of english text can be deleted while someone else can still restore them .",
    "these properties of natural language ensure the sequence obtained by taking off interword delimiters from a certain text being highly nonrandom and showing determinant and regular characteristics .",
    "it is expected that the correct segmentation reveals these characteristics as strongly as possible . from information point of view , this means that , if a form of information entropy can be properly defined on each segmentation , the entropy of the correct segmentation will be the smallest .",
    "interestingly , a maximum likelihood approach leads to the same proposal and automatically gives the definition of the entropy .",
    "given one sequence of length @xmath0 , we expect to find a likelihood function which reaches its maximum on the correct segmentation . for a concrete segmentation ,",
    "we assign a probability to each word in it @xmath10 with @xmath11 the likelihood function is written as @xmath12 where @xmath13 is the number of word @xmath14 in the segmentation , and @xmath15 is the length of the word .    by maximizing the likelihood function",
    "subjected to eq.(4 ) we obtain @xmath16 thus the maximum likelihood for the segmentation is @xmath17 the segmentation with maximum likelihood is just the one minimizing @xmath18 this function has the form of entropy  @xcite and will be called segmentation entropy ( se ) .",
    "starting from a maximum likelihood approach , we now come to the suggestion to minimize the segmentation entropy .",
    "this is in contrast to commonplace . maximizing likelihood leads to maximizing certain entropy in some cases  @xcite . as a general principle for investigating statistical problems ,",
    "maximum entropy method has been successfully applied in a variety of fields  @xcite .",
    "we propose that , instead of applying maximum entropy principle , one may choose to minimize certain entropy ( minimum entropy principle ) in some problems .",
    "this seems attractive especially in the era of bioinformatics when most of the problems are to reveal regularity in large amount of seemingly random sequences .",
    "because the present is a statistical method , the text under study needs to be not too short .",
    "for example , when we tried to find the segmentation with the smallest segmentation entropy for the saying    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ god is nowhere as much as he is in the soul ... and the soul means the world _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    ( by meister eckhart , 14-century dominican priest , preacher , and theologian ) , it was found that , among a total of @xmath19 segmentations under wlc , there are 15 segmentations whose se is @xmath20 , smaller than 2.3802 of the correct one .",
    "one example is    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ god isnow * he * rea smuchas * he * is int * he * * soul * andt * he * * soul * meanst * he * world _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in which the five _  he \" _ and two _  soul \" _ are revealed .    unfortunately , present computational power does not permit to exhaustively study even a text as short as _  the fox and the grapes \" _ , the number of permitted segmentations for which is @xmath21 under wlc .",
    "we choose to see the relevance of the concept of segmentation entropy in some special ways .",
    "the study focuses on  the fox and the grapes \" .    to change a segmentation slightly ,",
    "one way is to choose two adjacent words along the sequences randomly and then exchange their length .",
    "this way the original two words may change to different words .",
    "this procedure can be repeated on the resulting segmentations .",
    "the change does not violate the wlc .",
    "because of the large number of possible choices in each step , the segmentation is expected to become increasingly dissimilar to the original one .",
    "starting from the correct segmentation of  the fox and the grapes \" , we expect to see the evolution of se by changing the segmentation this way .",
    "figure 1 shows that se increase drastically in the first 500 steps , and then reaches and fluctuates around certain equilibrium value .",
    "compared with the gap between the equilibrium value and the original se , the fluctuation is minor .",
    "this shows that , at least locally , the correct segmentation is at the minimum of se . actually , we have traced a trajectory of evolution up to @xmath22 steps .",
    "no segmentation with se smaller than the correct one was observed .",
    "this implies that se of the correct segmentation is also globally minimal .",
    "the distribution of segmentation entropy may give further insight to the atypicality of the correct se .",
    "we randomly sampled @xmath22 segmentations in the following way : while keeping the wlc , the length of each words in the segmentation is assigned randomly .",
    "the distribution of se is shown in fig .",
    "the minimal se we sampled is 4.5298 , still much higher than 4.097 of the correct segmentation ( see fig .",
    "it is interesting to observe that the distribution shows fractal characteristics .",
    "the fractal - like distribution presents also for other text , even for random sequence ( fig .",
    "the fractal - like feature is determined by the wlc and the statistical structure of the sequence under study . in fig .",
    "3 we compared the distribution of se of two sequences ( under the same wlc ) , the original sequence of _  the fox and the grapes \" _ and a random sequence obtained by randomizing the order of letters in the text . the result is in accordance with the fact that the original sequence is in a much more ordered state , manifesting that segmentation entropy captures the statistical structure of the sequences successfully .",
    "there is one way to estimate the number of segmentations the se of which is 4.097 , the value for the correct segmentation .",
    "see fig . 4 in which the distribution of se in fig .",
    "2 are shown in logrithmic scale here .",
    "the left edge of the distribution fall on a line .",
    "the edge can be fitted by @xmath23 the number of segmentations with se x among the totally @xmath9 possible segmentations under wlc is : @xmath24 we obtained @xmath25 . from the distribution of se shown in fig .",
    "3(a ) we obtained the same value of @xmath26 .",
    "the estimation support the idea that segmentation entropy of correct segmentation is unique .",
    "we now consider how to release the wlc .",
    "unfortunately , searching the segmentation with the smallest se among all the possible is sure to fail to find the correct one .",
    "for example , se of the segmentation in which the whole sequence is considered as one word ( single - word segmentation ) is 0 , the smallest possible se . also , the segmentation in which each letter is viewed as a separate word ( @xmath0-word segmentation ) has a considerably small se ( 2.8655 for _  the fox and the grapes \" _ ) . these are called side attraction effects .",
    "these examples show that smaller se does not necessarily means better segmentation when we compare the ses of segmentations under different wlc ( here wlc refers to any partition of numbers of words of various length satisfying eq.(1 ) , not necessarily the same as the original text . )",
    "the bias induced by different wlc must be taken off . in order to do so , we suggest to use @xmath27 instead of @xmath28 . here",
    "@xmath29 is the average se under the same wlc of a sequence obtained by randomizing the order of letters in the original text .",
    "@xmath29 plays the role of chemical potential for a thermodynamic system  @xcite .",
    "@xmath30 for the single word and @xmath0-word segmentations are 1 , the largest possible value . by searching segmentation with the smallest @xmath30",
    ", it is expected to find meaningful segmentation . for examples , for the segmentation    _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ god isnow _ he _ rea smuchas _ he _ is int _ he _ _ soul _ andt _ he _ _ soul _ meanst _ he _ world , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    which has already been shown above , @xmath30 is 0.8601 ; while    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ god _ is _ now _ he _ re _ as _ much _ as _ _ he _ _ is _ int _ he _ _ soul _ _ an _ dt _ he _ _ soul _ me _ an _ st _ he _ world _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    is a better  actually one of the best ",
    "segmentation according to @xmath30 ( @xmath31 ) .",
    "intuitively this is reasonable , because in this second segmentation , more repeated  words \"  two copies of _  is \" _ , _  as \" _ and _  an \" _  are revealed . another segmentation    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ god _ is _ now _ he _ re _ as _ much _ as _ _ he _ _ is _ in _ thesoul _ _ an _ d _ thesoul _ me _ an _ st _ he _ world _ , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    which differs from the second segmentation by revealing the two _  thesoul \" _ , has a moderately small @xmath30 : 0.8481 .",
    "comparison shows that the five repeats of _  he \" _ is the most preferred part in good segmentations .",
    "in statistical linguistics many efforts are given on signal extracting and statistical inference .",
    "our method , however , is new on at least two points .",
    "first , there is neither assumption on distribution  @xcite nor demand for training sets , lexical or grammatical knowledge  @xcite .",
    "this feature is important for studying biological sequences , because present knowledge on the  language \" ( dna ) of life is still lack .",
    "second , instead of extracting a limit number of signals , we try to  read \" the sequence exactly as a  text \" .",
    "a text includes more than words : it also includes the organization of words .",
    "the results of segmentation form a basis for many further elaborations .",
    "principally , the concept of segmentation entropy can be applied to study the noncoding dna sequences of eukaryote genomes .",
    "it is expected that the study may gives more than some meaningful  words \" or regulatory elements .",
    "possible applications are not confined to studying noncoding dna sequences of course .",
    "segmentation entropy can be used to find patterns in any symbolic sequences . however , the application of segmentation entropy is restricted by the difficulty to find the segmentation with the smallest @xmath32 from the vast amount possible ones .",
    "we are now developing algorithm that can be used for regulatory binding sites prediction . in the algorithm",
    "the principle of minimun entropy will be incorporated in .",
    "i thanks professor bai - lin hao who helps to make the computing possible .",
    "i also thanks professor wei - mou zheng and professor bai - lin hao for stimulating discussions .",
    "xiong zhang carefully read the manuscript .",
    "the work was supported partly by national science fundation .",
    "see , e.g. , w. li , _ molecular evolution _",
    "( sinauer associates , 1997 ) .",
    "a.g . pedersen , p. baldi , y. chauvin , and s. brunak , comput .",
    "* 23 * , 191 ( 1997 ) . r.n .",
    "mantegna , s.v .",
    "buldyrev , a.l .",
    "goldberger , s. havlin , c .- k .",
    "peng , m. simons , and h.e .",
    "stanley , phys .",
    "lett . * 73 * , 3169 ( 1994 ) .",
    "v. brendel , j.s .",
    "beckmann , and e.n .",
    "trifonov , j. biomol .",
    "* 7 * , 11 ( 1986 ) ; p.a .",
    "pevzner , m.y .",
    "borodovsky , and a.a .",
    "mironov , j. biomol .",
    "* 6 * , 1013 ( 1989 ) .",
    "bussemaker , h. li , and e.d .",
    "siggia , preprint .",
    "ponte , and w.b .",
    "croft , umass computer science tech rep .",
    "1996 - 2002 ( 1996 ) , available at ftp://ftp.cs.umass.edu/pub/techrept/techreport/1996 ; r. ando and l. lee , cornell cs report tr99 - 1756 ( 1999 ) , available at http://www.cs.cornell.edu/home/llee/papers.html .",
    "zipf , _ human behavior and the principle of least effort _",
    "( addison - wesley press , reading , 1949 ) .",
    "shannon , bell system tech .",
    "j. * 27 * , 379 ( 1948 ) .",
    "frieden , j. opt .",
    "62 * , 511 ( 1972 ) ; e.t .",
    "jaynes , phys . rev .",
    "* 106 * , 620 ( 1975 ) ; * 108 * , 171 ( 1975 ) .",
    "n. wu , _ the maximum entropy method and its applications in radio astronomy _ , ph.d .",
    "thesis ( sydney university , 1985 ) .",
    "see , e.g. , l.e .",
    "reichl , _ a modern course in statistical physics _",
    "( anorld , 1980 ) .",
    "peitra , v.d .",
    "peitra , and j. lafferty , ieee transactions pattern analysis and machine intelligence * 19 * , 1 ( 1997 ) ."
  ],
  "abstract_text": [
    "<S> given a sequence composed of a limit number of characters , we try to  read \" it as a  text \" . </S>",
    "<S> this involves to segment the sequence into  words \" . </S>",
    "<S> the difficulty is to distinguish good segmentation from enormous number of random ones . aiming at revealing the nonrandomness of the sequence as strongly as possible , by applying maximum likelihood method </S>",
    "<S> , we find a quantity called * segmentation entropy * that can be used to fulfill the duty . </S>",
    "<S> contrary to commonplace where maximum entropy principle was applied to obtain good solution , we choose to _ minimize _ the segmentation entropy to obtain good segmentation . </S>",
    "<S> the concept developed in this letter can be used to study the noncoding dna sequences , e.g. , for regulatory elements prediction , in eukaryote genomes . </S>"
  ]
}