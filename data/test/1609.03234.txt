{
  "article_text": [
    "imperfect - information extensive - form games model strategic multi - step scenarios between agents with hidden information , such as auctions , security interactions ( both physical and virtual ) , negotiations , and military situations . typically in imperfect - information games ,",
    "one wishes to find a nash equilibrium , which is a profile of strategies in which no player can improve her outcome by unilaterally changing her strategy .",
    "a linear program can find an exact nash equilibrium in two - player zero - sum games containing fewer than about @xmath0 nodes  @xcite . for larger games , iterative algorithms",
    "are used to converge to a nash equilibrium .",
    "there are a number of such iterative algorithms  @xcite , the most popular of which is _ counterfactual regret minimization _",
    "( cfr )  @xcite .",
    "cfr minimizes regret independently at each decision point in the game .",
    "cfr+ , a variant of cfr , was used to essentially solve limit texas holdem , the largest imperfect - information game ever to be essentially solved  @xcite .",
    "both computation time and storage space are difficult challenges when solving large imperfect - information games .",
    "for example , solving limit texas holdem required nearly 8 million core hours and a complex , domain - specific streaming compression algorithm to store the 262 tib of uncompressed data in only 10.9 tib .",
    "this data had to be repeatedly decompressed from disk into memory and then compressed back to disk in order to run cfr+  @xcite .",
    "_ regret based pruning _ ( rbp ) is an improvement to cfr that greatly reduces the computation time needed to solve large games by temporarily pruning suboptimal actions  @xcite .",
    "specifically , if an action has negative regret , then rbp skips that action for the minimum number of iterations it would take for its regret to become positive in cfr .",
    "the skipped iterations are then `` made up '' in a single iteration once pruning ends .    in this paper",
    "we introduce a new form of rbp which we coin _ total rbp_. it alters the starting and ending conditions for pruning , and changes the way regrets are updated once pruning ends .",
    "we refer to the prior form of rbp as _ interval rbp _ to differentiate it from our new method .",
    "a primary advantage of total rbp is that in addition to faster convergence , it also reduces the _ space _ requirements of cfr over time .",
    "specifically , once pruning begins on a branch , total rbp ensures the regrets currently stored on that branch will never be needed again .",
    "in other words , all the data stored for a branch that is pruned can be discarded , and the space allocated to that branch can be freed .",
    "space need not be reallocated for that branch until pruning ends and the branch can not immediately be pruned again . in section  [ sec : rbpspace ] , we prove that after enough iterations are completed , space for certain pruned branches will _ never _ need to be allocated again . specifically , we prove that total rbp need only asymptotically store actions that have positive probability in a best response to a nash equilibrium .",
    "this is extremely advantageous when solving large imperfect - information games , which are often constrained by space and in which the set of best response actions may be orders of magnitude smaller than the size of the game .",
    "while total rbp still requires enough memory to store the entire game in the early iterations , recent work has shown that these early iterations can be skipped by first solving a low - memory abstraction of the game and then using its solution to warm starting cfr in the full game  @xcite .",
    "total rbp s reduction in space is also helpful to the _ simultaneous abstraction and equilibrium finding _ ( saef ) algorithm  @xcite , which starts cfr with a small abstraction of the game and progressively expands the abstraction while also solving the game .",
    "saef s space requirements increase the longer the algorithm runs , and may eventually exceed the constraints of a system .",
    "total rbp can counter this increase in space by eliminating the need to store suboptimal paths of the game tree .",
    "while prior work on interval rbp has shown empirical evidence of better performance , this paper proves that cfr converges faster when using total rbp , because certain suboptimal actions will only need to be traversed @xmath1 times over @xmath2 iterations .",
    "the magnitude of these gains in speed and space varies depending on the game .",
    "it is possible to construct games where total rbp provides no benefit .",
    "however , if there are many suboptimal actions in the game  as is frequently the case in large games  total rbp can speed up cfr by multiple orders of magnitude and require orders of magnitude less space .",
    "our experiments show an order of magnitude space reduction already in medium - sized games , and a reduction factor increase with game size .",
    "[ sec : background ] this section presents the notation used in the rest of the paper .",
    "an imperfect - information extensive - form game has a finite set of players , @xmath3 .",
    "@xmath4 is the set of all possible histories ( nodes ) in the game tree , represented as a sequence of actions , and includes the empty history .",
    "@xmath5 is the actions available in a history and @xmath6 is the player who acts at that history , where @xmath7 denotes chance .",
    "chance plays an action @xmath8 with a fixed probability @xmath9 that is known to all players .",
    "the history @xmath10 reached after action @xmath11 in @xmath12 is a child of @xmath12 , represented by @xmath13 , while @xmath12 is the parent of @xmath10 .",
    "more generally , @xmath10 is an ancestor of @xmath12 ( and @xmath12 is a descendant of @xmath10 ) , represented by @xmath14 , if there exists a sequence of actions from @xmath10 to @xmath12 .",
    "@xmath15 are terminal histories for which no actions are available . for each player @xmath16 ,",
    "there is a payoff function @xmath17 . if @xmath18 and @xmath19 , the game is two - player zero - sum .",
    "define @xmath20 and @xmath21 .",
    "imperfect information is represented by _",
    "information sets _ for each player @xmath16 by a partition @xmath22 of @xmath23 . for any information set @xmath24 , all histories @xmath25 are indistinguishable to player @xmath26 , so @xmath27 .",
    "@xmath28 is the information set @xmath29 where @xmath30 .",
    "@xmath31 is the player @xmath26 such that @xmath24 .",
    "@xmath32 is the set of actions such that for all @xmath30 , @xmath33 .",
    "@xmath34 and @xmath35 .",
    "define @xmath36 to be the maximum payoff reachable from a history in @xmath29 , and @xmath37 to be the minimum .",
    "that is , @xmath38 and @xmath39 .",
    "define @xmath40 to be the range of payoffs reachable from a history in @xmath29 .",
    "similarly @xmath41 , @xmath42 , and @xmath43 are the maximum , minimum , and range of payoffs ( respectively ) reachable from a history in @xmath29 after taking action @xmath11 .",
    "define @xmath44 to be the set of information sets reachable by player @xmath31 after taking action @xmath11 .",
    "formally , @xmath45 if for some history @xmath30 and @xmath46 , @xmath47 and @xmath48 .    a strategy @xmath49 is a probability vector over @xmath32 for player @xmath26 in information set @xmath29 .",
    "the probability of a particular action @xmath11 is denoted by @xmath50 .",
    "since all histories in an information set belonging to player @xmath26 are indistinguishable , the strategies in each of them must be identical .",
    "that is , for all @xmath30 , @xmath51 and @xmath52 .",
    "define @xmath53 to be a probability vector for player @xmath26 over all available strategies @xmath54 in the game .",
    "a strategy profile @xmath55 is a tuple of strategies , one for each player .",
    "@xmath56 is the expected payoff for player @xmath26 if all players play according to the strategy profile @xmath57 . if a series of strategies are played over @xmath2 iterations , then @xmath58 .",
    "@xmath59 is the joint probability of reaching @xmath12 if all players play according to @xmath55 .",
    "@xmath60 is the contribution of player @xmath26 to this probability ( that is , the probability of reaching @xmath12 if all players other than @xmath26 , and chance , always chose actions leading to @xmath12 ) .",
    "@xmath61 is the contribution of all players other than @xmath26 , and chance .",
    "@xmath62 is the probability of reaching @xmath10 given that @xmath12 has been reached , and @xmath63 if @xmath64 . in a _ perfect - recall _ game , @xmath65 , @xmath66 . in this paper",
    "we focus on perfect - recall games . therefore , for @xmath67 define @xmath68 for @xmath30 .",
    "moreover , @xmath69 if for some @xmath46 and some @xmath30 , @xmath14 . similarly , @xmath70 if @xmath71 . the average strategy @xmath72 for an information set @xmath29 is defined as @xmath73 . a _ best response _ to @xmath74 is a strategy @xmath75 such that @xmath76 .",
    "a _ nash equilibrium _",
    "@xmath77 is a strategy profile where every player plays a best response : @xmath78 , @xmath79 .",
    "a _ nash equilibrium strategy _ for player @xmath26 as a strategy @xmath53 that is part of any nash equilibrium . in two - player zero - sum games , if @xmath53 and @xmath74 are both nash equilibrium strategies , then @xmath57 is a nash equilibrium . an _ @xmath80-equilibrium _ as a strategy profile @xmath77 such that @xmath78 , @xmath81 .",
    "_ counterfactual regret minimization ( cfr ) _ is a popular algorithm for extensive - form games in which the strategy vector for each information set is determined according to a regret - minimization algorithm  @xcite .",
    "we use _ regret matching ( rm ) _",
    "@xcite as the regret - minimization algorithm .",
    "the analysis of cfr makes frequent use of _ counterfactual value_. informally , this is the expected utility of an information set given that player @xmath26 tries to reach it . for player @xmath26 at information",
    "set @xmath29 given a strategy profile @xmath55 , this is defined as @xmath82 the counterfactual value of an action @xmath11 is @xmath83    a _ counterfactual best response _",
    "@xcite ( cbr ) is a strategy similar to a best response , except that it maximizes counterfactual value even at information sets that it does not reach due to its earlier actions .",
    "specifically , a counterfactual best response to @xmath74 is a strategy @xmath84 such that if @xmath85 then @xmath86 . the _ counterfactual best response value _ @xmath87 is similar to counterfactual value , except that player @xmath67 plays according to a cbr to @xmath74 .",
    "formally , @xmath88 .",
    "let @xmath89 be the strategy profile used on iteration @xmath90 .",
    "the _ instantaneous regret _ on iteration @xmath90 for action @xmath11 in information set @xmath29 is @xmath91 and the _ regret _ for action @xmath11 in @xmath29 on iteration @xmath2 is @xmath92 .",
    "additionally , @xmath93 and @xmath94 .",
    "our analysis of total rbp will occasionally reference the _ potential function _ of @xmath95 , defined as @xmath96 .",
    "regret for player @xmath26 in the entire game is @xmath97 .    in regret",
    "matching , a player picks a distribution over actions in an information set in proportion to the positive regret on those actions .",
    "formally , on each iteration @xmath98 , player @xmath26 selects actions @xmath99 according to probabilities @xmath100 if a player plays according to rm on every iteration then on iteration @xmath2 , @xmath101 .    if a player plays according to cfr in every iteration then @xmath102 .",
    "so , as @xmath103 , @xmath104 . in two - player zero - sum games ,",
    "if both players average regret @xmath105 , their average strategies @xmath106 form a @xmath107-equilibrium  @xcite . thus , cfr constitutes an anytime algorithm for finding an @xmath80-nash equilibrium in zero - sum games .",
    "this section reviews forms of pruning that allow parts of the game tree to be skipped in cfr .",
    "typically , regret is updated by traversing each node in the game tree separately for each player , and calculating the contribution of a history @xmath30 to @xmath108 for each action @xmath99 .",
    "if a history @xmath12 is reached in which @xmath109 ( that is , an opponent s reach is zero ) , then from ( [ eq : counterfactual ] ) and ( [ eq : counterfactuala ] ) the strategy at @xmath12 contributes nothing on iteration @xmath90 to the regret of @xmath28 ( or to the information sets above it ) .",
    "moreover , any history that would be reached beyond @xmath12 would also contribute nothing to its information set s regret because @xmath110 for every history @xmath10 where @xmath111 and @xmath112 .",
    "thus , when traversing the game tree for player @xmath26 , there is no need to traverse beyond any history @xmath12 when @xmath109 .",
    "the benefit of this form of pruning , which we refer to as _ partial pruning _ , varies depending on the game , but empirical results show a factor of @xmath113 improvement in some games  @xcite .    while partial pruning allows one to prune paths that an _ opponent _ reaches with zero probability , _ interval regret - based pruning _ ( interval rbp ) allows one to also prune paths that the _ traverser _ reaches with zero probability  @xcite .",
    "however , this pruning is necessarily temporary .",
    "consider an action @xmath99 such that @xmath114 , and assume that it is known action  @xmath11 will not be played with positive probability until some far - future iteration @xmath115 ( in rm , this would be the case if @xmath116 ) .",
    "since action  @xmath11 is played with zero probability on iteration @xmath90 , so from ( [ eq : counterfactual ] ) the strategy played and reward received following action  @xmath11 ( that is , in @xmath44 ) will not contribute to the regret for any information set preceding action  @xmath11 on iteration @xmath90 .",
    "in fact , what happens in @xmath44 has no bearing on the rest of the game tree until iteration @xmath115 is reached .",
    "so one could , in theory , `` procrastinate '' in deciding what happened beyond action  @xmath11 on iteration @xmath90 , @xmath117 , ... , @xmath118 until iteration @xmath115 .",
    "however , upon reaching iteration @xmath115 , rather than individually making up the @xmath119 iterations over @xmath44 , one can instead do a _",
    "iteration , playing against the average of the opponents strategies in the @xmath119 iterations that were missed , and declare that strategy was played on all the @xmath119 iterations .",
    "this accomplishes the work of the @xmath119 iterations in a single traversal .",
    "moreover , since player @xmath26 never plays action @xmath11 with positive probability between iterations @xmath90 and @xmath115 , that means every _ other _ player can apply partial pruning on that part of the game tree for iterations @xmath119 , and skip it completely .",
    "this , in turn , means that player @xmath26 has free rein to play whatever they want in @xmath44 without affecting the regrets of the other players . in light of that , and of the fact that player @xmath26 gets to decide what is played in @xmath44 after knowing what the other players have played , player @xmath26 might as well play a strategy that ensures zero regret for all information sets @xmath45 in the iterations @xmath90 to @xmath115 .",
    "a cbr to the average of the opponent strategies on the @xmath119 iterations would qualify as such a zero - regret strategy .",
    "interval regret - based pruning only allows a player to skip traversing @xmath44 for as long as @xmath114 .",
    "thus , in rm , if @xmath120 , we can prune the game tree beyond action @xmath11 from iteration @xmath121 until iteration @xmath122 so long as @xmath123 .",
    "[ sec : warmrbp ]    this section introduces a new form of rbp which we coin _ total rbp_. when pruning ends and regret must be updated in the pruned branch , interval rbp calculates a cbr to the average opponent strategy over the skipped iterations , and updates regret in the pruned branch as if that cbr strategy were played on each of the skipped iterations .",
    "by contrast , when pruning ends in total rbp , it calculates a cbr in the pruned branch against the opponent s average strategy over _ all _ iterations played so far , and sets regret as if that cbr strategy were played on _ every _ iteration played in the game so far  even those that were played before pruning began .    while using a cbr works correctly in total rbp , it is also sound to choose a strategy that is _ almost _ a cbr ( formalized later in this section ) , as long as that strategy does not result in a violation of the cfr bound on the potential function @xmath124 of any information set @xmath29 . in practice , this means that the strategy is close to a cbr , and approaches a cbr as @xmath103 .",
    "we now present the theory to show that such a near - cbr can be used .",
    "however , in practice cfr converges much faster than the theoretical bound , so the potential function is typically far lower than the theoretical bound .",
    "thus , while choosing a near - cbr rather than an exact cbr may allow for slightly longer pruning according to the theory , it may actually result in worse performance .",
    "all of the theoretical results presented in this paper , including the improved convergence bound as well as the lower space requirements , still hold if only a cbr is used , and our experiments use a cbr .",
    "nevertheless , clever heuristics for deciding on a near - cbr may lead to even better performance in practice .",
    "we define a strategy @xmath125 as a @xmath2__-near counterfactual best response _ _",
    "( @xmath2-near cbr ) to @xmath74 if for all @xmath29 belonging to player @xmath26 @xmath126 where @xmath127 can be any value in the range @xmath128 and @xmath129 is the cfr bound on @xmath124 . if @xmath130 , then a @xmath2-near cbr is always a cbr .",
    "the set of strategies that are @xmath2-near cbrs to @xmath74 is represented as @xmath131 .",
    "we also define the @xmath2__-near counterfactual best response value _ _ as @xmath132 and @xmath133 .    in total rbp",
    ", an action is pruned only if it would still have negative regret had a @xmath2-near cbr against the opponent s average strategy been played on every iteration .",
    "specifically , on iteration @xmath2 of cfr with rm , if @xmath134 then @xmath44 can be pruned for @xmath135 iterations . after those @xmath136 iterations are over , we calculate a @xmath137-near cbr in @xmath44 to the opponent s average strategy and set regret as if that @xmath137-near cbr had been played on every iteration .",
    "specifically , for each @xmath138 we set and either @xmath139 or @xmath140 are stored . ]",
    "@xmath141 so that @xmath142 and for every information set @xmath45 we set @xmath143 and @xmath144 so that @xmath145    theorem  [ theorem : totalrbp ] proves that if ( [ eq : rbpcondition ] ) holds for some action , then the action can be pruned for @xmath136 iterations , where @xmath136 is defined in ( [ eq : prunesimple ] ) .",
    "the same theorem holds if one replaces the @xmath2-near counterfactual best response values with counterfactual best response values .",
    "the proof for theorem  [ theorem : totalrbp ] draws from recent work on warm starting cfr using only an average strategy profile  @xcite .",
    "essentially , we warm start regrets in the pruned branch using only the average strategy of the opponent and knowledge of @xmath2 .",
    "assume @xmath2 iterations of cfr with rm have been played in a two - player zero - sum game and assume @xmath146 where @xmath147 .",
    "let @xmath148 .",
    "if both players play according to cfr with rm for the next @xmath136 iterations in all information sets @xmath149 except that @xmath150 is set to zero and @xmath151 is renormalized , then @xmath152 . moreover , if one then sets @xmath141 for each @xmath138 and @xmath143 for each @xmath45 , then after @xmath153 additional iterations of cfr with rm , the bound on exploitability of @xmath154 is no worse than having played @xmath155 iterations of cfr with rm without rbp . [",
    "theorem : totalrbp ]    in practice , rather than check whether ( [ eq : rbpcondition ] ) is met for an action on every iteration , one could only check actions that have very negative regret , and do a check only once every several iterations .",
    "this would still be safe and would save some computational cost of the checks , but would lead to less pruning .",
    "as is the case with interval rbp , the duration of pruning can be increased by giving up knowledge beforehand of exactly how many iterations can be skipped . from ( [ eq : counterfactuala ] ) and ( [ eq : counterfactual ] ) we see that @xmath156 .",
    "thus , if @xmath157 is very low , then ( [ eq : rbpcondition ] ) would continue to hold for more iterations than ( [ eq : prunesimple ] ) guarantees .",
    "specifically , we can prune @xmath44 from iteration @xmath121 until iteration @xmath122 as long as @xmath158      a key advantage of total rbp is that setting the new regrets according to ( [ eq : pruneregreta ] ) and ( [ eq : pruneregret ] ) requires no knowledge of what the regrets were before pruning began .",
    "thus , once pruning begins , all the regrets in @xmath44 can be discarded and the space that was allocated to storing the regret can be freed .",
    "that space need only be re - allocated once ( [ eq : totalrbp ] ) ceases to hold _ and _ we can not immediately begin pruning again ( that is , ( [ eq : rbpcondition ] ) does not hold ) .",
    "theorem  [ theorem : rbpspace ] proves that for any information set @xmath29 and action @xmath99 that is not part of a best response to a nash equilibrium , there is an iteration @xmath159 such that for all @xmath160 , action @xmath11 in information set @xmath29 ( and its descendants ) can be pruned . and action @xmath99 that is not a best response to _ that particular _ nash equilibrium .",
    "while empirically cfr does appear to always converge to a particular nash equilibrium , there is no known proof that it always does so . ]",
    "thus , once this @xmath159 is reached , it will never be necessary to allocate space for regret in @xmath44 again .    in a two - player zero - sum game ,",
    "if for every opponent nash equilibrium strategy @xmath161 , @xmath162 , then there exists a @xmath159 and @xmath163 such that after @xmath160 iterations of cfr , @xmath164 .",
    "[ theorem : rbpspace ]    while such a constant @xmath159 exists for any suboptimal action , total rbp can not determine whether or when @xmath159 is reached .",
    "so , it is still necessary to check whether ( [ eq : rbpcondition ] ) is satisfied whenever ( [ eq : totalrbp ] ) no longer holds , and to recalculate how much longer @xmath44 can safely be pruned .",
    "this requires the algorithm to periodically calculate a best response ( or near - best response ) in @xmath44 . however , this ( near-)best response calculation does not require knowledge of regret in @xmath44 , so it is still never necessary to store regret after iteration @xmath159 is reached .",
    "while it is possible to discard regrets in @xmath44 without penalty once pruning begins , regret is only half the space requirement of cfr .",
    "every information set @xmath29 also stores a sum of the strategies played @xmath165 which is normalized once cfr ends in order to calculate @xmath166 .",
    "fortunately , if action @xmath11 in information set @xmath29 is pruned for long enough , then the stored cumulative strategy in @xmath44 can also be discarded at the cost of a small increase in the distance of the final average strategy from a nash equilibrium .",
    "specifically , if @xmath167 , where @xmath168 is some constant , then setting @xmath169 and renormalizing @xmath166 , and setting @xmath170 for @xmath45 , can result in at most @xmath171 higher exploitability for the whole strategy @xmath172 .",
    "since cfr only guarantees that @xmath172 is a @xmath173-nash equilibrium anyway , @xmath171 is only a constant factor of the bound . if an action is pruned from @xmath136 to @xmath2 , then @xmath174 .",
    "thus , if an action is pruned for long enough , then eventually @xmath175 for any @xmath168 , so @xmath176 could be set to zero ( as well as all descendants of @xmath177 ) , while suffering at most a constant factor increase in exploitability .",
    "as more iterations are played , this penalty will continue to decrease and eventually be negligible .",
    "the constant @xmath168 can be set by the user : a higher @xmath168 allows the average strategy to be discarded sooner , while a lower @xmath168 reduces the potential penalty in exploitability .",
    "we define @xmath178 as the set of information sets that are not guaranteed to be asymptotically pruned by theorem  [ theorem : rbpspace ] .",
    "specifically , @xmath179 if @xmath180 for some @xmath181 and @xmath182 such that for every opponent nash equilibrium strategy @xmath183 , @xmath184 .",
    "theorem  [ theorem : rbpspace ] implies the following .    in a two - player zero - sum game with some threshold on the average strategy @xmath185 for @xmath186 , after a finite number of iterations , cfr with total",
    "rbp requires only @xmath187 space .",
    "[ corollary : rbpspace ]      we now prove that total rbp in cfr speeds up convergence to an @xmath80-nash equilibrium .",
    "section  [ sec : warmrbp ] proved that cfr with total rbp converges in the same number of iterations as cfr alone . in this section , we prove that total rbp allows each iteration to be traversed more quickly .",
    "specifically , if an action @xmath99 is not a cbr to a nash equilibrium , then @xmath44 need only be traversed @xmath188 times over @xmath2 iterations .",
    "intuitively , as both players converge to a nash equilibrium , actions that are not a counterfactual best response will eventually do worse than actions that are , so those suboptimal actions will accumulate increasing amounts of negative regret .",
    "this negative regret allows the action to be safely pruned for increasingly longer periods of time .",
    "specifically , let @xmath189 be the set of histories where @xmath190 if @xmath191 and action @xmath11 is part of some cbr to some nash equilibrium .",
    "formally , @xmath192 contains @xmath193 and every history @xmath194 such that @xmath191 and @xmath195 for some nash equilibrium @xmath77 .    in a two - player zero - sum game , if both players choose strategies according to cfr with total rbp , then conducting @xmath2 iterations requires only @xmath196 nodes to be traversed .",
    "[ theorem : rbpfast ]    the definition of @xmath192 uses properties of the nash equilibria of the game , and an action @xmath99 not in @xmath192 is only guaranteed to be pruned by rbp after some @xmath159 is reached , which also depends on the nash equilibria of the game . since cfr converges to only an @xmath80-nash equilibrium , cfr can not determine with certainty which nodes are in @xmath192 or when @xmath159 is reached .",
    "nevertheless , both @xmath192 and @xmath159 are fixed properties of the game .",
    "we compare total rbp to interval rbp , to only partial pruning , and to no pruning at all .",
    "we also show the amount of space used by total rbp over the course of the run .",
    "the experiments are conducted on leduc holdem  @xcite and leduc-5  @xcite .",
    "leduc holdem is a common benchmark in imperfect - information game solving because it is small enough to be solved but still strategically complex . in leduc holdem",
    ", there is a deck consisting of six cards : two each of jack , queen , and king .",
    "there are two rounds . in the first round ,",
    "each player places an ante of @xmath197 chip in the pot and receives a single private card .",
    "a round of betting then takes place with a two - bet maximum , with player 1 going first . a public shared card",
    "is then dealt face up and another round of betting takes place .",
    "again , player 1 goes first , and there is a two - bet maximum .",
    "if one of the players has a pair with the public card , that players wins . otherwise , the player with the higher card wins .",
    "the bet size in the first round is @xmath198 chips , and @xmath199 chips in the second round .",
    "leduc-5 is like leduc holdem but larger : there are 5 bet sizes to choose from . in the first round a player may bet @xmath200 , @xmath197 , @xmath198 , @xmath199 , or @xmath201 chips , while in the second round a player may bet @xmath197 , @xmath198 , @xmath199 , @xmath201 , or @xmath202 chips .",
    "results are presented for both cfr and cfr+ .",
    "nodes touched is a hardware and implementation - independent proxy for time .",
    "overhead costs are counted in nodes touched .",
    "cfr+ is a variant of cfr in which a floor on regret is set at zero and each iteration is weighted linearly in the average strategy ( that is , iteration @xmath90 is weighted by @xmath90 ) rather than each iteration being weighted equally .",
    "since interval rbp can only prune negative - regret actions , interval rbp modifies the definition of cfr+ so that regret can be negative , but immediately jumps up to zero as soon as regret increases .",
    "total rbp does not require this modification .",
    "both forms of rbp modify the behavior of cfr+ because without pruning , cfr+ would put positive probability on an action as soon as its regret increases , while rbp waits until pruning is over .",
    "this is not , by itself , a problem .",
    "however , cfr+ s linear weighting of the average strategy is only guaranteed to converge to a nash equilibrium if pruning does not occur . while pruning does well empirically with cfr+ ,",
    "the convergence is noisy .",
    "this noise can be reduced by using the lowest - exploitability average strategy profile found so far .",
    "we do this in the experiments .",
    "figure  [ fig : rbpspace ] shows the reduction in space needed to store the average strategy and regrets for total rbp  for various values of the constant threshold @xmath168 , where an action s probability is set to zero if it is reached with probability less than @xmath185 in the average strategy , as we explained in section  [ sec : rbpspace ] . in both games , a threshold between 0.01 and 0.1 performed well in both space and number of iterations , with the lower thresholds converging somewhat faster and the higher thresholds reducing space faster .",
    "we also tested thresholds below 0.01 , but the speed of convergence was essentially the same as when using 0.01 . in leduc , all variants resulted in a quick drop - off in space to about half the initial amount . in leduc-5 ,",
    "a threshold of 0.1 resulted in a factor of 10 reduction in space for cfr+ , and a factor of 7 reduction for cfr . in the case of cfr",
    ", this space reduction factor appears to continue to increase .",
    "figure  [ fig : rbpconverge ] compares the convergence rates of total rbp , interval rbp , and only partial pruning for both cfr and cfr+ . in leduc ,",
    "total rbp and interval rbp perform comparably when added to cfr . when added to cfr+ ,",
    "interval rbp does significantly better . in leduc-5 , which is a far larger game , total rbp outperforms interval rbp by a factor of 2 when added to cfr . when added to cfr+ , total rbp initially does far better but its performance is eventually surpassed by interval rbp",
    "this may be due to the noisy performance of cfr+ with rbp .",
    "we introduced total rbp , a new form of regret - based pruning that provably reduces both the space needed to solve an imperfect - information game and the time needed to reach an @xmath80-nash equilibrium .",
    "this addresses both of the major bottlenecks in solving large imperfect - information games .",
    "experimentally , total rbp reduced the space needed to solve a game by an order of magnitude , with the reduction factor increasing with game size .    10    michael bowling , neil burch , michael johanson , and oskari tammelin .",
    "heads - up limit holdem poker is solved .",
    ", 347(6218):145149 , january 2015 .",
    "noam brown and tuomas sandholm .",
    "regret - based pruning in extensive - form games . in _ proceedings of the annual conference on neural information processing systems ( nips )",
    "_ , 2015 .    noam brown and tuomas sandholm .",
    "simultaneous abstraction and equilibrium finding in games . in _ proceedings of the international joint conference on artificial intelligence ( ijcai ) _ , 2015 .",
    "noam brown and tuomas sandholm .",
    "strategy - based warm starting for regret minimization in games . in _",
    "aaai conference on artificial intelligence ( aaai ) _ , 2016 .",
    "andrew gilpin and tuomas sandholm .",
    "lossless abstraction of imperfect information games . , 54(5 ) , 2007 .",
    "early version ` finding equilibria in large sequential games of imperfect information ' appeared in the proceedings of the acm conference on electronic commerce ( ec ) , pages 160169 , 2006 .    sergiu hart and andreu mas - colell .",
    "a simple adaptive procedure leading to correlated equilibrium .",
    ", 68:11271150 , 2000 .",
    "samid hoda , andrew gilpin , javier pea , and tuomas sandholm .",
    "smoothing techniques for computing nash equilibria of sequential games .",
    ", 35(2):494512 , 2010 .",
    "conference version appeared in wine-07 .",
    "christian kroer , kevin waugh , fatma kilin - karzan , and tuomas sandholm .",
    "faster first - order methods for extensive - form game solving . in _ proceedings of the acm conference on economics and computation ( ec ) _ , 2015 .",
    "marc lanctot , kevin waugh , martin zinkevich , and michael bowling .",
    "onte carlo sampling for regret minimization in extensive games . in _ proceedings of the annual conference on neural information processing systems ( nips ) _ , pages 10781086 , 2009 .",
    "matej moravcik , martin schmid , karel ha , milan hladik , and stephen  j gaukrodger .",
    "refining subgames in large imperfect information games . in _",
    "thirtieth aaai conference on artificial intelligence _ , 2016 .",
    "yurii nesterov .",
    "excessive gap technique in nonsmooth convex minimization . , 16(1):235249 , 2005 .",
    "franois pays .",
    "an interior point approach to large games of incomplete information . in _",
    "aaai computer poker workshop _ , 2014 .",
    "finnegan southey , michael bowling , bryce larson , carmelo piccione , neil burch , darse billings , and chris rayner .",
    "bayes bluff : opponent modelling in poker . in _ proceedings of the 21st annual conference on uncertainty in artificial intelligence ( uai ) _ , pages 550558 , july 2005 .",
    "oskari tammelin , neil burch , michael johanson , and michael bowling .",
    "solving heads - up limit texas holdem . in _ proceedings of the 24th international joint conference on artificial intelligence ( ijcai ) _ , 2015 .",
    "kevin waugh , david schnizlein , michael bowling , and duane szafron .",
    "abstraction pathologies in extensive games . in _ international conference on autonomous agents and multi - agent systems ( aamas )",
    "_ , 2009 .",
    "martin zinkevich , michael bowling , michael johanson , and carmelo piccione .",
    "regret minimization in games with incomplete information . in _ proceedings of the annual conference on neural information processing systems ( nips )",
    "_ , 2007 .    * appendix *    in the appendices we present the proofs , and additional lemmas that are used in the proofs .",
    "lemma  [ lemma : rbpwarm ] proves that if ( [ eq : rbpcondition ] ) is satisfied for some action @xmath99 on iteration @xmath2 , then the value of action @xmath11 and all its descendants on every iteration played so far can be set to the @xmath2-near counterfactual best response value .",
    "the same lemma holds if one replaces the @xmath2-near counterfactual best response values with exact counterfactual best response values .",
    "the proof for lemma  [ lemma : rbpwarm ] draws from recent work on warm starting cfr using only an average strategy profile  @xcite .",
    "assume @xmath2 iterations of cfr with rm have been played in a two - player zero - sum game . if @xmath146 and one sets @xmath203 for each @xmath204 and for each @xmath45 sets @xmath205 and @xmath206 then after @xmath136 additional iterations of cfr with rm , the bound on exploitability of @xmath207 is no worse than having played @xmath208 iterations of cfr with rm unaltered .",
    "[ lemma : rbpwarm ]    the proof builds upon theorem  2 in @xcite .",
    "assume @xmath146 .",
    "we wish to warm start to @xmath2 iterations . for each @xmath45 set @xmath205 and @xmath206 and set @xmath203 for all @xmath204 . for every other action , leave regret unchanged . for each @xmath45 we know by construction that @xmath209 is within the cfr bound @xmath210 after changing regret . by assumption @xmath146 , so @xmath211 and",
    "therefore @xmath124 is unchanged .",
    "finally , since the @xmath2 iterations were played according to cfr with rm and regret is unchanged for every other information set @xmath212 , so the conditions for theorem  2 in @xcite hold for every information set , and therefore we can warm start to @xmath2 iterations of cfr with rm with no penalty to the convergence bound .",
    "from lemma  [ lemma : rbpwarm ] we can immediately set regret for @xmath99 to @xmath203 . by construction of @xmath136 , @xmath213 is guaranteed to be nonpositive for @xmath214 and therefore @xmath114 .",
    "thus , @xmath215 for @xmath45 is identical regardless of what is played in @xmath44 during @xmath214 .    since @xmath216 and @xmath217 , so by the definition of @xmath136 , @xmath152 .",
    "so if regrets in @xmath44 and @xmath218 are set according to lemma  [ lemma : rbpwarm ] , then after @xmath153 additional iterations of cfr with rm , the bound on exploitability of @xmath154 is no worse than having played @xmath155 iterations of cfr with rm from scratch .",
    "consider an information set @xmath29 and action @xmath99 where for every opponent nash equilibrium strategy @xmath161 , @xmath162 .",
    "let @xmath67 .",
    "let @xmath219 where @xmath220 is the set of nash equilibria .",
    "let @xmath221 since @xmath222 is not a nash equilibrium strategy and cfr converges to a nash equilibrium strategy for both players , so there exists a @xmath223 such that for all @xmath224 , @xmath225 .",
    "let @xmath226 .",
    "for @xmath227 since @xmath102 , so @xmath228 .",
    "let @xmath229 and @xmath230 . then for @xmath160 , @xmath164 .",
    "let @xmath231 . then @xmath232 for some @xmath181 and @xmath182 such that for every opponent nash equilibrium strategy @xmath183 , @xmath184 .",
    "applying theorem  [ theorem : rbpspace ] , this means there exists a @xmath233 and @xmath234 such that for @xmath235 , @xmath236 .",
    "so ( [ eq : rbpcondition ] ) always applies for @xmath235 for @xmath181 and @xmath237 and @xmath29 will always be pruned . since ( [ eq : pruneregret ] )",
    "does not require knowledge of regret , it need not be stored for @xmath29 .    since @xmath238 will always be pruned for @xmath235 , so for any @xmath239 iterations for some constant @xmath186 , @xmath240 , which satisfies the threshold of the average strategy .",
    "thus , the average strategy in @xmath44 can be discarded .",
    "if for all @xmath241 iterations of cfr with rbp , @xmath242 for some @xmath243 , then any history @xmath10 such that @xmath47 for some @xmath30 need only be traversed at most @xmath1 times .",
    "[ lemma : negative ]    let @xmath99 be an action such that for all @xmath241 , @xmath244 for some @xmath243 .",
    "@xmath245 , so from theorem  [ theorem : totalrbp ] , @xmath44 can be pruned for @xmath246 iterations on iteration @xmath2 .",
    "thus , over iterations @xmath247 , only a constant number of traversals must be done .",
    "so each iteration requires only @xmath248 work when amortized , where @xmath168 is a constant . since @xmath249 , @xmath41 , and",
    "@xmath37 are constants , so on each iteration @xmath250 , only an average of @xmath251 traversals of @xmath44 is required .",
    "summing over all @xmath204 for @xmath241 , and recognizing that @xmath136 is a constant , we get that action @xmath11 is only taken @xmath1 over @xmath2 iterations .",
    "thus , any history @xmath10 such that @xmath47 for some @xmath30 need only be traversed at most @xmath1 times .",
    "consider an @xmath252 . then there exists some @xmath253 such that @xmath191 but @xmath254 .",
    "let @xmath255 and @xmath67 .",
    "since @xmath254 but @xmath191 , so for every nash equilibrium @xmath77 , @xmath256 . from theorem  [ theorem : rbpspace ]",
    ", there exists a @xmath159 and @xmath163 such that after @xmath160 iterations of cfr , @xmath257 .",
    "thus from lemma  [ lemma : negative ] , @xmath258 need only be traversed at most @xmath1 times ."
  ],
  "abstract_text": [
    "<S> _ counterfactual regret minimization _ ( cfr ) is the most popular iterative algorithm for solving zero - sum imperfect - information games . _ </S>",
    "<S> regret - based pruning _ ( rbp ) is an improvement that allows poorly - performing actions to be temporarily pruned , thus speeding up cfr . </S>",
    "<S> we introduce _ total rbp _ , a new form of rbp that reduces the space requirements of cfr as actions are pruned . </S>",
    "<S> we prove that in zero - sum games it asymptotically prunes any action that is not part of a best response to some nash equilibrium . </S>",
    "<S> this leads to provably faster convergence and lower space requirements . </S>",
    "<S> experiments show that total rbp results in an order of magnitude reduction in space , and the reduction factor increases with game size . </S>"
  ]
}