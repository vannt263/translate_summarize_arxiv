{
  "article_text": [
    "the construction of several new detectors of gravitational radiation is currently approaching completion .",
    "these instruments are of a different design and have significantly better sensitivity and broader bandwidth than previous detectors .",
    "they include the ligo detector being built in the united states by a joint caltech / mit collaboration @xcite , the virgo detector being built near pisa by an italian / french collaboration @xcite , the geo-600 detector being built in hannover by an anglo / german collaboration @xcite , and the tama-300 detector near tokyo @xcite .",
    "there are also several resonant bar detectors currently in operation @xcite , and several more refined bar and interferometric detectors presently in the planning and proposal stages @xcite .",
    "these instruments search for very weak signals .",
    "for the most likely sources , the signals will be buried in the noise of the detectors , and need to be extracted with sophisticated optimal signal - processing strategies @xcite .",
    "the standard assumption made in the literature is that the detector noise has multivariate gaussian statistics .",
    "this assumption is certainly incorrect : every sensitive gravitational wave detector operated to date has been characterized by noise that is both non - stationary and non - gaussian .",
    "some experimentation has shown that this is a serious matter @xcite : existing detection strategies for both deterministic and stochastic signals do not perform nearly as well when non - gaussian noise is present . roughly speaking ,",
    "if the non - gaussian fluctuations are large , they bias the statistics and make it more difficult to achieve a given level of statistical confidence .    in this paper , we develop a new set of statistical signal - processing techniques to search for deterministic and stochastic gravitational waves .",
    "these techniques are _ robust _ , meaning that they will work well even if the detector noise is not gaussian but falls into a broader statistical class that we expect includes realistic detectors . in large part , these new methods are similar to the older ones : one constructs matched filters to search for known waveforms or cross - correlates the instrument outputs at the different detector sites to search for a stochastic background .",
    "the essential difference is that by using locally optimal methods @xcite these statistical measures are modified .",
    "the effect is to _ truncate _ the statistics : detector samples that fall outside the central gaussian - like part of the sample distribution ( i.e. , the outliers ) are excluded from ( or saturated when constructing ) the measurement statistic . for both cases ,",
    "a robust statistic is found which performs better than the optimal linear filter in the case where the detector noise is non - gaussian , and almost as well in the gaussian - noise case .",
    "the paper is organized as follows . in sec .",
    "[ s : deterministic ] we derive the locally most powerful signal - processing tests for deterministic signals .",
    "we begin in sec .",
    "[ ss : sdwnkw ] with a derivation of the neyman - pearson criteria for optimality , in the case where a known waveform is hidden in white noise .",
    "we define the power function of a test and derive a criteria for the locally optimal test in the weak - signal regime .",
    "the locally optimal test is analyzed for a number of different types of non - gaussian noise , and we show that the locally optimal decision statistic is a matched filter where the non - gaussian sample values are truncated or excluded . in sec .",
    "[ ss : sdcnkw ] the results are generalized to the case where a known waveform is hidden in colored noise , and we introduce models for non - gaussian colored noise . in sec .",
    "[ s : stochastic ] , we turn to the detection of a stochastic background .",
    "section  [ ss:2dwnss ] considers the case of a stochastic signal ( i.e. , where the waveform is not known ) and derives the locally optimal statistic which can be used to correlate two identical detectors , where we assume that each detector has independent white noise and is co - aligned and coincident . in sec .",
    "[ ss:2dcnss ] , these results are generalized to the case where the noise is colored , and the detectors are in different locations , and not aligned in parallel . in sec .",
    "[ s : impsim ] , we discuss an implementation of these statistics , and we illustrate how one can compare the performance of different statistics using monte carlo simulations . section  [ s : conclude ] contains a short conclusion and summary .",
    "in order to describe the idea in a simple way we first discuss the case where we are searching for a known signal in the data stream of a single detector , where the time - domain detector noise samples are independent in the time - domain .    denote the data stream of the first detector by @xmath0 for @xmath1 . in this section , since we are going to only consider this single detector , we will drop the subscript `` 1 . ''",
    "imagine that we are looking for a signal of known waveform but unknown amplitude @xmath2 , which we will denote by @xmath3 .",
    "our primary interest is in the case where the amplitude @xmath2 is either small , or zero . for convenience ,",
    "imagine for the moment that this parameter can have only two possible values , either @xmath4 or @xmath5 .",
    "the detection problem that we need to solve is to partition the space of possible observations @xmath6 into two disjoint subsets .",
    "when the observation @xmath7 falls into one of these , we conclude that @xmath4 and that the null hypothesis is true .",
    "when the observation falls into the other set we conclude that the signal has been observed with @xmath8 . to describe the partition of @xmath6 into two regions , define a function @xmath9 which is zero in the null hypothesis region and unity elsewhere .",
    "this function is called a _",
    "test_. our goal is to find the `` best '' choice of a test @xmath10 .    to help characterize tests @xmath10 , it is helpful to define the _ power _ function of a test : @xmath11 here @xmath12 is the probability distribution of the measurement @xmath7 given signal amplitude @xmath2 .",
    "for example , for additive white , stationary gaussian noise of unit variance and vanishing mean , @xmath13 the quality of the test can be expressed in terms of the power function .",
    "we characterize the quality of the test by the false alarm and the false dismissal probabilities .",
    "the false alarm probability is the probability with which we conclude that @xmath8 when in fact @xmath2 vanishes .",
    "this is given by @xmath14 .",
    "the false dismissal probability is the probability with which we conclude that @xmath4 when in fact it is @xmath15 .",
    "this is given by @xmath16 .",
    "one standard definition of the `` best '' test @xmath10 is that it minimizes the false dismissal probability for a given false alarm probability .",
    "this is called the neyman - pearson test",
    ". one can find this test using calculus of variations , with a lagrange multiplier @xmath17 to enforce the constraint that the false alarm probability is fixed .",
    "the best test is obtained by partitioning @xmath6 as follows .",
    "choose a constant @xmath18 .",
    "then , set @xmath19 in regions where the likelihood ratio @xmath20 is greater than @xmath21 . set @xmath22 elsewhere .",
    "( we assume that the boundary between these two regions is a set of probability measure zero . )",
    "the value of the constant @xmath21 determines the false alarm probability .",
    "thus , the likelihood ratio is a `` decision statistic '' : a number that can be calculated from the observed data .",
    "if the statistic is less than some value , we conclude that the null hypothesis holds .",
    "if the statistic is greater than this value , we conclude the opposite .",
    "the decision statistic provides a partition of the space of observations into two disjoint regions .    in the case where the noise is gaussian ( [ e : gaussnoise ] ) this criteria is easily understood .",
    "the optimal neyman - pearson test divides the space of observation along an @xmath23-dimensional plane .",
    "on one side of this plane @xmath19 and on the other side @xmath10 vanishes .",
    "the plane is defined by setting the likelihood ratio ( [ e : like ] ) to a constant . for the gaussian probability distribution ( [ e : gaussnoise ] )",
    "the plane is defined by @xmath24 this plane is perpendicular to the vector @xmath25 .",
    "different choices of this plane correspond to different false alarm rates .    in the case where the noise is not gaussian ,",
    "the problem becomes more challenging . in the gaussian test , the decision statistic is independent of the signal amplitude @xmath2 .",
    "however when the noise in not gaussian , the choice of decision statistic depends upon @xmath2 . consider the graph in fig .",
    "[ f : powerfn ] showing the power function @xmath26 as a function of @xmath2 for several different tests .",
    "all the tests have the same false alarm rate , but the optimal test depends upon the value of @xmath2 .    for the case of weak signals in non - gaussian noise , there is a useful test called the `` locally optimal '' test . for a given noise probability distribution ,",
    "the locally optimal test is easy to describe , and leads to a simple decision statistic which can be calculated from the observed data @xcite . to define this test , it is useful to again consider the set of all tests with a given false alarm rate , as shown for example in fig .",
    "[ f : powerfn ] .",
    "the locally optimal test is the one that maximizes @xmath27 at @xmath4 for a fixed false alarm probability .",
    "as above , one can show that the locally optimal test sets @xmath19 inside the region where @xmath28_{\\epsilon=0}>\\text{constant}\\ ] ] for some constant , and @xmath22 elsewhere ( see fig .  [",
    "f : powerfn ] ) .",
    "the value of the constant determines ( or is determined by ) the false alarm probability . more generally , if the first derivative vanishes , the locally optimal test is determined by the first non - zero @xmath29 to understand the implications of this , it is helpful to consider several examples .",
    "the examples here are for the case where the ( additive ) detector noise is independent for each sample value ( so the noise spectrum is white ) but has an arbitrary probability distribution . for convenience ,",
    "we write @xmath30 where the function @xmath31 is a quadratic function of its argument for the case where the probability distribution of the noise is gaussian . [",
    "note : any probability distribution for stationary additive noise where the sample values are independent can be written in this way .",
    "if the noise is not stationary but is still additive and independent , then each function @xmath31 appearing in ( [ e : nongaussnoise ] ) may be different @xmath32 . ] the first derivative of the pdf ( [ e : nongaussnoise ] ) with respect to @xmath2 is @xmath33 where @xmath34 denotes the derivative of @xmath31 with respect to its argument . setting @xmath4 in this expression",
    "one can easily find the locally optimal test ( [ e : lotest ] ) .",
    "this is defined by setting @xmath19 in the region @xmath35 and setting @xmath22 elsewhere .",
    "[ note : if @xmath2 can take either sign @xmath36 then an absolute value sign should enclose the lhs of the inequality in eq .",
    "( [ e : forexamples ] ) . ] as before , the value of the constant determines the false alarm probability . here",
    "are several examples :    * * gaussian noise * : @xmath37 , so @xmath38 . for this case the locally optimal test ( [ e : forexamples ] ) and the optimal test ( [ e : simplegauss ] ) both give the same statistic : @xmath39 .",
    "this is the standard optimal linear filter . * * exponential noise * : @xmath40 , so @xmath41 . here",
    "the locally optimal statistic is given by ( [ e : forexamples ] ) as @xmath42 where the @xmath43 function is @xmath44 for @xmath45 and @xmath46 for @xmath47 .",
    "* * sum of distinct gaussian processes * : this is a white - noise version of the model given in  @xcite : @xmath48 where @xmath49 and @xmath50 .",
    "usually one also has @xmath51 .",
    "this noise model is discussed in more detail later in this paper .",
    "it often arises when the most common source of noise is gaussian , but there is also a `` tail '' of `` outlier '' events which dominates the wings of the distribution . here",
    "the locally optimal statistic is defined by ( [ e : forexamples ] ) where @xmath52.\\ ] ] this function is shown ( for the case @xmath53 , @xmath54 , @xmath55 ) in fig .",
    "[ f : weight2 ] . roughly speaking , for @xmath56 small compared to @xmath57 one has @xmath58 . for large @xmath56",
    "one has @xmath59 . *",
    "* gaussian noise plus uniform background * : here , we have a ( small ) uniform background superposed on gaussian noise of zero mean and unit variance .",
    "this is defined for ( small ) @xmath60 by @xmath61 here we assume that @xmath62 is the scale size of the uniform background ( the probability distribution is correctly normalized only in the limit @xmath63 ) . in this case one finds that @xmath64 for @xmath65 and @xmath66 for @xmath67 .",
    "while the results for the different probability distributions are technically different , they all carry same message , which is the central result of this paper : _ if the distribution of sample values has a central gaussian region , then sample values falling in this region should be correlated exactly as they would be in the gaussian case .",
    "if a sample value falls outside this region , its value should be truncated ( or clipped ) to the largest allowed value in the central region , or even dropped from any correlation statistic , depending upon the shape of the probability distribution_.    let us repeat this central point one more time .",
    "the results show that when the noise is not gaussian , the normal optimal filter used to construct a decision statistic is replaced by a somewhat different sum .",
    "the values of the expected signal @xmath68 are multiplied , not by the observed data @xmath69 but by some non - linear function of that data , then summed . in the event that the probability distribution of the noise has a non - gaussian tail ,",
    "the effect of this non - linear function is to `` clip '' or truncate sample values which fall outside the central bulge of the probability distribution function .",
    "if the detector s noise spectrum is colored rather than white , then the previous analysis does not apply : the assumption that the different sample values are uncorrelated no longer holds .",
    "however the analysis can be generalized to the colored case if we make assumptions that are motivated by the properties of stationary detector noise .    in explaining this , it helps to begin by describing the stationary gaussian case . for a colored gaussian process , the probability density function ( pdf ) of the detector samples",
    "may be expressed as @xmath70 where the @xmath71 correlation matrix @xmath72 is a positive - definite real symmetric matrix with @xmath73 real degrees of freedom and @xmath74 .",
    "we have assumed that the process has zero mean .",
    "the volume element associated with this pdf is @xmath75 . in the time - domain",
    ", @xmath7 is a vector of real numbers so @xmath76 .    in the case where the random process is stationary ,",
    "the matrix @xmath77 is a toeplitz matrix , which depends only upon @xmath78 .",
    "such a process is defined by the first row or first column of the matrix and has only @xmath79 real degrees of freedom .",
    "thus stationary gaussian processes are a tiny subset of _ all _ gaussian processes .",
    "now consider the pdf of new random variables that are linear combinations of the old ones : @xmath80 .",
    "take @xmath81 to be an arbitrary unitary matrix .",
    "clearly the pdf of these new variables @xmath82 is still gaussian .",
    "the matrix @xmath81 can be chosen to diagonalize the correlation matrix : this is called a karhunen - loeve transformation . in the limit where the time interval occupied by the @xmath79 samples is much larger than the correlation time of the noise , the linear combinations of random variables that diagonalize the correlation matrix asymptotically approach the discrete fourier transform ( dft ) .",
    "this is given by @xmath83 thus , if @xmath79 is sufficiently large , to a good approximation the pdf of the new variables in the gaussian case may be written as @xmath84 } 2\\pi^{-1}p_k^{-2 }    \\exp(-2|\\tilde x_k|^2/p_k)\\ ] ] where @xmath85 is the ( real , positive ) mean spectral amplitude in the @xmath86th frequency bin : @xmath87 for @xmath88 $ ] ; thus @xmath89 $ ] .",
    "in other words , it is a good approximation to express the pdf of a stationary colored gaussian process as a diagonal process in frequency space .",
    "the limits of the product in eq .",
    "( [ e : fspacegauss ] ) appear strange because @xmath82 can not take on arbitrary values since @xmath7 is real .",
    "the consequences include :    * @xmath90 .",
    "hence the amplitudes of @xmath91 for @xmath92 + 1,\\ldots , n-1 $ ] are completely determined by @xmath91 for @xmath93 $ ] . *",
    "@xmath94 and , for even @xmath79 , @xmath95 are real . however , we assume that the data set has had the mean value ( dc term ) removed : @xmath96 .",
    "since gravitational wave detectors are ac - coupled and have no useful low - frequency response , this is a valid assumption .",
    "it implies that @xmath94 is identically zero .",
    "second , when @xmath79 is even , we assume that there is no energy in the nyquist frequency bin : @xmath97 also vanishes identically .",
    "this is a very reasonable assumption , since an experiment will include an anti - aliasing filter whose response ( as a function of frequency ) falls off rapidly as the nyquist frequency is approached . *",
    "the volume element associated with this pdf is therefore @xmath98}d(\\re\\tilde x_k)d(\\im\\tilde x_k)$ ] .    the likelihood ratio in the case of colored , stationary , gaussian noise is @xmath99 or , in the frequency domain , @xmath100}\\tilde s_k^\\ast \\tilde x_k / p_k.\\ ] ] thus",
    ", the matched filter statistic , with a weighting equal to the inverse of the noise spectrum , is the optimal detection statistic .",
    "this motivates a more general model for the statistical distribution of colored non - gaussian detector noise , assuming that it is still stationary . in this case , to good approximation , the two - point correlation matrix @xmath101 is diagonal .",
    "there may be higher - order correlations present between the fourier amplitudes at different frequencies , but we will assume that this additional correlation is negligible , and that to a reasonable approximation the probability distribution of the noise in the non - gaussian case is described by a pdf in which the different frequency components are independent : @xmath102 } 2 \\pi^{-1 } p_k^{-2 }    \\exp[-2g_k(|\\tilde x_k|^2/p_k)],\\ ] ] with volume element @xmath98}d(\\re\\tilde x_k)d(\\im\\tilde x_k)$ ] .",
    "the functions @xmath103 depend upon the frequency bin index @xmath86 , so that the statistical distribution can depend upon the frequency .",
    "for the colored gaussian case the functions are @xmath104 . in order that the pdf be properly normalized , and that @xmath105 , the functions @xmath103 must obey @xmath106 respectively , these constrain the additive constant in the definition of @xmath107 , and the multiplicative scale of the argument of @xmath107 .",
    "this is _ not _ the most general possible form of the probability distribution of a stationary random process , but in many situations it should be a reasonable approximation , particularly if the quantities of interest are dominated by the second moments .    the locally optimal statistic may now be easily derived . letting @xmath108 denote the dft of the expected waveform , and as before zeroing its dc and nyquist components , the conditional probability distribution of the detector output is given by @xmath109 } 2 \\pi^{-1 } p_k^{-2 }     \\exp[-2g_k(|\\tilde x_k-\\epsilon\\tilde s_k|^2/p_k)]\\ ] ] the locally optimal test",
    "can then be obtained from the first derivative : @xmath110}\\re(\\tilde s_k^\\ast \\tilde x_k / p_k )      g_k'(|\\tilde x_k|^2/p_k).\\ ] ] in the colored gaussian case @xmath111 this is the ordinary optimal linear matched filter .",
    "the contributions of the different frequency bins are weighted by the inverse noise power spectrum in that bin . in the non - gaussian case , just as for the case of uncolored white noise , the correlation in frequency space is clipped or truncated for ( frequency - bin ) samples that lie outside the central gaussian part of the probability distribution , where @xmath112 .",
    "an example of this may be seen in fig .",
    "[ f : weight2 ] : for the illustrated case @xmath113 .",
    "let us consider another form of non - gaussian noise that describes a process in which there is an ambient gaussian noise background interrupted occasionally by a large noise burst , which we will model as a second component of gaussian noise with a much larger variance .",
    "the probability distribution we adopt is  @xcite : @xmath114 where @xmath77 is the autocorrelation matrix for the normal ambient detector noise and @xmath115 is the composite autocorrelation matrix for the detector noise when a noise burst is present .",
    "the noise bursts occur with probability @xmath116 in this model .",
    "also , @xmath74 and @xmath117 .",
    "we assume that @xmath118 is much smaller than @xmath119 , meaning that @xmath120 for all vectors @xmath7 .",
    "the locally optimal statistic is @xmath121 where @xmath122\\ ] ] is a detector of possible bursts .",
    "when a burst is absent , @xmath123 is typically small and the locally optimal statistic reduces to the matched filter .",
    "however , when a burst is present , @xmath123 is typically large and the matched filter is suppressed .",
    "thus the locally optimal statistic is nearly equivalent to the matched filter statistic with a veto if a segment of data has a large amount of excess power as measured by @xmath124 or , in the frequency domain , @xmath125 } |\\tilde x_k|^2/p_k.\\ ] ] the lengths ( in time ) of the data chunks used to estimate the autocorrelation matrices should be choosen to be significantly longer than the characteristic time of the signals being searched for , but still short enough that the detector behavior is quasi - stationary . for inspiral signals ,",
    "typical signals are in the detector band for tens of seconds , so the matrix estimation time should be at least of order tens of minutes . for stochastic background detection , the correlation time between the two instruments is tens of milliseconds , so that the matrix estimation time should be at least a few seconds .    based on the two forms of non - gaussian noise considered in this section , it seems reasonable to adopt the following detection rules : ( i ) veto immediately any segment of data that has an excess of power as measured by the excess power statistic ; ( ii ) for segments of data without an excess of power , construct the matched filter in the frequency domain , but exclude those frequency bins in which the detector power is too large .",
    "the resulting ( truncated ) matched filter is a good approximation of the locally optimal statistic for a wide variety of possible non - gaussian noise distribution . in this sense , it is a robust , nearly optimal detection statistic .",
    "observational limits from nucleosynthesis demonstrate that the stochastic background of gravitational radiation has such small amplitude that it would not be detectable with a single instrument @xcite . in a single instrument",
    ", there would be no practical way to discriminate between intrinsic detector noise and the small additional noise - like output arising from a stochastic background .",
    "however , one can correlate the outputs of two different instruments and search for a common signal in this way . if the instrumental noise is not gaussian , then the previous single - detector analysis can be easily generalized .",
    "we begin by considering the simple case in which the two detectors are coincident and co - aligned , so that they have identical output contributions from the stochastic background but independent intrinsic noise .",
    "we also assume that the intrinsic noise samples in each detector are independent , and hence white .",
    "if the signal were deterministic ( known ) then the joint probability distribution for the samples in the two detectors could be written as @xmath126 this system can be analyzed in exactly the same way as in sec .",
    "[ ss : sdwnkw ] .",
    "however the stochastic background does not produce a known ( deterministic ) signal , so that the probability distribution needs to be averaged over its expected distribution @xmath127 ( which , by reason of the central limit theorem , is almost certainly a multivariate gaussian ) .",
    "this leads to a joint probability distribution which is given by @xmath128 here @xmath2 may be thought of as the coupling of the detector .",
    "the case of small @xmath2 corresponds to a detector that is only weakly coupled to the signal . for this non - deterministic signal , it is still straightforward to construct a locally optimal test , and a corresponding decision statistic or threshold criterion .",
    "the locally optimal statistic is obtained from the derivative of the probability distribution with respect to @xmath2 .",
    "this is given by @xmath129 )   \\right )    \\nonumber\\\\    & & \\times\\prod_{i=0}^{n-1 }     e^{-f_1(x_{1,i}-\\epsilon s_i)-f_2(x_{2,i}-\\epsilon s_i)}.\\end{aligned}\\ ] ] setting @xmath4 and dividing by @xmath130 yields the locally optimal statistic : @xmath131    \\times\\int s_j p_{\\text{sb}}({{\\mathbf{s } } } ) d{{\\mathbf{s}}}.\\ ] ] unfortunately this vanishes if the random process described by @xmath132 has vanishing mean , since in this case @xmath133 .",
    "this is indeed the case for the gravitational - wave stochastic background .",
    "when the _ first _ derivative vanishes , the locally optimal statistic is defined by having the largest _ second _ derivative at @xmath4 . see fig .",
    "[ f : powerfn ] for example . taking another derivative of ( [ e : firstder ] ) and setting @xmath4 yields @xmath134{l }      \\biggl\\{\\bigl(\\sum_{j=0}^{n-1 } s_j [ f_1'(x_{1,j})+f_2'(x_{2,j } ) ] \\bigr)^2\\\\      \\quad-\\sum_{j=0}^{n-1}s_j^2[f_1''(x_{1,j})+f_2''(x_{2,j } ) ]",
    "\\biggr\\ }    \\end{array}\\ ] ] the terms that appear in this statistic have different character , and before moving on , some discussion is required .",
    "the locally optimal statistic depends upon the statistical character of the stochastic background radiation through the second - order moments .",
    "we will assume that the stochastic background is a stationary process , so that the second order correlation @xmath135 is a function of the lag @xmath78 only : @xmath136 in a stochastic background search , the `` signal model '' only requires an assumption about the form of the spectrum .",
    "this is ( roughly ) the fourier transform of @xmath137 . without loss of generality",
    "we normalize @xmath137",
    "so that @xmath138 ( this simply scales the value of @xmath2 ) . expressing the locally optimal statistic in terms of the correlation function @xmath139 then gives @xmath140 \\nonumber\\\\    & & + \\sum_{j , k=0}^{n-1 } c(|j - k| ) [ f_1'(x_{1,j } ) f_1'(x_{1,k } ) \\\\    & & \\qquad + f_2'(x_{2,j } ) f_2'(x_{2,k } ) + 2 f_1'(x_{1,j } ) f_2'(x_{2,k } ) ] .",
    "\\nonumber\\end{aligned}\\ ] ] each of the five terms that appears in ( [ e : lostochbg ] ) has a specific interpretation .",
    "the first four terms that appear in the locally optimal estimator @xmath141 are generalized `` single - detector '' statistics which do not cross - correlate the two detectors .",
    "they are generalized measures of the `` energy '' received by each individual detector , and provide useful information only if the stochastic background contributes substantially more to the measured signal than the detector output does , or if the detector s intrinsic noise contributions can somehow be separated from the noise contribution arising from the stochastic background .",
    "( this will not be the case for the first few generations of gravitational wave detectors ) .",
    "the last term in ( [ e : lostochbg ] ) is a generalized cross - correlation ( gcc ) statistic , that provides useful information even if the detector noise dominates the signal : the expected case for gravitational - wave stochastic background . to quote from kassam ( following eq .",
    "( 7 - 24 ) in ref .",
    "@xcite )    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ it is important to note that the increase in power level occurs whenever random signals are present at the individual receivers of the array regardless of whether the signals _ across _ the array are one common signal or are completely uncorrelated .",
    "the gcc part of the locally optimal ( lo ) statistic responds only to a _",
    "common _ signal or at least to signals which are spatially correlated across the array elements .",
    "this is a major reason why it is useful to employ only the gcc part of the lo statistic in applications involving detection as well as location of signal sources .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    "for this reason ( and others is positive definite ) and that for the expected `` gaussian + tail '' detector probability distribution , term 1 is also positive definite .",
    "baysian analysis ( in part ii of this series of papers ) also shows that the single - detector terms must be dropped .",
    "this may also be seen in the analysis at the end of sec .",
    "[ ss : estimators ] . ] ) we drop the single - detector terms from the statistic , and define the gcc statistic as : @xmath142 this generalized cross - correlation statistic reduces to the ordinary cross - correlation statistic in the case where the detector noise is gaussian : @xmath143 .",
    "it can be easily generalized to the case of three or more detectors @xcite .    in practical work",
    "@xmath139 will vanish for lags greater than the light travel time between the two detectors ( i.e. , 10  ms for the ligo detectors ) .",
    "this means that even if @xmath79 is chosen to be very large , @xmath144 only correlates samples from the two detectors taken within this time window .",
    "( note : if the detector noise is colored , then the time window may be larger , as will be seen shortly . )      in this section , we generalize the work of sec .  [ ss:2dwnss ] to the case where the two detectors are not coincident or co - aligned , and their noise power spectrum is not white .",
    "we assume that the intrinsic detector noise of the two detectors is independent . if the two detectors are widely separated and subject to different environmental influences , this assumption should hold .",
    "let us start by assuming that the two detectors each have internal ( instrumental ) colored gaussian noise with known autocorrelation matrices @xmath145 and @xmath146 , and that the instrumental noise of the two detectors is independent .",
    "the stochastic background produces an additional source of colored gaussian noise that is correlated between the two detectors .",
    "the stochastic background noise is measured by the autocorrelation matrices @xmath147 , @xmath148 , and the cross - correlation matrices @xmath149 , @xmath150 . since the stochastic background is isotropic , @xmath151 ( the stochastic background contribution to the detector s autocorrelation matrices ) and @xmath152 ( the cross - correlated noise between the detectors due to the stochastic background ) .",
    "the total autocorrelation noise of the two detectors are @xmath153 and @xmath154 . in the presence of the stochastic background ,",
    "the likelihood ratio is @xmath155 where @xmath156    \\quad\\text{and}\\quad    { { \\mathbf{\\sigma } } } = \\left [    \\begin{array}{cc }      { { \\mathbf{r}}}_1 & \\epsilon^2{{\\mathbf{s } } } \\\\ \\epsilon^2{{\\mathbf{s } } } & { { \\mathbf{r}}}_2    \\end{array } \\right].\\ ] ] in the weak signal approximation , @xmath157 \\nonumber\\\\    & & - \\epsilon^2 \\left [    \\begin{array}{cc }      { { \\mathbf{q}}}_{\\text{in},1}\\cdot{{\\mathbf{r}}}_{\\text{sb}}\\cdot{{\\mathbf{q}}}_{\\text{in},1 } &      { { \\mathbf{q}}}_{\\text{in},1}\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_{\\text{in},2 }              \\\\      { { \\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_{\\text{in},1 }              &      { { \\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{r}}}_{\\text{sb}}\\cdot{{\\mathbf{q}}}_{\\text{in},2 }    \\end{array } \\right ] \\nonumber\\\\    & & + \\epsilon^4 \\biggl\\ { \\left [    \\begin{array}{c }        { { \\mathbf{q}}}_{\\text{in},1}\\cdot{{\\mathbf{r}}}_{\\text{sb}}\\cdot{{\\mathbf{q}}}_{\\text{in},1 }        \\cdot{{\\mathbf{r}}}_{\\text{sb}}\\cdot{{\\mathbf{q}}}_{\\text{in},1 } , \\quad { { \\mathbf{0 } } } \\\\        { { \\mathbf{0 } } } , \\quad { { \\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{r}}}_{\\text{sb}}\\cdot        { { \\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{r}}}_{\\text{sb}}\\cdot{{\\mathbf{q}}}_{\\text{in},2 }    \\end{array}\\right ]    \\nonumber\\\\    & & \\quad + \\left [    \\begin{array}{c }        { { \\mathbf{q}}}_{\\text{in},1}\\cdot{{\\mathbf{s}}}\\cdot        { { \\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_{\\text{in},1 } , \\quad { { \\mathbf{0 } } } \\\\        { { \\mathbf{0 } } } , \\quad { { \\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{s}}}\\cdot        { { \\mathbf{q}}}_{\\text{in},1}\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_{\\text{in},2 }    \\end{array } \\right ] \\biggr\\ }",
    "\\nonumber\\\\    & & + o(\\epsilon^6),\\end{aligned}\\ ] ] @xmath158 \\nonumber\\\\    & & - \\epsilon^4 [         \\frac{1}{2}{{\\mathrm{tr}}}({{\\mathbf{q}}}_{\\text{in},1}\\cdot{{\\mathbf{r}}}_{\\text{sb } }             \\cdot{{\\mathbf{q}}}_{\\text{in},1}\\cdot{{\\mathbf{r}}}_{\\text{sb } } ) \\nonumber\\\\    & & \\qquad + \\frac{1}{2}{{\\mathrm{tr}}}({{\\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{r}}}_{\\text{sb } }             \\cdot{{\\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{r}}}_{\\text{sb } } ) \\nonumber\\\\    & & \\qquad + { { \\mathrm{tr}}}({{\\mathbf{q}}}_{\\text{in},2}\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_{\\text{in},1 }             \\cdot{{\\mathbf{s } } } ) ] \\nonumber\\\\    & & + o(\\epsilon^6),\\end{aligned}\\ ] ] and @xmath159 where @xmath160 and @xmath161 .",
    "the last two terms represent the autocorrelation `` energy '' detectors .",
    "the following question now becomes important : how does one obtain the quantities @xmath145 and @xmath146 .",
    "there are two possible methods : ( i ) by a theoretical understanding of the detector , or ( ii ) by shielding the instrument from the stochastic background and measuring the noise autocorrelation . for gravitational wave searches ,",
    "method ( ii ) is not available as there is no way to shield the detector from a stochastic background of gravitational waves .",
    "method ( i ) holds more promise , but if the stochastic background is expected to be weak , it is unlikely that our understanding of the detector will be sufficient to distinguish between the noise autocorrelations @xmath162 and @xmath163 .",
    "we expect that the noise matrices that should be used are the _ measured _ noise matrices @xmath164 and @xmath165 , which contain both the internal , instrumental noise as well as the stochastic background `` noise . ''",
    "since it is these quantities rather than @xmath145 and @xmath146 that are known , the previous analysis must be modified .",
    "we now have @xmath166    - \\epsilon^2 \\left [    \\begin{array}{cc }      { { \\mathbf{0 } } } & { { \\mathbf{q}}}_1\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_2   \\\\      { { \\mathbf{q}}}_2\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_1 & { { \\mathbf{0 } } }    \\end{array } \\right ] \\nonumber\\\\    & & + \\epsilon^4 \\left [    \\begin{array}{c }        { { \\mathbf{q}}}_1\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_2\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_1,\\quad { { \\mathbf{0 } } } \\\\        { { \\mathbf{0}}},\\quad { { \\mathbf{q}}}_2\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_1\\cdot{{\\mathbf{s}}}\\cdot{{\\mathbf{q}}}_2    \\end{array } \\right ] \\nonumber\\\\    & & + o(\\epsilon^6),\\end{aligned}\\ ] ] @xmath167 and @xmath168 where @xmath169 and @xmath170 .",
    "the locally optimal detection statistic ( which is appropriate for weak signals ) is the cross - correlation statistic .    to generalize to non - gaussian noise , it is helpful to use moment generating functions .",
    "suppose the vector @xmath171 represents the internal ( instrumental ) noise in the first detector .",
    "the moment generating function for @xmath171 is @xmath172 and the probability distribution for @xmath171 is the fourier transform of the moment generating function : @xmath173 the moment generating function @xmath174 for the internal noise in detector 2 is defined similarly .",
    "we assume that the stochastic background is a multivariate gaussian with a moment generating function @xmath175 with @xmath176    \\quad\\text{and}\\quad    { { \\mathbf{\\sigma}}}_{\\text{sb}}=\\left [    \\begin{array}{cc }      { { \\mathbf{r}}}_{\\text{sb } } & { { \\mathbf{s } } } \\\\ { { \\mathbf{s } } } & { { \\mathbf{r}}}_{\\text{sb } }    \\end{array } \\right].\\ ] ] then the moment generating function for the detectors output is @xmath177 and the joint probability distribution is @xmath178 thus , if we ignore the autocorrelation terms , the locally optimal statistic is @xmath179 this equation for the locally optimal statistic is good for the time domain , in which the detectors output vectors are real and so the derivative is meaningful .",
    "to extend the result to complex vectors , and thus to a frequency - domain representation , we use the following formal replacement : replace every complex number @xmath180 and derivative @xmath181 with the matrices @xmath182    \\quad\\text{and}\\quad    \\nabla \\to \\underline\\nabla = \\frac{1}{2 } \\left [    \\begin{array}{rr }      \\partial/\\partial a & -\\partial/\\partial b \\\\",
    "\\partial/\\partial b & \\partial/\\partial a    \\end{array } \\right].\\ ] ] note that this means @xmath183 is represented by @xmath184 and @xmath185 by @xmath186 . also , the meaning of @xmath187 is @xmath188 .",
    "the locally optimal statistic is @xmath189 for example , for the noise model in which @xmath190}g_k(|\\tilde x_k|^2/2p_k)$ ] and @xmath191 $ ] , the locally optimal statistic is @xmath192 }    \\frac{\\gamma_k\\sigma^2_k\\tilde x_{1,k}^\\ast\\tilde x_{2,k}}{p_{1,k}p_{2,k } }    \\nonumber\\\\    & & \\quad\\times    g_{1,k}'(|\\tilde x_{1,k}|^2/p_{1,k } )    g_{2,k}'(|\\tilde x_{2,k}|^2/p_{2,k}).\\end{aligned}\\ ] ]    before we examine specific non - gaussian noise models , we will describe the form of the matrices @xmath193 and @xmath194 .",
    "a stochastic background , if present , contributes to the signal amplitude at each detector . to simplify the analysis , in sec .",
    "[ ss:2dwnss ] , we assumed that the detectors were coincident and co - aligned , so that the amplitude contribution in each individual detector are identical . here",
    ", we drop that assumption .    because the detectors are not co - aligned , the axes of the two interferometer arms point in different directions , and are sensitive to different linear combinations of the two possible gravitational wave polarizations .",
    "this reduces the correlation between the amplitudes in the two detectors , since we will assume that the stochastic background is unpolarized .",
    "an additional loss of correlation occurs because the two detectors are separated .",
    "this loss of correlation becomes increasingly greater for shorter wavelengths .",
    "roughly speaking , there is no significant loss of correlation for wavelengths much longer than the inter - detector distance , and there is a complete loss of correlations for wavelengths much shorter than this@xcite .    the loss of amplitude correlation due to the separation and non - alignment of the two detectors may be described ( for an unpolarized and isotropic stochastic background ) in terms of the overlap reduction function @xmath195 defined by flanagan @xcite .",
    "this quantity is the average value of the product of the detector outputs , for a stochastic background of a given frequency @xmath31 , averaged over the possible directions of arrival and phases .",
    "it is given by : @xmath196 here @xmath197 is a unit - length vector on the two - sphere , @xmath198 is the separation between the two detector sites , and @xmath199 is the response of detector @xmath200 to the @xmath201 or @xmath202 polarization . for the @xmath200th detector @xmath203 one",
    "has @xmath204 where @xmath205 are the gravitational wave polarization tensors for a wave propagating in direction @xmath197 .",
    "the normalization of @xmath195 is chosen so that for coincident and co - aligned detectors , @xmath206 . for co - aligned but not coincident detectors , @xmath207 . for coincident but unaligned detectors ,",
    "@xmath195 is a frequency - independent constant that depends only upon the relative orientation of the two detectors , and vanishes if the two detectors are sensitive to orthogonal polarizations .",
    "general expressions for @xmath195 for arbitrary detectors may be found in refs .",
    "@xcite . for the pair of ligo detectors @xmath195",
    "is shown in fig .",
    "[ f : gammaligo ] , and is given by @xmath208 where @xmath209 is a frequency variable , @xmath210 is the detector separation , @xmath211 is the speed of light , and @xmath212 is a spherical bessel function .",
    "it is helpful to introduce notation for the overlap reduction function s values in the frequency bins of interest .",
    "let @xmath213 denote the frequency of the @xmath86th bin , with @xmath214 $ ] . here",
    "@xmath215 is the sample interval and @xmath216 is the total observation time .",
    "then @xmath217 are the values of the overlap reduction function in the @xmath86th bin .",
    "the stochastic background is characterized by its dimensionless energy density @xmath218 where @xmath219 is the energy density of the gravitational radiation contained in the frequency range @xmath31 to @xmath220 , and @xmath221 is the critical energy density required ( today ) to close the universe : @xmath222 @xmath223 is the hubble expansion rate ( today ) : @xmath224 and @xmath225 is a dimensionless factor that we have included to account for the different values of @xmath223 that are quoted in the literature . is probably very close to 0.65 . ]",
    "the pdf of the stochastic background strain can usually be expressed in closed form .",
    "the central limit theorem shows that if the stochastic background has been produced ( as it is in many scenarios ) by an incoherent sum of many small processes , then its statistics will be stationary@xcite and gaussian .",
    "this means that it is characterized by the single - site second moments @xmath226 with @xmath227 as before , we have assumed that @xmath79 is chosen so that @xmath228 is much larger than the correlation time of the stochastic background ( filtered by the instrument response function ) , so that the rhs of ( [ e : sbg2nd ] ) is proportional to @xmath229 .",
    "the expectation value of the product of the strain at the two different sites is reduced by the overlap reduction function : @xmath230 this follows from eqn .",
    "( 3.56 ) of reference @xcite . in practice , since the shape of the stochastic background spectrum is not know , the dependence of the @xmath231 on @xmath86 should be assumed to fit some simple parameterized model , such as a power law @xmath232 for a reasonable range of @xmath123 .",
    "we can now express the locally optimal detection statistic for a stochastic background in colored gaussian noise .",
    "it is : @xmath233 }      \\gamma_k \\sigma^2_k x_{1,k}^\\ast x_{2,k}/(p_{1,k}p_{2,k})\\ ] ] where @xmath234 and @xmath235 are the measured noise spectra in the two detectors .",
    "let us now turn to our first non - gaussian noise model .",
    "our starting point is a pdf for the noise in the two detectors in the absence of any stochastic background signal .",
    "we make the same assumptions about the detector noise as in sec .",
    "[ ss : sdcnkw ] .",
    "the pdf is given in frequency space by a product of two terms identical to ( [ e : assumedform ] ) , @xmath236 }      2 \\pi^{-1 } p_{1,k}^{-2 } e^{-2g_{1,k}(|\\tilde x_{1,k}|^2/p_{1,k } ) } \\\\    & & \\times \\prod_{k'=1}^{[(n-1)/2 ] }      2 \\pi^{-1 } p_{2,k'}^{-2 } e^{-2g_{2,k'}(|\\tilde x_{2,k'}|^2/p_{2,k ' } ) } \\\\    & = & \\prod_{k=1}^{[(n-1)/2 ] } 4 \\pi^{-2 } p_{1,k}^{-2 } p_{2,k}^{-2 } \\\\    & & \\times e^{-2g_{1,k}(|\\tilde x_{1,k}|^2/p_{1,k } )      -2g_{2,k}(|\\tilde x_{2,k}|^2/p_{2,k})}.\\end{aligned}\\ ] ]    the statistical distribution of the stochastic background is @xmath237 } ( \\pi\\sigma_k^2)^{-2}(1-\\gamma_k^2)^{-1 } \\nonumber\\\\    & & \\quad \\times \\exp\\left ( -       \\frac{|\\tilde s_{1,k}|^2 + |\\tilde s_{2,k}|^2            - 2\\gamma_k \\re(\\tilde s_{1,k}^\\ast \\tilde s_{2,k } ) }          { \\sigma_k^2 ( 1-\\gamma_k^2 ) }    \\right).\\end{aligned}\\ ] ]    we can now find the locally optimal statistic . since the detector is linear , as before , one has a joint probability distribution for the observed fourier amplitudes : @xmath238 this corresponds to a stochastic background with a characteristic energy - density function @xmath239 .",
    "should really be interpreted as `` coupling to the detector '' .",
    "the locally optimal statistic is the best choice in the `` weakly coupled detector '' limit . ]",
    "the locally optimal statistic is @xmath240 } & & \\biggl\\ {    \\frac{\\langle\\tilde s_{1,k}^\\ast\\rangle \\tilde x_{1,k }          g_{1,k}'(|\\tilde x_{1,k}|^2/p_{1,k})}{p_{1,k } } \\nonumber\\\\    & & \\quad +    \\frac{\\langle\\tilde s_{2,k}^\\ast\\rangle \\tilde x_{2,k }          g_{2,k}'(|\\tilde x_{2,k}|^2/p_{2,k})}{p_{2,k } } \\biggr\\}\\end{aligned}\\ ] ] where the quantities @xmath241 and @xmath242 are mean values of the stochastic background s fourier amplitudes at each of the two detector sites .",
    "these both vanish : @xmath243 since the mean values of the fourier amplitudes are zero . hence , as in sec .",
    "[ ss:2dwnss ] one must look for the locally optimal statistic at the next order in @xmath2 . taking an additional derivative , one can easily compute @xmath141 . as in sec .",
    "[ ss:2dwnss ] this consists of two types of terms . for the same reasons as before , we discard from this decision statistic all the _ single detector _ terms .",
    "this leaves us with the following generalized cross - correlation statistic : @xmath244 }    \\frac{\\re(\\tilde s_{1,k}^\\ast\\tilde x_{1,k } )          g_{1,k}'(|\\tilde x_{1,k}|^2/p_{1,k})}{p_{1,k } } \\nonumber\\\\    & & \\qquad \\times    \\frac{\\re(\\tilde s_{2,k'}^\\ast\\tilde x_{2,k ' } )          g_{2,k'}'(|\\tilde x_{2,k'}|^2/p_{2,k'})}{p_{2,k'}}.\\end{aligned}\\ ] ] since the expectation value of the product of the stochastic background at the two sites is given by @xmath245 one obtains the generalized cross - correlation statistic @xmath246 }    \\frac{\\gamma_k\\sigma^2_k\\tilde x_{1,k}^\\ast\\tilde x_{2,k}}{p_{1,k}p_{2,k } }    \\nonumber\\\\    & & \\quad\\times    g_{1,k}'(|\\tilde x_{1,k}|^2/p_{1,k } )    g_{2,k}'(|\\tilde x_{2,k}|^2/p_{2,k}).\\end{aligned}\\ ] ] if the functions @xmath247 are replaced by unity , this reduces to the standard result for the optimal filter for the case where the detector noise is assumed to be stationary and gaussian . for typical non - gaussian noise models ,",
    "the effect of the @xmath247 functions is to exclude those frequency bins in which @xmath248 is large in either detector .",
    "our second non - gaussian noise model is similar to the noise burst model used in sec .",
    "[ ss : sdcnkw ] , generalized to the two detector case .",
    "the composite pdf for this model is @xmath249 where @xmath250 and @xmath251 are the probabilities of bursts in detectors 1 and 2 .",
    "the matrices @xmath252 , @xmath253 , and @xmath254 represent the correlation matrices when a noise burst is present . as in sec .",
    "[ ss : sdcnkw ] , a burst effectively changes the noise level for the detector experiencing the burst .",
    "thus , if there is a burst in detector 1 , simply replace @xmath255 with @xmath256 in @xmath257 to obtain @xmath252 .",
    "then we find @xmath258 + o(\\epsilon^4)\\ ] ] and @xmath259 to first order in @xmath260 and similarly for @xmath253 .",
    "we also have @xmath261\\ ] ] and @xmath262 to first order in @xmath260 and @xmath263 .",
    "we can now compute the locally optimal statistic : @xmath264 where @xmath265 and @xmath266 is given by a similar expression . here",
    "we have neglected all @xmath118 terms .",
    "the terms @xmath267 and @xmath266 detect bursts , and their role is to suppress @xmath141 when a burst is present in either detector .",
    "in analyzing experimental data , there are different possible goals .",
    "one goal might be to set an upper limit ( with a certain statistical confidence ) on the stochastic background energy density in a particular frequency band .",
    "another goal might be to estimate this energy density in a particular frequency band .    for this latter purpose ,",
    "there are different possible estimators that might be used .",
    "one standard estimator is the maximum likelihood estimators ( mle ) . in this section ,",
    "we show how this estimator is related to the cross - correlation statistic .",
    "recall that the probability distribution for the joint detector output is @xmath268 suppose we wish to estimate the strength @xmath269 of the stochastic background .",
    "the maximum likelihood estimator is the value @xmath270 for which this probability is maximized : @xmath271_{\\epsilon^2_{\\text{mle } } } = 0 $ ] .",
    "the result is @xmath272 where @xmath273 is a measure of how how sensitive the detectors were to the stochastic background .",
    "normally @xmath274 will be on the order of unity so @xmath270 is approximately just the cross - correlation statistic .",
    "however , if the detector were abnormally noisy , then @xmath274 would be less that unity and the estimate of the stochastic background strength would be smaller than the cross - correlation statistic would indicate : this is a correction that compensates for artificially large values of the cross - correlation statistic due to noise fluctuations .",
    "another possible estimator is the bayesian estimator . in the long measurement ,",
    "weak signal case this again yields the same result as the mle estimator .",
    "a nice feature of these techniques is that in practice , they should be easy to implement .",
    "work by scott and whiting @xcite has shown that the pdfs of the fourier amplitudes in different frequency bins can be easily obtained .",
    "since the characteristic time - scale for stochastic background correlation is @xmath275 , these can be computed using data - segments with lengths seconds or tens of seconds .",
    "these pdfs can then be used to determine where to truncate or clip the correlation , frequency - bin by frequency - bin .",
    "provided that the instrument s characteristics are stable over periods of minutes or hours , it should be simple to accumulate sufficient statistics to determine the pdfs and therefore the truncation or weighting functions with reasonable accuracy .    in practice , it may also be desirable to `` discard '' a small part of the `` attainable - in - principle '' correlation in exchange for obtaining more robust statistics .",
    "for example , on can arbitrarily zero the 1% of frequency bins that are the largest number of standard deviations away from the mean value ( for that bin ) . since the dominant contribution in any bin always comes from the detector noise , this is only very weakly correlated with the actual stochastic background signal , and the net effect is to discard just a bit more than 1% of the `` in principle '' attainable signal - to - noise ration .",
    "but in exchange , the detection statistic becomes far less sensitive to non - gaussian detector fluctuations .",
    "the precise effects of such treatment , and the appropriate truncation thresholds , can be easily determined with monte carlo simulations using simulated signals added into real detector noise .    in searching for a known waveform ( e.g. , binary inspiral )",
    "the methods are again easily implementable . here , since the signal timescale is less than a minute , the frequency - bin by frequency - bin statistics take a bit more time to accumulate , and the detector s statistical properties have got to be stable over a slightly longer time - scale ( an hour , perhaps ) .",
    "this appears likely .",
    "since certain non - gaussian noise features are more likely to appear as outlier points in the time - domain , and others in the frequency - domain , a combination of the time- and frequency - domain methods may be desirable .",
    "unfortunately , if the detector noise is not white , this may require the removal ( vetoing ) of entire small sections of time - series data .",
    "this is easy in the stochastic background case , where only tens of milliseconds around a glitch need excision .",
    "it may be more problematic for signals like binary inspiral chirps that have longer duration .      in secs .",
    "[ s : deterministic ] and [ s : stochastic ] , we derived locally optimal statistics to search for deterministic and stochastic gravitational wave signals in the presence of non - gaussian noise .",
    "these statistics reduce to the standard matched - filtering and cross - correlation statistics when the detector noise is gaussian .",
    "but they are more _ robust _",
    "( i.e. , less sensitive to outliers ) when the detector noise has non - gaussian components . for both cases ,",
    "the standard and robust statistics take ( as input ) the output of one or more detectors , and return ( as output ) a single real number .",
    "but the statistics also depend on the gravitational wave signal and detector noise models , which are not directly observable .",
    "different choices for the signal and noise models correspond to different statistics , and these different statistics will in general perform differently given the same detector output . in order to compare and evaluate the statistics",
    ", we need a way to quantify their performance .    as mentioned in sec .",
    "[ s : deterministic ] , the quality of a test ( i.e. , a decision rule based on a particular statistic ) is characterized by its _ false alarm _ and _ false dismissal _",
    "probabilities for a given source .",
    "these are , respectively , the probability that the test leads us to conclude that a signal is present , when in fact it is absent ( @xmath4 ) , and the probability that the test leads us to conclude that a signal is absent , when in fact it is present ( @xmath276 ) .",
    "these two probabilities ( denoted @xmath123 and @xmath277 ) completely specify the long - term performance of a statistic . but to rank different tests , we need to reduce these multi - dimensional error measures to a single figure of merit .",
    "how we do this depends on the problem we are trying to solve ( see , e.g. @xcite ) , but in the context of gravitational wave detection , it is common to look for a test that minimizes the false dismissal probability , keeping the false alarm probability less than or equal to some maximum tolerable value .",
    "this criterion is known as the _ neyman - pearson _ criterion , and it was used in sec .",
    "[ s : deterministic ] to define the locally optimal statistics .    thus , to compare the performance of different statistics , we should plot false dismissal versus false alarm curves for different values of the signal amplitude @xmath2 .",
    "the best test ( or best statistic ) is the one that has the smallest false dismissal probability @xmath278 , for fixed false alarm probability @xmath123 and fixed signal amplitude @xmath2 .",
    "note that since the false dismissal probability depends on both @xmath123 and @xmath2 , it is possible that the best test for one choice of @xmath279 is not the best test for a different choice of @xmath279 .",
    "note also that this method of comparing statistics is different than simply comparing expected signal - to - noise ratios .",
    "what is important when determining error rates ( and hence the performance of a particular test ) is not the expected value of the statistic , but rather its probability _",
    "distribution_.    for sufficiently simple statistics with sufficiently simple signal and noise models , it may be possible to analytically calculate the corresponding false dismissal versus false alarm curves .",
    "but for most cases of interest , we must resort to _ monte carlo simulations _ to generate the curves .",
    "this consists of adding simulated signals to simulated ( or real ) detector noise , and then processing the resulting data with a statistic . for each stretch of data",
    ", the statistic outputs a single number which is then compared to a threshold to determine if we should claim detection .",
    "since we know if a signal is present in the data , we can easily determine the fraction of times that the decision rule was in error . in the absence of a signal",
    ", this procedure yields the false alarm probability @xmath123 as a function of the threshold @xmath21 . in the presence of a signal having fixed amplitude @xmath2 , we obtain the false dismissal probability @xmath277 , again as a function of the threshold .",
    "if we invert @xmath280 for @xmath281 , and substitute this expression back into @xmath282 , we obtain the false dismissal versus false alarm curve @xmath283 .",
    "we can then repeat these steps for a different signal amplitude @xmath284 to produce a new curve @xmath285 .",
    "the final result will be a set of curves similar to those shown in fig .",
    "[ f : typical1 ] .    alternatively , we can plot @xmath286 or @xmath287 versus @xmath123 , as shown in figs .",
    "[ f : typical2 ] and [ f : typical3 ] .",
    "note that the quantity @xmath288 is the difference of two probabilities : @xmath289 is the probability that the statistic exceeds some threshold in the presence of a signal ( @xmath290 , while @xmath123 is the probability that the statistic exceeds the same threshold in the absence of a signal ( i.e. , @xmath4 ) .",
    "although , figs .",
    "[ f : typical2 ] and [ f : typical3 ] contain the same information as the false dismissal versus false alarm curves ( fig .",
    "[ f : typical1 ] ) , plotting @xmath287 versus @xmath123 has the nice property that , for stochastic signals , the curves have a well - defined @xmath291 limit .      to illustrate how we can compare different statistics using monte carlo simulations , consider the simple case of a search for a white , gaussian stochastic background signal using two independent , identical , coincident and coaligned detectors .",
    "statistic 1 will be the standard cross - correlation statistic defined by a white , gaussian stochastic background signal and white , gaussian detector noise .",
    "statistic 2 will be a locally optimal statistic , also defined by a white , gaussian stochastic background signal , but with white , 2-component , mixture gaussian noise with an arbitrary knee .",
    "we will assume that we know ( a  priori ) that the two detectors are identical and have uncorrelated white noise .",
    "we will not assume , however , that we know ( a  priori ) the parameters describing the statistical properties of the detector noise or the overall amplitude of the stochastic background signal .",
    "each statistic will have to internally estimate the parameters from the detector output , without any other prior knowledge .",
    "we perform monte carlo simulations of the two statistics for the following three cases :    * uncorrelated , white , gaussian detector noise with zero mean and unit variance . * uncorrelated , white , 2-component , mixture gaussian detector noise with zero mean , unit variance , @xmath292 , and @xmath55 [ see eq .",
    "( [ sgs ] ) ] . *",
    "uncorrelated , white , exponential detector noise with zero mean and unit variance [ see eq .",
    "( [ e : exp ] ) ] .",
    "the first two simulations test the optimal behavior of the statistics .",
    "statistic 1 is designed for the data of case ( i ) , and statistic 2 is designed for the data of case ( ii ) .",
    "the third simulation tests the two statistics in a sub - optimal situation , representative of a real search where we do not know in advance the exact statistical character of the detector noise",
    ".    details of the monte carlo simulations are summarized below :    \\(i ) a single stretch of data consists of @xmath293 discrete - time samples .",
    "this @xmath79 is sufficiently large that the large observation time approximation is valid .",
    "since we are considering white noise ( which has zero correlation length ) , any @xmath294 would do .",
    "\\(ii ) the simulated stochastic gravitational - wave signal strengths are @xmath295 , .005 , .010 , .020 , and .040 , where @xmath2 is the ratio of the rms amplitude of the stochastic background signal to the rms amplitude of the detector noise .",
    "these signal strengths correspond to signal - to - noise ratios ( @xmath296 ) ranging from approximately 0.1 to 1 for a single stretch of data .",
    "note : since a real stochastic background is expected to have a smaller value of @xmath269 ( @xmath297 ) , we would need a much longer observation time to build - up similar signal - to - noise ratios in a real search .",
    "the purpose of this example , however , is to illustrate how one can compare two different statistics ; it is not meant to simulate a real ( @xmath298 month ) stochastic background search .",
    "\\(iii ) for all three types of simulated detector noise , the standard cross - correlation statistic estimates the variance of the noise by calculating the sample variance of a stretch of detector output equal to @xmath299 . since the detector output consists in general of signal plus noise , the estimate of the noise variance gets worse as the signal amplitude increases .",
    "the sample variance is needed to specify the white , gaussian noise model that enters the definition of the standard cross - correlation statistic [ c.f .",
    "[ e : gcc ] ] : @xmath300 where @xmath301 and @xmath302 are the estimated variances of the noise in detectors 1 and 2 , respectively .",
    "\\(iv ) in addition to estimating the variance of the detector noise , the locally optimal statistic also estimates the variances @xmath57 , @xmath303 , and breakpoint @xmath304 of the 2-component , mixture gaussian model that define this statistic .",
    "it does this by fitting two straight lines to a @xmath305 vs.  @xmath306 plot obtained from a histogram of a stretch of detector output , again equal to @xmath307 .",
    "best - fit lines at small @xmath308 and large @xmath308 , respectively , yield estimates of @xmath57 and @xmath303 , while the intersection of the lines yields an estimate of @xmath304 .",
    "actually , only the breakpoints for the detector noise are needed to define the following locally optimal statistic : @xmath309 which is a truncated version of @xmath310 .",
    "( see the discussion of truncation in the previous subsection . ) here @xmath311 is the usual step function , which equals 0 if @xmath47 , and equals 1 if @xmath312 .",
    "note : in order to handle pure gaussian noise ( which is a pathological case when one tries to model it as a 2-component , mixture gaussian distribution ) , the locally optimal statistic sets the breakpoint @xmath304 to @xmath313 whenever the estimated slopes at small and large values of @xmath308 have a percent difference less than @xmath314 . by doing this",
    ", the locally optimal statistic @xmath315 effectively reduces to the standard cross - correlation statistic @xmath316 when the noise is pure gaussian .",
    "\\(v ) we use @xmath317 trials to generate each false dismissal versus false alarm curve .",
    "\\(vi ) the simulations were written in matlab @xcite .",
    "the results of the simulation are shown in figs .",
    "[ f : noise1_beta]-[f : noise3_gamma ] .",
    "as noted in ( iv ) above , our implementation of the locally optimal statistic reduces to the standard cross - correlation statistic when the detector noise is pure gaussian .",
    "that is why the false dismissal versus false alarm curves for the two statistics are effectively identical in fig .",
    "[ f : noise1_beta ] .    from fig .",
    "[ f : noise2_beta ] we see that the locally optimal statistic performs better than the standard cross - correlation statistic when the simulated detector noise is mixture gaussian . for each value of the stochastic signal strength @xmath269 and for each false alarm probability @xmath123 ,",
    "the false dismissal probability @xmath283 for the locally optimal statistic is less than that for the standard cross - correlation statistic .",
    "this is as expected , since the locally optimal statistic was constructed precisely to handle mixture gaussian noise .    finally , from figs .",
    "[ f : noise3_beta]-[f : noise3_gamma ] we see that the locally optimal statistic also performs better than the standard cross - correlation statistic when the simulated detector noise has an exponential distribution .",
    "the difference in performance between the two statistics for this case is less than that for mixture gaussian noise , but it is still noticeable .",
    "( figure  [ f : noise3_blowup ] focuses attention on the false dismissal versus false alarm curves for small values of the false alarm probability , while fig .",
    "[ f : noise3_gamma ] is a plot of @xmath318 versus @xmath123 , which highlights the difference between the two statistics in the small signal limit . )",
    "this behavior is again as expected , since a locally optimal statistic is constructed to be less sensitive to the tails of a non - gaussian distribution .",
    "in this paper , we have constructed a replacement for the standard linear matched filter estimators used for gravitational wave detection .",
    "the replacements are more robust because they are less susceptible to corruption by non - gaussian detector noise .",
    "we have explicitly illustrated the locally optimal detection strategies for a variety of different noise pdfs , and for two different detection problems ( single detector known waveform , and two - detector stochastic background ) . in all cases , the optimal strategy is similar to the one for gaussian noise except that data samples that lie outside the central part of the distribution ( the outliers ) are excluded from the sums which form the estimators .",
    "this research was supported in part by nsf grants phy-9728704 , phy-9722189 , phy-9981795 , phy-0071028 , nasa grant nasa - jpl 961298 , the sloan foundation , and by the max planck society ( albert einstein institute , potsdam ) .",
    "a. abramovici , w. e. althouse , r. w. p. drever , y. grsel , s. kawamura , f. j. raab , d. shoemaker , l. sievers , r. e. spero , k. s. thorne , r. e. vogt , r. weiss , s. e. whitcomb , and m. e. zucker , science * 256 * , 325 ( 1992 ) .      c. bradaschia et al .",
    "methods * a289 * , 518 ( 1990 ) ; also in _ gravitation 1990 _ , proceedings of the banff summer institute , banff , alberta , 1990 , edited by r. mann and p. wesson ( world scientific , singapore , 1991 ) .",
    "i. s. heng , d. g. blair , e. n. ivanov , m. e. tobar , phys .",
    "a * 218 * , 190 ( 1996 ) ; e. mauceli et al .",
    ", 1996 phys .",
    "d * 54 * , 1264 ( 1996 ) ; p. astone et al . , _ ibid_. * 47 * , 362 ( 1993 ) ; m. cerdonio et al .",
    ", in _ gravitational wave experiments _ , proceedings of the edoardo amaldi conference , edited by e. coccia , g. pizzella , and f. ronga ( world scientific , singapore 1995 ) , p. 176 ; e. coccia , _",
    "ibid_. , p. 161 .",
    "simple experiments carried out by allen and romano using the grasp data analysis package ` http://www.lsc-group.phys.uwm.edu ` indicate that the large non - gaussian fluctuations present in the data from the ligo 40-m prototype created large biases in the cross - correlation estimators .",
    "the 1994 data stream was split into two parts , and each was assumed to come from an independent detector .",
    "b. allen , in _ proceedings of the les houches school on astrophysical sources of gravitational waves _ , edited by jean - alain marck and jean - pierre lasota ( cambridge university press , cambridge , england , 1997 ) .",
    " . flanagan , phys .",
    "d * 48 * , 2389 ( 1993 ) . note that the second term on the rhs of eq .",
    "( b6 ) should read @xmath319 rather than @xmath320 , that the sliding delay function shown in fig .",
    "2 is incorrect , and that the right hand side of eq .",
    "( 2.8 ) should be divided by @xmath321 .",
    "matlab : ` http://www.mathworks.com ` .",
    "the matlab scripts that we used to generate the monte carlo simulations are available at : ` http://feynman.utb.edu/\\simjoe/research/ stochastic / algorithms / robust / simulations / code/ ` ."
  ],
  "abstract_text": [
    "<S> gravitational wave detectors will need optimal signal - processing algorithms to extract weak signals from the detector noise . </S>",
    "<S> most algorithms designed to date are based on the unrealistic assumption that the detector noise may be modeled as a stationary gaussian process . </S>",
    "<S> however most experiments exhibit a non - gaussian `` tail '' in the probability distribution . </S>",
    "<S> this `` excess '' of large signals can be a troublesome source of false alarms . </S>",
    "<S> this article derives an optimal ( in the neyman - pearson sense , for weak signals ) signal processing strategy when the detector noise is non - gaussian and exhibits tail terms . </S>",
    "<S> this strategy is robust , meaning that it is close to optimal for gaussian noise but far less sensitive than conventional methods to the excess large events that form the tail of the distribution . </S>",
    "<S> the method is analyzed for two different signal analysis problems : ( i ) a known waveform ( e.g. , a binary inspiral chirp ) and ( ii ) a stochastic background , which requires a multi - detector signal processing algorithm . </S>",
    "<S> the methods should be easy to implement : they amount to truncation or clipping of sample values which lie in the outlier part of the probability distribution . </S>"
  ]
}