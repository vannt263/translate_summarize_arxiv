{
  "article_text": [
    "reed - solomon ( rs ) codes are one of the most widely used error - correcting codes in digital communication and data storage systems .",
    "this is primarily due to the fact that rs codes are maximum distance separable ( mds ) codes , can correct long bursts of errors , and have efficient hard - decision decoding ( hdd ) algorithms , such as the berlekamp - massey ( bm ) algorithm , which can correct up to half the minimum distance ( @xmath0 of the code .",
    "an  @xmath1  rs code of length  @xmath2  and dimension  @xmath3 is known to have  @xmath4  due to its mds nature .    since the arrival of rs codes",
    ", people have put a considerable effort into improving the decoding performance at the expense of complexity . a breakthrough result of guruswami and sudan ( gs ) introduces a hard - decision list - decoding algorithm based on algebraic bivariate interpolation and factorization techniques that can correct errors beyond half the minimum distance of the code @xcite .",
    "nevertheless , hdd algorithms do not fully exploit the information provided by the channel output .",
    "koetter and vardy ( kv ) later extended the gs decoder to an algebraic soft - decision ( asd ) decoding algorithm by converting the probabilities observed at the channel output into algebraic interpolation conditions in terms of a multiplicity matrix @xcite .",
    "both of these algorithms however have significant computational complexity .",
    "thus , multiple runs of error - and - erasure and error - only decoding with some low complexity algorithm , such as the bm algorithm , has renewed the interest of researchers .",
    "these algorithms essentially first construct a set of either erasure patterns @xcite , test patterns @xcite , or patterns combining both @xcite and then attempt to decode using each pattern .",
    "there has also been recent interest in lowering the complexity per decoding trial as can be seen in @xcite .    in the scope of multiple error - and - erasure decoding",
    ", there have been several algorithms using different sets of erasure patterns . after multiple decoding trials ,",
    "these algorithms produce a list of candidate codewords and then pick the best codeword on this list , whose size is usually small .",
    "the nature of multiple error - and - erasure decoding is to erase some of the least reliable symbols since those symbols are more prone to be erroneous .",
    "the first algorithm of this type is called generalized minimum distance ( gmd ) @xcite and it repeats error - and - erasure decoding while successively erasing an even number of the least reliable positions ( lrps ) ( assuming that  @xmath5  is odd ) .",
    "more recent work by lee and kumar @xcite proposes a soft - information successive ( multiple ) error - and - erasure decoding ( sed ) that achieves better performance but also increases the number of decoding attempts .",
    "literally , the lee - kumar s sed@xmath6  algorithm runs multiple error - and - erasure decoding trials with every combination of an even number  @xmath7  of erasures within the  @xmath8  lrps .",
    "a natural question that arises is how to construct the `` best '' set of erasure patterns for multiple error - and - erasure decoding .",
    "inspired by this , we first design a rate - distortion framework to analyze the asymptotic trade - off between performance and complexity of multiple error - and - erasure decoding of rs codes . the framework is also extended to analyze multiple algebraic soft - decision decoding ( asd ) .",
    "next , we proposed a group of multiple - decoding algorithms based on this approach that achieve better performance - versus - complexity trade - off than other algorithms .",
    "the multiple - decoding algorithm that achieves the best trade - off turns out to be a multiple error - only decoding using the set of patterns generated by random codes combining with covering codes .",
    "these are the main results of this paper .",
    "the paper is organized as follows . in section [ sec : multiplebma ] , we design an appropriate distortion measure and present a rate - distortion framework to analyze the performance - versus - complexity trade - off of multiple error - and - erasure decoding of rs codes .",
    "also in this section , we propose a general multiple - decoding algorithm that can be applied to error - and - erasure decoding .",
    "then , in section [ sec : computing - rd ] , we discuss a numerical computation of r - d function which is needed for the proposed algorithm . in section",
    "[ sec : multiple asd ] , we analyze both bit - level and symbol - level asd decoding and design distortion measures so that they can fit into the general algorithm . in section [ sec : ext - and - gen ] , we offer some extensions that help the algorithm achieve better performance and running time .",
    "simulation results are presented in section [ sec : simulation - results ] and finally , conclusion is provided in section [ sec : conclusion ] .",
    "in this section , we set up a rate - distortion framework to analyze multiple attempts of conventional hard decision error - and - erasure decoding .",
    "let  @xmath9  be the galois field with  @xmath10  elements denoted as  @xmath11 .",
    "we consider an @xmath1  rs code of length  @xmath2 , dimension  @xmath3 over  @xmath9 .",
    "assume that we transmit a codeword  @xmath12  over some channel and receive a vector  @xmath13  where  @xmath14  is the receive alphabet for a single rs symbol . in this paper , we assume that @xmath15 and all simulations are based on transmitting each of the @xmath16 bits in a symbol using binary phase - shift keying ( bpsk ) on an additive white gaussian noise ( awgn ) channel .",
    "for each codeword index  @xmath17 , let  @xmath18  be the permutation given by sorting  @xmath19  in decreasing order so that  @xmath20 .",
    "then , we can specify  @xmath21  as the  @xmath22-th most reliable symbol for  @xmath23  at codeword index  @xmath17 . to obtain the reliability of the codeword positions ( indices )",
    ", we construct the permutation  @xmath24  given by sorting the probabilities  @xmath25  of the most likely symbols in increasing order .",
    "thus , codeword position  @xmath26  is the  @xmath17-th lrp .",
    "these above notations will be used throughout this paper .",
    "consider  @xmath27  and  @xmath28 .",
    "assume that we have the probability  @xmath29 written in a matrix form as follows@xmath30_{j , i}\\ ] ]    then  @xmath31  and  @xmath32 .",
    "[ con : bmaerr - n - era](classical decoding threshold , see @xcite ) : if  @xmath33  symbols are erased , a conventional hard - decision error - and - erasure decoder such as the bm algorithm is able to correct  @xmath34  errors in unerased positions if @xmath35      [ def:(conv .",
    "patterns)](conventional error and erasure patterns ) we define  @xmath36  and  @xmath37  as an error pattern and an erasure pattern respectively , where  @xmath38  means that an error occurs ( i.e. the most likely symbol is incorrect ) and  @xmath39  means that an erasure occurs at index  @xmath17 .    if  @xmath5  is odd then @xmath40 is the set of erasure patterns for the gmd algorithm . for the sed@xmath41  algorithm ,",
    "the set of erasure patterns has the form  @xmath42 . here",
    ", in each erasure pattern the letters are written in increasing reliability order of the codeword positions .",
    "let us revisit the question how to construct the best set of erasure patterns for multiple error - and - erasure decoding .",
    "first , it can be seen that a multiple error - and - erasure decoding succeeds if the condition ( [ eq : scbma_0 ] ) is satisfied during at least one round of decoding .",
    "thus , our approach is to design a distortion measure that converts the condition ( [ eq : scbma_0 ] ) into a form where the distortion between an error pattern  @xmath43  and an erasure pattern  @xmath44 , denoted as  @xmath45 , is less than a fixed threshold .    given a _",
    "letter - by - letter _ distortion measure  @xmath46 , the distortion between an error pattern  @xmath43  and an erasure pattern  @xmath44  is defined by@xmath47    [ prop : bma1]if we choose the _ letter - by - letter _ distortion measure  @xmath48   as follows@xmath49 then the condition ( [ eq : scbma_0 ] ) for a successful error - and - erasure decoding then reduces to the form where the distortion is less than a fixed threshold@xmath50    first , we define @xmath51 to count the number of  @xmath52  pairs equal to  @xmath53  for every  @xmath54 . noticing that  @xmath55  and  @xmath56 , the condition ( [ eq : scbma_0 ] ) for one error - and - erasure decoding attempt to succeed becomes  @xmath57 . by seeing",
    "that  @xmath58  we conclude the proof .",
    "next , we try to maximize the chance that this successful decoding condition is satisfied by at least one of the decoding attempts ( i.e.  @xmath59  for at least one erasure patterns  @xmath44 ) .",
    "mathematically , we want to build a set  @xmath60  of no more than  @xmath61  erasure patterns  @xmath44  in order to @xmath62 the exact answer to this problem is difficult to find .",
    "however , one can see it as a covering problem where one wants to cover the space of error patterns using a minimum number of balls centered at the chosen erasure patterns .",
    "this view leads to an asymptotic solution of the problem based on rate - distortion theory .",
    "more precisely , we view the error pattern  @xmath43  as a source sequence and the erasure pattern  @xmath44  as a reproduction sequence .",
    "r7.2 cm    = [ draw = black , fill = blue!05,rectangle , rounded corners ] ( 0.5,0.2 ) circle ( 15pt ) ; ( 0,1 ) circle ( 15pt ) ; ( 0.9,0.9 ) circle ( 15pt ) ; ( 1.4,0.2 ) circle ( 15pt ) ; ( 1.8,1 ) circle ( 15pt ) ; ( 0.5,0.2 ) circle ( 1pt ) ; ( 0.5,0.2 ) circle ( 15pt ) ; ( 0,1 ) circle ( 1pt ) ; ( 0,1 ) circle ( 15pt ) ; ( 0.9,0.9 ) circle ( 1pt ) ; ( 0.9,0.9 ) circle ( 15pt ) ; ( 1.4,0.2 ) circle ( 1pt ) ; ( 1.4,0.2 ) circle ( 15pt ) ; ( 1.8,1 ) circle ( 1pt ) ; ( 1.8,1 ) circle ( 15pt ) ; ( 1,-0.05 ) rectangle ( 1.05,0 ) ; ( 0.05,-0.05 ) rectangle ( 0.1,0 ) ; ( -0.35,1.35 ) rectangle ( -0.3,1.4 ) ; ( 2.2,1.2 ) rectangle ( 2.25,1.25 ) ; ( 1.7,-0.2 ) rectangle ( 1.75,-0.15 ) ; ( 1,1.35 ) rectangle ( 1.05,1.4 ) ; ( 2,1.25 ) rectangle ( 2.05,1.3 ) ; ( 0.7,0.55 ) rectangle ( 0.75,0.6 ) ; ( 1.25,0.65 ) rectangle ( 1.3,0.7 ) ; ( 1.05,0.5 ) rectangle ( 1.1,0.55 ) ; ( -0.15,0.55 ) rectangle ( -0.1,0.6 ) ; ( 0.3,1.325 ) rectangle ( 0.35,1.375 ) ; ( 0.45,1.05 ) rectangle ( 0.5,1.1 ) ; ( 0.7,-0.25 ) rectangle ( 0.75,-0.2 ) ; ( 1.85,0.1 ) rectangle ( 1.9,0.15 ) ; ( 2.1,0.7 ) rectangle ( 2.15,0.75 ) ; ( box ) at ( 3.2,0 )    error pattern + erasure pattern    ; ( 3.875,0.125 ) rectangle ( 3.925,0.175 ) ; ( 3.9,-0.125 ) circle ( 1pt ) ;    rate - distortion theory shows that the set  @xmath60  of  @xmath61  reproduction sequences can be generated randomly so that@xmath63\\leq d\\ ] ] where the distortion  @xmath64  is minimized for a given rate  @xmath65 .",
    "thus , for large enough  @xmath2 , we have@xmath66 with high probability . here ,  @xmath65  and  @xmath64  are closely related to the complexity and the performance , respectively , of the decoding algorithm .",
    "therefore , we characterize the trade - off between those two aspects using the relationship between  @xmath65  and  @xmath64 .      in this subsection , we consider a generalization of the conventional error and erasure patterns under the same framework to make better use of the soft information . at each index of the rs codeword , beside erasing the symbol",
    "we can try to decode using not only the most likely symbol but also other ones as the hard decision ( hd ) symbol . to handle up to the  @xmath8  most likely symbols at each index  @xmath17 , we let  @xmath67  and consider the following definition .    [",
    "def:(patternsbma)](generalized error patterns and erasure patterns ) consider a positive integer  @xmath68 .",
    "let us define @xmath69  as the generalized error pattern where , at index  @xmath17 ,  @xmath70  implies that the  @xmath22-th most likely symbol is correct for  @xmath71 , and  @xmath38  implies none of the first  @xmath8  most likely symbols is correct .",
    "let @xmath72  be the generalized erasure pattern used for decoding where , at index  @xmath17 ,  @xmath73 implies that the  @xmath22-th most likely symbol is used as the hard - decision symbol for  @xmath74 , and  @xmath39  implies that an erasure is used at that index .    for simplicity",
    ", we will refer to  @xmath43  as the error pattern and  @xmath44  as the erasure pattern like in the conventional case .",
    "next , we also want to convert the condition ( [ eq : scbma_0 ] ) to the form where  @xmath45  is less than a fixed threshold .",
    "proposition [ prop : bma1 ] _ _ is thereby generalized into the following theorem .",
    "[ thm : extbma-1]we choose the _ letter - by - letter _ distortion measure  @xmath75   defined by  @xmath76_{x,\\hat{x}}$ ]  in terms of the @xmath77 )  matrix@xmath78 using this , the condition ( [ eq : scbma_0 ] ) for a successful error - and - erasure decoding becomes@xmath50    the reasoning is similar to proposition [ prop : bma1 ] using the fact that  @xmath79  and  @xmath80  where @xmath81 for every  @xmath82 .    for each  @xmath83 , we will refer to this generalized case as  mbm-@xmath8  decoding .",
    "we consider the case mbm-2 decoding where  @xmath84 .",
    "the distortion measure is given by following the matrix@xmath85 here , at each codeword position , we consider the first and second most likely symbols as the two hard - decision choices like in the chase - type decoding method proposed by bellorado and kavcic @xcite .      in this section",
    ", we propose a general multiple - decoding algorithm for rs codes based on the rate - distortion approach .",
    "this general algorithm applies to not only multiple error - and - erasure decoding but also multiple - decoding of other decoding schemes that we will discuss later .",
    "the first step is designing a distortion measure that converts the condition for a single decoding to succeed to the form where distortion is less than a fixed threshold .",
    "after that , decoding proceeds as described below .    *",
    "_ phase i : compute rate - distortion function .",
    "_    _  step 1 : _ transmit  @xmath86  ( say  @xmath87 ) arbitrary test rs codewords , indexed by time  @xmath88 , over the channel and",
    "compute a set of  @xmath86  @xmath89  matrices  @xmath90  where  @xmath91_{j , i}=p_{i,\\pi_{i}^{(t)}(j)}^{(t)}$ ]  is the probability of the  @xmath22-th most likely symbol at position  @xmath17  during time  @xmath92 .",
    "_ step 2 : _ for each time  @xmath92 , obtain the matrix  @xmath93  from  @xmath90  through a permutation  @xmath94  that sorts the probabilities  @xmath95  in increasing order to indicate the reliability order of codeword positions .",
    "take the entry - wise average of all  @xmath86  matrices  @xmath93  to get an average matrix  @xmath96 .",
    "_ step 3 : _ compute the r - d function of a source sequence ( error pattern ) with probability of source letters derived from  @xmath96  and the designed distortion measure ( see section [ sec : computing - rd ] and section [ sub : analyticalrd ] ) .",
    "determine the point on the r - d curve that corresponds to a designated rate  @xmath65  along with the test - channel input - probability distribution vector  @xmath97  that achieves that point .",
    "* _ phase ii : run actual decoder .",
    "_    _  step 4 : _ based on the actual received signal sequence , compute  @xmath25  and determine the permutation  @xmath98  that gives the reliability order of codeword positions by sorting  @xmath25  in increasing order .",
    "_ step 5 : _ randomly generate a set of  @xmath61  erasure patterns using the test - channel input - probability distribution vector  @xmath97 and permute the indices of each erasure pattern by the permutation  @xmath99    _ step 6 : _ run multiple attempts of the corresponding decoding scheme ( e.g. error - and erasure decoding ) using the set of erasure patterns in step 5 to produce a list of candidate codewords .",
    "_ step 7 : _ use maximum - likelihood ( ml ) decoding to pick the best codeword on the list .",
    "in this section , we will present a numerical method to compute the r - d function and the test - channel input - probability distribution that achieves a specific point in the r - d curve .",
    "this probability distribution will be needed to randomly generate the set of erasure patterns in the general multiple - decoding algorithm that we have proposed .    for an arbitrary discrete distortion measure",
    ", it can be difficult to compute the r - d function analytically .",
    "fortunately , the blahut - arimoto ( b - a ) algorithm ( see details in @xcite ) gives an alternating minimization technique that efficiently computes the r - d function of a single discrete source .",
    "more precisely , given a parameter  @xmath100  which represents the slope of the  @xmath101  curve at a specific point and an arbitrary all - positive initial test - channel input - probability distribution vector  @xmath102 , the b - a algorithm shows us how to compute the rate - distortion point  @xmath103  by means of computing the test - channel input - probability distribution vector  @xmath104 and the test - channel transition probability matrix  @xmath105  that achieves that point .",
    "however , it is not straightforward to apply the b - a algorithm to compute the r - d for a discrete source sequence  @xmath43  ( an error pattern in our context ) of  @xmath2  independent but non identical source components  @xmath106 . in order to do that",
    ", we consider the group of source letters  @xmath107  where  @xmath108  as a super - source letter  @xmath109 , the group of reproduction letters  @xmath110  where  @xmath111  as a super - reproduction letter  @xmath112 , and the source sequence  @xmath43  as a single source .",
    "for each super - source letter  @xmath113 ,  @xmath114  follows from the independence of source components .",
    "while we could apply the b - a algorithm to this source directly , the complexity is a problem because the alphabet sizes for  @xmath113  and  @xmath115   become the super - alphabet sizes  @xmath116  and  @xmath117  respectively .",
    "instead , we avoid this computational challenge by choosing the initial test - channel input - probability distribution so that it can be factorized into a product of  @xmath2  initial test - channel input - probability components , i.e.  @xmath118 .",
    "then , we see that this factorization rule still applies after every step of the iterative process . by doing this , for each parameter",
    "@xmath119  we only need to compute the rate - distortion pair for each component ( or index  @xmath17 ) separately and sum them together .",
    "this is captured into the following theorem .",
    "[ thm:(factored - blahut)](factored blahut - arimoto algorithm ) consider a discrete source sequence  @xmath43  of  @xmath2  independent but non identical source components  @xmath106 .",
    "given a parameter  @xmath100 , the rate and the distortion for this source sequence are given by@xmath120 where the components  @xmath121  and  @xmath122  are computed by the b - a algorithm with the parameter  @xmath119 .",
    "this pair of rate and distortion can be achieved by the corresponding test - channel input - probability distribution  @xmath123  where the component probability distribution  @xmath124 .",
    "see appendix [ sec : appblahut ] .",
    "in this section , we analyze and design a distortion measure to convert the condition for successful asd decoding to a suitable form so that we can apply the general multiple - decoding algorithm to asd decoding .",
    "first , let us give a brief review on asd decoding of rs codes .",
    "given a set  @xmath125  of  @xmath2  distinct elements in  @xmath126 from each message polynomial  @xmath127 , we can have a codeword  @xmath128  by evaluating the message polynomial at  @xmath129 , i.e.  @xmath130  for  @xmath131 .",
    "consider a received vector  @xmath132 , we can compute the _ a posteriori _ probability ( app ) matrix  @xmath133  as follows.@xmath134_{j , i}=p_{i , j}=\\pr(c_{i}=\\alpha_{j}|\\mathbf{r})\\,\\,\\,\\mbox{for}\\,\\,1\\leq i\\leq n,1\\leq j\\leq2^{q}.\\ ] ] the asd decoding as in @xcite has the following main steps .    1 .   _ multiplicity assignment _ : use a particular multiplicity assignment scheme ( mas ) to derive a  @xmath89 multiplicity matrix , denoted as  @xmath135 , of non - negative integer entries  @xmath136  from the app matrix  @xmath133 .",
    "_ interpolation _ : construct a bivariate polynomial  @xmath137  of minimum  @xmath138  weighted degree that passes through each of the point  @xmath139  with multiplicity  @xmath140  for  @xmath141  and  @xmath142 .",
    "factorization _ : find all polynomials  @xmath143  of degree less than  @xmath3  such that  @xmath144  is a factor of  @xmath137  and re - evaluate these polynomials to form a list of candidate codewords .    in this paper , we denote  @xmath145  as the maximum multiplicity .",
    "intuitively , higher multiplicity should be put on more likely symbols .",
    "increasing  @xmath146  generally gives rise to the performance of asd decoding .",
    "however , one of the drawbacks of asd decoding is that its decoding complexity is roughly  @xmath147  which sharply increases with  @xmath146 .",
    "thus , in this section we will work with small  @xmath146  to keep the complexity affordable .",
    "one of the main contributions of @xcite is to offer a condition for successful asd decoding represented in terms of two quantities specified as the score and the cost as follows .",
    "the score  @xmath148  with respect to a codeword  @xmath149  and a multiplicity matrix  @xmath135  is defined as  @xmath150,j}$ ] + where  @xmath151=i$ ]  such that  @xmath152 .",
    "the cost  @xmath153  of a multiplicity matrix  @xmath135  is defined as  @xmath154    ( asd decoding threshold , see @xcite ) .",
    "the transmitted codeword will be on the list if@xmath155\\end{aligned}\\ ] ] @xmath156    to match the general framework , the asd decoding threshold ( or condition for successful asd decoding ) should be converted to the form where the distortion is smaller than a fixed threshold .      in this subsection",
    ", we consider multiple trials of asd decoding using bit - level erasure patterns .",
    "a bit - level error pattern  @xmath157  and a bit - level erasure pattern  @xmath158  has length  @xmath159  since each symbol has  @xmath16  bits . similar to definition [ def:(conv . patterns ) ] of a conventional error pattern and a conventional erasure pattern ,  @xmath160  in a bit - level error pattern implies a bit - level error occurs and  @xmath161  in a bit - level erasure pattern implies that a bit - level erasure occurs .    from each bit - level erasure pattern",
    "we can specify entries of the multiplicity matrix  @xmath135  using the bit - level mas proposed in @xcite as follows : for each codeword position , assign multiplicity 2 to the symbol with no bit erased , assign multiplicity 1 to each of the two candidate symbols if there is 1 bit erased , and assign multiplicity zero to all the symbols if there are  @xmath162  bits erased .",
    "all the other entries are zeros by default .",
    "this mas has a larger decoding region compared to the conventional error - and - erasure decoding scheme .",
    "( bit - level asd decoding threshold , see @xcite ) for rs codes of rate  @xmath163 , asd decoding using the proposed bit - level mas will succeed ( i.e. the transmitted codeword is on the list ) if@xmath164 where  @xmath165  is the number of bit - level erasures and  @xmath166  is the number of bit - level errors in unerased locations .",
    "we can choose an appropriate distortion measure according to the following proposition which is a natural extension of proposition [ prop : bma1 ] in the symbol level .",
    "[ prop : bitasd]if we choose the bit - level _ letter - by - letter _ distortion measure  @xmath48  as follows@xmath167 then the condition ( [ eq : bgmdsc ] ) becomes @xmath168    the proof uses the same reasoning as the proof of _ _ proposition _ _ [ prop : bma1 ] .",
    "we refer the the multiple - decoding of bit - level asd as m - b - asd .      in this subsection",
    ", we try to convert the condition for successful asd decoding in general to the form that suits our goal",
    ". we will also determine which multiplicity assignment schemes allow us to do so .",
    "( multiplicity type ) for some codeword position , let us assign multiplicity  @xmath169  to the  @xmath22-th most likely symbol for  @xmath170  where  @xmath171 .",
    "the remaining entries in the column are zeros by default .",
    "we call the sequence ,  @xmath172 , the column multiplicity type for `` top-@xmath8 '' decoding .",
    "first , we notice that a choice of multiplicity types in asd decoding at each codeword position has the similar meaning to a choice of erasure decisions in the conventional error - and - erasure decoding .",
    "however , in asd decoding we are more flexible and may have more types of erasures . for example , assigning multiplicity zero to all the symbols ( all - zero multiplicity type ) at codeword position  @xmath17  corresponds to the case when we have a complete erasure at that position . assigning the maximum multiplicity  @xmath146  to one symbol corresponds to the case when we choose that symbol as the hard - decision one . hence with some abuse of terminology",
    ", we also use the term ( generalized ) erasure pattern  @xmath44  for the multiplicity assignment scheme in the asd context .",
    "each erasure - letter  @xmath106  gives the multiplicity type for the corresponding column of the multiplicity matrix  @xmath135 .",
    "( error and erasure patterns for asd decoding ) consider a mas with  @xmath173  multiplicity types . let  @xmath174 be an erasure pattern where , at index  @xmath17 ,  @xmath70  implies that  multiplicity type  @xmath22  is used at column  @xmath17  of the multiplicity matrix  @xmath135 .",
    "notice that the definition of an error pattern  @xmath69  in definition [ def:(patternsbma ) ] applies unchanged here .",
    "rate - distortion theory gives us the intuition that in general the more multiplicity types ( erasure choices ) we have , the better performance of multiple asd decoding we achieve as  @xmath2  becomes large .",
    "thus , we want to find as many as possible multiplicity types for `` top-@xmath8 '' that allow us to convert condition for successful asd decoding to the correct form .",
    "choosing @xmath175 , for example , gives four column multiplicity types for `` top-2 '' decoding as follows : the first is  @xmath176  where we assign multiplicity 2 to the most likely symbol  @xmath177 , the second is  @xmath178  where we assign equal multiplicity 1 to the first and second most likely symbols  @xmath177  and  @xmath179 , the third is  @xmath180  where we assign multiplicity 2 to the second most likely symbol  @xmath179 , and the fourth is  @xmath181  where we assign multiplicity zero to all the symbols at index  @xmath17  ( i.e. the  @xmath17-th column of  @xmath135  is an all - zero column ) . as a corollary of theorem [ thm : genasd ] below , the distortion matrix that converts ( [ eq : asdsc ] ) to the correct form for this case",
    "is@xmath182    the following definition and theorem provide a set of allowable multiplicity types that converts the condition for successful asd decoding into the form where distortion is less than a fixed threshold .",
    "the set of allowable multiplicity types for `` top-@xmath8 ''  decoding with maximum multiplicity  @xmath146 is defined to be  if  @xmath183.]@xmath184 taking the elements of this set in an arbitrary order , we let the @xmath22-th multiplicity type in the allowable set be  @xmath185 .",
    "@xmath186  consists of all permutations of  @xmath187 .",
    "meanwhile , @xmath188  comprises all the permutations of  @xmath189 and we refer to the multiple asd decoding algorithm using this set of multiplicity types as masd-2 .",
    "@xmath190  consists of all the permutations of  @xmath191 and this case is referred as masd-3 .",
    "we also consider another case called  masd-2a that uses the set of multiplicity types  @xmath192 .",
    "[ thm : genasd ] let @xmath193 be the number of multiplicity types in a mas for `` top-@xmath8 ''  decoding with maximum multiplicity  @xmath146 .",
    "let @xmath194 be a _",
    "letter - by - letter _ distortion measure defined by  @xmath76_{x,\\hat{x}}$ ] , where @xmath195is the  @xmath196  matrix@xmath197 with  @xmath198 .",
    "then , the condition ( [ eq : asdsc ] ) for successful asd decoding of a rs code with rate  @xmath199  is equivalent to @xmath200    [ sketch of proof ] ( see details in @xcite ) let @xmath201 and @xmath202 be the score and cost of the multiplicity assignment .",
    "first , we show that  @xmath203  in ( [ eq : asdsc ] ) implies that  @xmath204 . combining this inequality with the high - rate constraint in theorem [ thm : genasd ]",
    "implies that  @xmath205 . from ( [ eq : asdsc ] ) , we also know that  @xmath206  and this implies that  @xmath207 .",
    "but , the conditions of the theorem can also be used to show that @xmath208 .",
    "combining this with @xmath207 gives a contradiction unless  @xmath209 .",
    "thus , we conclude that  @xmath210 .",
    "therefore , the condition in ( [ eq : asdsc ] ) is equivalent to  @xmath211  because  @xmath212  is a consequence of  @xmath210 and  @xmath213 is satisfied by the high - rate constraint .",
    "finally , one can show that  @xmath211  is equivalent to  @xmath59  with the chosen distortion matrix .    for a fixed  @xmath146 , the size of @xmath214  is maximized  when  @xmath215 .",
    "multiplicity types  @xmath216  and any permutation of  @xmath217@xmath218  are always in the allowable set  @xmath219 .",
    "the r - d framework we use is most suitable when  @xmath220 . for a finite  @xmath2",
    ", the random coding approach may have problems with only a few lrps .",
    "we can instead use good covering codes to handle these lrps . in the scope of covering problems",
    ", one can use an  @xmath8-ary @xmath221-covering code ( e.g. a perfect hamming or golay code ) with covering radius  @xmath221  to cover the whole space of  @xmath8-ary vectors of the same length .",
    "the covering may still work well if the distortion measure is close to , but not exactly equal to the hamming distortion .    in",
    "order take care of up to the  @xmath8  most likely symbols at each of the  @xmath222  lrps of an  @xmath1  rs , we consider an  @xmath223  @xmath8-ary  @xmath221-covering code whose codeword alphabet is  @xmath224 then , we give a definition of the ( generalized ) error patterns and erasure patterns for this case . in order to draw similarities between this case and the previous cases",
    ", we still use the terminology `` generalized erasure pattern '' and shorten it to erasure pattern even if error - only decoding is used . for error - only decoding , condition [ con : bmaerr - n - era ] _",
    "_ for successful decoding becomes@xmath225    ( error and erasure patterns for error - only decoding ) let us define @xmath226  as an error pattern where , at index  @xmath17 ,  @xmath70  implies that the  @xmath22-th most likely symbol is correct for  @xmath71 , and  @xmath38  implies none of the first  @xmath8  most likely symbols is correct .",
    "let @xmath227  be an erasure pattern where , at index  @xmath17 ,  @xmath73 implies that the  @xmath22-th most likely symbol is chosen as the hard - decision symbol for  @xmath74 .",
    "if we choose the _ letter - by - letter _ distortion measure  @xmath228   defined by  @xmath76_{x,\\hat{x}}$ ]  in terms of the  @xmath229  matrix@xmath230 then the condition for successful error - only decoding then becomes@xmath231    it follows directly from  @xmath232 .",
    "if we delete the first row which corresponds to the case where none of the first  @xmath8  most likely symbols is correct then the distortion measure is exactly the hamming distortion .",
    "[ [ split - covering - approach ] ] split covering approach : + + + + + + + + + + + + + + + + + + + + + + + +    we can break an error pattern  @xmath43  into two sub - error patterns  @xmath233  of  @xmath234 least reliable positions and  @xmath235  of  @xmath236  most reliable positions .",
    "similarly , we can break an erasure pattern  @xmath44  into two sub - erasure patterns  @xmath237  and  @xmath238 .",
    "let @xmath239 be the number of positions in the  @xmath234  lrps where none of the first  @xmath8  most likely symbols  is correct , or @xmath240 .",
    "if we assign the set of all sub - error patterns  @xmath241  to be an  @xmath223  @xmath221-covering code then  @xmath242  because this covering code has covering radius  @xmath221 . since  @xmath243 , in order to increase the probability that the condition ( [ eq : scpf ] ) is satisfied we want to make  @xmath244  as small as possible by the use of the r - d approach .",
    "the following proposition summarizes how to generate a set of  @xmath61  erasure patterns for multiple runs of error - only decoding .    in each erasure pattern ,",
    "the letter sequence at  @xmath234  lrps is set to be a codeword of an  @xmath223  @xmath8-ary  @xmath245covering code .",
    "the letter sequence of the remaining  @xmath246 is generated randomly by the r - d method ( see section [ sec : proposed - algorithm ] ) with rate  @xmath247  and the distortion measure in ( [ eq : pfdst ] ) .",
    "since this covering code has  @xmath248  codewords , the total rate is  @xmath249    for a ( 7,4,3 ) binary hamming code which has covering radius  @xmath250 , we take care of the  @xmath251  most likely symbols at each of the 7 lrps .",
    "we see that  @xmath252  is a codeword of this hamming code and then form erasure patterns  @xmath253  with assumption that the positions are written in increasing reliability order .",
    "the  @xmath254 sub - erasure patterns  @xmath255  are generated randomly using the r - d approach with rate  @xmath256 .",
    "while it also makes sense to use a covering codes for the  @xmath234  lrps of the erasure patterns and set the the rest to be letter  @xmath257 ( i.e. chose the most likely symbol as the hard - decision ) , our simulation results shows that the performance can be improved by using a combination of covering codes and random ( i.e. , generated by the r - d approach ) codes .      for some simple distortion measures , we can compute the r - d functions analytically in closed form .",
    "first , we observe an error pattern as a sequence of independent but non - identical random sources .",
    "then , we compute the component r - d functions at each index of the sequence and use convex optimization techniques to allocate the total rate and distortion to various components .",
    "this method converges to the solution faster than the numerical method in section [ sec : computing - rd ] .",
    "the following two theorems describe how to compute the r - d functions for the simple distortion measures of proposition [ prop : bma1 ] and [ prop : bitasd ] .",
    "[ thm:(bma - rd)](conventional error - and - erasure decoding ) let @xmath258 , the overall rate - distortion function is given by  @xmath259^{+}$ ]  where @xmath260  and  @xmath261  can be found be a reverse water - filling procedure:@xmath262 where @xmath263 should be chosen so that  @xmath264 .",
    "the  @xmath265  function can be achieved by the test - channel input - probability distribution@xmath266    [ sketch of proof ] ( see @xcite for details ) with the distortion measure in ( [ eq : dstfnbma ] ) , we follow the method in @xcite to compute the rate - distortion function component  @xmath267^{+}$ ]  and the test - channel input - probability distribution  @xmath268  and  @xmath269  for each index  @xmath17 .",
    "then , one can show that the optimal allocation of rate and distortion to the various components is given by a reverse - water filling procedure like in @xcite .",
    "[ thm:(basd - rd)](bit - level asd case in proposition [ prop : bitasd ] ) the overall rate - distortion function in this case is given by  @xmath270^{+}$ ]  where  @xmath271  and the distortion component @xmath272 is given by@xmath273 where  @xmath274  should be chosen so that  @xmath275 .",
    "the  @xmath265  function can be achieved by the test - channel input - probability distribution@xmath276    [ sketch of proof ] ( see @xcite for details ) with the distortion measure in ( [ eq : dstfnbgmd ] ) , using the method in @xcite we can compute the rate - distortion function component  @xmath277  where  @xmath278  is a lagrange multiplier such that  @xmath279  for each index  @xmath17 .",
    "then , the kuhn - tucker conditions define the the overall rate allocation .",
    "performance of various decoding algorithms for the ( 255,239 ) rs code over an awgn channel . ]     performance of various decoding algorithms for the ( 255,239 ) rs code over an awgn channel . ]    using simulations , we consider the performance of the ( 255,239 ) rs code over an awgn channel with bpsk as the modulation format .",
    "the mbm-1 curve corresponds to standard error - and - erasure bm decoding with multiple erasure patterns . for @xmath280 ,",
    "the mbm-@xmath8 curves correspond to error - and - erasure bm decoding with multiple decoding trials using both erasures and top-@xmath8 symbols .",
    "the masd-@xmath146 curves correspond to multiple asd decoding trials with maximum multiplicity @xmath146 .",
    "the number of trial decoding patterns is @xmath61 where @xmath65 is denoted in parentheses in each algorithm s acronym ( e.g. , m - bm-2(11 ) uses @xmath281 ) .",
    "[ fig : rdcurve ] shows the r - d curves for various algorithms at  @xmath282  db . for this code ,",
    "the fixed threshold for decoding is @xmath283 .",
    "therefore , one might expect that algorithms whose average distortion is less than 17 should have a frame error rate ( fer ) less than @xmath284 .",
    "the r - d curve allows one to estimate the number of decoding patterns required to achieve this fer .",
    "conventional bm decoding is very similar to mbm-1 decoding at rate 0 .",
    "notice that the mbm-1 algorithm at rate 0 , which is very similar to conventional bm decoding , has an expected distortion of roughly 24 .",
    "for this reason , the fer on conventional decoding is close to 1 .",
    "the r - d curve tells us that trying roughly @xmath285 ( i.e. , @xmath286 ) erasure patterns would reduce the fer to roughly @xmath284 because this is where the distortion drops down to 17 .",
    "likewise , the mbm-2(11 ) algorithm has an expected distortion of less than 14 .",
    "so we expect ( and our simulations confirm ) that the fer should be less than @xmath284 .",
    "one weakness of this approach is that the r - d describes only the average distortion and does not directly consider the probability that the distortion is greater than 17 .",
    "still , we can make the following observations from the r - d curve . even at low rates ( e.g. , @xmath287 )",
    ", we see that the distortion  @xmath64  achieved by mbm-2 is roughly the same as mbm-3 , masd-2 , and masd-3 but smaller than masd-2a and mbm-1 .",
    "this implies that mbm-2 is no worse than the more complicated asd based approaches for a wide range of rates ( i.e. , @xmath288 ) .",
    "the fer of various algorithms can be seen in fig .",
    "[ fig : simulation ] .",
    "the focus on @xmath281 allows us to make fair comparisons with sed(12,12 ) . with the same number of decoding trials , mbm-2(11 )",
    "outperforms sed(12,12 ) by 0.3 db at an fer@xmath289 .",
    "even mbm-2(7 ) , with many fewer decoding trials , outperforms both sed(12,12 ) and the kv algorithm with  @xmath290 . among all our proposed algorithms with rate  @xmath281 , the mbm - hm74(11 ) achieves the best performance .",
    "this algorithm uses the hamming ( 7,4 ) covering code for the 7 lrps and the r - d approach for the remaining codeword positions .",
    "meanwhile , small differences in the performance between mbm-2(11 ) , mbm-3(11 ) , masd-2(11 ) , and masd-3(11 ) suggest that : ( i ) taking care of the  @xmath251  most likely symbols at each codeword position is good enough for multiple decoding of high - rate rs code and ( ii ) multiple runs of error - and - erasure decoding is almost as good as multiple runs of asd decoding . recall that this result is also correctly predicted by the r - d analysis .",
    "moreover , it is quite reasonable since we know that the gain of gs decoding , with infinite multiplicity , over the bm algorithm is negligible for high - rate rs codes . to compare with the lcc(@xmath291 ) chase - type approach used in @xcite",
    ", we also consider the mbm - hm74(4 ) algorithm , which uses the hamming ( 7,4 ) covering codes for the 7 lrps and the hard decision pattern for the remaining codeword positions .",
    "this shows that the covering code achieves better performance with the same number ( @xmath292 ) decoding attempts .",
    "the comparison is not entirely fair , however , because of their low - complexity approach to multiple decoding .",
    "we believe , nevertheless , that their technique can be generalized to covering codes .",
    "a rate - distortion approach is proposed as a unified framework to analyze multiple decoding trials , with various algorithms , of rs codes in terms of performance and complexity .",
    "a connection is made between the complexity and performance ( in some asymptotic sense ) of these multiple - decoding algorithms and the rate and distortion of an associated r - d problem .",
    "covering codes are also combined with the rate - distortion approach to mitigate the suboptimality of random codes when the effective block - length is not large . as part of this analysis , we also present numerical and analytical computations of the rate - distortion function for sequences of independent but non - identical sources .",
    "finally , the simulation results show that our proposed algorithms based on the r - d approach achieve a better performance - versus - complexity trade - off than previously proposed algorithms .",
    "one key result is that , for high - rate rs codes , multiple - decoding using the standard bm algorithm is as good as multiple - decoding using more complex asd algorithms .    in this paper",
    ", we only discuss the rate - distortion approach to solve the problem in ( [ eq : probstatement ] ) .",
    "however , the performance can be further improved by focusing on the rate - distortion error - exponent .",
    "this allows us to approximately solve the covering problem for finite  @xmath2 rather than just as  @xmath220 .",
    "the complexity of multiple decoding can also be decreased by using clever techniques to lower the complexity per decoding trial ( e.g. , @xcite ) .",
    "we will address these two improvements in a future paper .",
    "first , let us recall that for each source component  @xmath106 , the b - a algorithm computes the r - d pair in the following steps :    1 .",
    "choose an arbitrary all - positive test - channel input - probability distribution vector  @xmath102 .",
    "2 .   iterate the following steps at  @xmath293@xmath294 where  @xmath295  is the transition probability .",
    "it is shown by b - a that  @xmath296  and  @xmath297as  @xmath298 .",
    "now , we will prove theorem [ thm:(factored - blahut ) ] . since the input - distribution vector of the test channel is an arbitrary all - positive vector ,",
    "we choose  @xmath301  so that it can be factorized as follows  @xmath302 .",
    "s.  -w . lee and b.  v.  k.  v. kumar , `` soft - decision decoding of reed - solomon codes using successive error - and - erasure decoding , '' in _ proc .",
    "ieee global telecom .",
    "_ , new orleans , la , nov . 2008 , pp . 15 .",
    "h.  xia , h.  wang , and j.  r. cruz , `` a chase - gmd algorithm for soft - decision decoding of reed - solomon codes on perpendicular channels , '' in _ proc .",
    "_ , beijing , china , may 2008 , pp . 19771981 ."
  ],
  "abstract_text": [
    "<S> recently , a number of authors have proposed decoding schemes for reed - solomon ( rs ) codes based on multiple trials of a simple rs decoding algorithm . in this paper </S>",
    "<S> , we present a rate - distortion ( r - d ) approach to analyze these multiple - decoding algorithms for rs codes . </S>",
    "<S> this approach is first used to understand the asymptotic performance - versus - complexity trade - off of multiple error - and - erasure decoding of rs codes . by defining an appropriate distortion measure between an error pattern and an erasure pattern , the condition for a single error - and - erasure decoding to succeed reduces to a form where the distortion is compared to a fixed threshold . </S>",
    "<S> finding the best set of erasure patterns for multiple decoding trials then turns out to be a covering problem which can be solved asymptotically by rate - distortion theory . </S>",
    "<S> next , this approach is extended to analyze multiple algebraic soft - decision ( asd ) decoding of rs codes . </S>",
    "<S> both analytical and numerical computations of the r - d functions for the corresponding distortion measures are discussed . </S>",
    "<S> simulation results show that proposed algorithms using this approach perform better than other algorithms with the same complexity . </S>"
  ]
}