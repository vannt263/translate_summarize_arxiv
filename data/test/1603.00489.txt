{
  "article_text": [
    "given an image , an object localization method aims to recognize and locate interesting objects within the image .",
    "the ability to localize objects in images and videos efficiently and accurately opens up a lot of applications like automated vehicular systems , searching online shopping catalogues , home and health - care automation among others .",
    "objects can occur in images in varying conditions of occlusion , illumination , scale , pose and context .",
    "these variations make object detection a challenging problems in the field of computer vision .",
    "the current state of the art in object detection includes methods which involve ` strong ' supervision . in the context of object detection ,",
    "strong supervision entails annotating localization and pose information about present objects of interest .",
    "generating such rich annotations is a time - consuming process and is expensive to perform over large data - sets .",
    "weak supervision lends itself to large - scale object detection for data - sets where only image - level labels are available .",
    "effective localization under weak supervision enables extensions to new object classes and modalities without human - generated object bounding box annotations .",
    "also , such methods enable generation of inexpensive training data for training object detectors with strong supervision .",
    "deep convolutional neural networks ( cnns ) @xcite , @xcite have created new benchmarks in the object recognition challenge @xcite .",
    "cnns for object recognition are trained using image - level labels to predict the presence of objects of interest in new test images .",
    "a common paradigm in analyzing cnns has emerged where the convolutional layers are considered as data - driven feature extractors and the subsequent fully - connected layers constitute hyperplanes which delineate object categories in the learnt feature space .",
    "non - linearities through rectified linear units ( relu ) and sigmoidal transfer functions have helped to learn complex mapping functions which relate images to labels .",
    "the convolutional layers encode both semantic and spatial information extracted from training data .",
    "this information is represented by activations from the convolutional units in the network which are commonly termed as feature maps .        in this paper",
    ", we present a method that exploits correlation between semantic information present in feature maps and localization of an object of interest within an image .",
    "an example of such correlation can be seen in figure @xmath0 .",
    "note that crudely localized image - patches with the objects of classes,`chair ' , ` person ' and ` tv monitor ' , generate high classification scores for the corresponding classes .",
    "this suggests that one can coarsely localize objects solely by image classification scores in this context .    cnn based classifiers are trained for the task of image recognition on large image classification data - sets @xcite , @xcite , @xcite .",
    "the learnt convolutional filters compute spatially localized activations across layers for a given test image @xcite .",
    "we examine the activation values in the outermost convolutional layer and propose localization candidates ( or bounding boxes ) which maximize classification scores for a class of interest .",
    "class scores vary across localization candidates because of the aforementioned local nature of the convolutional filters .",
    "we then progressively explore smaller and smaller regions of interest till a point is reached where the classifier is no longer able to discriminate amongst the classes of interest .",
    "the localization candidates are organized in a search tree , the root node being represented by the entire test image . as we traverse from the root node towards the leaf nodes , we consider finer regions of interest . to approximate the search for optimal localization candidates ,",
    "we adopt a beam search strategy where the number of candidate bounding boxes are restricted as we progress to finer localizations .",
    "this strategy enables efficient localization of multiple objects of multiple classes in images .",
    "we outperform the state - of - the - art in localization accuracy by a significant margin of up to 8 map on two standard data - sets with complex scenes , pascal voc 2012 @xcite and the much larger ms coco @xcite .",
    "the main contributions of this paper are :    * we present a method that tackles the problem of object localization for images in a weakly supervised setting using deep convolutional neural networks trained for the simpler task of image - level classification . *",
    "we propose a method where the correlation between spatial and semantic information in the convolutional layers and localization of objects in images is used explicitly for the localization problem .",
    "the task of object detection is one of the fundamental problems in computer vision with wide applicability .",
    "variability of object appearance in images makes object detection and localization a very challenging task and thus has attracted a large body of work .",
    "surveys of the state - of - the - art are provided in @xcite , @xcite .",
    "a large selection of relevant work are trained in the strong supervision paradigm with detailed annotated ground truth in the form of bounding boxes @xcite , @xcite , object masks @xcite , @xcite , @xcite and 3d object appearance cues @xcite,@xcite .",
    "the requirement of rich annotations curb the application of these methods in data - sets and modalities where training data is limited to weaker forms of labeling .",
    "weak supervision for object detection tries to work around this limitation by learning localization cues from large collection of data with in - expensive annotations .",
    "large data - sets like imagenet @xcite and ms coco are available with image - level labels . there has been significant work in this direction for object localization and segmentation @xcite , @xcite , @xcite , @xcite , @xcite , @xcite . apart from image - level labels , other kinds of weak supervision include using eye - tracking data @xcite , @xcite .",
    "deep convolutional neural networks ( cnn ) have seen a surge of attention from the computer vision community in the recent years .",
    "new benchmarks have been created in diverse tasks such as image classification and recognition @xcite , @xcite , @xcite , @xcite , object detection @xcite , @xcite , @xcite , @xcite , @xcite and object segmentation @xcite , @xcite , @xcite among others by methods building on deep convolutional network architectures .",
    "these networks perform tasks using feature representations learnt from training data instead of traditional hand - engineered features @xcite , @xcite , @xcite . typical algorithms of this paradigm perform inference over the last layer of the network .",
    "there have been recent works @xcite , @xcite , @xcite which exploit semantic information encoded in convolutional feature map activations for semantic segmentation and object detection .",
    "a prerequisite for these cnn - based algorithms is strong supervision with systems focused on detection requiring location masks or object bounding boxes for training .",
    "@xcite studies the presence of object detector characteristics in image - classification cnns , but does not provide a computational method to carry out object detection .",
    "oquab et.al .",
    "@xcite has proposed a weakly supervised object localization system which learns from training samples with objects in composite scenes by explicitly searching over candidate object locations and scales during the training phase . while this method performs well on data - sets with complex scenes ,",
    "the extent of localization is limited with respect to estimating one point in the test image .",
    "the extent of the object is not estimated and detecting multiple instances of the same object class is not considered . in our proposed approach ,",
    "we estimate both the location and extent of objects and are capable of estimating multiple instances of objects in the test image .",
    "also , we use pre - existing classification networks for localization where as @xcite proposes training custom adaptation layers .",
    "we aim to localize and recognize objects in images using cnns trained for classification .",
    "there are two distinct phases .",
    "the first phase consists of learning image - level recognition from training image sets using existing deep cnn architectures .",
    "we use the popular alexnet @xcite and vgg-16 @xcite networks for our experiments .",
    "the next phase involves generating localization candidates in the form of bounding boxes for object classes of interest .",
    "these candidates are generated from a spatial grid corresponding to the final convolutional layer of the network and are organized in a search tree .",
    "we carry out a beam - search based exploration of these candidates with the image classifier scoring the candidates and reach at a set of final localization candidates for each class of interest .",
    "the alexnet network has five convolutional layers with associated rectification and pooling layers @xmath1 , along with three fully connected layers @xmath2 with @xmath3 , @xmath4 and @xmath5 .",
    "@xmath6 are learn - able parameters for the @xmath7-th layer , @xmath8 is the output of the @xmath7-th layer .",
    "@xmath9 is the rectification function and @xmath10}/\\sigma_{j}e^{\\textbf{x}[j]}]$ ] is the softmax function . of particular interest to us",
    "is the output of the last convolutional layer @xmath11 , @xmath12 which we will refer to subsequent sections .",
    "we learn the network parameters through stochastic gradient descent and back - propagation of learning loss error @xcite from the classification layer back through the fully connected and convolutional layers .",
    "keeping in mind that objects of multiple classes can be present in the same training image , we use the cross entropy loss function to model error loss @xmath13 between ground truth class probabilities @xmath14 and predicted class probabilities @xmath15 , where @xmath16 indexes the class labels .",
    "@xmath17\\ ] ]    as specified in @xcite , we remove @xmath18 and add two additional fully connected adaptation layers @xmath19 .",
    "similar to the alexnet network , the ouput of these layers are computed as @xmath20 and @xmath21 . in order to assess the effectiveness of the proposed method for localization",
    ", these additional layers are added to facilitate re - training of the network from the imagenet data - set to the pascal voc or ms coco object detection data - sets .",
    "we initialize network parameters to values trained on the imagenet data - set and fine - tune them @xcite to adapt onto a target data - set .",
    "this is achieved by setting the learning rate parameter for the last layer weights to a higher value relative to earlier layer weights .",
    "an illustration of the network architecture is presented in figure 2 of @xcite .",
    "we train the augmented network on labeled samples from the target data - set .",
    "the trained network produces class scores at the final layer which are treated as probability estimates of the presence of a class in the test image .    the vgg-16 network , being similar to the alexnet network , has thirteen convolutional layers @xmath22 with associated rectification and pooling layers , along with three fully connected layers @xmath2 .",
    "similar to the alexnet network , the feature map @xmath23 is of special interest to us .",
    "the increased number of layers and associated learnable parameters provides an improved image recognition performance when compared to the alexnet network .",
    "the improvement however comes at the cost of increased gpu memory ( 442 mb vs 735 mb ) and computations ( 6 milliseconds vs 26 milliseconds for classifying an image ) .",
    "in addition to using image - labels to train the deep cnns , we also use label co - occurrence information to improve classification .",
    "some classes tend to occur together frequently .",
    "for example , people and motorbikes or people and chairs tend to share training samples .",
    "we treat the class scores from the classifier as unary scores and combine them with the likelihood of co - existence of multiple objects of different classes in the same object .",
    "we model the co - existence likelihood by building a co - occurrence matrix for class labels from the training data - set . for the class @xmath24 ,    @xmath25    where @xmath26 is the initial classification score for the test image",
    ", @xmath27 is the pairwise score , @xmath28 denotes the number of training samples containing the labels @xmath24 and @xmath29 and @xmath30 is the combined score which we use to re - score the classes for the test image .",
    "the parameter @xmath31 denotes the importance given for pair - wise information in re - scoring .",
    "an optimal value is derived by testing over a randomly sampled validation sub - set from the training set .      in deep cnns trained for classification ,",
    "feature map activation values are the result of repeated localized convolutions , rectification ( or other non - linear operations ) and spatial pooling .",
    "hence the structure of the network inherently provides a receptive field for each activation on the input image .",
    "the foot - print region becomes progressively coarser as we go deeper in the layers towards the fully connected layers . in a first attempt",
    ", we explore ways to exploit the spatial information encoded in the last convolutional layer for object localization .    also ,",
    "standard state - of - the - art object recognition data - sets ( for e.g. imagenet ) typically have the object of interest represented in the middle of training samples .",
    "this gives rise to a bias in the classifier performance where more centered an object is in the input image , higher the corresponding class score becomes .",
    "an example is illustrated in figure @xmath0 .",
    "the correlation between the location of objects and class scores has been observed in other works @xcite , @xcite .        a naive approach to exploit the correlation would be to carry out a multi - scale sliding window sampling of sub - images from the test sample and spatially pool the classifier scores to generate a heat map of possible object locations for a given object class @xmath32 . the number of sub - images required for effective localization can be in the order of thousands . although powerful hardware like gpus have brought image recognition cnns into the domain of real - time methods , processing a large number of windows for every test sample is prohibitively expensive .",
    "a class of object detection methods @xcite try to reduce the number of candidate windows by using object region proposal methods @xcite , @xcite .",
    "time taken to detect objects in each image using these methods still range in tens of seconds when using powerful gpus .    for a more computationally efficient approach ,",
    "we take advantage of the spatial and semantic information encoded in the final convolutional feature maps to guide the search process .",
    "we refer to the maps as @xmath12 for alexnet and @xmath23 for vgg-16 in the section @xmath33 . for a general cnn network ,",
    "the final convolutional layer is of size @xmath34 which means there are @xmath35 feature maps of size @xmath36 .",
    "for the alexnet and vgg-16 networks , the feature maps are of size @xmath37 and @xmath38 respectively .    given a test image @xmath39 , we forward propagate the layer responses for the image up - to the final convolutional layer @xmath40 and generate the feature map activations @xmath41 .",
    "we generate localization candidates which are sub - grids of the @xmath36 grid . in concrete terms , these candidates are parametrised as boxes @xmath42 $ ] for @xmath43 where @xmath44 , @xmath45 , @xmath46 and @xmath47 represent the coordinates of the upper - left corner , width and height and @xmath48 is the total number of possible sub - grids . for each localization candidate",
    ", we sample the feature map activations contained within the corresponding boxes and interpolate them over the entire @xmath36 grid .",
    "this is done independently over all @xmath35 feature maps . for the box @xmath24 ,    @xmath49    where @xmath50 is an interpolation function which resizes the activation subset of size @xmath51 to the size @xmath36 . in the above equation , @xmath52 and bi - linear interpolation",
    "is used . after obtaining the reconstructed feature maps @xmath53",
    ", we forward propagate the activations into the fully connected layers and obtain the class scores .",
    "an illustration of this step is presented in figure @xmath54 .",
    "a limitation of the above approach is related to the fact that interpolating from a smaller subset to the larger grid will introduce interpolation artifacts into the reconstructed feature maps . in order to mitigate the effects of the artifacts , we limit the localization candidates to boxes with @xmath55 and @xmath56 . from this limited corpus of localization candidates , we generate the corresponding @xmath53 and consequently the object class scores , and choose the candidate with the highest class score . with the resultant localization candidate box",
    "@xmath57 , we backproject onto the image space by cropping : @xmath58    @xmath59    where @xmath60 indicate pixel locations , and @xmath61 and @xmath62 are width and height of the test image respectively .",
    "we then repeat the above described localization process on @xmath63 till a predetermined number of iterations .",
    "a visual example of progress in the iterative process is shown in figure @xmath64 .",
    "the localization strategy can be visualized as traversing down a search - tree where each node corresponds to a localization candidate @xmath24 .",
    "the root node of such a tree would be @xmath65 $ ] .",
    "the children of a node @xmath24 in the tree would be the candidates @xmath66 which lie within sub - grid corresponding to @xmath24 and whose parameters @xmath67 and @xmath68 satisfy the below conditions :    @xmath69    we consider children nodes whose width or height values , but not both of them differ from the parent node by @xmath70 .",
    "this restriction is put in place so that we are minimally modifying the feature map activations for discriminating amongst candidates .",
    "an example of a parent node @xmath24 and the corresponding children node set @xmath66 is shown in figure @xmath71 .",
    "grid , as is the case for the alexnet @xmath72 feature maps . ]    during traversal , the child candidate with the highest score for the class @xmath32 is selected .",
    "this approach is a greedy search strategy where we follow one path from the root node to a leaf node which represents the finest localization , and is susceptible to arrival at a locally optimal solution .",
    "alternatively , we could evaluate all the nodes in the entire search - tree and could come up with the localization candidate with the highest score for class @xmath32 .",
    "however , this would be computationally prohibitive .        to address this",
    ", we use the widely known beam - search @xcite strategy . at each level of the search - tree",
    "we generate sets of children nodes from the current set of localization candidates using equation @xmath73 .",
    "we then rank them according to the scores for class @xmath32 .",
    "only the top @xmath74 candidates are pursued for further evaluation .",
    "an illustration is presented in figure @xmath75 . in the figure",
    ", we show an example where the two highest candidates are chosen at each level .",
    "the children nodes of these candidates are evaluated and ranked .",
    "we traverse a total of @xmath62 levels .",
    "this approach helps us achieve a balance between keeping the number of computations to be tractable and avoiding greedy decisions .",
    "an additional advantage is the ability to localize multiple instances of the same class as the beam - search increases the set of localization candidates that are evaluated when compared to the greedy search strategy .",
    "regions in the image corresponding to top - ranked candidates from each level are spatially sum - pooled using candidates scores to generate a heat - map .",
    "the heat - map is then threshold - ed . bounding rectangles for the resulting binary blobs",
    "are extracted .",
    "the bounding rectangles are presented as detection results of our method .",
    "the average value of the heat - map values enclosed within detection boxes are assigned as the score of the boxes . in our experiments",
    ", we have set the value of @xmath74 as 8 and @xmath62 in the search tree as 10 for all data - sets .",
    "heat - map thresholds for each class were determined by evaluation on a small validation sub - set from the training set .",
    "we evaluate our localization method on two large image data - sets , the pascal voc 2007 @xcite , 2012 and the ms coco .",
    "the voc 2012 data - set has labels for 20 object categories and contains 5717 training images , 5823 validation images and 10991 test images .",
    "voc 2007 shares the same class - labels with 2501 training images , 2510 validation images and 4952 test images . for the ms coco data - set , there are 80000 images for training and 40504 images for validation with 80 object classes being present .",
    "these data - sets contain both image - level labels and object location annotations . for weak supervision",
    "we use the image - level labels from the training set to train classification networks and use the location annotations in the test and validation sets for evaluation .",
    "we fine - tune the original vgg-16 and alexnet networks ( trained on imagenet ) by re - training the final fully connected layer for the voc 2007 , 2012 and ms coco data - sets .",
    "we set the learning rate parameter to 0.001 which we decrease by a factor 10 for every 20000 training batches .",
    "each training batch consists of 50 samples and the network was trained with 400000 batches . in order to balance the data - sets with respect to number of samples per class , we oversampled training samples from under - represented classes .",
    "we generate additional samples by a combination of adding white gaussian noise and random rotations in the @xmath76 30@xmath77 range .",
    "we use caffe @xcite as our software platform for training and deploying classification networks on an nvidia titan x desktop gpu .      to compare results with the state - of - the - art in weakly supervised localization methods",
    ", we use the localization metric suggested by @xcite . from the class - specific heat - maps generated by our localization , we extract the region of maximal response . if the center location of the maximal response lies within the ground - truth bounding box of an object of the same class , we label the location prediction as correct . if not , the false positive count is increased as the background was assigned to the class , and the false negative count is increased because object was not detected .",
    "the maximal value of the heat - map is assigned as confidence of the localization .",
    "the confidence score is then used to rank localizations and associated precision - recall ( p - r ) curves are generated for each object class .",
    "the p - r curves are characterized by an estimate of the area under the curve , which is termed as the average precision ( ap ) .",
    "the ap score can vary from 0 to 100 .",
    "an @xmath78 score of 100 signifies that all true positives were localized and no false positives were assigned scores .",
    "the @xmath78 scores for all classes are averaged to derive the mean average precision ( map ) , which presents a summarized score for the entire test set .",
    "this evaluation metric differs from the traditional intersection - over - union ( @xmath79 ) measures to determine bounding box quality w.r.t the ground - truth , as the extent of the localization is not captured .",
    "in addition to the above metric , we are interested in measuring how effective our method is in capturing the extent of the object of interest .",
    "we calculate the standard average precision for our detection results , where true positives are determined when intersection over union ( iou ) between the predicted bounding boxes and the corresponding ground - truth box of the same class exceeds 0.5 .       & & & & & &    .comparison of image classification and object localization scores on the pascal voc 2012 @xmath80 set . for computing localization scores , responses are labeled as correct when the maximal responses fall within a ground - truth bounding box of the same class .",
    "false negatives are counted when no responses overlap with the ground - truth annotations .",
    "the class scores of the associated image - level classification are used to rank the responses and generate average precision scores . *",
    "rcnn and fast - rcnn are trained for object detection with object - level bounding box data .",
    "we use the most confident bounding box per class in every image for evaluation . [ cols=\"^ \" , ]",
    "the proposed method requires 2.6 sec to localize an object on an image on machine with a 2.3 ghz cpu with a nvidia titan x desktop gpu . compared to region proposal - based detection methods like rcnn which take around 20 seconds to detect objects ,",
    "we achieve a significant reduction in localization time .",
    "as can be seen from table @xmath81 , an improvement in the classification performance ( e.g. from alexnet to vgg-16 ) directly leads to an improvement in the localization performance .",
    "as the state - of - the - art of the classification cnns improves , we can expect a similar improvement in localization performance from our proposed method .    in summary",
    ", this method directly leverages feature map activations for object localization .",
    "this work uses the spatial and semantic information encoded in the convolutional layers and we have explored methods to utilize activations in the last convolutional layer",
    ". it would be interesting to see the improvements that could be derived by combining coarser semantic and finer localization information in earlier convolutional layers as well . another direction to explore",
    "would be combining fast super - pixel segmentation and localization candidates from proposed method to improve detection performance .",
    "the proposed method relies on weak supervision , with networks trained for image classification being used for localizing objects in test images with complex scenes and hence opens up possibilities for extending object localization to new object categories and image modalities without requiring expensive object - level annotations .",
    "bilen , h. , pedersoli , m. , tuytelaars , t. : weakly supervised object detection with convex clustering . in : proceedings of the ieee conference on computer vision and pattern recognition .",
    "10811089 ( 2015 )      brox , t. , bourdev , l. , maji , s. , malik , j. : object segmentation by alignment of poselet activations to image contours . in : computer vision and pattern recognition ( cvpr ) , 2011 ieee conference on .",
    ". 22252232 .",
    "ieee ( 2011 )          cinbis , r.g . ,",
    "verbeek , j. , schmid , c. : multi - fold mil training for weakly supervised object localization . in : computer vision and pattern recognition ( cvpr ) , 2014 ieee conference on .",
    ". 24092416 .",
    "ieee ( 2014 )      dalal , n. , triggs , b. : histograms of oriented gradients for human detection . in : computer vision and pattern recognition , 2005 .",
    "cvpr 2005 .",
    "ieee computer society conference on",
    ". vol .  1 ,",
    "ieee ( 2005 )    deng , j. , dong , w. , socher , r. , li , l.j .",
    ", li , k. , fei - fei , l. : imagenet : a large - scale hierarchical image database . in : computer vision and pattern recognition , 2009 .",
    "cvpr 2009 .",
    "ieee conference on .",
    ". 248255 .",
    "ieee ( 2009 )      everingham , m. , van  gool , l. , williams , c.k.i . ,",
    "winn , j. , zisserman , a. : the pascal visual object classes challenge 2007 ( voc2007 ) results .",
    "http://www.pascal-network.org/challenges/voc/voc2007/workshop/index.html    everingham , m. , van  gool , l. , williams , c.k.i . ,",
    "winn , j. , zisserman , a. : the pascal visual object classes challenge 2012 ( voc2012 ) results .",
    "http://www.pascal-network.org/challenges/voc/voc2012/workshop/index.html    felzenszwalb , p.f . ,",
    "girshick , r.b . ,",
    "mcallester , d. , ramanan , d. : object detection with discriminatively trained part - based models . pattern analysis and machine intelligence , ieee transactions on 32(9 ) , 16271645 ( 2010 )        girshick , r. , donahue , j. , darrell , t. , malik , j. : rich feature hierarchies for accurate object detection and semantic segmentation . in : computer vision and pattern recognition ( cvpr ) , 2014 ieee conference on .",
    "580587 . ieee ( 2014 )    glasner , d. , galun , m. , alpert , s. , basri , r. , shakhnarovich , g. : viewpoint - aware object detection and pose estimation . in : computer vision ( iccv ) ,",
    "2011 ieee international conference on .",
    ". 12751282 .",
    "ieee ( 2011 )      hariharan , b. , arbelaez , p. , girshick , r. , malik , j. : hypercolumns for object segmentation and fine - grained localization . in : the ieee conference on computer vision and pattern recognition ( cvpr ) ( june 2015 )    hartmann , g. , grundmann , m. , hoffman , j. , tsai , d. , kwatra , v. , madani , o. , vijayanarasimhan , s. , essa , i. , rehg , j. , sukthankar , r. : weakly supervised learning of object segmentations from web - scale video . in : computer vision ",
    "eccv 2012 .",
    "workshops and demonstrations .",
    ". 198208 .",
    "springer ( 2012 )    he , k. , zhang , x. , ren , s. , sun , j. : spatial pyramid pooling in deep convolutional networks for visual recognition .",
    "pattern analysis and machine intelligence , ieee transactions on 37(9 ) , 19041916 ( 2015 )    jia , y. , shelhamer , e. , donahue , j. , karayev , s. , long , j. , girshick , r. , guadarrama , s. , darrell , t. : caffe : convolutional architecture for fast feature embedding . in",
    ": proceedings of the acm international conference on multimedia .",
    "675678 . acm ( 2014 )                      oquab , m. , bottou , l. , laptev , i. , sivic , j. : is object localization for free ?  weakly - supervised learning with convolutional neural networks . in : proceedings of the ieee conference on computer vision and pattern recognition ( 2015 )    ouyang , w. , wang , x. , zeng , x. , qiu , s. , luo , p. , tian , y. , li , h. , yang , s. , wang , z. , loy , c.c . , tang , x. : deepid - net : deformable deep convolutional neural networks for object detection . in : the ieee conference on computer vision and pattern recognition ( cvpr ) ( june 2015 )      pourian , n. , vadivel , k.s . ,",
    "manjunath , b. : weakly supervised graph based semantic segmentation by learning communities of image - parts . in : computer vision",
    "( iccv ) , 2015 ieee international conference on .",
    "ieee ( 2015 )          sermanet , p. , eigen , d. , zhang , x. , mathieu , m. , fergus , r. , lecun , y. : overfeat : integrated recognition , localization and detection using convolutional networks . in : international conference on learning representations ( iclr 2014 ) .",
    "cbls ( april 2014 ) , http://openreview.net/document/d332e77d-459a-4af8-b3ed-55ba    shanmuga  vadivel , k. , ngo , t. , eckstein , m. , manjunath , b. : eye tracking assisted extraction of attentionally important objects from videos . in : the ieee conference on computer vision and pattern recognition ( cvpr ) ( june 2015 )        szegedy , c. , liu , w. , jia , y. , sermanet , p. , reed , s. , anguelov , d. , erhan , d. , vanhoucke , v. , rabinovich , a. : going deeper with convolutions . in : proceedings of the ieee conference on computer vision and pattern recognition .",
    "19 ( 2015 )      viola , p. , jones , m. : rapid object detection using a boosted cascade of simple features . in : computer vision and pattern recognition , 2001 .",
    "cvpr 2001 .",
    "proceedings of the 2001 ieee computer society conference on .",
    "vol .  1 , pp .",
    "i511 . ieee ( 2001 )        zhang , y. , sohn , k. , villegas , r. , pan , g. , lee , h. : improving object detection with deep convolutional networks via bayesian optimization and structured prediction . in : the ieee conference on computer vision and pattern recognition ( cvpr ) ( june 2015 )      zhu , y. , urtasun , r. , salakhutdinov , r. , fidler , s.",
    ": segdeepm : exploiting segmentation and context in deep neural networks for object detection . in : the ieee conference on computer vision and pattern recognition ( cvpr ) ( june 2015 )"
  ],
  "abstract_text": [
    "<S> object localization is an important computer vision problem with a variety of applications . </S>",
    "<S> the lack of large scale object - level annotations and the relative abundance of image - level labels makes a compelling case for weak supervision in the object localization task . </S>",
    "<S> deep convolutional neural networks are a class of state - of - the - art methods for the related problem of object recognition . in this paper , we describe a novel object localization algorithm which uses classification networks trained on only image labels . </S>",
    "<S> this weakly supervised method leverages local spatial and semantic patterns captured in the convolutional layers of classification networks . </S>",
    "<S> we propose an efficient beam search based approach to detect and localize multiple objects in images . </S>",
    "<S> the proposed method significantly outperforms the state - of - the - art in standard object localization data - sets with a 8 point increase in map scores . </S>"
  ]
}