{
  "article_text": [
    "the monte carlo method is a fundamental computational tool in science .",
    "its goal is to sample configurations @xmath0 in a given state space from a probability distribution @xmath1 .",
    "this can usually not be achieved directly for multi - dimensional distributions .",
    "markov - chain monte carlo methods @xcite overcome this problem by generating configurations @xmath2 starting from an initial configuration @xmath3 which belongs to a simpler distribution @xmath4 ( often a fixed initial condition , or some ad - hoc random choice ) .",
    "configurations @xmath5 are then generated from @xmath6 according to a stochastic algorithm which guarantees , as time moves on , that @xmath7 departs from the initial condition and converges for @xmath8 towards the equilibrium distribution @xmath9 .",
    "the markov - chain approach can be implemented for arbitrary distributions @xmath10 , using for example the metropolis and the heat - bath algorithms . for many applications ,",
    "enormous effort has gone into designing fast algorithms for which one reaches @xmath11 for reasonable running times @xmath12 . in this paper , we are concerned with a related problem : rather than to find the fastest algorithm for a given problem , we are interested in quantifying the speed of a given markov - chain algorithm .",
    "this is , we want to prove after which time @xmath12 the sample @xmath5 is equilibrated .",
    "it then reflects the equilibrium distribution and no longer the initial configurations . in many practical applications ,",
    "it is extremely difficult to decide from within the simulation whether it has indeed equilibrated @xcite .",
    "instead , one must validate the simulation results with other approaches , from exact solutions to experimental data .",
    "the correct characterization of the convergence towards equilibrium from within the simulation has remained a serious conceptual and practical problem of the monte carlo method .    from a fundamental viewpoint ,",
    "the problem of rigorously proving convergence of a simulation was solved , at least in principle , through a paradigm called `` exact sampling '' , which allows to generate , with markov chains , samples @xmath0 directly from the equilibrium distribution @xmath10 without any influence of the initial configuration@xcite . in practice , however , it has not been possible to implement exact sampling for many complicated problems , as for example disordered systems , for which standard methods of evaluating equilibration times fail .",
    "the reason for this difficulty is as follows : exact sampling proves for a given markov - chain simulation that the correlation of the initial configuration with the configuration at time @xmath12 strictly vanishes .",
    "this is done by showing explicitly that all possible initial configurations @xmath13 yield the same output under coupled monte carlo dynamics . in many simple models",
    ", one can prove this coupling property indirectly .",
    "in general , however , one must indeed survey the entire configuration space .",
    "this is usually too complicated to be achieved .",
    "we recently developed a local - patch algorithm@xcite which indeed monitors the entire configuration space of complicated systems , even for very large sizes .",
    "the approach uses local information , concentrated on so - called `` patches '' .",
    "the scale of these patches increases during the simulation .",
    "information on patches can then be combined for the entire system to provide a crucial upper bound for the ( global ) coupling time , and to generate an exact sample .",
    "the algorithm was demonstrated to work for spin glasses at lower temperatures than previous methods @xcite , even though the physically interesting regime has still not been reached yet .",
    "the local - patch algorithm is quite general : in addition to spin glasses , we implement it in this paper for hard disks and improve on previous results @xcite .",
    "the successful application of exact sampling to hard - sphere systems is remarquable because the configuration space is continuous so that , naively , its complete survey appears out of reach .",
    "a markov chain is fully characterized by the so - called `` transfer matrix '' of transition probabilities between any two configurations @xmath14 and @xmath15 . as will be illustrated shortly ( section  [ s : coupling_one_d ] ) in a specific example , the largest eigenvalue of the transfer matrix is @xmath16 and the corresponding eigenvector @xmath17 describes the equilibrium state .",
    "the convergence towards equilibrium is governed by the spectrum of the transfer matrix and by the overlap of the eigenvectors @xmath18 with the initial configuration : @xmath19 in the limit of infinite simulation time , the second - largest eigenvalue determines the exponential convergence of the probability distribution towards equilibrium .",
    "this eigenvalue sets a time scale @xmath20 and the convergence is as @xmath21 the rigorous determination of convergence properties of markov chains has been undertaken in many cases , from urn models to card - shuffling ( see @xcite ) , diffusion processes , and many more ( see @xcite ) .",
    "efficient algorithms , as for example the bunching method @xcite are commonly used to perform an empirical error analysis of monte carlo data in more complicated cases , where rigorous calculations are out of the question . however , these methods are not failsafe . in practice , it is often difficult to extract @xmath22 from the large number of physically relevant time scales .",
    "in disordered systems , for example , there is often no reliable way to ascertain that the simulation has run long enough , and @xmath22 may be much larger than assumed ( see e.g. @xcite , sect .",
    "1.5 ) .      in the limit of infinite times @xmath23",
    ", the markov chain converges towards the equilibrium distribution , and the positions @xmath5 become independent of the initial condition .",
    "the loss of correlation with the initial condition is evident for markov chains that couple , that is , which for each possible initial condition @xmath3 produce the same output @xmath5 . in many cases of interest",
    "this happens after a finite global `` coupling time '' @xmath24 , which depends on the realization of the markov chain .",
    "propp and wilson @xcite realized that this coupling property allows one to draw `` exact '' samples from the distribution @xmath10 .",
    "this approach , called `` coupling from the past '' , eliminates the problem of analyzing the convergence properties .",
    "however , to establish that a markov chain has coupled , the entire state space of the system must be supervised .",
    "this was believed infeasible except for special problems where the dynamics conserves a certain ( partial ) ordering relation on configurations .",
    "a partial order is conserved in heat - bath dynamics of the ferromagnetic ising model , whereas the frustration in the spin - glass model foils this simplification .",
    "[ s : coupling_one_d ]    we first discuss convergence and coupling for a markov chain describing the hopping of a single particle on a simple @xmath25-site lattice with periodic boundary conditions ( see fig .  [",
    "f : one_d_single ] ) . in one time step ,",
    "the particle hops with probability @xmath26 from one site to its two neighbors : @xmath27 in addition , we have @xmath28 .",
    "the equal hopping probabilities imply via the detailed balance condition @xmath29 that the stationary probability distribution @xmath30 of this problem is independent of @xmath14 .",
    "this system s monte carlo algorithm is encoded in the @xmath31 transfer matrix @xmath32 : @xmath33 the eigenvalues of @xmath32 are @xmath34 + 1 $ ] ( with multiplicities ) that is , for @xmath35 , @xmath36 .",
    "the largest eigenvalue , @xmath37 corresponds to the conservation of probabilities . by construction",
    ", it is associated with the equilibrium solution @xmath38 .",
    "the second - largest eigenvalue is @xmath39 .",
    "for @xmath35 we have @xmath40 .",
    "this eigenvalue controls the long - time corrections to the stationary solution , which vanish as @xmath41^{t } = { \\exp { \\left[}- t/{\\tau_{\\text{corr}}}{\\right]}}$ ] , with @xmath42 we note that the time scale @xmath22 only describes the asymptotic behavior of the correlation .",
    "the calculation of the time @xmath12 at which the probability distribution @xmath7 itself is within a suitably chosen @xmath43 of a the equilibrium distribution @xmath10 is more involved ( see , for example , @xcite ) .",
    "[ s : coupling ] as illustrated in fig .",
    "[ f : one_d_diffusion ] , the monte carlo algorithm can be formulated in terms of random maps . in our example",
    ", this means that instead of prescribing one move per time step , as in fig .",
    "[ f : one_d_single ] , we now sample moves for all times @xmath12 and all sites @xmath14 , in such a way that the dynamics of a single particle again satisfies the detailed balance condition of eq .",
    "( [ e : detailed_balance ] ) .",
    "the most natural implementation of this approach is illustrated in fig .",
    "[ f : one_d_diffusion ] : arrows are chosen independently for all times @xmath12 and all sites @xmath14 . at time @xmath44 , for example , the particle should move down from sites @xmath45 , @xmath46 , @xmath47 and @xmath48 and straight from site @xmath49 .",
    "we can now check the outcome of the monte carlo calculation . in the example of fig .",
    "[ f : one_d_diffusion ] , from time @xmath50 on , all initial configurations of the single particle yield the same output .",
    "this is remarkable because , evidently , at this time the initial conditions are completely forgotten .",
    "the coupling time @xmath51 is a random variable ( @xmath52 in fig .",
    "[ f : one_d_diffusion ] ) which depends on the realization of the full monte carlo simulation from time @xmath44 onwards ( until coupling has been reached ) .",
    "the independence of random maps on different time steps implies that the probability for not coupling vanishes at least exponentially fast in the limit @xmath8 .    under the random - map dynamics ,",
    "an initial state with @xmath25 particles eventually evolves into a state with one particle ( in later sections , spin - glass configurations will take the place of the single - particle positions ) .",
    "more generally , a state with @xmath14 configurations can evolve at each time step into a state with @xmath53 configurations .",
    "figure  [ f : one_d_diffusion ] displays a sequence of random maps and illustrates the associated time - forward search of the coupling time .",
    "this extended monte carlo dynamics on @xmath14-configuration states can again be described by a transfer matrix : @xmath54 where the block @xmath55 ( of sizes @xmath56 ) concerns all the processes which lead from a state at time @xmath12 with @xmath14 configurations to a state with @xmath57 configurations at time @xmath58 .",
    "the upper left block of this matrix , @xmath59 , is the original matrix from eq .",
    "( [ e : one_particle_mc ] ) . as an example , we find from eq .",
    "( [ e : algo_probabilities ] ) the following elements of this transfer matrix : @xmath60 etc .",
    "the matrix @xmath61 describes a physical system with variable particle number ( from @xmath45 to @xmath25 ) and a space comprising @xmath62 states , the number of non - empty states in this new simulation ( for a problem of @xmath25 spins , the number of configurations is @xmath63 and the total number of @xmath14-configuration states ( states with @xmath14 configurations ) is @xmath64 ) .",
    "the `` forward '' transfer matrix @xmath65 allows us to compute the coupling probabilities as a function of time in fig .",
    "[ f : coup_proba ] .",
    "the matrix @xmath61 is block - triangular in the number of particles @xmath66 , with the @xmath67 block given by @xmath59 .",
    "therefore , all the eigenvalues of @xmath59 are also eigenvalues of @xmath61 . in particular ,",
    "the largest eigenvalue of @xmath61 is again @xmath68 , with corresponding right eigenvector @xmath69 .",
    "the second - largest eigenvalue of @xmath61 belongs to the @xmath70 block and leads to the time scale of the coupling , @xmath71 .",
    "it is given by @xmath72 , larger than @xmath73 .",
    "this second - largest eigenvalue @xmath74 governs the coupling probability @xmath75 for large times .",
    "it follows from the block - triangular form of the forward transfer matrix @xmath61 that the time scales satisfy @xmath76 .",
    "a general argument allows us to better understand this result : for any running time @xmath12 we may separate all the markov chains into those that have already coupled and those that have not .",
    "only the non - coupled chains ( whose number vanishes as @xmath77 ) contribute to connected correlation functions : @xmath78 here , @xmath79 is an observable whose mean value is zero and @xmath80 the configuration of the system at time @xmath12 . for the chains which have coupled by the time @xmath12 , @xmath80 does not depend on @xmath81 , and the contribution to the correlation function vanishes . for the other chains ,",
    "we find @xmath82 where we suppose that even the non - coupled chains converge towards equilibrium on a time scale @xmath83 , and use that the probability for a chain not to have coupled behaves as @xmath77 in the long - time limit .",
    "equation  ( [ e : correlation_coupling_convergence ] ) shows that the difference between @xmath71 and @xmath22 is caused by the convergence taking place within non - coupling chains : @xmath84 this relation is illustrated in fig .",
    "[ f : coup_proba ] for the one - dimensional diffusion model with @xmath35 .",
    "a later figure , fig .",
    "[ f : spin_spin_corr ] , will illustrate for the case of spin glasses the split between the general spin ",
    "spin correlation function and that same object computed for non - coupling chains only .",
    "[ s : forward_and_backward ]    the probability distribution of coupling times in the forward direction can be obtained from the transfer matrix @xmath61 as we discussed in section  [ s : coupling ] . here",
    "we analyze the distribution of coupling times in the backward direction for the application of the `` coupling from the past '' protocol which , as we will see , is the same as the one in the forward direction .",
    "the backward coupling process leads to a generalized transfer matrix , @xmath85 , which again describes an extended monte carlo simulation .",
    "we consider a hypothetical simulation which has run since time @xmath86 up to time @xmath87 ( see fig .",
    "[ f : one_d_cftp ] ) .",
    "it follows from the discussion in section  [ s : coupling ] that the simulation has coupled .",
    "furthermore , because of the infinite separation between the infinitely remote initial condition and the final one , the resulting configuration ( at @xmath87 ) is in equilibrium .",
    "but it remains to be seen which one of the five configurations at @xmath87 is generated . in the example of fig .",
    "[ f : one_d_cftp ] , a one - step backtrack to time @xmath88 allows us to see that the configuration at @xmath87 can be neither @xmath89 nor @xmath90 nor @xmath91 .",
    "likewise , for @xmath92 output positions on the @xmath25-site ring this back - propagation leads to a dead end , and only a single position yields a full set of possibilities at some time @xmath93 . thus to find the output configuration of the simulation , one is interested in the first time in the past for which the simulation couples , that is one searches the `` backward '' coupling time . the implementation of this backward simulation , as defined for many particles , can again be described by a transfer matrix . for any distribution of arrows ,",
    "any occupied site @xmath14 at time @xmath12 propagates its occupation back to all the sites at time @xmath94 which have arrows pointing towards @xmath14 .",
    "the matrix element of @xmath95 between two states is given by the statistical weights of all the arrows connecting the two states .",
    "for example , we find for @xmath85 @xmath96 this is a non - trivial variant of the forward simulation as , for example , the matrix @xmath85 is not block - triangular as @xmath61 , but it is particle  hole symmetric ( as we see in the above example ) .    formally , a random map @xmath97 ( here a set of arrows ) associates configurations which are connected under the monte carlo dynamics .",
    "a @xmath14-configuration state @xmath98 is by definition a set of configurations . at time",
    "@xmath12 the state @xmath98 can be associated with the state @xmath99 at time @xmath58 via the forward matrix if and only if @xmath99 is the ( set ) image of @xmath98 by an allowed mapping @xmath97 ( i.e. @xmath100 ) .",
    "the same holds for the backward matrix but @xmath98 must be the reciprocal ( set ) image of @xmath99 ( i.e. @xmath101 ) .",
    "the backward transfer matrix @xmath85 manifestly differs from the forward matrix @xmath61 .",
    "however , we construct explicitly in appendix  [ s : similarity ] the similarity transform that maps @xmath61 onto @xmath85 .",
    "this means that @xmath102 ( see appendix  [ s : similarity ] ) .",
    "the similarity transformation @xmath103 associates a @xmath14-configuration state @xmath98 with the sum of states that share at least one configuration with @xmath98 , included itself .",
    "the spectrum of the backward transfer matrix thus agrees with the one of the forward matrix and the distribution of coupling times @xmath75 is identical for backward and forward dynamics .",
    "this result is natural because the probabilities for not coupling for @xmath12 time steps are identical in both forward and backward direction : @xmath104 ( see @xcite ) .",
    "the probability distribution @xmath105 measures the weight of the configuration @xmath106 under repeated application of the backward transfer matrix from the configuration at @xmath87 : @xmath107 .",
    "transition probabilities of the forward transfer matrix must satisfy the markov chain transition probabilities for single particles , but the choice of random maps is otherwise unrestricted .",
    "the one - particle sector is trivially correct for independent moves as in our diffusion model of section  [ s : coupling ] .",
    "we now discuss several alternative random maps for the one - dimensional diffusion , which may lower ( or increase ) the coupling time ( with , however @xmath76 ) or achieve a rapid reduction of the number of configurations for smaller time scales .    a naive example for the one - dimensional diffusion example consists of arrows , such as in fig .",
    "[ f : one_d_diffusion ] , but which for one time @xmath12 all point into the same direction , straight , up , and down , each with probability @xmath108 , so that single - particle moves satisfy the detailed balance condition . evidently , this random map does not couple , and the non - coupling markov chains , in eq .",
    "( [ e : coupling_convergence ] ) , converge in a time @xmath109 .",
    "we now modify this rigid algorithm by allowing arrows to change direction with probability @xmath43 .",
    "this makes the markov chain couple on a time scale @xmath110 , much larger than the correlation time @xmath22 , for small @xmath43 .",
    "the choice of independent random moves ( @xmath111 ) is optimal in this class of maps , but it is not the choice minimizing @xmath71 among all random maps . for example we may choose correlated moves for selected neighboring pairs of sites say , for sites @xmath112 and @xmath113 and let the move from site @xmath48 be independent ( see fig .",
    "[ f : one_d_corr_pairs ] ) .",
    "elements of @xmath114 are , for example , @xmath115 the single - particle sector of this algorithm is as before , but the second - largest eigenvalue of the transfer matrix @xmath61 with such correlated pair moves becomes smaller , indicating faster coupling : @xmath116 coupling times of both `` independent - arrow '' random mapping and `` correlated - pair '' random mapping scale alike for large @xmath25 .",
    "we note that in applications , as in our patch algorithm of section  [ s : local_patch ] , it might be not so much of interest to speed up the coupling than to rapidly decrease the number of possible configurations at times @xmath117 .",
    "therefore , one goal could be to decrease the eigenvalues of the matrix @xmath118 , whose time scales correspond to the rapid reduction of the number of configurations towards more manageable numbers .      as discussed in section  [ s : forward_and_backward ] , the coupling of markov chains allows one to produce exact samples of the equilibrium distribution : in the diffusion example , we were able to run the monte carlo simulation backwards in time using @xmath85 , but this matrix can usually not be constructed . to find the sample at time @xmath87 ,",
    "one may tentatively set a time @xmath119 and produce all the random maps between time @xmath44 and @xmath12 .",
    "one can then check explicitly whether all the possible initial conditions at time @xmath44 have coupled , that is , for the diffusion problem , whether the initial @xmath25-particle configuration @xmath106 has yielded one of the one - particle configurations .",
    "if this goal has not been reached , one must complement the random maps already computed with random maps for earlier times ( see fig .",
    "[ f : one_d_cftp ] ) .",
    "the one - dimensional diffusion problem without periodic boundary conditions illustrates an algorithm which determines the coupling time with much less effort .",
    "we consider odd times at which only sites @xmath120 and @xmath48 and even time steps at which only sites @xmath49 and @xmath47 may flip ( see fig .",
    "[ f : one_d_alternating ] ) .",
    "this preserves the correct stationary probability distribution , but the trajectories no longer cross each other ( as at time @xmath121 in fig .",
    "[ f : one_d_diffusion ] ) . as a consequence",
    ", it suffices to follow the two extremal configurations , which start at sites @xmath89 and @xmath122 , from time @xmath44 on in order to determine the coupling time for a given full monte carlo simulation .",
    "the multiple - particle monte carlo simulation starts with the state @xmath123 until it yields a single - particle state .",
    "the above strategy of following extremal configurations can be applied to the ferromagnetic ising model ( but not to spin glasses , see @xcite ) . in this case , the two configurations with all spins up and all spins down , respectively , are extremal .",
    "this idea also holds for the heat - bath algorithm of two - dimensional directed polymers in a random medium .",
    "we study the edwards  anderson @xmath124 ising spin glass on a @xmath125-dimensional square lattice , where each site is randomly coupled to all its @xmath126 neighbors .",
    "the energy of a configuration @xmath127 with @xmath128 is : @xmath129 where @xmath130 indicates the sum over nearest neighbors .",
    "this model has a phase transition at finite temperature in @xmath131 and at zero temperature in @xmath126 . sampling spin - glass configurations with markov - chain algorithms",
    "is extremely difficult in @xmath132 dimensions below the critical temperature , but it is also non - trivial in the two - dimensional case @xcite .",
    "we concentrate here on the study of a local heat - bath monte carlo algorithm , for which we apply the coupling - from - the - past protocol and obtain exact samples .",
    "we note that in two dimensions , the exact partition function of the ising model on a finite lattice can be determined exactly for any choice of couplings @xcite .",
    "this makes possible a direct - sampling algorithm , which is completely unrelated to the material presented here , but which we sketch , for the sake of completeness , in appendix  [ s : onsager_method ] .",
    "the heat - bath monte carlo algorithm for spin models updates at each time step a randomly chosen site @xmath133 of a spin configuration by comparing a function of the local field on site @xmath133 with a uniform random number @xmath134}$ ] : @xmath135}^{-1 } \\\\",
    "-1 & \\text{else } \\end{cases } , { \\label{e : heat_bath}}\\ ] ] where @xmath136 is the local field on site @xmath133 .",
    "a realization of the markov chain corresponds to sampling the real - valued random numbers @xmath137 and the random integers @xmath138 .",
    "the unit of `` physical '' time ( one `` sweep '' ) corresponds to @xmath25 individual updates .",
    "the situation is now much more complicated than for the @xmath139 diffusion , as the role of the five initial configurations in fig .",
    "[ f : one_d_diffusion ] is taken up by the @xmath63 possible spin configurations . to prove coupling one must show to which configuration they all converge at the coupling time .",
    "the state space is huge and one must find strategies to avoid enumerating and surveying @xmath63 configurations .      [",
    "s : partial_survey ]    in @xcite , we presented an exact - sampling algorithm which works down to quite low temperatures in the two - dimensional ising spin glass , and which is also operational in three dimensions .",
    "we found that practically the same results could be obtained by starting the simulation at time @xmath44 not from all the @xmath63 initial configurations , but from a more manageable number @xmath140 of randomly chosen configurations .",
    "we show in fig .",
    "[ f : ultra_naive_16x16_0.5 ] that such `` partial survey '' calculations yield useful lower bounds for the coupling time scale @xmath71 .",
    "each curve in the figure represents the mean number of distinct configurations remaining after coupled monte carlo simulations ( that is , with the same random numbers @xmath141 for all configurations ) for different values of @xmath140 . increasing @xmath140 within this partial - survey approximation naturally improves the lower bound on the coupling time but , in practice , the value obtained saturates quite quickly .",
    "as discussed previously , @xmath142 is always larger than @xmath22 because only non - coupling chains contribute to correlation functions ( see eq .",
    "( [ e : coupling_convergence ] ) ) .    to again illustrate the relation between coupling and convergence times , we separate in fig .  [",
    "f : spin_spin_corr ] non - coupling chains from the calculation of the spin ",
    "spin correlation function of a @xmath143 spin glass at inverse temperature @xmath144 . indeed ,",
    "even if the chain has not coupled , the configurations @xmath80 may lose the dependence on the initial configuration @xmath81 .",
    "in this section we discuss the application of the `` coupling from the past '' protocol to hard - sphere systems .",
    "the study of monte carlo algorithms for hard - sphere systems goes back a long time , as the metropolis algorithm was first implemented for hard disks , that is , two - dimensional spheres@xcite .",
    "even today , the physics of the hard - disk system is not well understood , and monte carlo algorithms have not been developed as successfully as , say , for the ising model . in this very constrained system ,",
    "the estimation of correlation times is quite controversial , especially at high densities@xcite , and rigorous results from exact - sampling approaches would be extremely welcome .",
    "we first discuss the birth  death formulation of the markov - chain monte carlo algorithm for this system and then compute lower bounds on coupling times using the partial - survey algorithm .",
    "its empirical coupling time saturates ( for increasing @xmath140 ) to much smaller values than the coupling times obtained by the summary - state method @xcite .",
    "this suggests that these previous algorithms are not optimal , an impression which is confirmed by our local - patch algorithm of section  [ s : patch_disk ] .",
    "the partition function of hard spheres in the grand - canonical ensemble , with fugacity @xmath145 , is given by a weighted sum over legal configurations of spheres : @xmath146 here , configurations of @xmath25 spheres are written as : @xmath147 where @xmath148 denotes the centers of the spheres . in eq .",
    "( [ e : partition_function ] ) , @xmath149 equals one if spheres of the configuration @xmath150 do no overlap and zero otherwise .",
    "we again use periodic boundary conditions .",
    "+      the spatial poisson birth  death process allows us to apply coupling from the past to hard - sphere systems ( see @xcite ) : disks of radius @xmath151 arrive ( `` are born '' ) randomly on a two - dimensional unit square with constant rate @xmath145 .",
    "once born , they disappear ( `` die '' ) with unit rate .    the probability for a disk to arrive within an infinitesimal time @xmath152 in a small box of area @xmath153 centered at @xmath154 is @xmath155 .",
    "this disk is added to the configuration only if it overlaps with no other disk present .",
    "each disk disappears with probability @xmath152 within the time interval @xmath152 .",
    "sphere are added at point @xmath154 or removed from the configuration @xmath150 according to the detailed balance condition . with the notation @xmath156",
    "we have : @xmath157    in fig .",
    "[ f : birth_death_w ] , we illustrate the time - evolution of accepted and rejected birth - death events on a one - dimensional hard - sphere problem , starting from an empty initial condition at time @xmath44 .    in the hard - sphere algorithm ,",
    "the probability distribution of time intervals between successive births is an exponential with parameter @xmath145 : @xmath158 . in fig .",
    "[ f : birth_death_w ] , the life time of a sphere is represented by a horizontal extension of the box , irrespective of whether it has been accepted or not ( the vertical dimension denotes the diameter ) .",
    "life times are exponentially distributed as well . for the exponential distribution , the time before the next death of a system of @xmath25 spheres follows an exponential distribution with parameter @xmath25 . likewise the time before any event , ( birth or death ) , follows an exponential distribution with parameter @xmath159 .",
    "the probability for the next event to be a birth is then @xmath160 .",
    "[ s : hard_disk_coup ]    coupling from the past applies to hard - sphere systems even though the space of configurations is continuous ( unlike in lattice simulations ) . to apply the protocol ,",
    "one considers a time evolution , as in fig .",
    "[ f : birth_death_w ] , but stretching back to time @xmath161 .",
    "two special aspects must now be handled :    first , we must determine which boxes ( corresponding to spheres ) are indeed placed ( `` true '' ) , and which ones are rejected ( `` false '' ) .",
    "this is difficult to decide at high density . however , in the low - density case presented in fig .",
    "[ f : time_space ] , several spheres are `` true '' , simply because they do not overlap with already present `` true '' or `` false '' spheres .",
    "this allows the status of other spheres to be fixed and , finally , the configuration to be constructed . in the limit @xmath162 ,",
    "the approach works up to a constant density @xcite .",
    "this density is much higher than the density @xmath163 direct - sampling algorithm can achieve@xcite .",
    "this approach @xcite is equivalent to deciding whether a given spin is up or down in the `` summary state '' algorithm for ising systems @xcite , which , in the thermodynamic limit works down to a fixed constant temperature .",
    "second , one must fix the initial condition at time @xmath164 , because spheres born at times smaller than @xmath164 may still be alive at time @xmath164 .",
    "this is solved through the sampling of a second time , @xmath165 , after which we know that all spheres present at time @xmath164 have disappeared .",
    "the time interval @xmath166 is sampled as the maximum of @xmath167 life times , where @xmath167 is an upper bound on the number of spheres in a legal configuration .",
    "figure  [ f : time_space ] sketches the time evolution of a monte carlo simulation for the one - dimensional hard - sphere problem which has started at time @xmath161 .",
    "boxes are drawn starting from time @xmath164 , but the simulation is picked up at time @xmath168 . it is straightforward to complement the simulation shown ( between times @xmath169 and @xmath164 , for example ) , in case it does not couple in the interval shown .",
    "however , we must show that it couples between @xmath169 and @xmath164 or at least results in less than @xmath167 spheres .",
    "in the monte carlo simulation in fig .  [ f : time_space ] , the status of the boxes at later times can be easily decided , because at later times all spheres belong to clusters which are disjoint from the initial condition .",
    "however , this possibility disappears at higher densities .",
    "a simple example of this is shown in fig .",
    "[ f : example_bd ] . as one can not decide on the status of the initial sphere ( which crosses the line at @xmath168 ) , we should initialize the simulation with the two configurations , one corresponding to a `` true '' state and one to a `` false '' state . after several steps of the time evolution ,",
    "we arrive in both cases at the same physical configuration ( the two dark spheres , which are both `` true '' ) .    for all times @xmath170",
    ", we consider the set @xmath171 of all `` true '' or `` false '' spheres crossing the time line at @xmath12 ( see fig .",
    "[ f : time_space ] ) . from the set @xmath172",
    ", one can in principle construct all the possible initial configurations , but their number remains huge . as in the spin - glass case , we may also select @xmath173 among these configurations , and propagate these .",
    "this is again the partial survey approximation . in fig .  [",
    "f : patches_vs_wilson ] we compare average lower bounds on the coupling time from this approximation with results from the summary state algorithm@xcite . in the time - evolution of fig .",
    "[ f : time_space ] , one can determine the number of remaining configurations at any time @xmath174 and detect when exactly the coupling occurs .",
    "[ s : local_patch ] in the present section , we discuss our local - patch algorithm , which performs the heat - bath dynamics for a general @xmath125-dimensional ising spin glass on an @xmath25-site hyper - cubic lattice .",
    "this algorithm allows us to control all the @xmath63 initial configurations even for very large lattices and to eventually prove that the system has coupled .",
    "the python script implementing this algorithm has less than 300 lines .",
    "it is available electronically and a listing of the code is contained in appendix  [ s : listing_python ] .",
    "the ( non - rigorous ) partial - survey algorithm of section  [ s : partial_survey ] determines the coupling time for a subset of all the configurations at time @xmath12 .",
    "the ( rigorous ) patch algorithm , in contrast , works with a superset of all configurations at time @xmath12 : by restricting the configurations to the smaller region of a patch , one severely limits their number , at the price of introducing compatibility problems between neighboring patches .",
    "for the two - dimensional spin glass , we use @xmath25 rectangular patches of same shape and orientation , with @xmath175 sites , and initially at @xmath176 , we have @xmath177 spin configurations on each patch . likewise ,",
    "the set of global spin configurations is broken up into a list @xmath178 $ ] of sets @xmath179 of spin configurations restricted to patches @xmath14 .",
    "we can recover a superset @xmath180 of all relevant spin configurations from the direct product @xmath181 here , each configuration of @xmath180 is pieced together from configurations on all patches , with compatible spins on all lattice sites .",
    "( two compatible spin configurations , on patches @xmath14 and @xmath15 , are shown in fig .",
    "[ f : patches_schema ] ) . on large lattices , the direct product in eq .",
    "( [ e : omega ] ) can be performed only if the number of spin configurations per patch is small .",
    "if there is only one configuration per patch , we can construct a unique global configuration on the whole lattice .",
    "for each time step @xmath12 of the heat - bath algorithm , we choose a random lattice site @xmath133 and a random number @xmath182}$ ] and then update the spin @xmath183 for all configurations on all patches containing @xmath133 . the site @xmath133 may be in the center of a patch @xmath14 ( all the neighbors of site @xmath133 also belong to @xmath14 , as in fig .  [",
    "f : patches_schema ] ) . in this case , each configuration of @xmath179 yields one configuration of @xmath184 .",
    "several configurations in @xmath179 may yield the same configuration in @xmath184 , so that the size of @xmath185 does not increase in this case .",
    "if the site @xmath133 is on the boundary of a patch @xmath15 , we only know upper and lower bounds for the field on the site @xmath133 and , depending on the value of the random number @xmath186 , may be unable to update @xmath183 .",
    "in this case , we add two configurations to the set @xmath184 , corresponding to @xmath187 as well as @xmath188 .",
    "the set @xmath184 may then contain more configurations than @xmath179 .",
    "[ s : pruning ]    besides updating configurations on patches , we also perform a `` pruning '' operation : figure  [ f : patches_schema ] presents two `` compatible '' configurations on patches @xmath14 and @xmath15 .",
    "these could possibly be pieced together into a global configuration , together with configurations on other patches . on the other hand ,",
    "if the set @xmath189 contains no configuration compatible with a configuration @xmath190 on patch @xmath14 , we can eliminate ( prune ) @xmath190 from @xmath185 .",
    "pruning may be implemented through a dictionary ( hash table ) , using as `` key '' the part of the patch configuration in the overlap region between @xmath14 and @xmath15 , and as `` value '' the list of patch configurations sharing this key ( see fig .",
    "[ f : dictionary ] ) .",
    "this is programmed very easily in the python programming language ( see appendix  [ s : listing_python ] ) .",
    "pruning can be iterated until all the sets @xmath179 are pairwise compatible . to achieve this goal",
    ", it suffices to prune nearest - neighbor patches only .",
    "we have found it useful to perform one pruning operation for each pair of nearest - neighbor patches after a certain number of updates ( see fig .  [",
    "f : patches_straight_16x16_1.0 ] ) . the average number of configurations per patch saturates to a value which depends on the temperature and also the size of the patch .",
    "this is due to the balance between the decrease of the number of configurations induced by the coupling and its increase caused by the noise at the patch boundaries .",
    "this noise is reduced through the crucial pruning step of the algorithm .      as illustrated in fig .  [",
    "f : patches_straight_16x16_1.0 ] , the number of configurations per patch does not necessarily drop to one at large times , even if the underlying heat - bath dynamics couples .",
    "the entropy per spin is smaller for larger patches , because the influence of the boundaries is reduced .",
    "however , one can not start the computation with large patches because of the large number of possible configurations .",
    "a merging procedure allows to increase the patch size in a rigorous way .",
    "merging is implemented analogously to pruning : for overlapping patches @xmath14 and @xmath15 , dictionaries are again computed with the same keys and values ( see again fig .  [",
    "f : patches_schema ] ) . for a given key configuration on the overlap region ,",
    "we assemble the corresponding values in the dictionary of patch @xmath14 with all corresponding values in the dictionary of patch @xmath15 .",
    "all these couples of configuration must be taken into account for the larger patch @xmath191 .",
    "the merging of the configurations on neighboring patches can be implemented very efficiently in the python programming language ( see appendix  [ s : listing_python ] ) . in our computations , we start with small square patches , say of size @xmath192 , and then pass to the size @xmath193 , after a few sweeps , then to size @xmath194 , etc . an analogous procedure is followed in higher dimensions .",
    "results obtained with this `` jump - start '' approach are shown in fig .",
    "[ f : fig_jump_32x32_0.5_5gen ] for the two - dimensional ising spin glass at temperature @xmath195 , with a disorder average performed over about @xmath196 samples .      in the patch algorithm ,",
    "the pruning procedure detects inconsistent configurations in a particular patch .",
    "two configurations on different patches are considered compatible if their spins match in the overlap region ( at time @xmath12 ) .",
    "more generally , we can keep track of the past evolution of patch configurations and may then declare them compatible only if they have matched for all times up to @xmath12 .",
    "otherwise , they can not belong to a unique global spin configuration .    in @xcite , the bipartite nature of the square lattice",
    "was used to update one entire sub - lattice at a time . in this approach ,",
    "only one sub - lattice is stored at a time .",
    "this allows one to start with larger patches , but the compatibilities between configurations are less well conserved . by contrast , in the present algorithm , we keep the information on both sub - lattices , and one of the sub - lattices is the past configuration .",
    "two configurations are compatible in this new version if they are compatible on both sub - lattices .",
    "likewise one can use past values of a configuration @xmath197 to restrict its compatibilities with configurations on other patches .",
    "other generalizations are more straightforward , one can for example optimize the shape of patches in order to minimize the number of spins on the boundary , and work with more than @xmath25 patches in order to increase the chance for detecting incompatibilities of configurations .",
    "[ s : patch_disk ]    in this section , we adapt the local - patch algorithm for the classical model of hard disks in a two - dimensional box with periodic boundary conditions . as mentioned , it works for large system sizes at higher density than previous method of exact sampling .    in section  [ s : hard_disk_coup ]",
    ", we introduced the set @xmath171 of all disks the dynamics has tried to add in the box and which have not disappeared at time @xmath12 .",
    "the coupled monte carlo simulations start with all possible configurations that are allowed by the set @xmath172 at time @xmath168 . because of possible overlap between disks",
    "some of the @xmath198 possible configurations are invalid but there may be far too many of them in practice .",
    "to reduce the number of configurations which must be handled , we introduce a regular square lattice with @xmath25 sites covering the simulation box .",
    "likewise , a superset of all feasible configurations on a patch at time @xmath168 can be deduced from the set @xmath172 , restricted to disks ( true or false ) with centers inside the patch . from then on , whenever disks appear in the simulation box , we can decide whether they are accepted on a particular patch configuration by checking overlaps into the patch only .",
    "disks that disappear are simply removed from all the concerned patch configurations . at birth time , if the disk to be placed on a patch configuration may overlap with a disk outside the patch , the configuration is split into two : one configuration with the new disk and one without ( as for spin systems ) . to detect and prune irrelevant configurations we check that the updated sets of configurations are compatible with other patches by a pruning procedure analogous to the one of section  [ s : pruning ] .",
    "after several updates , the pruning is performed for most of overlapping patches several times .    for any pair of overlapping patches @xmath14 and @xmath15 ,",
    "the pruning eliminates patch configurations with are inconsistent with all other configurations on a neighboring patch . as in the spin glass case",
    ", this process can be implemented with dictionaries ( hash tables ) ( see fig .  [ f : dictionary_disks ] ) and can be used to merge configurations on neighboring patches into larger local configurations .",
    "figure  [ f : patches_vs_wilson ] displays the mean coupling times of a hard - disk birth  death simulation for several choices of the fugacity @xmath145 .",
    "the radius of the disks is @xmath199 in a unit square box with periodic boundary conditions .",
    "results are compared to the partial - survey approximation algorithm , with @xmath200 initial configurations and to the results of the summary - state algorithm .",
    "we concentrated on determining the coupling times of the birth ",
    "death dynamics for hard disks .",
    "however , the regime of operation of this algorithm is far in the liquid phase ( see fig .  [",
    "f : patches_vs_wilson ] ) , and the physically interesting regime , around the liquid  solid transition density , @xmath201 @xcite is still out of reach for exact sampling methods . for hard disks , it remains a challenge to set up a working partial - survey algorithm with correlation times comparable to those of the usual metropolis algorithm @xcite .",
    "in this paper , we have discussed exact - sampling algorithms which allow one to totally eliminate the influence of the initial condition from a markov - chain monte carlo simulation .",
    "this overcomes one of the main limitations of the method , namely the rigorous estimation of the correlation time .",
    "we discussed central subjects , such as the relation between coupling times and convergence times , in a simple example of one - dimensional diffusion , before applying them to ising spin glasses and to hard - sphere simulations .",
    "algorithmically , the exact - sampling framework obliges one to follow the entire state space of a system . in the absence of simplifications , such as the half - order discussed in section  [ s : coupling_one_d ] , this can be done approximately through a partial survey of @xmath140 initial conditions .",
    "one can also restrict the configuration in size onto so - called patches , thereby restricting their number .",
    "a superset of the set of global configurations can in principle be reconstituted from the patches .",
    "this is easier when the patches are large , and we showed how pruning and merging operations allow one to increase the size of patches during the simulation and to finally prove coupling .",
    "our exact - sampling algorithm works both for spin glasses and hard - disk systems , and were able to go to lower temperatures , and higher densities than previous methods .",
    "the partial survey algorithm , which can be implemented easily , allowed us to prove that our local - patch algorithm is optimal for the local dynamics for both spin - glass and hard - disk systems .",
    "we have provided a number of new idea in order to allow exact - sampling methods to reach the phases transitions of the three - dimensional ising spin glass and the critical density of hard disks .",
    "[ s : similarity ] forward and backward transfer matrices completely describe the coupling dynamic of general markov chains ( on a finite state space ) , that is their elements are the coupled transition probabilities between sets of configurations .",
    "forward and backward matrices represent `` extended '' monte carlo dynamics , in the two time directions .",
    "these two formulations are equivalent , even though the forward dynamics , starting from @xmath87 , does not generate exact samples . here , we demonstrate similarity between forward and backward transfer matrices , and construct the similarity transformation between the two .",
    "let @xmath202 be the finite space of configurations of the problem of interest .",
    "@xmath202 may contain all @xmath25 positions on the @xmath25-site diffusion problem or the @xmath63 configurations of a @xmath25-site spin system .",
    "the @xmath14-configuration states build up an `` extended '' state space .",
    "they provide a natural basis for the forward and backward matrices .",
    "this basis is @xmath203 , the set of non trivial parts of @xmath202 . for any state @xmath204",
    "we define @xmath205 as the set of states of the basis @xmath206 that has at least one configuration in common with @xmath207 ( @xmath208 ) .",
    "the similarity matrix @xmath103 is then defined as :    @xmath209    a random mapping ",
    "arrows for the case of 1@xmath210-diffusion  is a mapping on @xmath202 : @xmath211 .",
    "it defines a time step of the markov chain for every configuration and satisfies @xmath212 and its weight is noted @xmath213 . in the case of 1@xmath125-diffusion with independent arrows , or any `` independent '' random map in general , we naturally define the weight of the random map as a product of elements of the monte carlo transfer matrix as @xmath214    the forward matrix associates any state @xmath207 to all states that it is connected to by a mapping : @xmath215 using eq .",
    "( [ e : similarity ] ) we find @xmath216    the backward matrix @xmath85 has different rules but we will show that the similarity @xmath217 holds . using a random map @xmath97",
    ", a state @xmath206 at time @xmath12 evolves to another state @xmath218 at time @xmath58 in the backward process if and only if @xmath219 .",
    "for example in the 1d - diffusion a hole goes to a hole and a particle goes to a particle .",
    "therefore : @xmath220 and finally : @xmath221 in fact eqs  ( [ e : bp ] ) and  ( [ e : pf ] ) are equivalent because @xmath222 overlaps @xmath207 if and only if @xmath218 overlaps @xmath223 ( @xmath224 ) .",
    "this proves the similarity of the backward and forward matrices .",
    "[ s : onsager_method ]    in this appendix , we sketch for completeness an unrelated direct - sampling algorithm for the two - dimensional ising spin glass . to generate exact samples ,",
    "this algorithm does not use markov chains .",
    "it rather relies on the fact that the partition function of the two - dimensional ising model or of one sample of the spin glass on a planar lattice with @xmath25 sites can be expressed as the square root of the determinant of one @xmath225 matrix ( for open boundary conditions ) or of four such matrices ( for periodic boundary conditions ) @xcite .",
    "this relation has been much used in the recent literature , in order to study the physics of the two - dimensional ising spin glass at low temperature @xcite .",
    "the partition function yields the thermodynamics of the system , but the knowledge of entire configurations gives for example access to complicated spatial configuration functions .",
    "the sampling algorithm for two - dimensional spin - glass configurations constructs the sample one site after another .",
    "let us suppose that the gray spins in the left panel of fig .",
    "[ f : onsager_direct ] are already fixed , as shown .",
    "we can now set a fictitious coupling @xmath226 either to @xmath227 or two @xmath228 and recalculate the partition function @xmath229 with both choices .",
    "the statistical weight of all configurations in the original partition function with spin `` @xmath230 '' is then given by @xmath231 and this two - valued distribution can be sampled with one random number . equation  ( [ e : direct_sampling ] ) resembles the heat - bath algorithm of eq .",
    "( [ e : heat_bath ] ) , but it is not part of a markov chain : after obtaining the value of the spin on site @xmath14 , we keep the fictitious coupling , and add more sites .",
    "going over all sites , we can generate direct spin - glass samples at any temperature .",
    "we note that this algorithm is polynomial , and the effort is basically temperature - independent , both for the two - dimensional ising model and the ising spin glass ( see also @xcite ) .",
    "[ s : listing_python ] the following python code has produced all the spin - glass data presented in this article . an analogous program was used for the hard - disk system .",
    "an electronic version of the code is available from the authors .    .... # !",
    "/usr / bin / python # # --------------------------------------------------------------------- # # program : pruning_nd.py # # purpose : this program performs the heat - bath and the pruning on a # #            n - dimensional hypercubic lattice with periodic boundary # #            conditions and with cuboid patches . # #            version with jump - start capability . # # output   : mean number of configurations per patch vs. time   # #            ( can be modified ) # # version : 04-oct-2009 # # author   : w. krauth , c. chanal # # language : python 2.5 # # --------------------------------------------------------------------- from random import uniform , randint , seed , shuffle , choice from operator import itemgetter import time , math , os , sys # # --------------------------------------------------------------------- # # sample geometry # # --------------------------------------------------------------------- def torus_neighbors(n_dim , l ) :     n = l**n_dim     site_dic = { }     coord_dic = { }     for j in range(n ) :        j_d = j        x_d = j//(l**(n_dim-1 ) )        coord = [ x_d ]        for d in range(n_dim-1 ) : # this loop does not run anything for n_dim=1           j_d = ( j_d - x_d*l**(n_dim - d-1 ) )           x_d = j_d//(l**(n_dim - d-2 ) )           coord.append(x_d )        coord.reverse ( ) # optional , to set the usual order of the directions        coord = tuple(coord )        site_dic[coord ] = j        coord_dic[j ] = coord     nbr = [ ]     for j in range(n ) :        coord = list(coord_dic[j ] )        nbr_list = [ ]        for d in range(n_dim ) :           coord[d ] = ( coord[d]+1)%l           coord_p = tuple(coord )           nbr_list.append(site_dic[coord_p ] )           coord[d ] = ( coord[d]-1+l)%l            for d in range(n_dim ) :           coord[d ] = ( coord[d]-1+l)%l           coord_p = tuple(coord )           nbr_list.append(site_dic[coord_p ] )           coord[d ] = ( coord[d]+1)%l                 nbr_list = tuple(nbr_list )        nbr.append(nbr_list )     nbr = tuple(nbr )     return nbr , site_dic , coord_dic # # --------------------------------------------------------------------- # # initial patch geometry # # --------------------------------------------------------------------- def patch_set(n_dim , l , m , site_dic , coord_dic ) :     patch = [ ]     for j in range(n ) :        coord = list(coord_dic[j ] )        dummy_list = [ ]        for k in range(m**n_dim ) :           coord_p = [ ]           for d in range(n_dim ) :              l = ( k//(m**d))%m              coord_p.append((coord[d]+ l)%l )           coord_p = tuple(coord_p )           dummy_list.append(site_dic[coord_p ] )        patch.append(tuple(dummy_list ) )     patch = tuple(patch )     return patch # # --------------------------------------------------------------------- # # neighbor relations on patches # # --------------------------------------------------------------------- def nbr_patch_set(example_patch , nbr ) :     nbr_patch = [ ]     for j in example_patch :        dummy = [ ]        for k in nbr[j ] :           if k in example_patch : dummy.append(example_patch.index(k ) )        dummy = tuple(dummy )        nbr_patch.append(dummy )     nbr_patch = tuple(nbr_patch )     return nbr_patch # # --------------------------------------------------------------------- # # initial patch configurations # # --------------------------------------------------------------------- def patch_init(patch ) :     def bin(n , conf_length ) : # # # # convert n to binary number with conf_length digits # #        q = -1        bin_conf = ''        n_digits = 0        while q ! = 0 :           q = n//2           r = n%2           bin_conf = ` r`+bin_conf           n = q           n_digits = n_digits+1        n_digits = conf_length - n_digits        for i in range(n_digits ) :           bin_conf = ` 0`+bin_conf        return bin_conf     configs = [ ]     dummy_list = [ ]     number = len(patch[0 ] )     for j in range(2**number ) :        x = bin(j , number )        dummy_list.append(x )     for i in range(len(patch ) ) :        configs.append(set(dummy_list ) )     return configs # # --------------------------------------------------------------------- # # updating configurations on all patches # # --------------------------------------------------------------------- def confs_update(n_dim , configs , nbr_patch , jij , patch , i_site , upsilon ) :     for k in range(n ) :        if i_site in patch[k ] :           dummy = list(patch[k ] )           pos = dummy.index(i_site )           llist = [ patch[k][x ] for x in nbr_patch[pos ] ]           jij_list = [ jij[(i_site , m ) ] for m in llist ]           config_k = configs[k ]            config_kp = set ( [ ] )           for c in config_k :              field_char = itemgetter(*nbr_patch[pos])(c )              field_sum = sum((2*eval(m)-1)*j for ( m , j ) in zip(field_char , jij_list ) )              field_min = field_sum-2*n_dim+len(field_char )              field_max = field_sum+2*n_dim - len(field_char )              b_one = c[:pos]+'1'+c[pos+1 : ] # configuration with ' 1 ' at position ' pos '              b_zero = c[:pos]+'0'+c[pos+1 : ] # configuration with ' 0 ' at position ' pos '              if upsilon < phplus[field_min ] :                  config_kp.add(b_one )              elif upsilon > phplus[field_max ] :                  config_kp.add(b_zero )              else :                 config_kp.add(b_zero )                 config_kp.add(b_one )           configs[k ] = config_kp     return configs # # --------------------------------------------------------------------- # # pruning of two patches # # --------------------------------------------------------------------- def prune_pair(config_k , config_l , key_k , key_l ) :     f = itemgetter(*key_k )     dic_k = { }     for x in config_k :        a = f(x )        if dic_k.has_key(a ) : dic_k[a].add(x )        else : dic_k[a ] = set([x ] )     set_k = set(dic_k.keys ( ) )     f = itemgetter(*key_l )         dic_l = { }     for x in config_l :        a = f(x )        if dic_l.has_key(a ) : dic_l[a].add(x )        else : dic_l[a ] = set([x ] )     set_l = set(dic_l.keys ( ) )     set_kl = set.intersection(set_k,set_l )      config_k = set ( )     config_l = set ( )     for x in set_kl :        config_k.update(dic_k[x ] )        config_l.update(dic_l[x ] )     return config_k , config_l # # --------------------------------------------------------------------- # # merging of two patches # # --------------------------------------------------------------------- def merge_pair(config_k , config_l , key_k , key_l , key_add ) :     f = itemgetter(*key_k )     dic_k = { }     for x in config_k :        a = f(x )        if dic_k.has_key(a ) : dic_k[a].add(x )        else : dic_k[a ] = set([x ] )     set_k = set(dic_k.keys ( ) )     f = itemgetter(*key_l )         dic_l = { }     for x in config_l :        a = f(x )        if dic_l.has_key(a ) : dic_l[a].add(x )        else : dic_l[a ] = set([x ] )     set_l = set(dic_l.keys ( ) )     set_kl = set.intersection(set_k,set_l )      config_kl = set ( ) # merged set     for x in set_kl :        for y in dic_k[x ] :           for z in dic_l[x ] :              zprime = ' ' .join(itemgetter(*key_add)(z ) )              config_kl.add(y+zprime )     return config_kl # # --------------------------------------------------------------------- # # main program starts here # # --------------------------------------------------------------------- # seed(13 ) beta = 0.25 # inverse of temperature # # --------------------------------------------------------------------- # # heat bath definitions ( see smac fig . 5.20 , and smac eq . 5.18 )",
    "# # --------------------------------------------------------------------- n_dim = 3 phplus = { } for d in range(n_dim+1 ) :     field = 2*d     phplus[field ] = 1/(1+math.exp(-2*field*beta ) )     phplus[-field ] = 1/(1+math.exp(2*field*beta ) ) # # --------------------------------------------------------------------- # # loop over samples starts here # # ---------------------------------------------------------------------",
    "l = 6 os.system('echo ` hostname ` ` date ` ' ) print   beta , l , ' beta l ' for nsamp in range(100 ) :     n = l**n_dim     m = 2 # m^n_dim is the initial size of patches     over_min = ( m-1)*m**(n_dim-1 ) # minimum overlap for the pruning      del_t = 40 # time lap on each patch size     n_gen = 7 # number of generations      t_max = 2000 # total number of sweeps     n_frac = 6 # do n / n_frac spin updates between prunings     nbr , site_dic , coord_dic = torus_neighbors(n_dim , l ) # # --------------------------------------------------------------------- # # jij : a dictionary ( i , j ) - > j_ij # # ---------------------------------------------------------------------     jij = { }     for k in range(n ) :        for d in range(n_dim ) :           jij[(k , nbr[k][d ] ) ] = choice([-1,1 ] )           jij[(nbr[k][d],k ) ] = jij[(k , nbr[k][d ] ) ]          patch = patch_set(n_dim , l , m , site_dic , coord_dic )     nbr_patch = nbr_patch_set(list(patch[0]),nbr )     permut = [ k for k in range(n ) ]     configs = patch_init(patch ) # # --------------------------------------------------------------------- # # loop over generations in the jump - start procedure # # ---------------------------------------------------------------------     for iter1 in range(n_gen ) :        i_dir = iter1 % n_dim        tot_it = 0 .",
    "patch_size = len(patch[0 ] )        print patch_size , ' size of patch '        while ( tot_it < del_t and iter1 < n_gen-1 ) or ( iter1 = = n_gen-1 and \\                      tot_it + del_t*iter1 <",
    "t_max ) :            quality = sum([len(configs[k ] ) for k in range(n)])/float(n )           sys.stdout.flush ( )           print tot_it+del_t*iter1 , quality           # if ( iter1==n_gen-1 ) : n_frac=18 # do n / n_frac spin updates between prunings           for iter3 in range(n / n_frac ) :              tot_it + = 1./n              i_site = randint(0,n-1 )              upsilon = uniform(0,1 )              configs = confs_update(n_dim , configs , nbr_patch , jij , patch , i_site , upsilon ) # # --------------------------------------------------------------------- # # pruning starts here # # ---------------------------------------------------------------------           shuffle(permut )           for kk in range(n ) :              k = permut[kk ]              for ll in range(kk+1,n ) :                 l = permut[ll ]                 inter_set = set(patch[k ] ) & set(patch[l ] )                 if len(inter_set ) > = over_min :   # minimum overlap                    key_k = [ list(patch[k]).index(i ) for i in inter_set ]                    key_l = [ list(patch[l]).index(i ) for i in inter_set ]                    configs[k],configs[l ] = prune_pair(configs[k],configs[l],key_k ,",
    "key_l )           if ( quality==1 ) : break        if ( quality==1):break # # --------------------------------------------------------------------- # # merging starts here : producing new patches , and computing configurations on them # # ---------------------------------------------------------------------        patch_new = [ ]        configs_new = [ ]        for k in range(n ) :           key_add = [ ]           dummy_new = list(patch[k ] )           l = nbr[k][i_dir ] # l is the neighbor of k in the ' i_dir ' direction           for x in patch[l ] :              if x not in patch[k ] :                 dummy_new.append(x )                 key_add.append(list(patch[l]).index(x ) )           patch_new.append(tuple(dummy_new ) )           inter_set = set(patch[k ] ) & set(patch[l ] )           key_k = [ list(patch[k]).index(i ) for i in inter_set ]           key_l = [ list(patch[l]).index(i ) for i in inter_set ]           config_k_merge = merge_pair(configs[k],configs[l],key_k , key_l ,",
    "key_add )           configs_new.append(config_k_merge ) # # --------------------------------------------------------------------- # # merging ( final steps ) : computing neighbor relations on the new patches   # # ---------------------------------------------------------------------        patch = tuple(patch_new )        nbr_patch = nbr_patch_set(list(patch[0]),nbr )        configs = configs_new        if i_dir = = n_dim-1 :           m + = 1           over_min = ( m-1)*m**(n_dim-1 ) ...."
  ],
  "abstract_text": [
    "<S> we discuss convergence and coupling of markov chains , and present general relations between the transfer matrices describing these two processes . </S>",
    "<S> we then analyze a recently developed local - patch algorithm , which computes rigorous upper bound for the coupling time of a markov chain for non - trivial statistical - mechanics models . using the `` coupling from the past '' protocol , </S>",
    "<S> this allows one to exactly sample the underlying equilibrium distribution . for spin glasses in two and three spatial dimensions , the local - patch algorithm works at lower temperatures than previous exact - sampling methods . </S>",
    "<S> we discuss variants of the algorithm which might allow one to reach , in three dimensions , the spin - glass transition temperature . </S>",
    "<S> the algorithm can be adapted to hard - sphere models . for two - dimensional hard disks , </S>",
    "<S> the algorithm allows us to draw exact samples at higher densities than previously possible . </S>"
  ]
}