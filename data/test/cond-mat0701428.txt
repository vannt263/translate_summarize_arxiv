{
  "article_text": [
    "the dmrg algorithm was introduced by steven white @xcite , as an algorithm for calculating ground state properties of principally one - dimensional strongly correlated systems in condensed matter physics .",
    "the connection between dmrg and matrix product states @xcite ( also known as finitely correlated states ) was first made by rommer and stlund @xcite , who identified the thermodynamic limit of dmrg with a position - independent matrix product wavefunction .",
    "although dmrg had already proven itself to be useful empirically , this was an important step in rigorously establishing the physical basis of the algorithm due to the concrete and easy to manipulate form of matrix product states .",
    "work on the spectra of density matrices @xcite , later formulated as scaling of the von neumann entropy @xcite has placed the algorithm on a firm footing , showing that the required computational effort ( realized via the basis dimension @xmath0 ) is essentially a function of the entanglement of the wavefunction @xcite , which for one - dimensional ground - states scales at worst logarithmically with the system size @xcite .",
    "computationally , mps algorithms came to the fore with the assistance of a quantum information perspective , leading to algorithms for periodic boundary conditions @xcite , and finite temperature algorithms based on density operators @xcite . at around the same time , methods for simulation of real time evolution were developed in dmrg @xcite , which can also benefit from mps formulations @xcite .",
    "the common theme of mps approaches is to allow algorithms that operate on multiple , distinct wavefunctions at the same time .",
    "this is possible in the original formulation of dmrg only by constructing a mixed effective hilbert space that is weighted appropriately to represent all of the relevant states simultaneously .",
    "this is inefficient , as the algorithms typically scale as @xmath1 ( or up to @xmath2 for periodic boundary conditions @xcite ) in the number of basis states @xmath0 , so increasing @xmath0 so as to represent multiple states in the same basis is typically much slower than performing separate operations on each basis .",
    "in addition , the mixed basis approach lacks flexibility . while traditional dmrg programs calculate the wavefunction and a few ( often predetermined ) expectation values or correlation functions , if instead the wavefunction is calculated in the mps representation of eq .",
    "( [ eq : mpwavefunction ] ) it can be saved for later use as an _ input _ for many purposes .",
    "perhaps the simplest such operation beyond the scope of traditional dmrg is to calculate the _ fidelity _ , or _",
    "overlap _ between the wavefunctions obtained from separate calculations . in the mps formulation ,",
    "this calculation is straightforward .",
    "nevertheless the determination of the scaling function for the fidelity of finite - size wavefunctions for different interaction strengths , provides a new tool for investigating phase transitions and crossover phenomena @xcite .",
    "indeed , due to the simplicity of the calculation the fidelity is likely in the coming years to be the first choice for quantitatively determining critical points .",
    "similar measures of entanglement , such as the concurrence and single- and two - site entropy @xcite , are also straightforward to calculate , hence the mps formalism allows us to apply directly the emerging tools of quantum information to the study of realistic systems in condensed matter physics .",
    "an alternative measure , the loschmidt echo @xcite is important because , unlike many of the quantum information theoretic measures , this is directly accessible in experiments while showing the rich behavior of the simpler measures .",
    "the loschmidt echo is more time - consuming to measure numerically as it requires a full time evolution simulation rather than a direct measurement , nevertheless it is well within the current state of the art @xcite .    in this paper",
    ", we focus on the case of open boundary condition matrix product states",
    ". this does not preclude calculation of periodic systems , however the entanglement of such periodic states is increased such that in the large @xmath3 limit ( where @xmath3 is the lattice size ) , the number of states kept tends to the square of that required for open boundary conditions @xcite .",
    "algorithms exist for periodic boundary conditions @xcite and infinite systems @xcite ( not to be confused with the ` infinite - size ' dmrg algorithm ) , and the basic formulas introduced here carry over to these cases , but we do not describe the specific algorithms here . in sec .",
    "[ sec : mps ] , we introduce the basic formulation of matrix product states , and formulas for the fidelity .",
    "[ sec : operators ] is devoted to a new approach , whereby we construct the hamiltonian operator itself as an mps , with many advantages .",
    "we cover some remaining details of the dmrg algorithm in sec .",
    "[ sec : dmrg ] , before discussing in detail the use of abelian and non - abelian quantum numbers in sec .",
    "[ sec : quantumnumbers ] .",
    "we finish with a few concluding remarks in sec .  [",
    "sec : conclusions ] , including some observations on finite temperature states .",
    "we denote an mps on an @xmath3-site lattice by the form @xmath4 the local index @xmath5 represents an element of a local hilbert space at site @xmath6 .",
    "the two important cases we cover here are when @xmath5 runs over a @xmath7-dimensional local basis for a wavefunction @xmath8 , in which case we refer to this as a matrix product wavefunction ( mpw ) , or @xmath5 is a @xmath9-dimensional local basis for all operators acting on a local site , which we refer to as a matrix product operator ( mpo ) . in this paper",
    ", we use mps for a generic state irrespective of the form of the local space , and use mpw or mpo as necessary when the distinction between wavefunctions and operators is important . in general , the matrix product form can also represent periodic @xcite and infinite ( non - periodic ) states @xcite , but here we use only the open - boundary form equivalent to the wavefunction obtained by dmrg @xcite . to enforce this boundary condition , we require the left - most matrix @xmath10 to be @xmath11 dimensional , and the right - most matrix @xmath12 to be @xmath13 . here we have introduced @xmath0 as the basis size , or dimension of the _ matrix basis _ of the @xmath14-matrices .",
    "this quantity is often denoted @xmath15 , or sometimes @xmath16 , in the quantum information literature , but we emphasize it is exactly the same quantity in all cases . in general @xmath0 is position",
    "dependent , as we do not require the @xmath14-matrices to be square even away from the boundary .",
    "because of the 1-dimensional basis at the boundaries we can regard the mps wavefunction to be a sequence of operators attached to left and right ( or outgoing and incoming ) vacuum states .",
    "this makes the operator product in eq .",
    "( [ eq : mpwavefunction ] ) an ordinary number , so the trace operation can be dropped .      in practice , a mps state with no particular constraints on the form of the @xmath14-matrices",
    "is numerically difficult to handle .",
    "we are always free to insert some product of a non - singular @xmath17 operator @xmath18 and its inverse @xmath19 in the middle of our mps , thus we can apply an arbitrary transformation to the matrix basis of an @xmath14-matrix , as long as we make the corresponding transformation to its neighbor . using this freedom , we can transform the @xmath14-matrices into a form where they are orthonormalized , that is , we prefer that they satisfy one of two possible constraints , @xmath20 states satisfying these conditions are orthonormalized in the sense that if all @xmath14-matrices to the left of some matrix @xmath21 are orthogonalized in the left - handed sense , then the basis on the left - hand side of @xmath21 is orthonormal ( _ ie _ the identity operator in the effective hilbert space is trivial ) .",
    "conversely , if all @xmath14-matrices to the right of @xmath21 are orthogonalized in the right - hand sense , then the basis on the right - hand side of @xmath21 is orthogonal .",
    "usually , we want both these conditions to be true simultaneously .",
    "note that it is not , in general , possible for _ all _ of the @xmath14-matrices ( including @xmath21 itself ) to be in orthonormal form at the same time .",
    "there are several ways of transforming an arbitrary mps into this normalized form .",
    "two ways that we consider here are the singular value decomposition ( svd ) , and the related reduced density matrix , as used in dmrg @xcite .",
    "the simplest , and in principle the fastest , is the svd , well - known from linear algebra @xcite .",
    "for example , for the left - handed orthogonality constraint on @xmath22 , where we have re - inserted the matrix indices @xmath23 , we consider @xmath24 to be a single index of dimension @xmath25 , giving an ordinary @xmath26 dimensional matrix , and carry out the singular value decomposition , @xmath27 where @xmath28 is column - orthogonal , @xmath29 , and @xmath30 is row - orthogonal , @xmath31 .",
    "@xmath15 is a non - negative diagonal matrix containing the singular values .",
    "this form coincides with the schmidt decomposition , where @xmath15 gives the coefficients of the wavefunction in the schmidt basis @xcite .",
    "the matrix @xmath28 therefore satisfies the left - handed orthogonality constraint , so we use this as the updated @xmath14-matrix , and multiply the @xmath14-matrix on the right by @xmath32 .",
    "this implies that the @xmath14-matrix on the right is no longer orthonormalized ( even if it was originally ) , but we can apply this procedure iteratively , to shift the non - orthogonal @xmath14-matrix to the boundary  or even beyond it  at which point the @xmath33 @xmath14-matrix coincides with the norm of the wavefunction . an important point here is that we can choose to discard some of the states , typically those that have the smallest singular value .",
    "this reduces the matrix dimension @xmath0 , at the expense of introducing an approximation to our wavefunction , such that the squared norm of the difference of our approximate and exact wavefunctions is equal to the sum of the squares of the discarded singular values .",
    "note however that the singular values only correspond to the coefficients of the schmidt decomposition if all of the remaining @xmath14-matrices are orthogonalized according to eq .",
    "( [ eq : normalizationconstraint ] ) .",
    "if this is not the case , the singular values are not useful for determining which states can be safely discarded .    alternatively , we can construct the reduced density matrix , obtained by tracing over half of the system .",
    "this is achieved by @xmath34 which is a @xmath35 matrix , with @xmath0 eigenvalues coinciding with the values on the diagonal of @xmath36 , and the remaining eigenvalues are zero .",
    "again , the eigenvalues are only meaningful if the remaining @xmath14-matrices are appropriately orthogonalized .",
    "the utility of the density matrix approach over the svd , is that we can introduce mixing terms into the density matrix which can have the effect of stabilizing the algorithm and accelerating the convergence , which is further discussed in sec .",
    "[ sec : dmrg ] .",
    "the overlap of two mps is an operation that appears in many contexts . for wavefunctions",
    "this gives the fidelity of the two states , and for operators this is equivalent to the operator inner product @xmath37 which induces the frobenius norm .",
    "direct expansion of the mps form yields , @xmath38 due to the open boundary conditions , the direct product @xmath39 reduces to an ordinary @xmath17 matrix , after which can construct successive terms recursively , via @xmath40 with an analogous formula if we wish to start at the right hand side of the system and iterate towards the left boundary , @xmath41 for the purposes of numerical stability , it is advisable for the @xmath14- and @xmath42-matrices to be orthogonalized in the same pattern , that is , @xmath43-matrices are associated exclusively with the left - hand orthogonality constraint and @xmath44-matrices are associated with the right - hand orthogonality constraint . if we iterate all the way to the boundary , the @xmath43- ( or @xmath44- ) matrix ends up as a @xmath33 matrix that contains the final value of the fidelity .",
    "alternatively , we can iterate from both ends towards the middle and calculate the fidelity as @xmath45 .",
    "the key notion of the matrix product scheme is that of _ local updates _ ; that is , we modify , typically though some iterative optimization scheme , one ( or perhaps a few ) @xmath14-matrix while keeping the remainder fixed .",
    "a useful and flexible alternative is the _ center matrix formulation _",
    ", where , instead of modifying an @xmath14-matrix directly , we introduce an additional matrix @xmath46 into the mps , @xmath47 this allows us to preserve orthogonality of the matrices at all times ; matrices @xmath48 for @xmath49 are normalized always according to the left - handed constraint , and matrices for @xmath50 are normalized according to the right - handed constraint .",
    "we directly modify only the matrix @xmath46 which simplifies the local optimization problem as @xmath46 is just an ordinary matrix . to introduce the local degrees of freedom ,",
    "say for the @xmath51 states , we _ expand _ the basis for @xmath21 .",
    "that is , we replace the @xmath17 dimensional matrices @xmath21 with @xmath52 matrices @xmath53 , given by @xmath54 and introduce the @xmath26 dimensional center matrix @xmath55 with @xmath56 running over @xmath25 states .",
    "this does nt change the physical wavefunction , as @xmath57 .",
    "similarly , we can expand the basis for the @xmath14-matrix on the right side of @xmath46 , to give the effect of modifying either a single @xmath14-matrix , or two ( or more ) at once .",
    "in the center matrix formulation , the singular value decomposition required for truncating the basis is simply the ordinary svd on the matrix @xmath58 , and we multiply ( for a right - moving iteration ) @xmath59 , which preserves the left - handed orthogonality constraint , and @xmath60 which is not orthogonal , but becomes so when we again expand the basis to construct the new @xmath46 matrix .",
    "the density matrix in the center matrix formulation is simply @xmath61 or @xmath62 for left and right moving iterations respectively . for readers already familiar with dmrg",
    ", the center matrix corresponds exactly with the matrix form of the _ superblock wavefunction _ @xcite .",
    "the utility of the mps approach is realized immediately upon attempting manipulations on the wavefunction eq .",
    "( [ eq : mpwavefunction ] ) .",
    "suppose we have two distinct mps , defined over the same local hilbert spaces , @xmath63 the superposition @xmath64 is formed by taking the sum of the matrix products , @xmath65 , which can be factorized into a new mps , @xmath66 , with @xmath67 to preserve the one - dimensional basis at the boundaries , the direct sum is replaced by a concatenation of columns or rows , for the left and right boundary respectively .",
    "this procedure results in an mps of increased dimension , @xmath68 .",
    "thus , after constructing these matrices we need to re - orthogonalize the state , and then we can , if necessary , truncate the basis size to a given truncation error , which is well defined here and measures the exact difference between the original and truncated wavefunctions .",
    "alternatively , the normalized and truncated mps @xmath69 can be constructed directly , by calculating the overlap matrices @xmath43 between @xmath70 and @xmath71 . from the @xmath43-matrices introduced in eq .",
    "( [ eq : ematrix ] ) , we can construct directly the orthogonalized reduced density matrices of @xmath69 and truncate the basis as required , in a single step .",
    "this approach has better computational scaling than the two - step procedure of first orthogonalizing and then truncating , especially when the number of mps in the superposition is large .",
    "but in general , iterative optimization approaches , where we use a dmrg - like algorithm to optimize the overlap @xmath72 , have even better performance scaling with large @xmath0 or more states in the superposition .",
    "a useful generalization of the mps structure eq .",
    "( [ eq : mpwavefunction ] ) is to use it to represent an operator ( an mpo ) instead of a wavefunction .",
    "this has been used before for calculating finite - temperature density matrices @xcite , but here we instead want to use this structure to represent the hamiltonian operator itself . all hamiltonian operators with finite - range interactions have an _ exact _ mps representation with a relatively small matrix dimension @xmath73 .",
    "for example , the ising model in a transverse field has a dimension @xmath74 , and the fermionic hubbard model has dimension @xmath75 .",
    "we use the capital letter to distinguish from the dimension of the wavefunction , @xmath0 .",
    "similarly , the local dimension of the upper index is denoted here by @xmath15 , which is usually just equal to @xmath9 , but slightly complicated in the case of non - abelian quantum numbers ( see sec .  [",
    "sec : nonabelian ] ) .",
    "we denote an mpo by the form @xmath76 where again we require that the first and last dimensions are @xmath77 , for open boundary conditions .",
    "the orthogonality constraint used previously for the mps , eq .",
    "( [ eq : normalizationconstraint ] ) , is not appropriate for hamiltonian operators .",
    "when applied to an operator , the usual orthogonality constraints utilize the ( frobenius ) operator norm , which scales exponentially with the dimension of the hilbert space . with this normalization ,",
    "components of an mpo hamiltonian , such as the identity operator or some interaction term , tend to differ in magnitude by some factor that increases exponentially with the lattice size .",
    "arithmetic manipulations on such quantities is a recipe for catastrophic cancellation @xcite resulting in loss of precision . mixing operators with a unitary transformation ( for example @xmath78 ) , will lead to a disaster if @xmath79 and @xmath80 differ by a sufficiently large order of magnitude , @xmath81 for typical double - precision floating point arithmetic .",
    "but such rotations are inevitable in the orthogonalization procedure because in general the operator inner product @xmath82 will not be zero .",
    "instead we completely avoid mixing different rows / columns of the operator @xmath73-matrices , only collapsing a row or column if it is exactly parallel with another row or column . in this case , the actual norm of each component of the @xmath14-matrices is irrelevant , as they are never mixed with each other ( but see also the discussion of the single - site algorithm in sec .  [ sec : dmrg ] ) .",
    "for physical hamiltonian operators this remains essentially optimal , with the minimum possible matrix dimension @xmath73 .",
    "the only operators for which this orthogonalization scheme does not produce an optimal representation are operators that have a form analogous to an aklt @xcite state where the local basis states of the @xmath83 chain are replaced by local operators .",
    "the resulting operator contains an exponentially large number of @xmath84-body interactions for all @xmath85 .",
    "we know of no physical hamiltonians of this form .    given a hamiltonian as a sum of finite - range interactions , it is possible to construct the operator @xmath73-matrices such that they are entirely lower ( or upper ) triangular matrices , thus in principle we can ` normalize ' the matrices via some kind of generalized @xmath86 or @xmath87 decomposition . in practice we do nt need to do this , as the hamiltonian can easily be constructed in lower - triangular form from the beginning .",
    "imposing , again without loss of generality , that the top - left and bottom - right components of the operator @xmath73-matrices are equal to the identity operator @xmath88 , we can construct the sum of @xmath89-site local terms @xmath90 as a position - independent mps , @xmath91 which we regard as a @xmath92 matrix , the elements of which are @xmath93 dimensional local operators .",
    "for nearest - neighbor terms , @xmath94 , we have @xmath95 with the obvious generalization to @xmath84-body terms .",
    "the direct sum and direct product of lower triangular matrices is itself lower triangular , thus this form can be preserved throughout all operations .",
    "for open boundary conditions , the left ( right ) boundary @xmath96 ( or @xmath97 ) matrices are initialized to @xmath98 and @xmath99 respectively .    the principal advantage of formulating the hamiltonian operator ( and indeed , _ all _ operators needed in the calculation ) in this way that it can be manipulated extremely easily , amounting to a symbolic computation on the operators .",
    "this is in contrast to the ad hoc approach used in past dmrg and mps approaches where the block transformations required for each operator are encoded manually , with limited scope for arithmetic operations . in particular , the sum of operators is achieved via eq .",
    "( [ eq : mpssum ] ) .",
    "products of operators are achieved by matrix direct product ; given mpo s @xmath14 and @xmath42 , the product @xmath100 is given by the matrices @xmath101 an implication of this is that the square of an mpo has a matrix dimension of at most @xmath102 , which , since @xmath73 is usually rather small , means that it is quite practical to calculate expectation values for higher - order moments , for example of the _ variance _ @xmath103 which has been mentioned previously @xcite as it gives a rigorous _ lower bound _ on the energy ( although with no guarantee that this corresponds to the ground - state ) . in practice",
    "this lower bound is too wide to be useful in all but the simplest cases , but of more interest is the property that the variance is , to first order , proportional to the squared norm of the difference between the exact and numerical wavefunctions , and therefore also proportional to the truncation error @xcite ( see sec .  [ sec : dmrg ] ) .",
    "thus , this quantity gives a quantitative estimate of the goodness of the wavefunction even for situations where the truncation error is not available . for our numerical mps algorithms",
    "the variance takes the role of the precision @xmath104 in numerical analysis @xcite via @xmath105 .    of a similar form to the product of two operators ,",
    "the action of an operator @xmath73 on a wavefunction @xmath106 gives a wavefunction @xmath107 with matrix elements , @xmath108 the mpo formulation also gives a natural form for the evaluation of expectation values , similarly to the fidelity of eq .",
    "( [ eq : overlap ] ) , @xmath109 where the @xmath43- and @xmath44-matrices now have an additional index @xmath110 that represents the terms in the mpo @xmath73 , with a recursive definition @xmath111 where again we can either iterate all the way to a boundary , at which point the @xmath110 index collapses down to one - dimensional and the @xmath112 or @xmath113 are @xmath33 dimensional matrices containing the expectation value , or we can iterate from both boundaries and meet at the middle , where our expectation value is given by the scalar product eq .",
    "( [ eq : expectation ] ) .",
    "incidentally , given that the identity operators occur in a fixed location in the operator @xmath73-matrix ( ie .",
    "at the top - left and bottom - right of the @xmath73-matrix ) this fixes the index @xmath110 of the reduced hamiltonian and identity operators for the left and right partitions of the system .",
    "that is , in the application of the hamiltonian @xmath114 matrices to the wavefunction we are guaranteed that the @xmath115 component of @xmath116 corresponds precisely to @xmath117 , and the @xmath118 component corresponds to @xmath119 .",
    "thus , even after an arbitrary series of mpo computations we can still identify exactly which component of the @xmath120 matrices corresponds to the block hamiltonian .",
    "this is useful for eigensolver preconditioning schemes @xcite , for example to change to a basis where the block hamiltonian is diagonal .    .",
    "the @xmath121 symbols denote the impurity magnetization calculated via adaptive time dmrg , the dashed line is a guide to the eye .",
    "parameters of the calculation were ( in units of bandwidth ) , @xmath122 , on a log - discretized wilson chain with @xmath123 . at time @xmath124 , the hamiltonian was switched to @xmath125 and @xmath126 . , scaledwidth=80.0% ]    as an example of the utility of this approach , fig . [",
    "fig : timeexample ] shows the time evolution of the magnetization of the impurity spin in the single impurity anderson model ( siam ) , where the ground - state is obtained with a small magnetic field which is then turned off at time @xmath124 .",
    "the mps operator approach readily allows the evaluation of the commutators required for a small @xmath127 expansion of the expectation value of an observable in the heisenberg picture , @xmath128 - \\frac{t^2}{2!\\hbar^2}[h,[h , a ] ] - \\frac{it^3}{3!\\hbar^3}[h,[h,[h , a ] ] ] + \\cdots \\ ; .\\ ] ] since the number of terms in the repeated commutator will , in general , increase exponentially the accessible time - scales from such an expansion are clearly limited .",
    "nevertheless this is a very fast and accurate way to obtain short - time - scale dynamics , and in this example @xmath129 order is easily enough to determine the @xmath130 relaxation rate . for this calculation",
    ", the terms up to @xmath131 took a few seconds to calculate , while the @xmath132 term took 6 minutes and the @xmath133 term took just over an hour , on a single processor 2ghz athlon64 .",
    "this time was divided between calculating the mpo matrix elements ( the dimension of which was just over 2500 at the impurity site ) , and calculating the expectation value itself .",
    "we now have all of the ingredients necessary to construct the dmrg algorithm for determining the ground - state .",
    "indeed , given the previous formulations , the dmrg itself is rather simple ; using the center matrix formulation , we iteratively improve the wavefunction locally by using the center matrix @xmath46 as input to an eigensolver for the ground - state of the hamiltonian .",
    "the details of this calculation are precisely as for dmrg , already covered elsewhere @xcite .",
    "an important component of dmrg , which has been neglected in some matrix product approaches , is the truncation error .",
    "if only a single site is modified at a time , the maximum number of non - zero singular values is bounded by the matrix dimension @xmath0 , thus the matrix dimension can not be incrementally increased as the calculation progresses .",
    "some way of avoiding this limitation is practically essential for a robust algorithm .",
    "the original dmrg formulation @xcite solved this problem by modifying two a - matrices simultaneously , equivalent to expanding the matrix dimension for both the left and right @xmath14-matrices in eq .",
    "( [ eq : centermatrixmps ] ) so that the center matrix has dimension @xmath134 .",
    "a scheme for single - site algorithms that avoids the limit on the singular values was introduced by steven white @xcite , which uses a mixed density matrix constructed by a weighted sum of the usual reduced density matrix and a perturbed density matrix formed by applying the @xmath112-matrices ( on a right - moving sweep ) or @xmath113-matrices ( on a left - moving sweep ) of the hamiltonian , @xmath135 where @xmath136 is some small factor that fixes the magnitude of the fluctuations .",
    "this solves nicely the problem of the bound on the number of singular values and introduces fluctuations into the density matrix that give the algorithm good convergence properties , often better than the two - site algorithm .",
    "a minor problem is that the scaling of the @xmath112 matrices is not well defined , in that we can scale the @xmath112-matrices by an arbitrary @xmath137 non - singular matrix @xmath138 , while at the same time scaling the @xmath44-matrices by @xmath19 . for one- and two - site terms",
    ", there is an ` obvious ' scaling factor to use , whereby the scaling factors are chosen such that the ( frobenius ) operator norm of the @xmath43 and @xmath44-matrices are identical , but i do nt know how this would apply more generally . an alternative that appears interesting is to apply the full hamiltonian to a density operator for the full system , @xmath139 , constructed from the left ( right ) reduced density matrix and the right ( left ) identity operator , followed by a trace over the right ( left ) partition . in mps form , this operation is @xmath140 where @xmath141 is an @xmath137 coefficient matrix .",
    "however , this scheme often fails ; incorporating the @xmath142 matrix reduces the fluctuations such that @xmath143 differs little from @xmath144 itself and the algorithm typically fails to reach the ground - state .",
    "the single - site algorithm @xcite corresponds to choosing @xmath145 .",
    "a useful compromise appears to be using only the _ diagonal _ elements , such that @xmath146 , but this is surely not the last word on this approach . both the two - site and mixed single - site algorithm inevitably result in a reduction in the norm of the wavefunction by truncating the smallest non - zero eigenvalues of the density matrix .",
    "the sum of the discarded eigenvalues , summed over all iterations in one sweep , is equal to the truncation error @xmath147 , familiar from dmrg @xcite ( but note that it is common in the literature to quote an average or maximum truncation error _ per site _ ) .",
    "this quantity is useful in giving an estimate of the error in the wavefunction in this is , for a properly converged wavefunction , proportional to the norm of the difference between the exact ground - state and the numerical approximation .",
    "the presence of the truncation error explains why the bare single - site algorithm , despite having slightly better variational wavefunction than the two - site or mixed single - site algorithms @xcite , converges much slower ; the single site algorithm is a highly constrained optimization within an @xmath0-dimensional basis , whereas the two - site and mixed single - site algorithms are selecting the optimal @xmath0 basis states out of a pool of a much larger set of states , namely the discarded states at each iteration ( total @xmath148 states ) . while the notion of truncation error remains useful in mps algorithms , for the purposes of error analysis we much prefer the variance eq .",
    "( [ eq : variance ] ) as being a direct measure of the accuracy of the wavefunction , independent of the details of a particular algorithm @xcite .",
    "low - lying excited states can be constructed using this algorithm .",
    "this has been done in the past in dmrg by targeting multiple eigenstates in the density matrix , but the mps formulation allows a substantial improvement .",
    "namely , it is easy to incorporate into the eigensolver a constraint that the obtained wavefunction is orthogonal to an arbitrary set of predetermined mps s .",
    "that is , after constructing the mps approximation to the ground - state , we can , as a separate calculation , determine the first excited state by running the algorithm again with the constraint that our obtained wavefunction is orthogonal to the ground - state .",
    "this is achieved by constructing the @xmath43-matrices that project the set of states to orthogonalize against onto the local hilbert space .",
    "these matrices are precisely those used in constructing the fidelity , eq .",
    "( [ eq : overlap ] ) , thus given the center matrix of some state @xmath149 , we project this onto the current hilbert space @xmath150 , and as part of the eigensolver , orthogonalize our center matrix against this state .",
    "this is a very fast operation , much faster than even a single hamiltonian - wavefunction multiplication .",
    "so it is quite practical to orthogonalize against a rather large number of states , the practical limit is rather on numerical limitations in orthogonalizing the krylov subspace in the eigensolver .",
    "if this is combined with an eigensolver capable of converging to eigenvalues in the middle of the spectrum ( say , the lowest eigenvalue larger than some bound @xmath151 ) , then we need only a small number of states to orthogonalize against , say half a dozen states immediately above @xmath151 in energy",
    ". in our numerical tests it seems to be rather common to skip eigenvalues , which is why we can not simply orthogonalize against a single state . with a larger number of states to orthogonalize against , skipping eigenvalues is less of a problem as we are likely to recover the missing eigenstate on a later calculation . using this approach",
    ", quantities such as the level spacing statistics can be determined for system sizes far beyond exact diagonalization @xcite .",
    "an important feature of matrix product states is that they can easily be constrained by quantum numbers representing the global symmetries of the hamiltonian , as long as the symmetry is not broken by the spatial geometry of the mps .",
    "for example , internal rotational symmetries such as @xmath152 and @xmath153 @xcite can be maintained exactly , but for a real - space lattice we can not utilize the momentum in the same way because the representation itself violates this symmetry . to achieve this , we impose a symmetry constraint on the form of the @xmath14-matrices , so that they are _ irreducible tensor operators_. that is , under a symmetry rotation the matrix @xmath154 for each local degree of freedom @xmath155 transforms according to an irreducible representation @xmath156 of the global symmetry group .",
    "this is a very general procedure , that is applicable to essentially all mps approaches and generalizations thereof .      for abelian symmetries ,",
    "the representations are one - dimensional therefore the set of quantum numbers labeling the irreducible representations also forms a group , which we can write as @xmath157 for two representations @xmath158 and @xmath159 , where @xmath160 denotes the group operation . thus to incorporate abelian symmetries into the algorithm we simply attach a quantum number to all of the labels appearing in the mps , with the constraint that each @xmath14-matrix transforms irreducibly , so that the only non - zero matrix elements are @xmath161 where @xmath162 are the quantum numbers attached to the local basis state and left and right matrix basis states respectively .",
    "we have suppressed here indices not associated with a quantum number , a convention which will be followed for the remainder of the paper .    by convention",
    ", for our open boundary condition mps we choose the right hand vacuum state to have quantum number zero .",
    "the symmetry constraint eq .",
    "( [ eq : quantumnumbers ] ) then implies that the quantum number at the left hand vacuum will denote how the state as a whole transforms ( the _ target state _ , in dmrg terminology ) .",
    "this is the only real difference between dmrg and mps algorithms , in that the dmrg convention is to construct both blocks starting from a scalar ( quantum number zero ) vacuum state , so that the superblock wavefunction is a tensor product of two ket states , @xmath163 whereas for the mps formulation the superblock wavefunction is represented by a scalar operator with a tensor product basis @xmath164 with quantum numbers @xmath165 .",
    "this means that , in contrast to the usual formulation of dmrg , the target quantum number is not encoded in the superblock but rather in the left vacuum state .",
    "a consequence of this is that dmrg is capable of representing simultaneously states with different quantum numbers , but an mps is not .",
    "this is an important detail , for example in the calculation of dynamical correlations , as both the correction vector @xcite and the similar ddmrg @xcite algorithm require a basis optimized for both the ground - state @xmath166 and the so - called lanczos - vector @xmath167 , where @xmath14 is some operator that may not be scalar .",
    "however , the mps formulation allows significant optimizations to these algorithms whereby the the calculation of the ground - state is decoupled from that of the lanczos vector @xcite and the two need never appear in the same basis .",
    "if the symmetry group is large enough that some elements do not commute with each other , then it is no longer possible to construct a basis that simultaneously diagonalizes all of the generators hence the approach of the previous section needs some modification .",
    "instead , we label the basis states by quantum numbers that denote the representation , which is no longer simply related to the group elements themselves as the representations are in general no longer ordinary numbers , but instead are matrices of dimension @xmath168 , and eq .  ( [ eq : abeliangrouprep ] ) no longer applies . for @xmath153 ,",
    "we choose to label the representations by the total spin @xmath155 , being related to the eigenvalue of of the spin operator , @xmath169 .",
    "assuming that all of the required operations can be formulated in terms of manipulations of these representations , we have a formulation that is _ manifestly _ @xmath153 invariant ; the rotational invariance is preserved at all steps and at no time in the calculation is it necessary to choose an axis of quantization @xcite .",
    "this supersedes the earlier approach based on the clebsch - gordan coefficients @xcite .",
    "the non - abelian formulation is an important optimization , because it increases the performance of the algorithm by an order of magnitude or more @xcite compared with the abelian case , while enabling more accurate and detailed information about the ground - state magnetization .",
    "the basic ingredient that enables this rotationally invariant construction is the wigner - eckart theorem @xcite , which we can state as : when written in an angular momentum basis , each matrix element of an irreducible tensor operator is a product of two factors , a purely angular momentum dependent factor ( the `` clebsch - gordan coefficient '' ) and a factor that is independent of the projection quantum numbers ( the `` reduced matrix element '' ) .",
    "we formulate the algorithm in such a way that we store and manipulate only the reduced matrix elements , factorizing out completely the clebsch - gordan coefficients .",
    "the efficiency improvement resulting from the non - abelian formulation is that the matrix dimensions @xmath0 and @xmath73 now refer to the number of irreducible representations in the basis , which is typically much smaller than the total degree of the representation . for a scalar state ,",
    "this equivalence is precise : a single representation of degree @xmath84 in the non - abelian approach results in @xmath84 degenerate eigenstates when the symmetry is not used , with a corresponding improvement in efficiency .",
    "we do not give here a full introduction to the theory of quantum angular momentum , rather we present , in the style of a reference , the important formulas required to manipulate mps wavefunctions and operators . for a comprehensive introduction see for example references @xcite .",
    "using the normalization convention of biedenharn @xcite , we define the matrix elements of a tensor operator @xmath170}$ ] transforming as a rank @xmath171 tensor under @xmath153 rotations , as @xmath172}_m \\",
    ", | \\ , jm \\ , \\rangle } = { \\langle \\ , j ' \\ , \\| \\ , { \\mbox{\\boldmath $ t$}}^{[k ] } \\ , \\| \\ , j \\ , \\rangle } \\ ; { \\mbox{$c { } ^{j}_{m } { } ^{k}_{m } { } ^{j'}_{m'}$ } } \\ ; , \\ ] ] where @xmath173 is the clebsch - gordan ( cg ) coefficient , @xmath174 label the representation of @xmath153 , and @xmath175 and @xmath176 label the projections of the total spin onto the @xmath177-axis . using the orthogonality of the clebsch - gordan coefficients , this defines the reduced matrix elements , @xmath178 } \\ , \\| \\",
    ", j \\ , \\rangle } = \\sum_{mm } { \\mbox{$c { } ^{j}_{m } { } ^{k}_{m } { } ^{j'}_{m'}$ } } { \\langle \\ , j'm ' \\ , | \\ , t^{[k]}_m \\ , | \\ , jm \\ , \\rangle } \\ ; , \\ ] ] where @xmath179 is arbitrary .",
    "note that this normalization is _ not _ the same as that used by varshalovich _ et .",
    "al _ @xcite , whom instead use an additional factor @xmath180 in the reduced matrix elements .",
    "this is a tradeoff ; some formulas simplify slightly with this normalization , but the normalization used here has the advantage that the reduced matrix elements of scalar operators ( with @xmath181 ) coincide with the actual matrix elements as all of the relevant clebsch - gordan coefficients are equal to unity .",
    "given the definition of the reduced matrix elements , we formulate the remaining formulas without further reference to the axis of quantization , except as an intermediate step to relate the reduced matrix elements prior to factorizing out the clebsch - gordan coefficients .",
    "the coupling of two operators is just as for the coupling of ordinary spins ; @xmath182}$ } } \\times { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } \\right]^{[k ] } \\ ; , \\ ] ] which denotes the set of operators with components @xmath182}$ } } \\times { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } \\right]^{[k]}_{\\mu } = \\sum_{\\mu_1 \\mu_2 } { \\mbox{$c { } ^{k_1}_{\\mu_1 } { } ^{k_2}_{\\mu_2 } { } ^{k}_{\\mu}$ } } { \\hbox{${s}^{[k_1]}_{\\mu_1}$ } } { \\hbox{${t}^{[k_2]}_{\\mu_2}$ } } \\ ; .\\ ] ] applying the wigner - eckart theorem gives , after a few lines of algebra , @xmath183}$ } } \\times   { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } \\right]^{[k ] } \\ , \\| \\ , j \\ , \\rangle } \\\\ = ( -1)^{j+j'+k } \\sum_{j '' } \\sqrt{(2j''+1)(2k+1 ) }   { \\mbox{$\\left\\ { \\begin{array}{ccc } \\!{j'}\\ ! &                  \\!{k_1}\\ ! & \\!{j''}\\ ! \\\\",
    "\\!{k_2}\\ ! & \\!{j}\\ ! &                  \\!{k}\\ !",
    "\\end{array } \\right\\}$ } } \\\\ \\times { \\langle \\ , j ' \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ s$}}^{[k_1]}$ } } \\ , \\| \\ ,",
    "j '' \\ , \\rangle } { \\langle \\ , j '' \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } \\ , \\| \\ , j \\ , \\rangle } \\ ; , \\end{array } \\label{eq : irredproduct}\\ ] ] where @xmath184 denotes the @xmath185 coefficient @xcite .    a special case of the coupling law eq .  ( [ eq : irredproduct ] ) that we will need is when the operators act on different spaces , such that they have a tensor product form @xmath186}_{\\mu_1}$ } } & = &   { \\hbox{${t}^{[k_1]}_{\\mu_1}$}}(1 ) \\otimes i(2 )",
    "\\ ; , \\\\ { \\hbox{${t}^{[k_2]}_{\\mu_2}$ } } & = &   i(1 ) \\otimes { \\hbox{${t}^{[k_2]}_{\\mu_2}$}}(2 ) \\ ; .",
    "\\end{array}\\ ] ] here @xmath187 denotes the identity operator and @xmath188}$}}(i)$ ] is an irreducible tensor operator with respect to the angular momentum @xmath189 of part @xmath6 of a two - part physical system ( @xmath190 ) .",
    "the total angular momentum of the system is @xmath191 . in this case",
    ", we write the coupling as @xmath192}$ } } \\mathbf{\\times } { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } { \\big]}$}^{[k]}}$ ] @xmath193 @xmath194}$}}(1 ) \\mathbf{\\otimes } { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$}}(2 ) { \\big]}$}^{[k]}}$ ] . repeated application of the wigner - eckart theorem to these tensor operators",
    "gives , after some algebra , @xmath195}$}}(1 ) \\mathbf{\\otimes } { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$}}(2 ) { \\big]}$}^{[k ] } } \\ , \\| \\",
    ", j \\ , ( j_1j_2\\alpha_1\\alpha_2 ) \\",
    ", \\rangle } \\vspace{0.25 cm } \\\\",
    "= { \\mbox{$\\left [ \\begin{array}{ccc } \\!{j_1}\\ ! &                                  \\!{j_2}\\ ! & \\!{j}\\ ! \\\\",
    "\\!{k_1}\\ ! & \\!{k_2}\\ ! &                                  \\!{k}\\ ! \\\\",
    "\\!{j'_1}\\ ! & \\!{j'_2}\\ ! & \\!{j'}\\ !",
    "\\end{array } \\right]$ } }          { \\langle \\ , j'_1 \\ , ( \\alpha'_1 ) \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_1]}$}}(1 ) \\ , \\| \\ , j_1 \\ , ( \\alpha_1 ) \\ ,",
    "\\rangle }          { \\langle \\ , j'_2 \\ , ( \\alpha'_2 ) \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$}}(2 ) \\ , \\| \\ , j_2 \\ , ( \\alpha_2 ) \\ , \\rangle } \\ ; , \\end{array } \\label{eq : tensorproductcoupling}\\ ] ] where @xmath196 $ } } \\equiv           [ ( 2j'_1 + 1)(2j'_2 + 1)(2j+1)(2k+1)]^{\\frac{1}{2 } }           { \\mbox{$\\left\\ { \\begin{array}{ccc } \\!{j_1}\\ ! &                                  \\!{j_2}\\ ! & \\!{j}\\ ! \\\\",
    "\\!{k_1}\\ ! & \\!{k_2}\\ ! &                                  \\!{k}\\ ! \\\\",
    "\\!{j'_1}\\ ! & \\!{j'_2}\\ ! & \\!{j'}\\ !",
    "\\end{array } \\right\\}$ } } \\ ; , \\ ] ] and the term in curly brackets is the wigner @xmath197 coefficient , which can be defined as a summation over @xmath185 coefficients @xcite , @xmath198    we can define an operator norm , corresponding to the usual frobenius norm , such that @xmath199}$}}||^2_{\\mbox{\\tiny frob } } = \\tr { \\hbox{${\\mbox{\\boldmath $ x$}}^{[k]}$ } } \\cdot   { \\hbox{${\\mbox{\\boldmath $ x$}}^{\\dagger[k]}$ } } =   \\tr { \\hbox{${\\mbox{\\boldmath $ x$}}^{\\dagger[k]}$ } } \\cdot { \\hbox{${\\mbox{\\boldmath $ x$}}^{[k]}$ } } \\ ; .\\ ] ] after some arithmetic , we see that @xmath199}$}}||^2_{\\mbox{\\tiny frob } } = \\sum_{j'j } ( 2j'+1 ) |{\\langle \\ , j ' \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k]}$ } } \\ , \\| \\ , j \\ , \\rangle}|^2\\ ] ] for the center - matrix formalism , we need the transformation @xmath200}$}}_{ij } \\rightarrow \\sum_k \\ ; c_{ik } \\ ; { \\hbox{${\\mbox{\\boldmath $ a'$}}^{[s]}$}}_{kj}\\ ] ] where @xmath171 is a @xmath201 dimensional index that encapsulates both a @xmath202 and a @xmath203 index runs over the clebsch - gordan expansion of @xmath204 . ] : @xmath205 . requiring @xmath206}$}}_{kj}$ ] to satisfy the right orthogonality constraint ,",
    "@xmath207 , this requires @xmath208}$}}_{kj } = \\delta_{j'j}\\delta_{s 's } \\quad \\left[\\mbox{with }   k \\simeq ( s',j')\\right]\\ ] ] with @xmath209}$}}_{ij'}\\ ] ] in the other direction , we need @xmath200}$}}_{ij } \\rightarrow \\sum_k \\ ; { \\hbox{${\\mbox{\\boldmath $ a'$}}^{[s]}$}}_{ik } \\ ; c_{kj}\\ ] ] where @xmath210 .",
    "requiring @xmath206}$}}_{ik}$ ] to satisfy the left orthogonality constraint , @xmath211 , this requires @xmath208}$}}_{ik } = \\delta_{s 's } \\delta_{i'i } \\sqrt{\\frac{2k+1}{2i+1 } }   \\quad \\left[\\mbox{with } k \\simeq ( s',i')\\right]\\ ] ] and @xmath212}$}}_{j'j } \\sqrt{\\frac{2i+1}{2k+1}}\\ ] ]    the most natural definition for a matrix product operator has two lower indices and three upper , @xmath213}_{s'i ' } { } ^{si}\\ ] ] which transforms as the product of two operators of rank @xmath214 $ ] , with matrix elements @xmath215}_{r}$ } } \\ , | \\ , sq ; jm \\ , \\rangle } = { \\langle \\ , s';j ' \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ m$}}^{[k]}$ } } \\ , \\| \\ , s;j \\ , \\rangle } \\ ; { \\mbox{$c { } ^{s}_{q } { } ^{k}_{r } { } ^{s'}_{q'}$ } } \\ ; { \\mbox{$c { } ^{j}_{m } { } ^{k}_{r } { } ^{j'}_{m'}$ } } \\ ; .\\ ] ] note that the product of an operator and a state requires a contraction of the index @xmath155 , which has the symmetry of over two _ lower _",
    "indices , and then shifting the result index @xmath202 from upper to lower . for @xmath153 ,",
    "the required phase factor is @xmath216 , giving the rule @xmath217}$ } } = { \\hbox{${\\mbox{\\boldmath $ ( ma)$}}^{[s']}$ } }   = \\sum_s ( -1)^{s+k - s ' } { \\hbox{${\\mbox{\\boldmath $ m$}}^{[k]}$}}^{s 's } \\otimes { \\hbox{${\\mbox{\\boldmath $ a$}}^{[s]}$ } } \\ ; . \\label{eq : operatorstateproduct}\\ ] ]    the action of a matrix - product operator on another matrix product operator is @xmath218}$ } } = { \\hbox{${\\mbox{\\boldmath $ m$}}^{[m]}$ } } { \\hbox{${\\mbox{\\boldmath $ n$}}^{[n]}$ } } \\ ; , \\ ] ] which corresponds to the ordinary ( contraction ) product in the local basis and the tensor product in the matrix basis , and therefore results in the product of a @xmath185 and a @xmath197 coefficient from equations eq .",
    "( [ eq : irredproduct ] ) and eq .",
    "( [ eq : tensorproductcoupling ] ) respectively .    for the evaluation of matrix elements ,",
    "we need the operation @xmath219 on expanding out the reduced matrix elements , we see immediately that the coupling coefficient is @xmath220}$}}_{i'j ' } = \\sum_{a , i , j , k , s , s ' } { \\mbox{$\\left [ \\begin{array}{ccc } \\!{j}\\ ! &                                  \\!{s}\\ ! & \\!{j'}\\ ! \\\\",
    "\\!{a}\\ ! & \\!{k}\\ ! &                                  \\!{a'}\\ ! \\\\",
    "\\!{i}\\ ! & \\!{s'}\\ ! & \\!{i'}\\ !",
    "\\end{array } \\right]$ } } { \\hbox{${\\mbox{\\boldmath $ m$}}^{[k]}$}}^{s's}_{a'a } { \\hbox{${\\mbox{\\boldmath $ a$}}^{[s']}$}}^*_{i'i } { \\hbox{${\\mbox{\\boldmath $ b$}}^{[s]}$}}_{j'j }   { \\hbox{${\\mbox{\\boldmath $ f$}}^{[a]}$}}_{ij}\\ ] ] conversely , from the left hand side , @xmath221 is @xmath222}$}}_{ij } = \\sum_{a',i',j',k , s',s } \\frac{2i'+1}{2i+1 } { \\mbox{$\\left [ \\begin{array}{ccc } \\!{j}\\ ! &                                  \\!{s}\\ ! & \\!{j'}\\ ! \\\\",
    "\\!{a}\\ ! & \\!{k}\\ ! &                                  \\!{a'}\\ ! \\\\",
    "\\!{i}\\ ! & \\!{s'}\\ ! & \\!{i'}\\ !",
    "\\end{array } \\right]$ } } { \\hbox{${\\mbox{\\boldmath $ e$}}^{[a']}$}}_{i'j ' } { \\hbox{${\\mbox{\\boldmath $ m$}}^{[k]}$}}^{s's}_{a'a } { \\hbox{${\\mbox{\\boldmath",
    "$ a$}}^{[s']}$}}^*_{i'i } { \\hbox{${\\mbox{\\boldmath $ b$}}^{[s]}$}}_{j'j}\\ ] ]    on interchanging @xmath223 , @xmath224 , this becomes the equation for a direct operator - matrix - product multiply .",
    "but using the center - matrix formalism , we want instead the operation @xmath225 where @xmath46 and @xmath226 transform as scalars , the quantum numbers impose @xmath227 , @xmath228 .",
    "this is essentially a scalar product @xmath229 , and the coupling coefficients drop out .",
    "in this paper , we have presented an introduction to the mps formulation of the dmrg algorithm for the calculation of ground- and excited states of one - dimensional lattice hamiltonians .",
    "the mps formulation is extremely flexible , allowing the possibility for algorithms that act on several distinct wavefunctions at once .",
    "the simplest such algorithms are for the fidelity and expectation values involving unrelated wavefunctions , @xmath230 and @xmath231 , which are difficult to extract from conventional dmrg .",
    "this gives access to new tools for the analysis of quantum phase transitions , by measuring the scaling function and exponents for the fidelity between ground - states as a function of the interaction strength .",
    "in addition , the mps formulation allow optimized versions of algorithms for dynamical correlations @xcite and time evolution @xcite , which remains a fertile area for continued algorithmic improvements .",
    "finally , we note that in the simulation of finite temperature states via a density operator or purification @xcite in the absence of dissipative terms that mix the particle numbers between the real and auxiliary systems , the symmetries of the system are _ doubled _ , such that the symmetries of the hamiltonian are preserved by the real and auxiliary parts independently . for simulations in a canonical ensemble , this leads to a significant efficiency improvement that , as far as we know , has not yet been taken into consideration .",
    "thanks to ulrich schollwck and thomas barthel for many stimulating conversations .",
    "while preparing this manuscript , we learned that a rotationally invariant formulation using the clebsch - gordan coefficients @xcite has been applied to the tebd algorithm for infinite systems @xcite ."
  ],
  "abstract_text": [
    "<S> in this paper we give an introduction to the numerical density matrix renormalization group ( dmrg ) algorithm , from the perspective of the more general matrix product state ( mps ) formulation . </S>",
    "<S> we cover in detail the differences between the original dmrg formulation and the mps approach , demonstrating the additional flexibility that arises from constructing both the wavefunction and the hamiltonian in mps form . </S>",
    "<S> we also show how to make use of global symmetries , for both the abelian and non - abelian cases . </S>"
  ]
}