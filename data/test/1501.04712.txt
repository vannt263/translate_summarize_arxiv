{
  "article_text": [
    "among the extensive literature on long - range dependence , relatively few publications are devoted to cyclical long - memory processes or long - range dependent random fields .",
    "however , models with singularities at non - zero frequencies are of great importance in applications . for example , many time series show cyclical / seasonal evolutions .",
    "singularities at non - zero frequencies produces peaks in the spectral density whose locations define periods of the cycles .",
    "a survey of some recent asymptotic results for cyclical long - range dependent random processes and fields can be found in @xcite and @xcite .    in image analysis",
    "popular isotropic spatial processes with singularities of the spectral density at non - zero frequencies are wave , @xmath0-bessel , and gegenbauer models .",
    "@xcite investigated probabilistic properties of spatial gegenbauer models .",
    "a realization of the gegenbauer random field on @xmath1 grid is shown in figure  [ fig1 ] .",
    "[ fig1 ]    this article studies minimum contrast estimators ( mces ) of parameters of the gegenbauer random fields .",
    "the mce methodology has been widely applied in different statistical frameworks ( see , for example , @xcite ; @xcite ) .",
    "one of the first works which used a mce methodology for the parameter estimation of spectral densities of stationary processes was the paper by @xcite .",
    "@xcite introduced a class of mces for random fields . @xcite derived consistency and asymptotic normality of a class of mces for stationary processes within the class of fractional riesz - bessel motion ( see @xcite ) .",
    "results based on the second and third - order cumulant spectra were given by @xcite .",
    "they also provided asymptotic properties of second and third - order sample spectral functionals .",
    "these properties are of independent interest , since they can be applied to study the limiting properties of nonparametric estimators of processes with short or long - range dependence .",
    "@xcite applied the minimum contrast parameter estimation to approximate the drift parameter of the ornstein - uhlenbeck process , when the corresponding stochastic differential equation is driven by the fractional brownian motion with a specific hurst index .",
    "a burgeoning literature on spatio - temporal estimation has emerged in recent decades ( see @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , among others ) .",
    "one of the most popular estimation tools applied was the maximum likelihood estimation method  ( mle ) .",
    "@xcite addressed the problem of parameter estimation of fractionally integrated processes with seasonal components . in order to estimate the fractional parameters , they propose several log - periodogram regression estimators with different bandwidths selected around and/or between the seasonal frequencies .",
    "the same methodology was used by @xcite for fractionally differenced autoregressive - moving average processes in the stationary time series context .",
    "several contributions have also been made for mle of long memory spatial processes ( see , for example , @xcite ) . for two - dimensional spatial data the paper by @xcite introduced a spatial unilateral first - order autoregressive moving average ( arma ) model . to implement mle they provided a proper treatment to border cell values with a substantial effect in estimation of parameters .",
    "@xcite addressed the problem of the least - squares estimation of autoregressive fractionally integrated moving - average ( farima ) processes with long - memory .",
    "@xcite investigated asymptotic properties of least - squares estimators in regression models for two - dimensional random fields .",
    "maximization of the whittle likelihood has been also considered in the recent literature on the mce ( see for example , @xcite , @xcite , @xcite ) .",
    "@xcite gave a continuous version of the whittle contrast functional supplied with a specific weight function for the estimation of continuous - parameter stochastic processes , deriving the consistency and asymptotic normality of such estimators .",
    "@xcite demonstrated that the whittle maximum likelihood estimator is consistent and asymptotically normal for stationary seasonal autoregressive fractionally integrated moving - average ( sarfima ) processes .",
    "parameter estimation of stationary gegenbauer random processes was considered by numerous authors , see , for example , @xcite , @xcite , @xcite , @xcite , @xcite .",
    "@xcite used the generating function of the gegenbauer polynomials to develop long memory gegenbauer autoregressive moving - average ( garma ) models that generalize the farima process .",
    "garma models were estimated by applying the mle methodology .",
    "@xcite also applied this methodology with slight modifications based on the conditional sum of squares method .",
    "@xcite extended these results to the two - parameter context within the garma process class .",
    "@xcite introduced a @xmath2-factor extension of the garma model that allowed to associate the long - memory behavior with each one of the @xmath2 gegenbauer frequencies involved .",
    "in this article we restrict our consideration to the estimation of long - range dependence parameters .",
    "it is motivated in part by cyclic processes , for which pole locations are known .",
    "also in some applications the spectral density singularity location can be estimated in advance .",
    "various methods , including semiparametric , wavelet , and pseudo - maximum likelihood techniques , of the estimation of a singularity location were discussed by , for example , @xcite , @xcite , and @xcite .",
    "this paper introduces and studies the mce of parameters of spatial gegenbauer processes .",
    "specifically , analogous of continuous - space results by @xcite are formulated for random fields defined on integer grids .",
    "the consistency and asymptotic normality of the mce are obtained using a spatial discrete version of the ibragimov contrast function .",
    "the article develops a methodology to practically verify general theoretical assumptions for consistency and asymptotic normality of mces for specific models .",
    "the results provide a rigorous platform to conduct model selection and statistical inference .",
    "the outline of the article is the following . in section 2 ,",
    "we start by introducing the main notations of the paper .",
    "some fundamental definitions and the main results of this article , theorem 1 and 2 , are given in  3 .",
    "section 4 consists of the proofs of the main results .",
    "section 5 presents simulation studies which support the theoretical findings .",
    "the appendix provides auxiliary materials that specify for our case the conditions that ensure the consistency and asymptotic normality of the mce based on the ibragimov contrast function formulated in @xcite .    in what follows",
    "we use the symbol @xmath3 to denote constants which are not important for our discussion .",
    "moreover , the same symbol @xmath3 may be used for different constants appearing in the same proof .",
    "all calculations in the article were performed using the software _",
    "r _ version  3.0.2 and _ maple 16 , _ maplesoft .",
    "this section introduces some of the main definitions of the gegenbauer random fields given in @xcite ( see also , @xcite , @xcite , and @xcite , for the temporal case ) .",
    "let @xmath4 @xmath5 be a random field defined on the grid lattice @xmath6 consider the fractional difference operator @xmath7 defined by @xmath8^{d},\\end{aligned}\\ ] ] where @xmath9 is the backward - shift operator ,",
    "@xmath10 i.e. @xmath11 @xmath12 and @xmath13 assume that @xmath14 satisfies the following state equation @xmath15 where @xmath16 @xmath17 is given by equation ( [ fog ] ) , with @xmath18 @xmath17 denoting the backward - shift operator for each spatial coordinate , i.e. @xmath19 , and @xmath20 here , @xmath21 @xmath22 is a zero - mean white noise field with the common variance @xmath23=\\sigma^{2}_{\\varepsilon}.$ ] the random field @xmath14 is called a spatial gegenbauer white noise in @xcite .    by equation ( [ eqgegenbauer ] )",
    "the gegenbauer random field @xmath14 can be defined in terms of the inverse of the operator @xmath24 expanded in a gegenbauer polynomial series as follows @xmath25 where @xmath26 @xmath17 and @xmath27 is the gegenbauer polynomial given by @xmath28 } ( -1)^{k } \\frac{(2u)^{n-2k}\\gamma(d - k+n)}{k!(n-2k)!\\gamma(d)}.\\ ] ] the generating function for the gegenbauer polynomials is given by @xmath29 which explains the expansion of the inverse operator in ( [ gegenb ] ) .",
    "in general , a random field @xmath14 is called invertible if the white noise @xmath30 @xmath22 can be expressed as the convergent sum @xmath31 where @xmath32    the gegenbauer random field has the following property , see @xcite .",
    "[ proposition ] if @xmath33 and @xmath34 @xmath17 then @xmath14 is a stationary invertible long range dependent random field .",
    "the spectral density of a stationary gegenbauer random field is given by @xcite , and @xcite , for the one - parameter case , and @xcite , for the two - parameter case : @xmath35 where @xmath36 @xmath37 , and @xmath38 @xmath39 using the spectral density function ( [ spectral_density ] ) , one can compute the auto - covariance function of @xmath14 as follows : @xmath40^{\\frac{1}{2}-2d_{1 } }      \\left [ p_{j_{i}-\\frac{1}{2}}^{2d_{i}-\\frac{1}{2 } } ( u_{i } ) + ( -1)^{j_{i } } p_{j_{i}-\\frac{1}{2}}^{2d_{i}-\\frac{1}{2 } } ( -u_{i } ) \\right],\\ ] ] where @xmath41 is the associated legendre function of the first kind , consult  8 in @xcite .    from @xcite , @xcite and @xcite , the following asymptotic approximation of the autocovariance function",
    "can be obtained @xmath42 .",
    "\\nonumber\\end{aligned}\\ ] ]    the random field @xmath14 is long range dependent as its auto - covariance function satisfies the condition @xmath43 a detailed discussion on relations between local specifications of spectral functions and the tail behaviour of auto - covariance functions of long range dependent random fields can be found in @xcite .",
    "figure  [ fig2 ] gives an example of the spectral density and the auto - covariance function of the gegenbauer random field for the values of the parameters @xmath44 @xmath45 @xmath46 and @xmath47     and @xmath48,width=226 ]     and @xmath48,width=226 ]",
    "very detailed discussions about estimation of parameters of seasonal / cyclical long memory time series were given in @xcite,@xcite , @xcite , and references therein .",
    "it was shown that the case of spectral singularities outside the origin is much more difficult comparing to the situation of a spectral pole at 0 .",
    "in particular , estimators of parameters @xmath49 and @xmath50 have different rates of convergence and their joint distributions are still unknown under general conditions .",
    "@xcite pointed out that , in practice , parameter estimation of seasonal / cyclical long memory data is done in two steps .",
    "the first step consists in estimation of singularity locations , which does not represent a difficult issue .",
    "then , the obtained values of location parameters are used in estimators of the long memory parameters .",
    "it has been shown that this 2-steps method provides quasi - similar results to simultaneous procedures .",
    "similarly , the results of this paper may also be used in a hierarchical modeling framework .",
    "namely , locations of the singularities can be included in the first level of the hierarchical procedure .",
    "then , on the second step of the hierarchical procedure , the long - range dependence parameters can be estimated by the mce method , conditioning on the locations obtained on the first step .",
    "it also allows to construct a suitable weight function before applying the mce methodology .",
    "therefore , in this paper we only concentrate our attention on long - range dependence parameters .",
    "suppose that the conditions imposed in proposition  [ proposition ] to ensure stationarity , invertibility and long - range dependence hold .",
    "assume the value of the parameter @xmath51 is known a priori or was estimated on step 1 .",
    "then @xmath52 is the vector of parameters to estimate of the gegenbauer random field defined by equation  ( [ eqgegenbauer ] ) ( see also equation  ( [ spectral_density ] ) for the corresponding spectral density ) .",
    "let @xmath4 @xmath53 be a part of a realization of the gegenbauer random field .",
    "let @xmath54 , @xmath55^{2}$ ] , be a nonnegative function .",
    "suppose the condition * a3 * in the appendix holds .",
    "we define @xmath56^{2 } }       f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})w(\\boldsymbol{\\lambda } ) \\,\\ , d\\boldsymbol{\\lambda}\\ ] ] and consider the factorization @xmath57 for all @xmath58 the function @xmath59 has the following property @xmath60^{2 } }        \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda } ) \\ , \\",
    ", d\\boldsymbol{\\lambda } = 1.\\ ] ]    let @xmath61 be a non - random real - valued function , usually referred as the _ contrast function _ , given  by @xmath62^{2 } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta_{0 } } ) w(\\boldsymbol{\\lambda } ) \\log \\frac{\\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta_{0 } } ) } { \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) }   \\,\\ , d\\boldsymbol{\\lambda},\\ ] ] and let the _ contrast field _ be @xmath63^{2 } }       f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta_{0 } } ) w(\\boldsymbol{\\lambda } )       \\log \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\,\\",
    ", d\\boldsymbol{\\lambda},\\ ] ] where @xmath64 is the true parameter value . in",
    "what follows , @xmath65 denotes the probability distribution with the density function @xmath66    the empirical version @xmath67 @xmath68 @xmath69 is defined by @xmath70^{2 } }       i_{t}(\\boldsymbol{\\lambda } ) w(\\boldsymbol{\\lambda } ) \\log\\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\,\\ , d\\boldsymbol{\\lambda},\\ ] ] where @xmath71 is the periodogram of the observations @xmath4 @xmath53 of the gegenbauer random field , that is , @xmath72    the mce is defined by the empirical contrast field @xmath73 and the contrast function @xmath61 being @xmath74 and having a unique minimum at @xmath75    in particular , we choose @xmath76^{2},\\ ] ] where @xmath77 @xmath17 @xmath78 is a positive function with continuous second order derivatives on @xmath79^{2}.$ ]    notice that by ( [ weightfunction ] ) the weight function @xmath54 is nonnegative and symmetric about @xmath80 due to the boundedness of @xmath54 the product @xmath81 is integrable .",
    "thus , the choice of @xmath54 fulfils condition  * a3 * in the appendix .",
    "the developed methodology is readily adjustable to other classes of weight functions .",
    "theorems  [ theorem_1 ] and [ theorem_2 ] give consistency and asymptotic normality results for the mce .",
    "[ theorem_1 ] let @xmath82 be a stationary gegenbauer random field which spectral density satisfies equation ( [ spectral_density ] ) .",
    "if @xmath73 is the empirical contrast field defined by equation  ( [ equation_ut ] ) , then    * @xmath83 satisfies the conditions * a1-a6 * in the appendix ; * the minimum contrast estimator @xmath84 is a consistent estimator of the parameter vector @xmath85 that is , there is a convergence in @xmath65 probability : @xmath86 * @xmath87 where the variance estimator @xmath88 is given by @xmath89 ^ 2 } i_{t}(\\boldsymbol{\\lambda})w(\\boldsymbol{\\lambda})\\,\\ , d\\boldsymbol{\\lambda}.\\ ] ]    notice that assumption * a4 * is not required to prove the last two statements in theorem  [ theorem_1 ] , but it will be used in the proof of theorem  [ theorem_2 ] .    to formulate theorem  [ theorem_2 ]",
    "we introduce the following notations .",
    "the unbiased estimator of the correlation function @xmath90 @xmath91 of the gegenbauer random field @xmath83 is @xmath92 note that all indices of the random field in the sum above are within the set @xmath93 where the observations are available .",
    "the unbiased periodogram is given by @xmath94 and the corresponding empirical _",
    "contrast field _",
    "is @xmath95 ^ 2 }       i_{t}^{*}(\\boldsymbol{\\lambda } ) w(\\boldsymbol{\\lambda } ) \\log \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\,\\ , d\\boldsymbol{\\lambda}.\\ ] ] we also define @xmath96 ^ 2 } i_{t}^{*}(\\boldsymbol{\\lambda})w(\\boldsymbol{\\lambda})\\,\\ ,   d\\boldsymbol{\\lambda}$ ] and the associated adjusted mce @xmath97    [ theorem_2 ] if @xmath82 is a stationary gegenbauer random field which spectral density satisfies equation ( [ spectral_density ] ) with @xmath98 then    * @xmath83 satisfies the conditions * a1-a9 * in the appendix ; * the adjusted mce defined by ( [ equation_theta_estimado2 ] ) is asymptotically normal .",
    "that is , @xmath99 where the entries of the matrices @xmath100 and @xmath101 are @xmath102^{2 } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda } ) \\frac{\\partial^{2}}{\\partial \\theta_{i}\\partial \\theta_{j } } \\log \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\,\\ ,",
    "d\\boldsymbol{\\lambda}=\\sigma^{2}(\\boldsymbol{\\theta } ) \\displaystyle\\int_{[-\\pi,\\pi]^{2 } } w(\\boldsymbol{\\lambda } ) \\nonumber \\\\ & & \\times\\left [ \\frac{\\partial^{2}}{\\partial \\theta_{i}\\partial \\theta_{j } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) - \\frac{1}{\\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) }    \\frac{\\partial}{\\partial \\theta_{i } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } )    \\frac{\\partial}{\\partial \\theta_{j } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ] \\ , d\\boldsymbol{\\lambda } , \\label{sij}\\end{aligned}\\ ] ] @xmath103^{2 } } f^{2}(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) w^{2}(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial \\theta_{i } } \\log \\left(\\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } )",
    "\\right ) \\frac{\\partial}{\\partial \\theta_{j } } \\log \\left(\\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ) \\,\\ , d\\boldsymbol{\\lambda } \\nonumber \\\\ & = &   8\\pi^{2 } \\sigma^{4}(\\boldsymbol{\\theta } )",
    "\\displaystyle\\int_{[-\\pi,\\pi]^{2 } } w^{2}(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial \\theta_{i } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } )   \\frac{\\partial}{\\partial \\theta_{j } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } )   \\,\\ , d\\boldsymbol{\\lambda}. \\label{aij}\\end{aligned}\\ ] ]    to avoid the edge effect @xcite employed the modified periodogram approach suggested by @xcite .",
    "we use their assumptions in theorem  [ theorem_2 ] . note that some authors pointed few problems in using @xmath104",
    "see @xcite , @xcite , and references therein .",
    "various other modifications , for example , typed variograms , smoothed variograms , kernel estimators , to reduce the edge effect have been proposed .",
    "it would be interesting to prove analogous of the results by @xcite and theorem  [ theorem_2 ] for these modifications , too .",
    "however , it is beyond the scope of this paper .",
    "moreover , it remains as an open problem whether the edge - effect modification is essential for the asymptotic normality or not , see @xcite .",
    "to prove the theorems we will use the following differentiability lemma .    [",
    "* theorem 11.5)][lem1 ] let @xmath105 be a measurable space , @xmath106 and @xmath107 be an open set .",
    "suppose the function @xmath108 satisfies the following conditions :    1 .   for all",
    "@xmath109 @xmath110 2 .   for almost all",
    "@xmath111 the derivative @xmath112 exists for all @xmath113 3 .",
    "there is an integrable function @xmath114 such that @xmath115 for almost all @xmath116    then there exists @xmath117    [ lem2 ] the function @xmath118 is bounded and separated from zero on @xmath119 moreover , its first and second order derivatives are bounded on @xmath120 and can be computed by @xmath121^{2 } } w(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial          \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\ , d\\boldsymbol{\\lambda}\\nonumber\\\\ & = & -2\\int_{[-\\pi,\\pi]^{2 } }          \\log\\left|2\\cos\\lambda_{i}-2u_{i}\\right|\\,w(\\boldsymbol{\\lambda } )   f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\ , d\\boldsymbol{\\lambda},\\end{aligned}\\ ] ] @xmath122^{2 } }                w(\\boldsymbol{\\lambda } ) \\frac{\\partial^{2}}{\\partial                    \\theta_{j}\\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\ , d\\boldsymbol{\\lambda}= 4\\int_{[-\\pi,\\pi]^{2 } }                            \\log\\left|2\\cos\\lambda_{i}-2u_{i}\\right|\\nonumber\\\\ & & \\times \\log\\left|2\\cos\\lambda_{j}-2u_{j}\\right|\\,w(\\boldsymbol{\\lambda } )   f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\ , d\\boldsymbol{\\lambda},\\label{d2theta }     \\end{aligned}\\ ] ] where @xmath123    by the choice ( [ weightfunction ] ) of the weight function we obtain @xmath124^{2}\\times \\theta}f(\\boldsymbol{\\lambda } , \\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda } ) < + \\infty\\ ] ] and @xmath125^{2}}\\sup_{\\theta\\in \\theta}f(\\boldsymbol{\\lambda } , \\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda } ) d\\boldsymbol{\\lambda } \\leq 4\\pi^{2 } \\sup_{[-\\pi,\\pi]^{2}\\times \\theta}f(\\boldsymbol{\\lambda } , \\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda } ) < + \\infty.\\ ] ] hence , @xmath118 is bounded .",
    "note that @xmath126^{2}\\times \\theta}\\left\\{\\left|2\\cos\\lambda_{1}-2u_{1}\\right|\\right\\}^{2d_{1 } } \\ ,      \\left\\{\\left|2\\cos\\lambda_{2}-2u_{2}\\right|\\right\\}^{2d_{2}}<+\\infty .",
    "$ ] also , by the choice of the weight function , there exists @xmath127 and a set @xmath128^{2}$ ] of non - zero lebesgue measure such that @xmath129 for all @xmath130 therefore , @xmath131^{2}}f(\\boldsymbol{\\lambda } , \\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda } ) d\\boldsymbol{\\lambda } \\nonumber\\\\ & \\geq \\frac{\\delta\\ , \\boldsymbol{\\lambda } ( a_0)}{\\sup_{[-\\pi,\\pi]^{2}\\times \\theta}\\left\\{\\left|2\\cos\\lambda_{1}-2u_{1}\\right|\\right\\}^{2d_{1 } } \\ ,      \\left\\{\\left|2\\cos\\lambda_{2}-2u_{2}\\right|\\right\\}^{2d_{2}}}>0,\\nonumber    \\end{aligned}\\ ] ] which means that @xmath118 is separated from zero on @xmath119    now , to study @xmath132 we compute @xmath133 @xmath134 @xmath135^{-2d_{i } } \\nonumber\\\\          & \\quad\\times\\left[2(\\cos\\lambda_{j}-u_{j } ) \\right]^{-2d_{j } } = -2\\log\\left|2\\cos\\lambda_{i}-2u_{i}\\right| f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) , \\label{deriv_f_d }          \\end{aligned}\\ ] ] where @xmath136 and @xmath137    using ( [ weightfunction ] ) and ( [ deriv_f_d ] ) we conclude that @xmath138^{2}\\times \\theta}\\left|w(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial    \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right|<+\\infty.\\ ] ] thus , by ( [ eq_sigma_factorization ] ) and lemma  [ lem1 ] there exists @xmath139^{2 } } w(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial          \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\,\\ , d\\boldsymbol{\\lambda}\\ ] ] and @xmath140^{2}\\times \\theta}\\left|w(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial      \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right|<+\\infty.\\ ] ]    it is not difficult to find @xmath141 by ( [ deriv_f_d ] ) , for @xmath142 @xmath143 the second derivatives of @xmath144 are given by @xmath145 @xmath146    it follows from ( [ eqsdds3 ] ) , ( [ eqsdds4 ] ) , and ( [ weightfunction ] ) that @xmath147^{2}\\times \\theta}\\left|w(\\boldsymbol{\\lambda } ) \\frac{\\partial^{2}}{\\partial          \\theta_{j}\\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right|<+\\infty,\\quad i , j=1,2.\\ ] ] finally , by ( [ dtheta ] ) and lemma  [ lem1 ] there exists @xmath148^{2 } }        w(\\boldsymbol{\\lambda } ) \\frac{\\partial^{2}}{\\partial            \\theta_{j}\\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\,\\ , d\\boldsymbol{\\lambda}\\ ] ] and @xmath149^{2}\\times \\theta}\\left|w(\\boldsymbol{\\lambda } ) \\frac{\\partial^{2}}{\\partial                \\theta_{j}\\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right|<+\\infty.\\vspace{-3mm}\\ ] ] @xmath150    _ of theorem _ [ theorem_1 ] .",
    "we will prove that the conditions * a1-a6 * in the appendix are satisfied .",
    "therefore , we will be able to apply theorem 3 by @xcite and obtain the statement of theorem  [ theorem_1 ] .",
    "the condition * a1 * holds , since @xmath151 belongs to the parameter space @xmath152 which is an interior of the compact set @xmath153^{2}$ ] .",
    "it follows from representation ( [ spectral_density ] ) of the spectral density that @xmath154 for @xmath155 thus , the condition * a2 * is satisfied .",
    "the class of non - negative weight functions @xmath54 defined by ( [ weightfunction ] ) consists of symmetric functions .",
    "note that @xmath156 when @xmath157 thus , by ( [ weightfunction ] ) and representation ( [ spectral_density ] ) of the spectral density we get @xmath158^{2})$ ] for all @xmath85    to verify * a4 * , that is , to prove @xmath159^{2 } }       \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda})\\,\\ , d\\boldsymbol{\\lambda } =              \\displaystyle\\int_{[-\\pi,\\pi]^{2 } } \\nabla_{\\boldsymbol{\\theta } }       \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda})\\,\\ , d\\boldsymbol{\\lambda } =       0,\\ ] ] we find @xmath160}_{s_{1}(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) }   - \\underbrace{\\frac{w(\\boldsymbol{\\lambda})}{\\sigma^{4}(\\boldsymbol{\\theta})}\\left[\\frac{\\partial}{\\partial \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})}_{s_{2}(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})}\\ ] ] and apply lemma 1 .",
    "the same symbol @xmath3 is used for different nonessential constants appearing in the calculations below .    by ( [ spectral_density ] ) and the choice of the weight function we obtain @xmath161^{2}\\times \\theta}\\big|\\log\\left|2\\cos\\lambda_{i}-2u_{i}\\right|\\big|\\,f(\\boldsymbol{\\lambda } , \\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda } ) < + \\infty.\\ ] ]    therefore , by equation ( [ deriv_f_d ] ) and lemma  [ lem2 ] : @xmath162^{2}).\\ ] ]    now , by ( [ fw1 ] ) , ( [ s2 ] ) and lemma  [ lem2 ] we can estimate @xmath163 as @xmath164 f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) } { \\sigma^{4}(\\boldsymbol{\\theta})}\\right|\\leq c\\ ,   \\frac{w(\\boldsymbol{\\lambda})f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) } { \\min_{\\theta}\\sigma^{4}(\\boldsymbol{\\theta})}\\le c.\\ ] ]    finally , * a4 * follows from ( [ s1up ] ) , ( [ s2up ] ) , and lemma  [ lem1 ] with @xmath165    note that @xmath166^{2})\\cap l_{2}([-\\pi,\\pi]^{2})= l_{2}([-\\pi,\\pi]^{2}).$ ] to verify the condition * a5 * for the weight function @xmath167 we have to show that @xmath168 @xmath169^{2}),$ ] for all @xmath170 by ( [ spectral_density ] ) and ( [ weightfunction ] ) the product @xmath171 @xmath172 is bounded for all @xmath173 except @xmath174 let @xmath175 then , for @xmath176 @xmath134 @xmath177^{2}\\leq c\\prod_{i=1}^{2}|{\\lambda_i}\\pm { \\nu_i}|^{2a_i-4\\tilde{d}_i}\\log|\\lambda_{i}\\pm \\nu_{i}|\\in   l_{1}([-\\pi,\\pi]^{2}).\\ ] ] therefore , combining the above results we conclude that * a5 * holds .",
    "to verify the condition * a6 * we use the following function @xmath178 @xmath179 note that @xmath180 when @xmath157 thus , by the choice of @xmath181 and properties of @xmath182 the function @xmath183 is uniformly continuous on @xmath79^{2}\\times \\theta .$ ]    also , it holds @xmath184^{2}).\\ ] ]    since the conditions * a1 * -*a6 * are satisfied theorem 1 follows from theorem 3 in @xcite.@xmath185    _ of theorem _ 2 . to prove the asymptotic normality of the mce in theorem  [ theorem_2 ] we will show that the conditions * a7 * -*a9 * of the appendix hold .",
    "we begin by proving the condition * a7*. first , to verify the twice differentiability of the function @xmath186 on @xmath120 we formally compute the second - order derivatives of @xmath187 @xmath188   \\sigma^{2}(\\boldsymbol{\\theta } ) -   \\left[\\frac{\\partial } { \\partial \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ]   f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})}{\\sigma^{4}(\\boldsymbol{\\theta } ) }   \\right ] \\nonumber\\\\   & = & \\frac{1}{\\sigma^{4}(\\boldsymbol{\\theta } ) } \\left\\ {    \\left[\\frac{\\partial^{2 } } { \\partial \\theta_{j}\\partial \\theta_{i } }    f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right ]   \\sigma^{2}(\\boldsymbol{\\theta } ) +   \\left[\\frac{\\partial } { \\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ]   \\left[\\frac{\\partial } { \\partial \\theta}_{i } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right ] \\right\\ } \\nonumber\\\\ & -&\\frac{1}{\\sigma^{4}(\\boldsymbol{\\theta } ) } \\left\\ {   \\left[\\frac{\\partial^{2 } } { \\partial \\theta_{j}\\partial \\theta_{i } }   \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})-   \\left[\\frac{\\partial } { \\partial \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ]   \\left[\\frac{\\partial } { \\partial \\theta_{j } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right ]   \\right\\}\\nonumber \\\\",
    "& -&\\frac{1}{\\sigma^{8}(\\boldsymbol{\\theta } ) } \\left\\ { \\frac{\\partial } { \\partial \\theta_{j } } \\sigma^{4}(\\boldsymbol{\\theta } ) \\left ( \\left[\\frac{\\partial}{\\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right]\\sigma^{2}(\\boldsymbol{\\theta } )   - \\left[\\frac{\\partial } { \\partial \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ) \\right\\}.\\nonumber\\end{aligned}\\ ] ]    note that in lemma  [ lem2 ] we proved that the derivatives @xmath189",
    "@xmath190 @xmath191 and @xmath192 exist .",
    "hence , by the above computations and lemma  [ lem2 ] the function @xmath193 is twice differentiable on @xmath119    in addition , by estimates ( [ dsup ] ) , ( [ df2 ] ) , ( [ d2sigma ] ) , lemma  [ lem2 ] , and the above representation for @xmath194 the product @xmath195 is bounded on @xmath79^{2}\\times \\theta.$ ] hence , for @xmath196 @xmath197 @xmath198^{2})\\cap                  l_{2}([-\\pi,\\pi]^{2}).\\ ] ]    to prove part 2 of the condition * a7 * , we first note that by ( [ equation_spectraldensity ] ) and ( [ deriv_f_d ] ) : @xmath199 by lemma  [ lem2 ] the second term is bounded .",
    "hence , it follows from ( [ fw1 ] ) and ( [ fw2 ] ) that the product @xmath200 is bounded on @xmath79^{2}\\times \\theta,$ ] that implies @xmath201^{2}),\\quad k\\geq 1,\\ \\   i=1,2 ,                  \\ \\ \\boldsymbol{\\theta } \\in \\theta .\\ ] ]    to verify the condition * a8 * we first check the positive definiteness of the matrices @xmath202 and @xmath203    the entries of @xmath202 can be rewritten as @xmath204^{2}}\\psi_w(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\frac{\\partial^{2}}{\\partial \\theta_{i}\\partial \\theta_{j}}\\log \\psi_w(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})d\\boldsymbol{\\lambda},\\ ] ] where @xmath205    by ( [ spectral_density ] ) , ( [ weightfunction ] ) , and lemma  [ lem2 ] the function @xmath206 is integrable , i.e. there is a constant @xmath3 such that @xmath207 is a density .",
    "hence , @xmath208 where @xmath209 is the fisher information matrix of the random vector @xmath210 with the density @xmath211^{2}}\\psi_w(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) d\\boldsymbol{\\lambda}.$ ] therefore , @xmath202 is non - negative definite .",
    "note that @xmath212 where @xmath213 the random variables @xmath214 and @xmath215 are not a.s .",
    "linearly related which implies positive definiteness of @xmath202 .",
    "the entries of @xmath216 can be rewritten as @xmath217^{2 } } w^{2}(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial \\theta_{i } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } )   \\frac{\\partial}{\\partial \\theta_{j } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } )   \\ , d\\boldsymbol{\\lambda } = c\\sigma^{4}(\\boldsymbol{\\theta})\\,e\\left(q_iq_j\\right ) , \\ ] ] where @xmath218 and the random vector @xmath219 has the density @xmath220^{2 } } w^{2}(\\boldsymbol{\\lambda } )   \\ , d\\boldsymbol{\\lambda}}.$ ]    as @xmath221 is a non - negative definite matrix , @xmath216 is non - negative definite too .",
    "moreover , it is positive definite , because the random variables @xmath222 and @xmath223 are not a.s .",
    "linearly related .",
    "now we compute elements of the matrix @xmath224 by ( [ sij ] ) @xmath225^{2}}w(\\boldsymbol{\\lambda } ) \\left [ \\frac{\\partial^{2}}{\\partial \\theta_{i}\\partial \\theta_{j } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) - \\frac{1}{\\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) }    \\frac{\\partial}{\\partial \\theta_{i } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } )    \\frac{\\partial}{\\partial \\theta_{j } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right]d\\boldsymbol{\\lambda}\\nonumber\\\\ & = & \\sigma^{2}(\\boldsymbol{\\theta } ) \\int_{[-\\pi,\\pi]^{2}}\\left(w(\\boldsymbol{\\lambda } ) \\frac{\\partial } { \\partial \\theta_{j } } \\left [ \\frac {   \\left[\\frac{\\partial } { \\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right ]   \\sigma^{2}(\\boldsymbol{\\theta } ) -   \\left[\\frac{\\partial } { \\partial \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) }   { \\sigma^{4}(\\boldsymbol{\\theta } ) }   \\right]\\right.\\nonumber\\\\ & & - \\frac{w(\\boldsymbol{\\lambda})}{f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\sigma^{6}(\\boldsymbol{\\theta } ) }   \\left ( \\left[\\frac{\\partial}{\\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ] \\sigma^{2}(\\boldsymbol{\\theta } ) - \\left[\\frac{\\partial}{\\partial \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right)\\nonumber\\\\ & & \\left .",
    "\\times \\left ( \\left[\\frac{\\partial}{\\partial \\theta_{j } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ] \\sigma^{2}(\\boldsymbol{\\theta } ) - \\left[\\frac{\\partial}{\\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right)\\right)d\\boldsymbol{\\lambda }   \\nonumber   \\end{aligned}\\ ] ] @xmath226^{2}}\\left(\\frac{w(\\boldsymbol{\\lambda})}{\\sigma^{2}(\\boldsymbol{\\theta } ) } \\left (    \\left[\\frac{\\partial^{2 } } { \\partial \\theta_{j}\\partial \\theta_{i } }    f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right ]   \\sigma^{2}(\\boldsymbol{\\theta } ) +   \\left[\\frac{\\partial } { \\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ]   \\left[\\frac{\\partial } { \\partial \\theta}_{i } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right ] \\right)\\right .",
    "\\nonumber\\\\ & &   -\\frac{w(\\boldsymbol{\\lambda})}{\\sigma^{2}(\\boldsymbol{\\theta } ) } \\left (   \\left[\\frac{\\partial^{2 } } { \\partial \\theta_{j}\\partial \\theta_{i } }    \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})-   \\left[\\frac{\\partial } { \\partial \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ]   \\left[\\frac{\\partial } { \\partial \\theta_{j } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right ]   \\right)\\nonumber \\\\ & &   -2\\frac{w(\\boldsymbol{\\lambda})}{\\sigma^{6}(\\boldsymbol{\\theta } ) } \\left ( \\frac{\\partial } { \\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\left ( \\left[\\frac{\\partial } { \\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right]\\sigma^{2}(\\boldsymbol{\\theta } ) - \\left[\\frac{\\partial } { \\partial \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ) \\right)\\nonumber \\\\ & & - \\frac{w(\\boldsymbol{\\lambda})}{\\sigma^{4}(\\boldsymbol{\\theta } ) f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) } \\left(\\left[\\frac{\\partial}{\\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ] \\sigma^{2}(\\boldsymbol{\\theta } ) - \\left[\\frac{\\partial}{\\partial \\theta_{i}}\\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right )   \\nonumber\\\\ & & \\times \\left(\\left[\\frac{\\partial}{\\partial \\theta_{j } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ] \\sigma^{2}(\\boldsymbol{\\theta } ) - \\left[\\frac{\\partial}{\\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right)d\\boldsymbol{\\lambda}. \\nonumber\\end{aligned}\\ ] ] by ( [ eq_sigma_factorization ] ) , ( [ dtheta ] ) , ( [ d2theta ] ) , and ( [ deriv_f_d ] ) we obtain @xmath227^{2}}\\frac{w(\\boldsymbol{\\lambda } ) } { \\sigma^{2}(\\boldsymbol{\\theta } ) } \\left[\\frac{\\partial } { \\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ]   \\left[\\frac{\\partial } { \\partial \\theta}_{i } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right]d\\boldsymbol{\\lambda}\\ ] ] @xmath228^{2}}\\frac{w(\\boldsymbol{\\lambda})}{f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) }   \\left[\\frac{\\partial}{\\partial \\theta_{i } }   f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ]   \\left[\\frac{\\partial}{\\partial \\theta_{j } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right]d\\boldsymbol{\\lambda}= \\frac{3}{\\sigma^{2}(\\boldsymbol{\\theta } ) } \\left[\\frac{\\partial } { \\partial    \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] \\left[\\frac{\\partial } { \\partial    \\theta_{i } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right]\\ ] ] @xmath229^{2 } } \\log\\left|2\\cos\\lambda_{i}-2u_{i}\\right|\\log\\left|2\\cos\\lambda_{j}-2u_{j}\\right|\\ , w(\\boldsymbol{\\lambda } ) f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})d\\boldsymbol{\\lambda}.\\ ] ]    by ( [ aij ] ) the elements of the matrix @xmath216 are @xmath230^{2}}w^2(\\boldsymbol{\\lambda } )     \\frac{\\partial}{\\partial \\theta_{i } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } )    \\frac{\\partial}{\\partial \\theta_{j } } \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\,d\\boldsymbol{\\lambda}\\nonumber\\\\ & = & 8\\pi^2 \\int_{[-\\pi,\\pi]^{2}}w^2(\\boldsymbol{\\lambda } )   \\left(\\left[\\frac{\\partial}{\\partial \\theta_{i } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ] \\sigma^{2}(\\boldsymbol{\\theta } ) - \\left[\\frac{\\partial}{\\partial \\theta_{i}}\\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right )   \\nonumber\\\\ & & \\times \\left(\\left[\\frac{\\partial}{\\partial \\theta_{j } } f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\right ] \\sigma^{2}(\\boldsymbol{\\theta } ) - \\left[\\frac{\\partial}{\\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right ] f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\right)\\,d\\boldsymbol{\\lambda}. \\nonumber\\end{aligned}\\ ] ] hence , by ( [ deriv_f_d ] ) we get @xmath231 where @xmath232^{2}}\\log\\left|2\\cos\\lambda_{i}-2u_{i}\\right|\\log\\left|2\\cos\\lambda_{j}-2u_{j}\\right|\\ , w^2(\\boldsymbol{\\lambda } ) f^2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})d\\boldsymbol{\\lambda},\\vspace{-4mm}\\ ] ] @xmath233\\int_{[-\\pi,\\pi]^{2}}\\log\\left|2\\cos\\lambda_{i}-2u_{i}\\right|\\ , w^2(\\boldsymbol{\\lambda } ) f^2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})d\\boldsymbol{\\lambda } , \\nonumber\\\\ s_3 & = & 8\\pi^2\\left[\\frac{\\partial}{\\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right]\\left[\\frac{\\partial}{\\partial \\theta_{j } } \\sigma^{2}(\\boldsymbol{\\theta } ) \\right]\\int_{[-\\pi,\\pi]^{2 } } w^2(\\boldsymbol{\\lambda } ) f^2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})d\\boldsymbol{\\lambda}.\\nonumber\\end{aligned}\\ ] ]    the proof of the condition * a9 * is based on the approach in @xcite .",
    "notice , that by ( [ weightfunction ] ) there exists a factorization @xmath234 of @xmath54 such that both @xmath235 and @xmath236 are bounded functions of  @xmath237 for example , one can select the function @xmath238 to be equal a product of @xmath239 and a positive smooth function on @xmath79^{2}.$ ] let us denote @xmath240 then , @xmath241 ^ 2 } ( ei^{*}_{t}(\\boldsymbol{\\lambda})-f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta}_0 ) ) w(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial \\theta_{i } } \\log \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\ , d\\boldsymbol{\\lambda } = t\\displaystyle\\int_{[-\\pi,\\pi]^2 } ( ei^{*}_{t}(\\boldsymbol{\\lambda})w_1(\\boldsymbol{\\lambda})\\ ] ] @xmath242 ^ 2 } ( ei^{*}_{t}(\\boldsymbol{\\lambda})w_1(\\boldsymbol{\\lambda})-e\\tilde{i}^{*}_{t}(\\boldsymbol{\\lambda } ) ) \\tilde{w}_2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\ , d\\boldsymbol{\\lambda}\\ ] ] @xmath243 ^ 2 } ( e\\tilde{i}^{*}_{t}(\\boldsymbol{\\lambda})-\\tilde{f}(\\boldsymbol{\\lambda},\\boldsymbol{\\theta}_0 ) ) \\tilde{w}_2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\ , d\\boldsymbol{\\lambda},\\ ] ] where @xmath244 denotes the unbiased periodogram of the random field with the spectral density  @xmath245    notice that @xmath246 is bounded . hence , by the first statement of proposition  2 in @xcite the last integral in ( [ integ ] ) is @xmath247 and the second term in ( [ integ ] ) vanishes when @xmath248 therefore , to prove the condition * a9 * , it is enough to show that the first term in ( [ integ ] ) vanishes too .",
    "let @xmath249 denote the auto - covariance function of the random field with the spectral density  @xmath245 by multidimensional parseval s theorem , see @xcite , we get @xmath250 ^ 2 } ( ei^{*}_{t}(\\boldsymbol{\\lambda})w_1(\\boldsymbol{\\lambda})-e\\tilde{i}^{*}_{t}(\\boldsymbol{\\lambda } ) ) \\tilde{w}_2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\ , d\\boldsymbol{\\lambda}\\ ] ] @xmath251 ^ 2 } \\bigl(w_1(\\boldsymbol{\\lambda } ) \\sum_{t_{1}=1-t}^{t-1}\\sum_{t_{2}=1-t}^{t-1 } e^{- i(\\lambda_{1}t_{1}+\\lambda_{2}t_{2 } ) } { \\gamma}(\\boldsymbol{t},\\boldsymbol{\\theta}_0)\\ ] ] @xmath252 @xmath253 ^ 2 } \\bigl(w_1(\\boldsymbol{\\lambda } ) \\sum_{(t_{1},t_{2})\\in \\mathbb{z}^2 } e^{- i(\\lambda_{1}t_{1}+\\lambda_{2}t_{2 } ) } { \\gamma}(\\boldsymbol{t},\\boldsymbol{\\theta}_0)i_{[1-t , t-1]^2}(t_{1},t_{2})\\]]@xmath254 ^ 2}(t_{1},t_{2})\\bigr)\\tilde{w}_2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\ , d\\boldsymbol{\\lambda}\\ ] ] @xmath255 ^ 2 } \\bigl(w_1(\\boldsymbol{\\lambda})\\displaystyle\\int_{[-\\pi,\\pi]^2 } { f}(\\boldsymbol{x},\\boldsymbol{\\theta}_0)\\phi_{t-1}(\\boldsymbol{\\lambda}-\\boldsymbol{x})\\,d\\boldsymbol{x}\\ ] ] @xmath228 ^ 2 } \\tilde{f}(\\boldsymbol{x},\\boldsymbol{\\theta}_0)\\phi_{t-1}(\\boldsymbol{\\lambda}-\\boldsymbol{x})\\,d\\boldsymbol{x}\\bigr)\\tilde{w}_2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\ , d\\boldsymbol{\\lambda}\\ ] ] @xmath256",
    "^ 2 } \\bigl(\\displaystyle\\int_{[-\\pi,\\pi]^2 } { f}(\\boldsymbol{x}+\\boldsymbol{\\lambda},\\boldsymbol{\\theta}_0)\\phi_{t-1}(\\boldsymbol{x})(w_1(\\boldsymbol{\\lambda})-w_1(\\boldsymbol{\\lambda}+\\boldsymbol{x}))\\,d\\boldsymbol{x}\\bigr)\\tilde{w}_2(\\boldsymbol{\\lambda},\\boldsymbol{\\theta})\\ , d\\boldsymbol{\\lambda},\\ ] ] where @xmath257 is the fejr kernel , @xmath258 ^ 2}(t_{1},t_{2})$ ] is the indicator function of the cube @xmath259",
    "^ 2.$ ]    let @xmath260 ^ 2),$ ] i.e. @xmath261 then , one can refine the approach in theorems  2.1 and  2.2 by @xcite for the two - dimensional case with @xmath262 namely , let us split the inner integral in ( [ secint ] ) into two parts : the first integral is over the region @xmath263 and the second integral is over @xmath264\\setminus a_{\\alpha}.$ ]    for @xmath265 , by the choice of @xmath238 and @xmath266\\setminus a_\\alpha}\\phi_{t-1}(\\boldsymbol{x})\\,d\\boldsymbol{x}=\\left(\\frac{1}{{\\pi(t-1)}}\\int_{t^{-\\alpha}}^\\pi\\left(\\frac{\\sin ( ( t-1)x_1/2)}{\\sin ( x_1/2)}\\right)^2 dx_1\\right)^2\\ ] ] @xmath267 the both above integrals are bounded by @xmath268 where @xmath269 when @xmath248 it implies that first term in ( [ integ ] ) vanishes and completes the proof of the condition * a9*.@xmath185",
    "in this section we present some numerical results to confirm the theoretical findings .",
    "figure  [ fig3a ] demonstrates a series of box plots to characterize the sample distribution of mces of the parameters @xmath270 @xmath17 as a function of @xmath271 to compute it monte carlo simulations of the gegenbauer field with 100 replications for each @xmath272 were performed . for the parameters @xmath44 @xmath45 @xmath46 @xmath273 and @xmath274 realizations of @xmath275",
    "were simulated using the truncated sum @xmath276 in ( [ gegenb ] ) .",
    "for example , a realization of the gegenbauer random field on a @xmath1 grid is shown in figure  [ fig1 ] .",
    "we set the parameter values of the weight function in ( [ weightfunction ] ) to @xmath277 and @xmath278 the periodogram @xmath71 was computed and the minimizing argument @xmath279 of the functional @xmath73 was found numerically for each simulation .",
    "figure  [ fig3a ] demonstrates that the sample distribution of @xmath279 converges to @xmath280 as @xmath281 increases .",
    "the plot of the sample probabilities @xmath282 in figure  [ fig3b ] also confirms convergence in probability of @xmath279 to @xmath283    ]    ]    for each generated realization we also computed the value of @xmath88 using @xmath284 analogously to figures  [ fig3a ] ,  [ fig3b ] , plots in figures  [ fig4a ] ,  [ fig4b ] support convergence in probability of @xmath88 to @xmath285 when @xmath281 increases .",
    "notice that by ( [ eq_sigma_factorization ] ) we get @xmath286 for the selected parameters .",
    "the larger values of @xmath287 in figure  [ fig4b ] comparing to figure  [ fig3b ] are due to the difference in the scales for the parameters ( small values measured in decimals ) and variances ( large values measured in tens ) .    ]    ]    to verify the result of theorem  [ theorem_2 ] we used sample values @xmath288 which minimized the functional @xmath289 for each simulation . to avoid possible negative values",
    "the modified periodogram @xmath290 was truncated at zero by the r program .",
    "bearing in mind the edge effect and modified periodogram s correction , figures  [ fig5a ] ,  [ fig5b ] demonstrate that the results are close to the expected ones even for the relatively small @xmath291 the normal q - q plot of each component of @xmath292 in figures  [ fig5b ] matches with the theoretical normal distribution . to test the bivariate normality hypothesis about @xmath292 we used the shapiro - wilk , energy , and kurtosis tests of multivariate normality from the r packages mvnormtest , energy , and ics . in all the tests , p - values ( @xmath293 @xmath294 and @xmath295 ) confirmed that @xmath296 asymptotically follows a bivariate normal distribution .",
    "simulations for other values of the parameters were run , with similar results .    ]    ]    hence , we conclude that the mces are consistent estimators and the distributions of @xmath296 converge to the bivariate normal law .",
    "note that the simulation studies not only comply with the obtained results for @xmath98 but also indicate that the theoretical results may be extended to all possible values of @xmath297 in @xmath298",
    "the estimation methodology based on the unbiased periodogram was introduced in @xcite , see also @xcite .",
    "recently , the paper by @xcite and the references therein provided a detailed discussion on the topic .",
    "it studied mainly the difficulties arising in the application of the methodology in high dimensions .",
    "in particular , they investigated problems arising in relation to non - uniformly increasing domain asymptotics associated with different expansion rates of the studied domain in each spatial direction . in this paper , we considered the case @xmath299 and restricted out attention to the case of uniformly increasing domain asymptotics .",
    "the case of non - uniformly increasing domain asymptotics is left for future investigations .",
    "an extended version of the derived results can be obtained for more general formulations of the unbiased periodogram . in particular ,",
    "different growing rates can be allowed for each spatial dimension in the definition of the sampling area .",
    "for example , one can consider the following generalized version of the two - dimensional unbiased periodogram ( see , for example , @xcite ) @xmath300 where the functions @xmath301 @xmath302 satisfy some suitable conditions ( for example , @xmath303 @xmath304 and @xmath305 @xmath306 for @xmath17 and sufficiently large @xmath281 ) .    an important area for future explorations is to extend the results of @xcite and simultaneously estimate the locations of singularities and long - range dependence parameters using the mce methodology .",
    "a feasible way to approach this problem would be relaxing the @xmath307-integrability assumptions in conditions * a5-a8 .",
    "*    it also would be interesting to extend the methodology by @xcite to prove the condition * a9 * for all @xmath297 in @xmath298    note that our simulation results show that the proposed minimum contrast estimation methodology works in the case of uniformly increasing domain asymptotics .",
    "* supplementary materials * the codes used for simulations in this paper are available from the site ` https://googledrive.com/host/ `    ` 0b7uxm8o_bnbxdg9znu9mdhfoquu / mce%20gegenbauer%20fields/ `    the authors are grateful for the referee s careful reading of the paper and many detailed comments and suggestions , which helped to improve the paper .",
    "also , this work has been supported in part by projects mtm2012 - 32674 of the dgi , mec , and p09-fqm-5052 of the andalousian cice , spain .",
    "a.olenko was partially supported by the 2013 ltu research grant .",
    "the conditions for consistency and asymptotic normality of the mce for parameters of stationary fractional riesz - bessel type random fields given in @xcite are specified below for random fields on @xmath6    let @xmath308 be a real - valued measurable stationary gaussian random field with zero mean and a spectral density @xmath309 where @xmath310^{2},$ ] @xmath69 and @xmath120 is a compact set .",
    "assume that @xmath311 where @xmath151 is the true value of the parameter vector @xmath85          the derivatives @xmath318 exist and it is legitimate to differentiate under the integral sign in equation ( [ equation_psi ] ) , i.e. @xmath159^{2 } }       \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda})\\,\\ , d\\boldsymbol{\\lambda } =              \\displaystyle\\int_{[-\\pi,\\pi]^{2 } } \\nabla_{\\boldsymbol{\\theta } }       \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) w(\\boldsymbol{\\lambda})\\,\\ , d\\boldsymbol{\\lambda } = 0 . \\nonumber\\ ] ]                the spectral density @xmath309 the weight function @xmath331 and the function @xmath332 are such that for all @xmath333 and @xmath334 @xmath241 ^ 2 } ( ei^{*}_{t}(\\boldsymbol{\\lambda})-f(\\boldsymbol{\\lambda},\\boldsymbol{\\theta}_0 ) ) w(\\boldsymbol{\\lambda } ) \\frac{\\partial}{\\partial \\theta_{i } } \\log \\psi(\\boldsymbol{\\lambda},\\boldsymbol{\\theta } ) \\,\\ , d\\boldsymbol{\\lambda } \\longrightarrow 0 , \\quad\\text{as } \\quad t\\longrightarrow \\infty.\\ ] ]                                      ferrara l , gugan d ( 2001 ) comparison of parameter estimation methods in cyclical long memory time series . in : junis c ,",
    "moody j , timmermann a ( eds . ) development in forecast combination and portfolio choice , chapter  8 , wiley , new york"
  ],
  "abstract_text": [
    "<S> the article introduces spatial long - range dependent models based on the fractional difference operators associated with the gegenbauer polynomials . </S>",
    "<S> the results on consistency and asymptotic normality of a class of minimum contrast estimators of long - range dependence parameters of the models are obtained . a methodology to verify assumptions for consistency and asymptotic normality of minimum contrast estimators </S>",
    "<S> is developed . </S>",
    "<S> numerical results are presented to confirm the theoretical findings .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}