{
  "article_text": [
    "recently , the problem of within - network classification in partial labeled networks has attracted much attention . given a network with partial nodes being labeled ,",
    "the problem is to predict the labels of these unlabeled nodes based on the known labels and the network structure .",
    "many algorithms have been proposed .",
    "these methods can be widely applied to many fileds , such as the hypertext categorization @xcite , distinguishing the fraud and legit users in cell phone network @xcite , detecting whether an email is for a certain task @xcite and predicting the disease - related genes @xcite . generally speaking",
    ", the known methods can be classified into two groups .",
    "one is collective classification , which refers to the combined classification by using three types of correlations : ( 1 ) between the node s label and its attributes , ( ii ) between node s label and its neighbor s attributes , ( iii ) between node s label and its neighbor s label ( see a brief introduction in ref .",
    "one remarkably advantage of this method is its high ability to learn the dependency structure , such as positive or negative correlation ( i.e. consistency or unconsistency ) .",
    "however , when the labeled nodes are sparse , this method is difficult to give accurate classification .",
    "the sparse problem can be solved by another group of methods , named semi - supervised learning , which make use of both labeled and unlabeled data for training ( see ref .",
    "@xcite for more information ) . the latent assumption of this method is the consistency with the label information , namely the nearby nodes tend to have the same label .",
    "therefore when this assumption does not hold the performance of this method will be largely degraded .",
    "_ proposed a method by adding ghost edges between every pair of labeled and unlabeled node to the target network , which enable the flow of information from the labeled nodes to the unlabeled nodes @xcite .",
    "they assigned a weight to each ghost edge based on the score of the two endpoints obtained by the _ even - step random walk with restart _",
    "( even - step rwr)algorithm .",
    "the experimental results on real - world data showed that their method can to some extent solve the sparse problem and negative correlation problem ( i.e. unconsistency ) , and perform well while the existing approaches , such as collective classification and semi - supervised learning , will fail . in this paper",
    ", we compare the performances of even - step rwr index with other nine similarity indices which have been widely used in link prediction problem @xcite .",
    "these include five local indices , namely the _ common neighbors _",
    "@xcite , _ jaccard coefficient _",
    "@xcite , _ srensen index _",
    "@xcite , _ adamic - adar index _ @xcite and _ resource allocation index _",
    "@xcite , and four global indices , namely _ katz index _",
    "@xcite , _ average commute time _",
    "@xcite , _ cosine based on the pseudoinverse of the laplacian matrix _ ( @xmath0 ) and _ random walk with restart _ ( rwr ) @xcite .",
    "in addition , we also consider a simple relational neighbors algorithm , which claims that an unlabeled node tends to have the same label with its neighbors @xcite . empirical results on the co - purchase network of political books show that the similarity - based methods perform better than the relational neighbors algorithm .",
    "especially when the labeled nodes are sparse , the improvement is prominent . furthermore , when the data is dense , the local indices perform as good as the global indices , while when the data is spare the global indices will perform better .    the rest of this paper is organized as follows . in section 2",
    "we introduce ten similarity indices , including five indices based on local information and others based on global information .",
    "section 3 describes the metric to evaluate the algorithm s accuracy .",
    "section 4 shows the experimental results of the ten indices on the co - purchase network of political books .",
    "finally , we conclude this paper in section 5 .",
    "we consider five local similarity indices as well as five global ones .",
    "all are defined based on the network structure .",
    "a short introduction of each index is shown as :    \\(1 ) _ common neighbors _  for a node @xmath1 , let @xmath2 denote the set of neighbors of @xmath1",
    ". by common sense , two nodes , @xmath1 and @xmath3 , are more similar if they have many common neighbors .",
    "the simplest measure of this neighborhood overlap is the directed count , namely @xmath4 where @xmath5 is the cardinality of the set @xmath6 .",
    "it is obvious that @xmath7 , where @xmath8 is the adjacency matrix , in which @xmath9 if @xmath1 and @xmath3 are directly connected and @xmath10 otherwise . note that , @xmath11 is also the number of different paths with length 2 connecting @xmath1 and @xmath3 .",
    "\\(2 ) _ jaccard index _",
    "@xcite  this index was proposed by jaccard over a hundred years ago , and is defined as @xmath12    \\(3 ) _ srensen index _ @xcite  this index is used mainly for ecological community data , and is defined as @xmath13    \\(4 ) _ adamic - adar index _",
    "@xcite  this index refines the simple counting of common neighbors by assigning the less - connected neighbors more weight , and is defined as : @xmath14    \\(5 ) _ resource allocation _",
    "@xcite consider a pair of nodes , @xmath1 and @xmath3 , which are not directly connected .",
    "the node @xmath1 can send some resource to @xmath3 , with their common neighbors playing the role of transmitters . in the simplest case",
    ", we assume that each transmitter has a unit of resource , and will equally distribute it between all its neighbors .",
    "the similarity between @xmath1 and @xmath3 can be defined as the amount of resource @xmath3 received from @xmath1 , which is : @xmath15 clearly , this measure is symmetric , namely @xmath16 .",
    "note that , although resulting from different motivations , the aa index and ra index have the very similar form .",
    "indeed , they both depress the contribution of the high - degree common neighbors in different ways . aa index takes the @xmath17 form while ra index takes the linear form .",
    "the difference is insignificant when the degree , @xmath18 , is small , while it is great when @xmath18 is large .",
    "therefor , ra index punishes the high - degree common neighbors heavily .",
    "\\(6 ) _ katz index _",
    "@xcite  this measure is based on the ensemble of all paths , which directly sums over the collection of paths and exponentially damped by length to give the short paths more weights .",
    "the mathematical expression reads @xmath19 where @xmath20 is the set of all paths with length @xmath21 connecting @xmath1 and @xmath3 , and @xmath22 is a free parameter controlling the weights of the paths .",
    "obviously , a very small @xmath22 yields a measure close to cn , because the long paths contribute very little .",
    "the @xmath23 matrix can be written as @xmath24 .",
    "note that , @xmath22 must be lower than the reciprocal of the maximum of the eigenvalues of matrix @xmath8 to ensure the convergence .",
    "\\(7 ) _ average commute time",
    "_ @xcite  denoting by @xmath25 the average number of steps required by a random walker starting form node @xmath1 to reach node @xmath3 , the average commute time between @xmath1 and @xmath3 is @xmath26 , which can be computed in terms of the pseudoinverse of the laplacian matrix @xmath27 , as : @xmath28 where @xmath29 denotes the corresponding entry in @xmath27 . assuming two nodes are considered to be more similar",
    "if they have a small average commute time , then the similarity between the nodes @xmath1 and @xmath3 can be defined as the reciprocal of @xmath30 , namely @xmath31    \\(8 ) _ cosine based on @xmath27 _",
    "@xcite  this index is an inner - product based measure , which is defined as the * cosine * of node vectors , namely @xmath32    \\(9 ) _ random walk with restart _ @xcite",
    " this index is a direct application of the pagerank algorithm .",
    "consider a random walker starting from node @xmath1 , who will iteratively moves to a random neighbor with probability @xmath33 and return to node @xmath1 with probability @xmath34 .",
    "denote by @xmath35 the probability this random walker locates at node @xmath3 in the steady state , then we have @xmath36 where @xmath37 is an @xmath38 vector with the @xmath39 element equal to @xmath40 and others all equal to @xmath41 , and @xmath42 where @xmath43 .",
    "the solution is straightforward , as @xmath44 then we define the similarity between node @xmath1 and node @xmath3 equals @xmath45 .",
    "\\(10 ) _ even - step rwr",
    "_ @xcite  to avoid the immediate neighbors , we can consider only the even - length paths .",
    "mathematically , we should replace the transition matrix with @xmath46 .    for comparison",
    ", we compare the above - mentioned ten indices with the simplest method , says relational neighbors ( rn ) @xcite .",
    "given an unlabeled node @xmath47 , the probability that its label is @xmath48 equals @xmath49 where @xmath50 is the set constituted by @xmath47 s neighbors whose label is @xmath48 , and @xmath51 is the set of @xmath47 s neighbors being labeled .",
    "consider an unweighted undirected network of both labeled and unlabeled nodes : @xmath52 , where @xmath53 is the set of nodes , @xmath54 is the set of links and @xmath55 is the set of labels .",
    "for each pair of nodes , @xmath1 and @xmath3 , every algorithm referred in this paper assigns a score as @xmath56 . for an unlabeled node @xmath47 ,",
    "the probability that it belongs to @xmath48 is @xmath57 where @xmath58 .",
    "the predicted label of node @xmath47 is determined by the largest @xmath59 .",
    "if there are more than one maximum values , we randomly select one .",
    "a simple example is shown in fig .  [ 1 ] , where there are two kinds of labels ( i.e. @xmath60 and @xmath61 ) and five nodes , four of which are labeled already .",
    "our task is to predict the label of the node 5 . according to the common neighbors algorithm",
    ", we obtain the similarity between node 5 and the other four labeled nodes , and then we infer that the probability that node 5 is labeled by @xmath60 equals @xmath62 .    to test the algorithm s accuracy ,",
    "all the labeled nodes are randomly divided into two parts : the training set , @xmath63 , is treated as known information , while the probe set , @xmath64 , is used for testing .",
    "we denote @xmath65 the proportion of labeled nodes divided into training set , which is considered as the density index .",
    "a smaller @xmath65 indicates a sparser labeled network . the accuracy is quantified by the probability that we predict right . for a testing node @xmath66 whose label is @xmath48 , if @xmath67 , we predict right , and thus @xmath68 .",
    "if there is @xmath69 maximum values corresponding to @xmath69 different labels and the right label is one of them , we have @xmath70 .",
    "run over all the testing nodes we have the accuracy equals @xmath71 where @xmath72 is the number of nodes in the probe set .",
    "for example , if there are two categories in the target network , namely @xmath73 and @xmath74 , accuracy can be obtained by @xmath75 where @xmath76 is the number of nodes in probe set being predicted right and @xmath77 is the number of nodes @xmath66 having the same probability of two labels ( i.e. @xmath78 ) .",
    "we compare the above - mentioned ten similarity indices on the co - purchases network of political books @xcite .",
    "this network contains 105 nodes ( books ) and 441 edges .",
    "all books are classified into three categories , neutral , liberal and conservative . for simplicity , we start the experiments with the sampled networks containing only two classes . therefore , we sample three labeled networks with three tasks as follows :    * task 1 : * _ whether an unlabel node is neutral ? _ for this task , we label the books which are neutral by @xmath60 and others by @xmath61 ( i.e. not neutral ) .    *",
    "task 2 : * _ whether an unlabel node is liberal ?",
    "_ for this task , we label the books which are liberal by @xmath60 and others by @xmath61 ( i.e. not liberal ) .    *",
    "task 3 : * _ whether an unlabel node is conservative ?",
    "_ we label the books which are conservative by @xmath60 and others by @xmath61 ( i.e. not conservative ) .",
    "table.1 summarize the basic statistics of these three sampled networks corresponding to task 1 , task 2 and task 3 respectively .",
    "@xmath79 ( @xmath80 ) is the number of nodes labeled by @xmath1 .",
    "@xmath81 indicates the number of edges connecting to the nodes labeled by @xmath1 .",
    "denote by @xmath82 the number of edges whose two endpoints have the same label @xmath1 , then @xmath83 indicats the local consistency of the subgraph constituted by the nodes labeled by @xmath1 and the edges connecting to these nodes .",
    "@xmath84 is the local consistency of the whole network , which reads @xmath85 , where @xmath54 is the total number of edges of the whole network ( here @xmath86 ) .",
    "note that , @xmath87 . here , we further develop the definition of local consistency to two - step consistency denoting by @xmath88 which equals to the number of path with length 2 whose two endpoints have the same label divide by the number of the path with length 2 .",
    "clearly , the common neighbor index will perform well in the network with high @xmath88 .",
    "four simple examples of calculating @xmath89 , @xmath84 and @xmath88 are shown in fig .",
    "one can see that in the first graph , because of @xmath90 , rn will perform very bad , while cn performs very good ( @xmath91 ) .",
    "however in the forth graph both rn and cn can give good performance .        .",
    "each number is obtained by averaging over 1000 implementations with independently random division of training set and probe set.,title=\"fig:\",width=257 ] .",
    "each number is obtained by averaging over 1000 implementations with independently random division of training set and probe set.,title=\"fig:\",width=257 ] .",
    "each number is obtained by averaging over 1000 implementations with independently random division of training set and probe set.,title=\"fig:\",width=257 ] .",
    "each number is obtained by averaging over 1000 implementations with independently random division of training set and probe set.,title=\"fig:\",width=257 ] .",
    "each number is obtained by averaging over 1000 implementations with independently random division of training set and probe set.,title=\"fig:\",width=257 ] .",
    "each number is obtained by averaging over 1000 implementations with independently random division of training set and probe set.,title=\"fig:\",width=257 ]    ccccccccccc net & @xmath92 & @xmath93 & @xmath94 & @xmath95 & @xmath96 & @xmath97 & @xmath98 & @xmath99 & @xmath84 & @xmath88 + net1 & 13 & 92 & 67 & 432 & 9 & 374 & 0.134 & 0.866 & 0.869 & 0.864 + net2 & 43 & 62 & 208 & 269 & 172 & 233 & 0.827 & 0.866 & 0.918 &",
    "0.894 + net3 & 49 & 56 & 236 & 251 & 190 & 205 & 0.805 & 0.817 & 0.890 & 0.882 +    comparison of the ten similarity indices on three sampled networks are shown in fig .",
    "[ sample ] .",
    "the subgraphs ( a ) , ( c ) and ( e ) show the results of the local indices , while ( b ) , ( d ) and ( f ) report the results of the global indices .",
    "it is interesting that all these five local indices give almost the same results especially when the density of labeled nodes is small .",
    "this is because all these five indices are common - neighbor based and when @xmath65 is small whether an unlabeled node relevant with a labeled node play a more important role than the exact correlation ( similarity score ) between them .",
    "furthermore , because of the high @xmath88 of these three networks , all the common - neighbor - based indices performs well and even when the data is sparse they can give much better prediction than rn .",
    "compare with global indices , the local indices can give competitively accurate classification when @xmath65 is large , but when the labeled data is sparse , for most unlabeled node it is too difficult to find a labeled node nearby , and thus the global indices will perform better . among these five global indices ,",
    "the performance of katz index , rwr and even - step rwr are stable , while the performance of act and @xmath0 are not .",
    "for example , in sampled network 1 , the act index performs very well but @xmath0 is even worse than pure chance .",
    "however , in sampled network 3 , the @xmath0 index preforms the best but the act index performs even worse than the simplest method rn .    obviously , it will be more difficult to obtain highly accurate classification when we consider many categories together .",
    "we futher carry out an experiment on the network containing all the three categories .",
    "our task is to detect the category of an unlabel book , namely is it neutral , liberal or conservative ?",
    "we label the books by @xmath69 ( i.e. neutral ) , @xmath21 ( i.e. liberal ) and @xmath33 ( i.e. conservative ) according to their categories .",
    "the local consistency and two - step consistency of this network are 0.8413 and 0.8204 respectively , which are all lower than the three sampled networks containing only two classes , and thus the accuracy is also lower , as shown in fig .  [ all ] .",
    "one can see that the results are similar to the one on the sampled network 3 where the biggest class , conservative , is considered .",
    "this result demonstrates that the majorities play the main role .    .",
    "each number is obtained by averaging over 1000 implementations with independently random division of training set and probe set.,title=\"fig:\",width=257 ] .",
    "each number is obtained by averaging over 1000 implementations with independently random division of training set and probe set.,title=\"fig:\",width=257 ]",
    "in this paper , we investigated the similarity - based classification for partial labeled network .",
    "the basic assumption is that two nodes are more likely to have the same label if they are more similar to each other .",
    "we introduced ten similarity indices which have been widely used to solve the link prediction problem of complex networks , including five common - neighbor - based indices , namely _ common neighbors _ , _ jaccard coefficient _ , _ srensen index _ , _ adamic - adar index _ and _ resource allocation index _ , and five global indices , namely _",
    "katz index _ , _ average commute time _ , _ cosine based on the pseudoinverse of the laplacian matrix _ ( @xmath0 ) , _ random walk with restart _ ( rwr ) and _ even - step rwr_. we carried out the experiments on the co - purchase network of political books .",
    "the results showed that the similarity - based classification perform much better than the relational neighbors algorithm , especially when the labeled nodes are sparse .",
    "furthermore , we found that when the data is dense the local indices can perform as good as the global indices .",
    "however , when the data is sparse , for an unlabeled node it is too difficult to find a labeled node nearby , and thus the global indices perform better . compare with the former proposed algorithms the group of similarity - based classification methods has three advantages : firstly , it can to some extent solve the sparse data problem by using the global indices ; secondly , when the network consistency assumption is not hold it can still give high accurate classification ; thirdly , without any learning process this method has lower calculation complexity than other complicated methods .",
    "however , there are still some open problems left .",
    "for example what is the relation between the network label structure and the performance of each similarity index . in - depth analysis on the modeled networks may be helpful , where we can control the label density , network consistency and also the proportion of each class .",
    "anyway , we hope this work can provide a novel view for the study of classification in partial labeled networks and we believe that there is still a large space for further contribution . for example , when the number of nodes in one class is much lager than in the others , the unlabeled nodes are more likely to have the same labels with the majority . to solve this problem we can only consider the top-@xmath18 similar labeled nodes when calculate the probability .",
    "in addition , we can also use negative correlation in the adjacent matrix @xmath8 directly , namely for the nonzero element in @xmath8 if the node @xmath1 and @xmath3 have the different labels , we set @xmath100 . to do this ,",
    "we can not only obtain the strength of the correlation between the unlabeled node and the labeled one but also know the correlation type , positive or negative .",
    "we acknowledge tao zhou for his assistance of manuscript preparation . this work is partially supported by the swiss national science foundation ( 200020 - 121848 ) , the china postdoctoral science foundation ( 20080431273 ) and the national natural science foundation of china ( 60973069 , 90924011 ) .",
    "99 s. chakrabarti , b. e. dom , p. indyk , _ enhanced hypertext categorization using hyperlinks _ , in _ proceedings of sigmod-98 , acm international conference on management of data _ ( acm press , seattle , wa , 1998 ) .",
    "y. yang , s. slattery , r. ghani , a study of approaches to hypertext categorization , journal of intelligent information systems * 18 * , 219 ( 2002 ) .",
    "b. gallagher , h. tong , t. eliassi - rad , c. faloutsos , _ using ghost edges for classification in sparsely labeled networks _ , in _ proceedings of the acm sigkdd international conference on knowledge discovery and data mining _",
    "( acm press , new york , 2008 ) . v.",
    "r. carvalho , w. w. cohen , _ on the collective classification of email `` speech acts '' _ , in _ proceedings of the 28th annual international acm sigir conference on research and development in information retrieval _",
    "( acm press , new york , 2005 ) .",
    "p. sen , g. namata , m. bilgic , l. getoor , b. gallagher , t. eliassi - rad , collective classification in network data , ai magazine * 29 * , 93 ( 2008 ) .",
    "x. zhu , a. b. goldberg , synthesis lectures on artificial intelligence and machine learning * 3 * , 1 ( 2009 ) .",
    "d. liben - nowell , j. kleinberg , the link - prediction problem for social networks , j. am .",
    "soc . inf .",
    "technol . * 58 * , 1019 ( 2007 ) .",
    "t. zhou , l. l , y .- c .",
    "zhang , predicting missing links via local information , eur .",
    "j. b * 71 * , 623 ( 2009 ) .",
    "l. l , c .- h .",
    "jin , t. zhou , effective and efficient similarity index for link prediction of complex networks , phys .",
    "e * 80 * , 046122 ( 2009 ) .",
    "f. lorrain , h. c. white , structural equivalence of individual in social networks , j. math .",
    "* 1 * , 49 ( 1971 ) .",
    "p. jaccard , etude comparative de la distribution florale dans une portion des alpes et des jura , bull . soc .",
    "nat . * 37 * , 547 ( 1901 ) .",
    "t. srensen , a method for establishing groups of equal magnitude in plant sociology based on similarity of species contentand and its application to analyses of the vegetation on danish commons , biol . skr . * 5 * , 1 ( 1948 ) .",
    "l. a. adamic , e. adar , friends and neighbors on the web , social networks * 25 * , 211 ( 2003 ) .",
    "l. katz , a new status index derived from sociometric analysis , psychmetrika * 18 * , 39 ( 1953 ) .",
    "d. j. klein , m. randic , resistance distance , j. math .",
    "* 12 * , 81 ( 1993 ) .",
    "s. brin , l. page , the anatomy of a large - scale hypertextual web search engine , computer networks and isdn systems * 30 * , 107 ( 1998 ) .",
    "s. macskassy , f. provost , _ a simple relational classifier _ , in _ proceedings of the 2nd international workshop on multi - relational data mining _ ( acm press , new york , 2003 ) .",
    "v. krebs , working in the connected world : book network , international association for human resource information management journal * 4 * , 87 ( 2000 ) ."
  ],
  "abstract_text": [
    "<S> we propose a similarity - based method , using the similarity between nodes , to address the problem of classification in partially labeled networks . </S>",
    "<S> the basic assumption is that two nodes are more likely to be categorized into the same class if they are more similar . in this paper , we introduce ten similarity indices , including five local ones and five global ones </S>",
    "<S> . empirical results on the co - purchase network of political books show that the similarity - based method can give high accurate classification even when the labeled nodes are sparse which is one of the difficulties in classification . </S>",
    "<S> furthermore , we find that when the target network has many labeled nodes , the local indices can perform as good as those global indices do , while when the data is spares the global indices perform better . </S>",
    "<S> besides , the similarity - based method can to some extent overcome the unconsistency problem which is another difficulty in classification .    </S>",
    "<S> complex networks , similarity , classification , labeled network    89.20.ff , 89.75.hc , 89.65.-s </S>"
  ]
}