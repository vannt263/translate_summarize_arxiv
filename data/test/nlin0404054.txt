{
  "article_text": [
    "surrogate tests @xcite are examples of monte carlo hypothesis tests @xcite . taking the surrogate test of nonlinearity in a time series @xcite as an example ,",
    "we first need to adopt a null hypothesis , which usually supposes the time series is generated by a linear stochastic process and potentially filtered by a nonlinear filter @xcite . based on this null hypothesis ,",
    "a large number of data sets ( surrogates ) are to be produced from the original time series , which keeps the linearity of the original time series but destroys all other structures .",
    "we then calculate some nonlinear statistics ( discriminating statistics ) , for example , correlation dimension , of both the original time series and the surrogates .",
    "if the discriminating statistic of the original time series deviates from those of the surrogates , we can reject the null hypothesis we proposed and claim that the original time series is deterministic with certain confidence level ( depending on how many surrogates we have generated , to be shown later ) . in general",
    ", to apply the surrogate technique to test if a time series possesses the property @xmath0 we are interested , we first select a null hypothesis , which assumes the time series instead has a property @xmath1 opposite to @xmath0 .",
    "we then devise a corresponding algorithm to produce surrogates from the observed data set . in principle",
    ", these surrogates shall preserve the potential property @xmath1 while destroying all others .",
    "the next step is to choose a suitable discriminating statistic , which shall be an invariant measure for both the surrogates and the original time series if the null hypothesis is true .",
    "hence if the discriminating statistic of the original time series distinctly deviates from the distribution of the discriminating statistic of the surrogates , the null hypothesis is unlikely to be true , or in other words , the time series is much more likely to possess the property @xmath0 than @xmath1 . in this way",
    ", we can assess the statistical significance of our calculations through surrogate test technique even when we have only a very limited amount of observations .",
    "such assessments are important because in many practical situations statistical fluctuations are inevitable due to the presence of noise , hence the surrogate test is a proper tool to evaluate the reliability of our results in a statistical sense .    in this communication ,",
    "we are focused on discussing the algorithm to generate surrogates for pseudoperiodic time series . by pseudoperiodic time series",
    "we mean a representative of a periodic orbit perturbed by dynamical noise , or contaminated by observational noise , or with the combination of the both noises , whose states within one cycle are largely independent of those within previous cycles given a cycle length .",
    "note that , in our discussions we will always assume we have detected that the time series are produced from nonlinear deterministic systems , but they are also possibly contaminated by some noises . as we know",
    ", if an irregular time series comes from a nonlinear deterministic system , it shall be either chaotic or pseudoperiodic in most cases . in some situations",
    ", it might be important for us to discriminate between pseudoperiodicity and chaos .",
    "however , chaotic and pseudoperiodic time series often look similar , we might not be able to distinguish them from each other only through visual inspections , quantitative techniques are needed instead at this time .",
    "one choice is to apply the direct test techniques .",
    "for instance , we can calculate some characteristic statistics of the time series , such as the lyapunov exponent and the correlation dimension .",
    "however , a direct test usually will not give out the confidence level .",
    "if we find the lyapunov exponent of a time series is , for example , @xmath2 , it may be difficult for us to tell whether the time series is chaotic or the time series is pseudoperiodic , but the presence of noise causes the lyapunov exponent to be slightly larger than zero . as an alternative choice , we suggest one utilizes the surrogate test rather than the direct test , which can provide us the confidence level by calculating a large number of surrogates . through the surrogate tests , if we could exclude the possibility that the time series is pseudoperiodic , then the time series is more likely to be chaotic .",
    "this is the essential idea to apply our algorithm to distinguish chaos from pseudoperiodicity , as to be shown in section iii .",
    "first let us briefly review some of the algorithms to generate surrogates for pseudoperiodic time series .",
    "initially , to generate surrogates for pseudoperiodic time series , theiler @xcite proposed the cycle shuffling algorithm .",
    "the idea is to divide the whole data set into some segments and let each segment contain exactly an integer number of cycles .",
    "the surrogates are obtained by randomly shuffling these segments , which will preserve the intracycle dynamics but destroy the intercycle ones by randomizing the temporal sequence of the individual cycles .",
    "the difficulty in applying this algorithm is that it requires preknowledge of the precise periodicity , otherwise shuffling the individual cycles might lead to spurious results @xcite .    recently , with the development of the cyclic theory of chaos @xcite , many authors have shown interest in searching unstable periodic orbits ( upos ) in noisy data sets from chaotic dynamical systems .",
    "the algorithms proposed in @xcite essentially deal with the unstable fixed points of the upos .",
    "but as observed , the presence of noise will reduce the statistical significance of these algorithms .",
    "one remedy is to introduce the surrogate test for reliability assessments , e.g. , dolan _ et.al _",
    "@xcite claimed that the randomly shuffling surrogate algorithm @xcite together with the simple recurrence method @xcite correctly tests the appropriate null hypothesis .",
    "essentially , this approach is very similar to the cycle shuffling algorithm described previously .",
    "the simple recurrence algorithm is equivalent to applying a poincar map on the continuous dynamical systems and then studying only the data points falling on the cross - section plane , hence one does not need to consider the intracycle dynamics and no knowledge of the periodicity is required , while randomly shuffling these data points exactly aims to randomize the temporal sequence of the cycles .",
    "however , one potential problem of this algorithm is that it might generate spuriously high statistical significance due to the correlation between the cycles @xcite .",
    "later , small _ et.al _",
    "@xcite _ _  _ _ proposed the pseudoperiodic surrogate ( pps ) algorithm from another viewpoint .",
    "they first apply the time delay embedding reconstruction @xcite to the original data set , then utilize a method based on local linear modelling techniques to produce surrogate data which approximate the behavior of the underlying dynamical system . as the authors pointed out , this algorithm works well even with very large dynamical noise , but it may incorrectly reject the null hypothesis if the intercycles of the pseudoperiodic orbit have a linear stochastic dependence induced by colored additive observational noise @xcite .    in this communication",
    "we propose a new surrogate algorithm for continuous dynamical systems , which properly copes with linear stochastic dependence between the cycles of the pseudoperiodic orbits .",
    "the null hypothesis to be tested is that the stationary data set is pseudoperiodic with noise components which are ( approximately ) identically distributed and uncorrelated for sufficiently large temporal translations .",
    "note the constraints of the noise components in our null hypothesis are stronger than that of theiler s algorithm , which requires the noise distribution only periodically depends on the phase of the signal .",
    "however , under our hypothesis , we can produce the surrogates in a simple way through the algorithm to be described below .",
    "in addition , a large scope of noise processes often encountered in practical situations , including ( but not limited to ) linear colored additive observational noise described by the @xmath3 model @xcite , match the above constraints .",
    "the remainder of this communication is organized as follows . in sec .",
    "ii we will introduce the new algorithm to generate pseudoperiodic surrogates , while in sec .",
    "iii we will apply this algorithm to simulation data sets from the rssler system , which demonstrates the ability of the surrogate test based on this algorithm to distinguish chaotic orbits from pseudoperiodic ones . as one of the applications , we will use this surrogate technique to investigate whether a human electrocardiogram ( ecg ) record is possibly presentative of a chaotic dynamical system . finally , in sec .",
    "iv , we will have a summary of the whole communication .",
    "let @xmath4 be a data set with @xmath5 observations ( the form @xmath6 is adopted instead for convenience when causing no confusion ) , where @xmath7 means the observation measured at time @xmath8 with @xmath9 denoting the sampling time .",
    "we assume @xmath4 is stationary and can be decomposed into the deterministic components and the noise components , which are approximately independent of each other .",
    "similar to the surrogate test idea of time shifting to desynchronize two data sets @xcite , we assume the noise components ( approximately ) follow an identical distribution and are uncorrelated for sufficiently large temporal translations ( or time shifts ) . according to the null hypothesis we proposed in the previous section ,",
    "if the deterministic components are periodic , then we can write a data point @xmath7 as @xmath10 , where @xmath11 and @xmath12 denote the periodic component and the noise component respectively .",
    "in many cases , we can set @xmath13 where @xmath14 is the expectation operator .",
    "since @xmath15 are roughly independent of @xmath16 , we have the autocovariance @xmath17 .",
    "let @xmath18with @xmath19 , where coefficients @xmath20 and @xmath21 satisfy @xmath22 and parameter @xmath23 is the temporal translation between subsets @xmath24 and @xmath25 , then the autocovariance function @xmath26 .",
    "now let us consider the noise components .",
    "if @xmath27 is sufficiently large , under our hypothesis , @xmath28 and @xmath29 are uncorrelated .",
    "we also note that @xmath30 and @xmath31 are drawn from ( approximately ) the same distribution , we have @xmath32 . for the deterministic component , if we require the translation @xmath23 to satisfy @xmath33 , then @xmath34 .",
    "hence by choosing a suitable temporal translation , the noise levels of @xmath35 , defined by @xmath36 , will be the same as that of @xmath4 , i.e. , @xmath37 .",
    "the reason to preserve the noise level is that , the presence of noise will affect the calculation of the correlation dimension , hence we would like to let the surrogates and the original time series ( roughly ) have the same noise level in order to make the results more conceivable .",
    "the above deduction leads to the central idea of our surrogate algorithm . from eq .",
    "( [ linear combination ] ) , we note that if @xmath15 is periodic , the nonconstant deterministic components @xmath38 shall also be periodic .",
    "in addition , @xmath39 and @xmath35 shall have the same noise level if a suitable translation @xmath23 is selected .",
    "therefore by randomizing the coefficient @xmath20 or @xmath21 , we can generate many data sets @xmath35 as the surrogates of @xmath4 .",
    "note that @xmath15 and @xmath40 have the same degree - of - freedom , if both of them are periodic , their correlation dimensions @xcite will theoretically be the same .",
    "now let us consider the noise components . although the noise components @xmath41 may have a different distribution from that of @xmath30 , the noise level is preserved after the transform in eq .",
    "( [ linear combination ] ) .",
    "as diks @xcite has reported , the gaussian kernel algorithm ( gka ) can reasonably estimate the correlation dimensions of noisy data sets with different noise distributions .",
    "this implies that , under the same noise level , the correlation dimensions of @xmath4 and @xmath42 , calculated by the gka , shall statistically be the same if @xmath4 and @xmath43 are both pseudoperiodic ( and satisfy the constraints we imposed ) .",
    "in contrast , if @xmath15 is chaotic , its linear combination , @xmath40 , may have a new dynamical structure with a different correlation dimension from that of @xmath44 , hence by adopting the correlation dimension as the discriminating statistic we might detect this difference .",
    "we shall also note that , for an unstable periodic orbit , even a small dynamical noise might drive the resultant orbit far away from the original position after a sufficiently long time , and the pseudoperiodicity might be broken . in such situations , our algorithm might fail to work .",
    "nevertheless , we suggest to apply our algorithm as the first step in pseudoperiodicity test , which is computationally fast and in principle deals well with a large scope of observational noise ( comparatively , the pps algorithm will sometimes fail for colored observational noise ) . if we can reject the null hypothesis proposed previously , the time series in test is possibly chaotic or pseudoperiodic perturbed by dynamical noise",
    ". then we can adopt the pps algorithm for further tests , which works well even under a large amount of dynamical noise .",
    "if  the corresponding null hypothesis , i.e. , the time series is pseudoperiodic perturbed by dynamical noise , can be rejected again , then we may claim the time series is very likely to be chaotic .",
    "we now consider several computational issues in our algorithms .",
    "as described in eq .",
    "( [ linear combination ] ) , to generate the surrogates @xmath45 , we select two subsets of @xmath46 , @xmath24 and @xmath47 , multiply them by the coefficients @xmath20 and @xmath21 respectively and then add them together",
    ". we shall emphasize that choosing the temporal translation @xmath23 is a crucial issue for our algorithm . from one aspect",
    ", we require the translation @xmath23 to satisfy the condition @xmath48 .",
    "the reason is that we want to keep the noise level for the original time series and the surrogates .",
    "in addition , we want the deterministic components @xmath49 to be orthogonal to @xmath50 for arbitrary coefficients @xmath20 and @xmath21 , otherwise the projection of @xmath51 onto @xmath50 might counteract @xmath50 under some situations , for example , if @xmath52 and @xmath53 , the deterministic components @xmath40 will almost vanish while the noise components @xmath54 remain . hence the correlation dimensions calculated are actually those of the noise components instead of the deterministic components , which will certainly cause the false rejection of the null hypothesis . from another aspect , we require @xmath23 to be sufficiently large to guarantee the decorrelation between the noise components .",
    "however , we expect @xmath24 and @xmath47 shall have at least some overlaps to make use of the information of the whole data set @xmath4 , which means @xmath23 shall not exceed @xmath55 . in addition",
    ", it is recommended the length of a data set shall not be too short in order to appropriately calculate its correlation dimension @xcite , which also implies @xmath23 shall not be too large .        from eq .",
    "( [ linear combination ] ) we see that the surrogates are generated from two segments @xmath56 and @xmath57 of the original time series @xmath58 .",
    "we want segments @xmath56 and @xmath59 to equivalently affect the generation of the surrogates , therefore we would like to let @xmath60 , @xmath61 and @xmath62 , where @xmath63 , @xmath64 and @xmath65 denote the maximal function , the minimal function and the probability function respectively . but note that the coefficient ratio @xmath66 ( or @xmath67 ) shall not be too large or too small , otherwise @xmath35 will be very close to @xmath68 or @xmath69 , which will lead to approximately the same correlation dimensions of @xmath4 and @xmath43 regardless of the dynamical behavior of @xmath46 , and thus decrease the discriminating power of the correlation dimension . in our calculations",
    "we let @xmath20 be uniformly drawn from the interval @xmath70 \\cup \\left [ 0.6,0.8\\right ] $ ] and @xmath71 , which satisfies our requirements and provides moderate values for the ratio @xmath72 .",
    "in this section , through four examples from the rssler system , we demonstrate the ability of surrogate test based on our algorithm to discriminate chaotic orbits from pseudoperiodic ones . as an application",
    ", we will also employ the surrogate technique to investigate whether a recorded human electrocardiogram ( ecg ) data set is possibly chaotic .",
    "the equations of the rssler system are given by @xmath73with the initial conditions @xmath74 .",
    "we choose parameters @xmath75 , @xmath76 and the sampling time @xmath9 @xmath77 time units .",
    "for each example , the system is to be integrated @xmath78 times and the first @xmath79 data points are discarded to avoid including transient states .    in the first example",
    ", we set parameter @xmath80 .",
    "the rssler system exhibits limit cycle behavior of period 6 . to obtain pseudoperiodic time series ,",
    "we introduce @xmath81 observational noise into the periodic time series .",
    "although gaussian white observational noise is the most common choice in this situation , in order to demonstrate the ability of our surrogate algorithm to deal with colored noise , we will instead adopt the noise generated from the @xmath82 process @xcite @xmath83 with the variable @xmath84 following the normal gaussian distribution @xmath85 , which is the more difficult case due to the correlation between noise components",
    ". however , one shall note that , gaussian white noise and other colored noises satisfying the constraints in our null hypothesis , for example , those modelled by the @xmath86 processes , in principle can be dealt with in the same way . for convenience of observation and comparison , we plot the time series and the corresponding attractor in two dimensional state space ( or embedding space ) in panels @xmath87 and @xmath88 of fig .",
    "[ rosslerp5perobvdim4 ] respectively .    to produce surrogate data ,",
    "first we shall choose a suitable temporal translation .",
    "since it is impractical to separate noise from signal completely , in general it is difficult to estimate the correlation decay time between noise components .",
    "fortunately , to decorrelate noise components , all temporal translations are equivalent as long as they are large enough .",
    "in addition , in many real situations , it is often possible to observe the background noise and thus estimate the decay time . in our example , we think the @xmath82 noise to be uncorrelated when the temporal translation is larger than @xmath89 ( in units of the sampling time @xmath9 ) . as another requirement , temporal translation satisfying @xmath48 is desired . in practice , of course , this requirement is generally impractical due to the digitization and quantization in sampling process . recall the discussion in the previous section , by letting @xmath90 and @xmath91 , we have @xmath92 .",
    "function @xmath93 means we do not preserve the noise level .",
    "however , under the null hypothesis of pseudoperiodicity , there shall always be some temporal translations to make @xmath94 , hence the noise level will not deviate from the original one too much . besides , according to eq .",
    "( [ linear combination ] ) , we generate the surrogates by uniformly drawing coefficient @xmath20 from interval @xmath95 \\cup \\left [ 0.6,0.8\\right ] $ ] ( @xmath96 is always kept positive ) , the noise level of the surrogates will fluctuate around that of the original one due to the alternative signs of product @xmath97 .",
    "therefore , @xmath98 will only cause some fluctuations when to calculate the correlation dimension because of the fluctuations of noise level , however , generally such fluctuations will not affect our conclusion if we can select a temporal translation @xmath23 to let @xmath94 . since we have assumed the noise components are roughly independent of the deterministic components , then @xmath99 for a large enough temporal translation ( to decorrelate noise components ) , therefore in all of the examples , in order to let @xmath94 , we can equivalently require @xmath100",
    ". in the first example , there are many temporal translations satisfying the two constraints discussed above , i.e. , @xmath101 and @xmath100 . to pick a value from all these candidates , we first select an interval @xmath102 $ ] , then search the temporal translation which makes the absolute value @xmath103 be the minimum ( most close to zero ) among all translations @xmath104 .",
    "one shall note that the choice of the interval @xmath102 $ ] is arbitrary , except that we have to make sure that the lower bound of the interval is larger than @xmath89 , and there exists temporal translations to let @xmath100 within the interval .",
    "after selecting the temporal translation , by randomizing the coefficient @xmath105 we will generate @xmath106 surrogates according to eq .",
    "( [ linear combination ] ) .    in order to calculate the correlation dimension",
    ", we adopt the time delay embedding reconstruction @xcite to recover the underlying system from the scalar time series .",
    "two parameters , i.e. , embedding dimension and time delay , shall be properly chosen to apply this technique . throughout this communication",
    ", we will use the false nearest neighbour criterion @xcite to determine the global optimal embedding dimension . using the program in tisean package @xcite , the embedding dimension @xmath107 of the original time series",
    "is selected at @xmath108 , which is the minimal value to make the fraction of false nearest neighbours be zero . to choose a suitable time delay",
    ", we will use the algorithm of redundancy and irrelevance tradeoff exponent ( rite ) proposed in @xcite .",
    "this algorithm selects the time delay by searching the optimal tradeoff between redundancy ( due to too small time delay ) and irrelevance ( due to too large time delay ) .",
    "as demonstrated , the rite algorithm can select equivalently suitable time delays compared to the average mutual information ( ami ) criterion @xcite , however , its implementation is much simpler and the computational cost is fairly low . therefore in case of large data sets , adopting the rite algorithm can facilitate our calculations . in the first example we generate @xmath106 surrogates , and for each surrogate we keep the embedding dimension @xmath109 and use the rite algorithm to choose the suitable time delay for time delay reconstruction .",
    "we will follow diks s method @xcite to calculate the correlation dimension , which is more robust against noise by extending the hard kernel function ( or the heaviside function ) @xcite in calculation of correlation integral to the general kernel functions . in his discussions",
    ", diks adopted the gaussian kernel function , hence this method is called gaussian kernel algorithm ( gka ) . here",
    "we will use the gka implemented in @xcite to calculate the correlation dimensions , which further enhances the computational speed . note that to speed up the calculation , only 2000 data points are used as the reference points for the gka .",
    "there are some statistical fluctuations even for the same data set when calculating its correlation dimension , therefore for the original time series , we will calculate @xmath106 times to estimate the mean correlation dimension and the standard deviation . as shown in panel @xmath110 of fig .",
    "[ rosslerp5perobvdim4 ] , there are three lines parallel to the abscissa .",
    "the middle line denote the estimation of the mean correlation dimension of the original time series , while the upper and lower lines indicate the positions twice the standard deviation away from the mean value . for the surrogates , however , we will calculate their correlation dimensions only once to save time .",
    "the results are illustrated as the asterisks in panel @xmath111 of fig .",
    "[ rosslerp5perobvdim4 ] .    after the calculation of the correlation dimensions ,",
    "we need to inspect whether the result is consistent with our null hypothesis . here",
    "we use the ranking criterion @xcite to determine whether the null hypothesis shall be rejected or not .",
    "the idea of this criterion is that , suppose the discriminating statistic of the original data set is @xmath112 , and those of @xmath113 surrogates are @xmath114 .",
    "rank the statistics @xmath115 in the increasing order and denote the rank of @xmath112 by @xmath116 , if the data set is consistent with the hypothesis ( i.e. , no evidence to reject ) , @xmath116 can have an equal possibility be any integer value between @xmath117 and @xmath118 .",
    "however , if the hypothesis is false , @xmath112 might deviate from the surrogate distribution @xmath119 , i.e , @xmath112 will be the smallest or largest amongst @xmath120 , hence we can reject the null hypothesis if @xmath121 or @xmath118 , the probability of a false rejection is @xmath122 for one - sided tests and @xmath123 for two - sided tests .",
    "for the first example , from panel @xmath111 of fig .",
    "rosslerp5perobvdim4 we can see that , the mean correlation dimension of the original time series falls within the dimension distribution of the surrogates , therefore we can not reject the null hypothesis as we expect , which means the original time series is possibly pseudoperiodic @xcite .",
    "now let us examine the other examples .",
    "in the second example , we still set parameter @xmath80 in eq .",
    "( [ rossler ] ) .",
    "however , to obtain the pseudoperiodic time series , we first generate a data set by adding gaussian white noise with the standard deviation of @xmath124 to the @xmath125 component at each integration step , which simulates the system perturbed by additive dynamical noise , and then introduce @xmath81 observational @xmath82 noise into the previously obtained data set .",
    "the global optimal embedding dimension is chosen at @xmath109 .",
    "note in all of the four examples , we will generate @xmath106 surrogates , and parameter choices for surrogate generation will be the same , i.e. , we let the temporal translation be selected from @xmath126 $ ] and coefficient @xmath20 be uniformly drawn from @xmath70 \\cup \\left [ 0.6,0.8\\right ] $ ] ( @xmath96 ) . for the second example , the correlation dimensions of the original time series and the surrogates are shown in panel @xmath111 of fig . rosslerp5perobv015ddim4 . under the ranking criterion ,",
    "once again we can not reject our null hypothesis .",
    "therefore the time series is possibly pseudoperiodic , which is consistent with our knowledge .    in the third example , we change parameter @xmath127 of eq .",
    "( [ rossler ] ) to be @xmath128 .",
    "the rssler system exhibits chaotic behavior .",
    "we integrate eq .",
    "( [ rossler ] ) to obtain a time series and then introduce @xmath81 observational @xmath82 noise .",
    "the optimal embedding dimension @xmath107 is selected at @xmath129 . from panel @xmath111 of fig .",
    "[ rosslech5perobvdim5_pps ] , we find that the mean correlation dimension of the original time series deviates from the distribution of the surrogate dimensions . using the ranking criterion , we can reject our null hypothesis . in order to exclude the possibility that the time series is generated from an unstable period orbit perturbed by dynamical noise",
    ", we also apply the pps  algorithm for further test . from the pps algorithm",
    "we generate @xmath106 surrogates , and then use the gka to calculate their correlation dimensions .",
    "the results are shown in panel @xmath130 of fig .",
    "[ rosslech5perobvdim5_pps ] , as we can see , the mean correlation dimension of the original time series also falls outside the distribution of the surrogate dimensions , therefore we can reject the null hypothesis again .",
    "after the two surrogate tests for pseudoperiodicity , we can claim the time series is chaotic with a confidence level up to @xmath131 ( @xmath132 ) for two - sided test .",
    "the final example to be demonstrated is a chaotic time series also from the rssler system . to generate the time series ,",
    "we keep parameter @xmath133 .",
    "similar to the way in the second example , we add gaussian white noise with the standard deviation of @xmath124 to the @xmath125 component at each integration step as the dynamical noise , and then introduce @xmath81 observational @xmath82 noise into the previously obtained data set .",
    "the global optimal embedding dimension is found to be @xmath109 .",
    "the results of surrogate tests based on the new algorithm and the pps algorithm are shown in panel @xmath134 and @xmath135 of fig .",
    "[ rosslech5perobv015ddim4_pps ] respectively , from which we can see that , surrogate tests based on both algorithms can detect the chaos in the time series .",
    "again we can claim the time series is chaotic with a confidence level up to @xmath131 for two - sided test .",
    "we have also investigated examples under different observational noise levels ( but keep the same dynamical noise if they have ) .",
    "for example , if we reduce the @xmath82 observational noise levels to @xmath136 in the above four examples , we can obtain the same results as we have reported .",
    "if we increase the observational noise levels to @xmath137 , for the pseudoperiodic time series we can still obtain the expected results , i.e. , we can not reject our null hypothesis .",
    "however , for the chaotic time series , we will falsely accept our null hypothesis due to the correlation dimension of the original time series marginally falling within the dimension distribution of the surrogates .",
    "the reason of false acceptance might be that , under large noise levels , the correlation dimension is not sensitive enough to detect the structure changes of the chaotic time series . for such cases , we will have to look for more powerful discriminating statistics @xcite .      as an example of application",
    ", we employ the surrogate test based on our algorithm to investigate whether a human electrocardiogram ( ecg ) record ( with @xmath138 data points ) is likely to be chaotic .",
    "the ecg record was obtained by measuring from a resting healthy subject ( @xmath139 years old ) in a shielded room at the sampling rate of @xmath117 khz .",
    "the ecg record indicated in panel @xmath140 of fig .",
    "[ ecgtestem5 ] looks very regular and even possibly periodic , but we need a quantitative approach to verify the periodicity . here",
    "we choose the surrogate test technique . using the false nearest neighbour criterion ,",
    "the global optimal embedding dimension is chosen at @xmath141 .",
    "the background noise is mainly from the measurement instruments , usually it is a blend of white and correlated noise . by observing the linear second order correlation function of the ecg data ,",
    "we let the temporal translation be within the interval @xmath126 $ ] ( large enough to decorrelate the noise components ) , where there exists an integer temporal translation to make the correlation function almost be zero .",
    "then by uniformly drawing values from @xmath70 \\cup \\left [ 0.6,0.8% \\right ] $ ] for coefficient @xmath20 in eq .",
    "( [ linear combination ] ) ( @xmath142 ) , we generate @xmath106 surrogates . for demonstration , we plot in panel @xmath111 one surrogate generated from eq .",
    "( [ linear combination ] ) with coefficient @xmath143 .",
    "we can see that the surrogate is different from the original ecg data in that there appear more spikes in the surrogate .",
    "however , as we can also find , the surrogate indicates the similar regularity to that in the original data , which implies that the surrogate preserves the potential periodicity in the original data as we expect ( although in a different pattern ) . with regards to the surrogate test , our calculation of the correlation dimensions is also based on the gka .",
    "the results are indicated in panel @xmath144 of fig .",
    "[ ecgtestem5 ] , from which we can see that the mean correlation dimension of the ecg data falls within the distribution of the correlation dimensions of the surrogates , therefore we can not reject our null hypothesis .",
    "hence the ecg record is possibly periodic .",
    "moreover , there is no evidence of chaos .",
    "to summarize , by imposing a few constraints on the noise process , we devise a simple but effective way to produce surrogates for pseudoperiodic orbits .",
    "the main idea of this algorithm is that a linear combination of any two segments of the same periodic orbit will generate another periodic orbit . by properly choosing the temporal translation between the two segments , under the same noise level",
    "we can obtain statistically the same correlation dimensions of the pseudoperiodic orbit and its surrogates .",
    "choosing the temporal translation is a crucial issue for our algorithm , which in principle shall guarantee the decorrelation between the noise components and preserve the noise level .",
    "another important issue is to select a proper discriminating statistic which helps determine whether to reject the null hypothesis .",
    "the correlation dimension is a suitable discriminating statistic in this case .",
    "it is possible there are other suitable discriminating statistics , we will leave the problem of finding such statistics for future study .    the surrogate test technique based on our algorithm",
    "can be utilized to distinguish between chaotic and pseudoperiodic time series .",
    "initially , the pps algorithm was proposed to generate surrogates for a pseudoperiodic orbit driven by dynamical noise , but sometimes surrogate tests based on this algorithm will falsely reject the null hypothesis if the time series is also contaminated by colored observational noise . as a complement to the pps algorithm , our algorithm deals well with observational noise , but it might fail for large dynamical noise .",
    "however , due to the convenience in computation , we suggest to adopt surrogate test based on our algorithm as the first step for pseudoperiodicity detection .",
    "if we can reject the null hypothesis of our algorithm , then we shall use the pps algorithm for further tests .",
    "if we can reject the null hypotheses of both the algorithms , then the time series under investigation is very likely to be chaotic . in this communication ,",
    "the concrete procedures of surrogate test for pseudoperiodicity are demonstrated through four simulation examples . as an application in practice",
    ", we also employ the surrogate technique based on our algorithm to investigate whether a human ecg record is possible to be chaotic .              here",
    "we would like to elucidate that , the irregularity of a time series is usually brought by stochasticity or nonlinearity ( often chaos ) , therefore in the example of nonlinearity detection , if we can exclude ( most of ) the probability that the time series is generated by a stochastic process , then it is very likely that the time series is generated from a nonlinear deterministic system .",
    "d. pierson and f. moss , phys .",
    "75 , 2124 ( 1995 ) ; x. pei and f. moss , nature ( lodon ) 379 , 618 ( 1996 ) ; p.",
    "so , e. ott , s.j .",
    "schiff , d.t .",
    "kaplan , t. sauer , and c. grebogi , phys .",
    "76 , 4705 ( 1996 ) ; p. schmelcher and f.k .",
    "diakonos , phys .",
    "78 , 4733 ( 1997 ) ; k. dolan , a. witt , m.l .",
    "spano , a. neiman , and f. moss , phys .",
    "e 59 , 5235 ( 1999 ) .",
    "we can not claim the time series is pseudoperiodic definitely , because if we can not reject a null hypothesis , there could be many interpretations other than that the data in test is consistent with our null hypothsis . for more details , see , for example , ref . @xcite ."
  ],
  "abstract_text": [
    "<S> in this communication a new algorithm is proposed to produce surrogates for pseudoperiodic time series . by imposing a few constraints on the noise components of pseudoperiodic data sets </S>",
    "<S> , we devise an effective method to generate surrogates . </S>",
    "<S> unlike other algorithms , this method properly copes with pseudoperiodic orbits contaminated with linear colored observational noise . </S>",
    "<S> we will demonstrate the ability of this algorithm to distinguish chaotic orbits from pseudoperiodic orbits through simulation data sets from the rssler system . </S>",
    "<S> as an example of application of this algorithm , we will also employ it to investigate a human electrocardiogram ( ecg ) record . </S>"
  ]
}