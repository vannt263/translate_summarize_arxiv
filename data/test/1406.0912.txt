{
  "article_text": [
    "in recent years , the amount of connected devices that are carried by mobile users has increased drastically and will become one of the dominant drivers for future mobile networking , as described by cisco , inc .",
    "a secondary forecasted trend is the continuously large fraction of mobile data that is required due to multimedia consumption while users are `` on  the  go . ''",
    "while currently , smartphones and tablet computers are the dominant form of media consumption and display , the prospect of reality  augmenting wearable devices will likely account for a significant portion of the interaction with mobile multimedia content in future immersive communications systems  @xcite .",
    "augmented reality has been an area of research in ubiquitous computing for some time  @xcite and is subject to ongoing research efforts  @xcite .",
    "several application scenarios were evaluated in recent years in different domains , such as smartphone  based information overlay systems  @xcite , outdoor systems with multiple elements  @xcite , navigation  @xcite , or general information systems combining both  @xcite .",
    "several industry - based solutions were developed recently in parallel to augmented reality devices , which target the multimedia playback application scenario in the predominantly consumer market space .",
    "augmented reality devices that are performing in a heads - up - display ( hud ) or head  mounted display ( hmd ) manner are increasingly targeting the professional and consumer application space alike , indicating future broad adaptation .",
    "while these types of devices are available in a broad variety of implementations ( see , e.g. , @xcite for an overview of different types ) , a slow convergence of systems has begun , especially in the consumer space .",
    "examples for current commercial off - the  shelf ( cots ) devices available include the occulus rift , sony hmz - t1 personal 3d viewer , epson moverio bt-100 , or google glasses .",
    "we note that only the latter two are optical see  through devices and thus similar to the one presented in  @xcite , showcasing how these device types have undergone additional improvements and are now consumer  graded .",
    "the evaluation of these types of systems and related issues have attracted different research groups and a recent survey  @xcite highlights ongoing issues for the various system types .",
    "evaluations performed also target the user  perception of augmentation for daily life scenarios , such as in  @xcite , or how to limit the amount of additional information , as in , e.g. , @xcite .",
    "perceptual evaluations oftentimes consider the segmentation of virtualized / augmented items , such as in , e.g. , @xcite .",
    "there are several constraints that have to be considered in this particular scenario , especially from a communications point of view , when targeting the delivery of video data to these types of systems , as the replication of video content with natural features might behave significantly different from overlaid computer  generated information . in  @xcite , the authors evaluate an industrial system that consists of an opaque hmd that displays video sequences at different target bit rates ( and resulting imperfection or distortion levels ) and user select different encoder properties at the target rate ",
    "points , resulting in a combination of frame rate and compression .",
    "our evaluation is significantly different in that we provide participating users with a see  trough cots hmd at prescribed video frame rates .",
    "significant differences can be expected for the perceived video quality based on the type of the visual display  @xcite .    in this paper , we investigate the applicability of existing video quality metrics , such as the frequently used peak signal  to  noise ratio ( psnr ) , structural similarity index metric ( ssim ) , and video quality metric ( vqm ) , in the augmented reality space and correlate encoded video quality with subjectively rated perceived video quality levels . the perceptual video quality is measured using mean opinion scores ( mos ) obtained from multiple human test subjects according to  @xcite .",
    "we note that currently , no specific testing standard has been established for the determination or evaluation of audio  visual objective or perceptual qualities employing cots see  through devices or for augmented reality settings . in turn , we consider the existing standard as outlined in recommendation itu  t bt.50013 @xcite as a general guideline for the experiments we perform here . in this seminal work ,",
    "we provide a high  level overview of subjective quality ratings for longer movie segments performing an initial view at the underlying characteristics at play .",
    "the broad potential for implementation in future systems that contain augmented single view or binocular vision display modalities is manifold , as media adaptations for specific video material might benefit content and network providers while maintaining a sufficiently high level of quality of experience  @xcite . here , we focus on the evaluation of video compression quality without potentially lossy network transport when viewed in a scenario where binocular vision is augmented .    in the remainder of this contribution , we initially describe the measurement setup ( including the wearable device , the developed mobile application , and the encoded video sequence characteristics ) in greater detail .",
    "we continue with a detailed description of the obtained results in section  [ s : results ] and evaluate the participating users video quality selection performance in section  [ s : selection ] .",
    "we conclude with an outlook on future activities in section  [ s : conc ] .",
    "in this section , we initially describe the employed wearable head  mounted optical see  through display and the application we developed for the experimentation .",
    "we continue with a description of media characteristics and performed experimentation with volunteering participants .",
    "we employed the epson moverio bt100 mobile viewer , which consists of a wearable 3d  capable heads ",
    "up display unit and a central processing unit .",
    "the processing unit features both a directional pad and a touch pad and employs the android operating system version 2.2 ( `` froyo '' ) .",
    "the unit is connected via wires to deliver video signals and power to the see  through display unit , with a display control being integrated into the wired connection .",
    "we illustrate the overall system configuration in figure  [ fig : viewer ] , noting that no networking is involved for the display of the content , as it is contained on the processing unit .",
    "the display unit has a resolution of @xmath0 pixels of 24bit color with led light sources and a 23 degree field of view . without the additionally available shade ,",
    "a maximum of 70 % transparency is realized for the display .",
    "the images are projected from a display panel built into the device s sides , from which light is reflected through a lens , and in turn hits a half  mirror layer in the light guide material . as we consider an evaluation of a commercially available off - the  shelf augmented binocular vision hmd , no specific calibration was performed .",
    "factory settings were applied , which allow for 24-bit color reproduction at 60 hz and the built  in led light intensity was set to maximum for highest contrast .",
    "we developed a mobile android application that can be executed on the wearable display s control unit .",
    "the application displays a movie sequence ( video and audio content ) , followed by a likert ",
    "scale question to rate the quality of the last displayed sequence .",
    "we illustrate this approach in figure  [ fig : app ] .        initially , a random quality for a movie sequence is selected and its value stored in a text file on ",
    "device before starting the audio / video play  out from the on  device storage , disabling potential network transmission impacts . after play  out , the user is asked to select a quality level from a presented likert ",
    "scale , with each selection of a quality level captured in the same text file on  device .",
    "we do not enforce a time limit for the rating procedure , as users need to interface with the mobile application through the processing unit s touchpad . adding a time limit at this stage would increase the potential stress on participants as they make their selections , in turn potentially influencing their ratings .",
    "this process continues until all movie sequences are played out .",
    "the created text file with the randomly chosen movie qualities and user rankings of movie qualities can afterwards be copied from the device to a desktop computer for further processing .",
    "we employ the publicly available and creative commons licensed _ tears of steel _ short movie as source , which depicts an epic struggle between humans and robots in the future .",
    "the video was made by the blender foundation , merging computer  generated graphics generated by the the open ",
    "sourced blender software with real  world filmed scenes in amsterdam , the netherlands .",
    "we employ this short film as representative of today s video contents which commonly feature a combination of real  world and computer  generated source materials ( we refer the interested reader to http://tearsofsteel.org for more details about the movie ) .",
    "we employ the publicly available 720p version of the movie and segment this source into logically connected scenes for processing , as illustrated in figure  [ fig : segmentation ] .",
    "the individual video segments were resized to support the native @xmath0 resolution of the augmented binocular vision glasses and re  encoded using the popular open  source ` ffmpeg ` video tool in 24 frames per second .",
    "the encoder used was ` libx264 ` with constant rate factor ( also known as constant quantization scale factor ) settings of 1 , 30 , 35 , 40 , and 45 , resulting in a constant quality encoding with variable bitrates .",
    "we selected this approach , as the source video sequence itself was professionally encoded with high fidelity settings , and minimal encoding losses ; these are contained in our encodings as well .",
    "the output was visually inspected to ensure that the settings provided significant differences in visual quality to allow mapping to a quality scale from 15 , respectively .",
    "this represents quality level differences observable within typical streaming scenarios ; the resulting values for the psnr as an objective video quality metric comparing the source video quality to the encoded video are provided in table  [ tab : psnr ] .    [ cols=\"^,^,^,^,^,^,^,^ \" , ]",
    "we initially observe that with exceptions for segments 5 and 10 , the difference average is slightly negative , indicating that on average , participants chose higher quality levels than displayed .",
    "the comparatively large standard deviation indicates that users deviate significantly from the actual displayed values in almost every segment , with the exceptions of segments 8 and 9 .",
    "these two segments exhibits higher levels of content dynamics as the plot of the movie moves towards its climax .",
    "we note that the correlation is with few exceptions over 0.5 , indicating again that user  selected values and randomly displayed video quality levels are potentially related .",
    "we compare these findings by performing paired t ",
    "tests for the individual user selections in each segment and present results in table  [ tab : correl ] as well .",
    "the relatively small differences in average , paired with the calculated standard deviations , do not indicate that there is a statistically significant difference between the video categories presented and the ones that were participant  selected , which is corroborated by the @xmath1values obtained for the individual segments .",
    "the smallest @xmath1value determined is 0.11 , which is slightly above typical significance levels .",
    "in this section , we interpret the selection of the video quality by participants as a retrieval process and calculate the typical performance measures .",
    "we denote the user  selected quality level @xmath2 and the randomly displayed encoded video quality level @xmath3 for each segment @xmath4 as in the preceding section  [ s : results ] and provided in table  [ tab : selections ] .",
    "we note that throughout this section , we assume that the the video quality level @xmath3 is at least a ranking  wise close representation of the grounded truth . commonly , a determination of the ground truth requires extensive human subject ratings to allow for a broad judgment base . here , we assume that the ranking of video qualities as performed based on the different metrics is a reflection of the ground truth .",
    "this assumption leans itself onto prior comparisons of full reference metrics , such as @xcite for still images or @xcite for applications .",
    "we employ the common notation introduced in , e.g. , @xcite , by defining the confusion matrix in dependence of a specific video quality level @xmath5 ( where @xmath6 $ ] denotes the iverson bracket ) as follows : @xmath7 \\cdot \\left [ u(s , u ) = \\nu \\right]\\\\ \\mathrm{false positive } & & fp(\\nu ) = \\sum_{s , u } \\left [ v(s , u ) \\ne",
    "\\nu \\right ] \\cdot \\left [ u(s , u ) = \\nu \\right]\\\\ \\mathrm{false negative } & &   fn(\\nu ) = \\sum_{s , u } \\left [ v(s , u ) = \\nu \\right ] \\cdot \\left [ u(s , u ) \\ne",
    "\\nu \\right]\\\\ \\mathrm{true negative } & &   tn(\\nu ) = \\sum_{s , u } \\left [ v(s , u ) \\ne",
    "\\nu \\right ] \\cdot \\left [ u(s , u ) \\ne \\nu \\right]\\end{aligned}\\ ] ] omitting the relationship to @xmath5 for clarity , the common performance metrics are defined as : @xmath8 we employ these values to determine the performance of the participant selection of a displayed video quality as result of the human quality perception in relationship to the encoded video quality levels for the individual segments .",
    "we initially note an overall average accuracy in video quality selection of @xmath9 % ( or error rate of 25.4 % ) , indicating that for the majority of segments , participants were able to discern the video quality without training correctly into one of the five quality levels .",
    "the precision and recall values observed are @xmath10 % and @xmath11 % , respectively , resulting in an f - score of @xmath12 .",
    "this indicates that overall , users were only exhibiting low  medium ability to correctly identify the video quality level .",
    "the error rate can be explained by the nature of the see  through display , which might allow certain types of video quality impairments to go unnoticed .",
    "the dependency of the different values becomes more apparent when evaluating the user performance in dependency of the underlying video quality , as illustrated in figure  [ fig : all ] .",
    "-score depending on the video quality level @xmath3 .",
    "medium video quality level ranges result in lower participant selection performance . ]",
    "we observe that the accuracy and @xmath13 scores both start on a high level , decrease with higher quality levels , followed by an additional increase .",
    "only the @xmath13 score exhibits a slight decrease for the highest quality .",
    "the accuracy is the lowest for the medium quality , which can be explained with parts of sequences exhibiting higher levels of complexity , which result in higher levels of compression artifacts even in medium quality settings . as a result",
    ", participants are rating the displayed quality lower than it actually is ; opposite considerations apply for a better quality rating . at the extreme ends , there are either significant quality impairments throughout a segment or only very few , which likely makes it relatively easy to discern these endpoints and , thus , results in higher accuracy .",
    "we now shift the view to evaluate the impact of the content present in the different segments on the accuracy and @xmath13 score of the participants selection of the video quality when compared to the actual ones , illustrated in figure  [ fig : segments ] .",
    "we observe an average accuracy that overall remains around or above 70 % .",
    "we note an initial rise , followed by a drop to the middle of the complete movie , followed by an increase and a final decrease .",
    "this behavior is followed closely by the @xmath13 score as well , but with larger differences in the rising and falling trends .",
    "segment 9 exhibits the highest values for both , with an accuracy above 85 % and an @xmath13 score just above 60 % . as a segment with several highly dynamic action ",
    "scenes , the imperfections become more obvious , e.g. , pixelations or blockiness in explosions . however , the rise to this point also coincides with the tension of the actual movie ( that climaxes in segments 9 and 10 ) , which might be an additionally contributing factor .",
    "overall , these results indicate that content variation has an impact on accuracy and precision / recall and needs to be considered as in regular display facilities for video encodings .",
    "the mobile consumption of movie content in augmented reality settings gives rise to the question of how mobile users perceive the display of multimedia content on their devices ; here , we presented the the first study addressing this research domain for wearable binocular vision see  through displays using a commercial off - the  shelf consumer device .",
    "for the publicly available _ tears of steel _ short movie , segmented into multiple shorter sequences , we find that users tend to slightly overestimate the video quality , with no statistically significant difference of means ( but approaching it for individual segments ) .",
    "the participant  selected high quality levels tend to correlate with the content of the segments , with higher levels of content dynamics exhibiting larger positive ratings compared to the presented video quality level . though overall",
    ", we notice a medium  high accuracy level around 75 % , the precision and recall values are significantly lower , corroborating the general results .",
    "we reason that a significant portion of the positive viewer bias stems from the nature of the optical see - through device , which likely obscures smaller visual imperfections when compared to a traditional display method .",
    "this is substantiated by participant selections exhibiting higher levels of accuracy , precision , and recall for high and low video quality levels throughout , but lower values in the medium range , where some obfuscation might lead to higher quality ratings .",
    "future multimedia delivery systems targeting this form of media display can take these findings into account to optimize content modification and delivery mechanisms . a necessary refinement required for future evaluations of content characteristics , compression , delivery , and adaptation methods",
    "is the determination of a detailed testing protocol that allows researchers to perform comparable evaluations . with a consensus on such a protocol , future investigations in this domain",
    "will become enabled to target fine  grained parameters commonly employed in today s traditional display settings .",
    "future research avenues can evaluate more interplays of audio quality or `` background '' real  world settings and their influence on the perceived quality .",
    "we thank joshua whaley for his development efforts of the mobile application . sponsored in part by an early career grant from the office of research and sponsored programs at central michigan university .",
    "10 url # 1`#1`urlprefixhref # 1#2#2 # 1#1    , http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white_paper_c11-520862.pdf[cisco visual networking index : global mobile data traffic forecast update , 20132018 ] , tech . rep .",
    "j.  g. apostolopoulos , p.  a. chou , b.  culbertson , t.  kalker , m.  d. trott , s.  wee , http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6153337[the road to immersive communication ] , proceedings of the ieee 100  ( 4 ) ( 2012 ) 974990 .",
    "http://dx.doi.org/10.1109/jproc.2011.2182069 [ ] .",
    "s.  mann , http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.5056[mediated reality ] , tech . rep .",
    "tr 260 , m.i.t .",
    "media lab perceptual computing section , cambridge , massachusetts , usa ( 1994 ) .",
    "f.  zhou , h.  duh , m.  billinghurst , http://dl.acm.org/citation.cfm?id=1605333[*trends in augmented reality tracking , interaction and display : a review of ten years of ismar * ] , in : proc . of ieee and",
    "acm international symposium on mixed and augmented reality ( ismar ) , cambridge , uk , 2008 , pp .",
    "g.  takacs , v.  chandrasekhar , n.  gelfand , http://dl.acm.org/citation.cfm?id=1460165[*outdoors augmented reality on mobile phone using loxel - based visual feature organization * ] , in : proc . of the acm conference on multimedia information retrieval ( mir ) , vancouver , british columbia , ca , 2008 , pp .",
    "j.  wither , y .- t .",
    "tsai , r.  azuma , http://linkinghub.elsevier.com/retrieve/pii/s0097849311001130[indirect augmented reality ] , computers graphics 35  ( 4 ) ( 2011 ) 810822 . http://dx.doi.org/10.1016/j.cag.2011.04.010 [ ] . http://linkinghub.elsevier.com/retrieve/pii/s0097849311001130    t.  gleue , p.  dhne , http://dl.acm.org/citation.cfm?id=585018[design and implementation of a mobile device for outdoor augmented reality in the archeoguide project ] , in : proc . of the acm conference on virtual reality , archeologym and cultural heritage ( vast ) , 2001 .",
    "m.  ribo , p.  lang , h.  ganster , m.  brandner , http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1046629[*hybrid tracking for outdoor augmented reality applications * ] , ieee computer graphics and applications 22  ( 6 ) ( 2002 ) 5463 .",
    "r.  castle , g.  klein , d.  w. murray , http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4911577[video-rate localization in multiple maps for wearable augmented reality ] , in : proc . of the ieee international symposium on wearable computers , ieee , pittsburgh ,",
    "pa , usa , 2008 , pp . 1522 . http://dx.doi.org/10.1109/iswc.2008.4911577 [ ] .",
    "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4911577    c.  sulisz , p.  seeling , http://doi.acm.org/10.1145/2406367.2406439[*an off - the - shelf wearable hud system for support in indoor environments * ] , in : proc .",
    "of the international conference on mobile and ubiquitous multimedia mum , acm press , ulm , germany , 2012 , pp .",
    "http://dx.doi.org/10.1145/2406367.2406439 [ ] .",
    "d.  van  krevelen , r.  poelman , a survey of augmented reality technologies , applications and limitations , the international journal of virtual reality 9  ( 2 ) ( 2010 ) 120 .",
    "m.  kanbara , t.  okuma , h.  takemura , http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=840506[*a stereoscopic video see - through augmented reality system based on real - time vision - based registration * ] , in : proc . of the ieee virtual reality ,",
    "new brunswick , nj , usa , 2000 , pp .",
    "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=840506    e.  kruijff , j.  e. swan  ii , s.  feiner , http://www.cse.msstate.edu/~swan/publications/papers/2010_kruijff-etal_perceptual-issues_ismar.pdf[*perceptual issues in augmented reality revisited * ] , in : proc . of ieee and",
    "acm international symposium on mixed and augmented reality ( ismar ) , seoul , korea , 2010 , pp .",
    "l.  bonanni , c.  h. lee , t.  selker , http://dl.acm.org/citation.cfm?id=1056883[*attention-based design of augmented reality interfaces * ] , in : proc . of the acm human factors in computing systems conference chi , portland , or , usa , 2005 , pp .",
    "d.  kalkofen , e.  mendez , d.  schmalstieg , http://dl.acm.org/citation.cfm?id=1514357[*interactive focus and context visualization for augmented reality * ] , in : proc . of ieee and",
    "acm international symposium on mixed and augmented reality ( ismar ) , nara , japan , 2007 , pp .",
    "s.  r.  r. sanches , d.  m. tokunaga , v.  f. silva , r.  tori , http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6297559[subjective video quality assessment in segmentation for augmented reality applications ] , in : proc . of the symposium on virtual and augmented reality ( svr ) , ieee , rio de janeiro , brazil , 2012 , pp .",
    "http://dx.doi.org/10.1109/svr.2012.2 [ ] .",
    "d.  perritaz , c.  salzmann , d.  gillet , http://portal.acm.org/citation.cfm?doid=1378063.1378171[*user perception model for wearable supervision systems * ] , in : proc . of the international conference on mobile technology , applications and systems mobility ,  acm ,",
    "singapore , singapore , 2007 , pp .",
    "http://dx.doi.org/10.1145/1378063.1378171 [ ] .",
    "j.  nam , y.  m. ro , y.  huh , m.  kim , http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430719[visual content adaptation according to user perception characteristics ] , ieee transactions on multimedia 7  ( 3 ) ( 2005 ) 435445 .",
    "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430719      american national standards institute ( ansi ) , american national standard for telecommunications - digital transport of one - way video signals - parameters for objective performance assessment ( ansi t1.801.03 - 2003 ) , 2003 .",
    "s.  tasaka , j.  sako , y.  ito , mmc02 - 1 : enhancement of user - level qos in audio - video ip transmission by utilizing the mutually compensatory property , in : proc .",
    "of ieee global telecommunications conference ( globecom ) , san francisco , ca , usa , nov .",
    "2006 , pp . 16 .",
    "v.  aggarwal , e.  halepovic , j.  pang , s.  venkataraman , h.  yan , prometheus : toward quality - of - experience estimation for mobile apps from passive network measurements , in : proc . of acm workshop on mobile computing systems and applications ( hotmobile ) , santa barbara , ca , usa , feb",
    ". 2014 18:118:6 .",
    "m.  sokolova , g.  lapalme , http://linkinghub.elsevier.com/retrieve/pii/s0306457309000259[a systematic analysis of performance measures for classification tasks ] , information processing & management 45  ( 4 ) ( 2009 ) 427437 .",
    "http://dx.doi.org/10.1016/j.ipm.2009.03.002 [ ] ."
  ],
  "abstract_text": [
    "<S> with the continuous growth in the consumer markets of mobile smartphones and increasingly in augmented binocular vision wearable devices , several avenues of research investigate the relationships between the quality perceived by mobile users and the delivery mechanisms at play to support a high quality of experience for mobile users . in this paper , we present the first study that evaluates the relationships of mobile movie quality and the viewer  perceived quality thereof in an augmented binocular vision setting employing commercially available head  mounted see  through devices . </S>",
    "<S> we find that participants tend to overestimate the video quality when compared to a scaled representation and exhibit a significant variation of accuracy that leans onto the movie content and its dynamics . </S>",
    "<S> our findings , thus , can broadly impact future media adaptation and delivery mechanisms for this new display format of mobile multimedia and spur follow  </S>",
    "<S> up research in this increasingly popular domain .    augmented reality , multimedia systems , perceptual quality , quality of experience , quality of service </S>"
  ]
}