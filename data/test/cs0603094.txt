{
  "article_text": [
    "since the seminal work of telatar ( @xcite ) , it is widely recognized that the use of multiple antennas at both the transmitter and the receiver has the potential to increase the capacity of digital communication systems .",
    "however , to take benefit of the potential of mimo systems , it is necessary to adapt the transmitter to the channel in some optimal way . in the context of the so - called block - fading channel ,",
    "the channel matrix is generally modelled as a random complex gaussian matrix , and one of the most popular figure of merit is the ergodic capacity defined as the maximum over the input covariance matrices of the average mutual information .",
    "it is in general reasonnable to assume that the mean and the covariance of the channel are available at the transmitter side .",
    "therefore , the average mutual information can , in principle , be evaluated and optimized w.r.t .",
    "the input covariance matrix at the transmitter side . +",
    "this optimization problem has been addressed extensively in the case of certain rayleigh channels . in the context of the so - called kronecker model",
    ", it has been shown by various authors ( see e.g. @xcite for a review ) that the eigenvectors of the optimal input covariance matrix coincide with the eigenvectors of the transmit correlation matrix .",
    "it is therefore sufficient to evaluate the eigenvalues of the optimal matrix , a problem which can be solved by using standard optimization algorithms .",
    "note that @xcite extended this result to more general ( non kronecker ) rayleigh channels .",
    "rician channels have been comparatively less studied from this point of view .",
    "we mention the work @xcite devoted to the case of uncorrelated rician channels .",
    "@xcite proved that the eigenvectors of the optimal input covariance matrix are the right - singular vectors of the line of sight component of the channel .",
    "as in the rayleigh case , its eigenvalues can be evaluated by standard routines .",
    "the case of correlated rician channels is undoubtly more complicated because the eigenvectors of the optimum matrix have no closed form expressions .",
    "therefore , both its eigenvalues and its eigenvectors have to be evaluated numerically . for this",
    ", it is necessary to use numerical methods : see in particular @xcite where a barrier interior - point method has been implemented .",
    "the corresponding algorithms are however not very attractive because the exact expression of the average mutual information is quite complicated ( @xcite ) .",
    "therefore , its gradient and its hessian have rather to be evaluated using computationally intensive monte - carlo simulation methods .",
    "+ in this paper , we address the optimization of the input covariance of bi - correlated rician channels . as the exact expression of the average mutual information is quite complicated",
    ", we propose to evaluate its limit when the number of transmit and receive antennas converge to @xmath0 at the same rate , and to address the optimization of its asymptotic approximation , hopefully a simpler problem .",
    "the asymptotic expression of the mutual information has been obtained by various authors in the case of mimo rayleigh channels , and has been shown to be quite reliable even for a quite moderate number of antennas : see e.g. @xcite , @xcite in which large random matrix results have been used , @xcite which uses the non rigorous , but useful , replica method . in our knowledge ,",
    "the asymptotic analysis of rician channels has been considered in @xcite ( using a result of girko @xcite valid in the context of restrictive assumptions ) and @xcite ( using the replica method ) in the uncorrelated case and in @xcite in the case of receive correlated ricean channels . in this paper",
    ", we use the recent results of @xcite in which a closed form asymptotic approximation of the mutual information is provided , and state without proof new results concerning its accuracy .",
    "then , we address the optimization of the large system approximation w.r.t . the input covariance matrix . as the average mutual information ,",
    "the corresponding function is strictly concave .",
    "we propose a simple iterative maximization algorithm , which , in some sense , can be seen as a generalization to the rician case of proposal of @xcite devoted to the rayleigh context : each iteration needs to solve a system of 2 non linear equations as well as a standard waterfilling problem .",
    "in contrast with @xcite , we give some convergence results : we prove that , if convergent , then the algorithm converges toward the optimum input covariance matrix .",
    "finally , simulation results confirm the relevance of our approach .",
    "+ this paper is organized as follows .",
    "section [ sec : model ] is devoted to the presentation of the model and of the underlying assumptions . section [ sec : asymptotic ] presents our asymptotic approximation of the average mutual information .",
    "section [ sec : maximization ] is devoted to the maximization of our mutual information approximation .",
    "finally , simulation results are provided in section [ sec : simulation ] .",
    "we consider a block fading mimo static channel and denote by @xmath1 and @xmath2 the number of transmit and receive antennas respectively .",
    "the @xmath3 channel matrix , denoted @xmath4 , is supposed to be given by @xmath5 .",
    "@xmath6 is a zero mean @xmath3 complex gaussian random matrix ( sometimes called complex circular gaussian random matrix ) given by @xmath7 where @xmath8 and @xmath9 are the receive and transmit correlation matrices , and where @xmath10 is a zero mean independent identically distributed complex gaussian matrix in the sense that the real and imaginary parts of the entries of @xmath10 are independent , and have the same variance @xmath11 .",
    "@xmath12 represents a deterministic @xmath3 matrix .",
    "very often , @xmath12 is assumed to be a rank one matrix ( see e.g. @xcite , @xcite ) .",
    "however , in important contexts , this hypothesis is not valid .",
    "macro diversity downlink transmissions are typical examples in which @xmath12 is likely to be full rank . in this context ,",
    "transmit antennas are very far from each other , while the distance between the receive antennas are of the order of the wavelength of the transmitted signals .",
    "in such a context , the line of sight components between each transmit antenna and the receive antenna arrays are different , so that @xmath12 is likely to be full rank . if the receive antennas array is linear and uniform , a typical example for @xmath12 is @xmath13 { { \\boldsymbol}\\lambda}\\ ] ] where @xmath14 and @xmath15 is a diagonal matrix , the entries of which represent the complex amplitudes of the @xmath1 line of sight components .",
    "@xmath16 is the so - called rice factor of the channel . in the following",
    ", we therefore do not formulate any assumption on the rank of @xmath12 .",
    "finally , matrices @xmath17 are normalized in such a way that @xmath18 where @xmath16 is the rice factor of the channel .",
    "in the following , we denote by @xmath19 the cone of non negative hermitian @xmath20 matrices , and by @xmath21 the subset of all matrices @xmath22 of @xmath19 for which @xmath23 .",
    "let @xmath24 be an element of @xmath21 .",
    "let @xmath25 be a fixed noise level .",
    "then , we denote by @xmath26 the average mutual information at the noise level @xmath25 given by @xmath27\\ ] ] as it is well known , the ergodic capacity @xmath28 of the channel is defined as @xmath29 the optimal input covariance matrix thus coincides with the argument of the above maximization problem .",
    "note that function @xmath30 is strictly concave while the set @xmath21 on which it is defined is convex .",
    "therefore ( @xcite ) , the maximum of @xmath31 on @xmath21 is reached in a unique point .",
    "if @xmath32 and @xmath33 , it is shown in @xcite that the eigenvectors of the optimal input covariance matrix coincides with the right - singular vectors of @xmath12 . apart this simple case , it seems difficult to characterize in closed form the eigenvectors of the optimal matrix .",
    "therefore , its evaluation requires to use numerical technics ( see @xcite ) .",
    "this approach is complicated by the fact that the expression of function @xmath34 is quite complicated ( @xcite ) .",
    "therefore , its gradient and hessian have to be evaluated using monte carlo simulations . in the asymptotic regime @xmath35 , @xmath36 in such a way that @xmath37 where @xmath38 , @xmath26 turns out to be equivalent to a much simpler term .",
    "the purpose of this section is to review the corresponding asymptotic results . in order to simplify the notations ,",
    "the symbol @xmath36 should be understood from now on as @xmath1 and @xmath2 converge to @xmath0 in such a way @xmath39 .",
    "@xmath26 coincides with the average mutual information of the virtual channel @xmath40 where matrix @xmath41 is the constant @xmath20 unitary matrix @xmath42 as @xmath43 has the same statistical properties than @xmath10 , it appears that @xmath44 can be interpreted as a bi - correlated gaussian rician channel with mean @xmath45 and receive and transmit correlation matrices @xmath8 and @xmath46 respectively . in the following ,",
    "we denote by @xmath47 the matrix @xmath48 . in order to derive an asymptotic approximation of @xmath26 ,",
    "it is therefore possible to use the results of @xcite .",
    "we note that the results of @xcite are obtained if matrices @xmath8 and @xmath46 are diagonal .",
    "the unitary invariance of the mutual information of gaussian random matrices allows however to use these results .",
    "we first state the following result , which derives partly from @xcite .",
    "[ theo : canonique ] assume that @xmath49 , @xmath50 , @xmath51 , and @xmath52 where @xmath53 stands for the spectral norm .",
    "consider the system of equations @xmath54 where @xmath55 is given by @xmath56\\ ] ] and @xmath57 by @xmath58\\ ] ] then , equations ( [ eq : canonique ] ) have unique strictly positive solutions @xmath59 .",
    "moreover , when @xmath36 , @xmath60 where the asymptotic approximant @xmath61 is defined by @xmath62   \\\\",
    "+   \\log \\mbox{det } \\left[{\\bf i } + \\tilde{\\delta}({\\tilde{{\\bf q } } } ) { \\bf r } \\right ] - \\sigma^{2 } n \\delta({\\tilde{{\\bf q } } } ) \\tilde{\\delta}({\\tilde{{\\bf q } } } ) \\end{array}\\ ] ] where @xmath63 represents the @xmath20 positive definite is positive definite because @xmath64 matrix defined by @xmath65^{1/2}\\ ] ]    the proof of this result is far from being obvious , and is of course omitted .",
    "it is partly based on the results of @xcite , from which one can deduce that @xmath66 . the fact that @xmath67 is not obvious at all , and follows specifically from the fact that matrix @xmath4 has a gaussian complex distribution . in particular , in the gaussian real case ,",
    "@xmath68 . this in accordance with @xcite in which a similar result is proved in the simpler context @xmath69 and @xmath70 , and with the predictions of the replica method in @xcite in the case @xmath69 and @xcite in the case @xmath32 , @xmath33 and @xmath70 .",
    "this very fast convergence rate tends to explain why the asymptotic evaluations of the mean mutual information are reliable even for a quite moderate number of antennas , as remarked e.g. in @xcite .",
    "see section [ sec : simulation ] for simulation evidence .",
    "+ we end this section by a very useful remark .",
    "consider the function @xmath71 defined by replacing in ( [ eq : exprecbarre ] ) solutions @xmath59 of ( [ eq : canonique ] ) by fixed parameters @xmath72 : @xmath73   \\\\",
    "+   \\log \\mbox{det } \\left[{\\bf i } + \\tilde{\\kappa } { \\bf r } \\right ] - \\sigma^{2 } n \\kappa \\tilde{\\kappa } \\end{array}\\ ] ] where @xmath74 represents the @xmath20 positive definite matrix defined by @xmath75^{1/2}\\ ] ] we of course note that @xmath76 and @xmath77 .",
    "it is straightforward to check that @xmath78 as @xmath59 satisfy eq .",
    "( [ eq : canonique ] ) , we get immediately that @xmath79 this simple observation is the key point of our input covariance optimization algorithm .",
    "the results of section [ sec : asymptotic ] show that @xmath26 can be approximated with a good accuracy by @xmath61 .",
    "therefore , the optimum input covariance matrix can itself be approximated by the argument of the maximum of @xmath61 over the set @xmath21 . in this section ,",
    "we propose an attractive maximization algorithm of @xmath61 . before presenting the algorithm",
    ", we have to introduce some concepts and results .",
    "[ def : gateau ] let @xmath80 be a function defined on @xmath21 . if @xmath81 are 2 elements of @xmath21 , then @xmath82 is said to be differentiable in the gateaux sense at point @xmath24 in the direction @xmath83 if the limit @xmath84 exists . in this case , this limit is denoted @xmath85 .",
    "note that for each @xmath86 $ ] , matrix @xmath87 of course belongs to @xmath21 .",
    "therefore , + @xmath88 makes sense for @xmath89 small enough .",
    "[ prop : caracterisation ] let @xmath82 be a strictly concave function defined on @xmath21 . then , the maximum of @xmath82 on @xmath21 is reached at a unique point @xmath90 of @xmath21 .",
    "assume that for every elements @xmath81 of @xmath21 , @xmath82 is differentiable in the gateaux sense at point @xmath24 in the direction @xmath83",
    ". then , @xmath90 is the unique element of @xmath21 verifying @xmath91 for each element @xmath24 of @xmath21 .",
    "this result is a simple adaptation of known results ( see e.g. @xcite ) .",
    "the proof is therefore omitted .",
    "we now give some useful properties of function @xmath92 .",
    "[ prop : proprietesibarre ] function @xmath61 is strictly concave on @xmath21 .",
    "moreover , for every elements @xmath81 of @xmath21 , @xmath92 is differentiable in the gateaux sense at point @xmath24 in the direction @xmath83 .",
    "the fact that @xmath92 is gateaux differentiable is rather obvious .",
    "the strict concavity of @xmath92 needs some work , but is not surprising because it is an approximant of a strictly concave function .",
    "+ proposition [ prop : caracterisation ] thus implies that the maximum of @xmath92 on @xmath21 is reached at a unique point denoted @xmath93 . before presenting our maximization algorithm of @xmath92 ,",
    "we first give some insights on the structure of matrix @xmath93 . for this , we denote @xmath94 and @xmath95 by @xmath96 and @xmath97 respectively . then , we have the following result .    [ prop : waterfilling ] matrix @xmath93 is the solution of the standard water - filling problem : maximize over @xmath98 the function @xmath99\\ ] ] where @xmath100^{1/2}$ ] .    * proof . *",
    "the proof of this result is based on the following identity , to be proved below : @xmath101 for each @xmath102 , where @xmath103 represents the gateaux differential of function @xmath104 . in effect , if ( [ eq : egalite ] ) holds , then , proposition [ prop : caracterisation ] implies that @xmath105 for each @xmath102 . by proposition [ prop : caracterisation ] , @xmath90 maximizes the function @xmath104 , i.e. @xmath106 because the latter functions differ up to a constant term .",
    "it remains to prove ( [ eq : egalite ] ) .",
    "for this , we remark that , by ( [ eq : annulation - derivees ] ) , @xmath107 on the other hand , for each @xmath81 , @xmath108 where @xmath109 and @xmath110 represent the gateaux differentials of functions @xmath111 and @xmath112 .",
    "( [ eq : crucial ] ) thus implies ( [ eq : egalite ] ) .",
    "+ @xmath96 and @xmath113 depend on matrix @xmath93 .",
    "therefore , proposition [ prop : waterfilling ] does not provide by itself any optimization algorithm .",
    "however , it gives insights on the structure of @xmath93 .",
    "consider first the case @xmath32 and @xmath33 .",
    "then , @xmath114 is a linear combination of @xmath115 and matrix @xmath116 .",
    "the eigenvectors of @xmath93 thus coincide with the right singular vectors of matrix @xmath12 , a result consistent with the work @xcite devoted to the maximization of the average mutual information @xmath117 . if @xmath32 and @xmath118 , @xmath114 can be interpreted as a linear combination of matrices @xmath9 and @xmath116 .",
    "therefore , if the transmit antennas are correlated , the eigenvectors of the optimum matrix @xmath93 coincide with the eigenvectors of some weighted sum of @xmath9 and @xmath116 .",
    "this result provides a simple explanation of the impact of correlated transmit antennas on the structure of the capacity - achieving input covariance matrix .",
    "the effect of correlated receive antennas on @xmath93 is however less intuitive because matrix @xmath116 has to be replaced by @xmath119 .",
    "+ we are now in position to introduce our maximization algorithm of @xmath92 .",
    "it is mainly motivated by the simple observation that for each fixed @xmath72 , the maximization w.r.t .",
    "@xmath24 of function @xmath71 defined by ( [ eq : exprev ] ) can be achieved by a standard waterfilling procedure , which , of course , does not need the use of numerical technics . on the other hand , for @xmath24",
    "fixed , the equations ( [ eq : canonique ] ) have unique solutions that , in practice , can be obtained using a standard fixed - point algorithm .",
    "our algorithm thus consists in adapting parameters @xmath24 and @xmath120 separately by the following iterative scheme :    * initialization : @xmath121 , @xmath122 are defined as the unique solutions of system ( [ eq : canonique ] ) in which @xmath123 .",
    "then , define @xmath124 are the maximum of function @xmath125 on @xmath21 . * iteration @xmath126 : assume @xmath127 , @xmath128 available .",
    "then , @xmath129 is defined as the unique solution of ( [ eq : canonique ] ) in which @xmath130 .",
    "then , define @xmath131 are the maximum of function @xmath132 on @xmath21 .",
    "we now study the convergence properties of this algorithm , and state a result , which implies that if the algorithm converges , then it converges to the global maximum of @xmath133 .",
    "[ eq : convergence ] assume that the 2 sequences @xmath134 and @xmath135 verify @xmath136 then , the sequence @xmath137 converges toward the maximum @xmath90 of @xmath92 on @xmath21 .",
    "due to the lack of space , the proof is omitted .",
    "proposition [ eq : convergence ] implies that if the sequence @xmath138 is convergent , then , its limit coincides with the optimum matrix @xmath90 .",
    "in fact , if @xmath138 converges , then the 2 sequences @xmath139 also converge .",
    "this of course implies condition ( [ eq : condition ] ) , and the convergence of @xmath138 toward @xmath90 .",
    "unfortunately , we have not been able to prove the convergence of @xmath138 by itself . however , all the numerical experiments we have conducted tend to indicate that the algorithm is convergent . in any case ,",
    "condition ( [ eq : condition ] ) is very easy to verify during the algorithm execution . in case of non convergence ,",
    "other numerical technics could be used in order to optimize @xmath61 , a simpler task than the optimization of @xmath26 .",
    "in this section , we compare our algorithm with the method presented in @xcite based on the maximization of @xmath26 .",
    "we recall that vu - paulraj s algorithm is based on a newton method and a barrier interior point method .",
    "moreover , the average mutual informations and their first and second derivatives are evaluated by monte - carlo simulations . in fig .",
    "[ fig : canal - paulraj ] , we have evaluated @xmath140 versus the snr for @xmath141 .",
    "matrix @xmath142 coincides with the example considered in @xcite .",
    "the solid line corresponds to the results provided by the vu - paulraj s algorithm ; the number of trials used to evaluate the mutual informations and its first and second derivatives is equal to @xmath143 , and the maximum number of iterations is fixed to 10 .",
    "the dashed line corresponds to the results provided by our algorithm : each point represent @xmath144 at the corresponding snr , where @xmath90 is the `` optimal '' matrix provided by our approach ; the average mutual information at point @xmath90 is evaluted by monte - carlo simulation ( 30.000 trials are used ) . the number of iterations is also limited to 10 .",
    "figure [ fig : canal - paulraj ] shows that our asymptotic approach provides the same results than the vu - paulraj s algorithm . however , our algorithm is computationally much more efficient as the above table shows .",
    "the table gives the average executation time ( in sec . ) of one iteration for both algorithms for @xmath145 .",
    "[ fig : canal - aleatoire ] , we again compare vu - paulraj s algorithm and our proposal .",
    "matrix @xmath12 is generated according to ( [ eq : exemplea ] ) , the angles being chosen at random .",
    "the transmit and receive antennas correlations are exponential with parameter @xmath146 and @xmath147 respectively . in the experiments , @xmath141 , while various values of @xmath148 , @xmath149 and of the rice factor @xmath150 have been considered . as in the previous experiment ,",
    "the maximum number of iterations for both algorithms is 10 , while the number of trials generated to evaluate the average mutual informations and their derivatives is equal to 30.000 .",
    "our approach again provides the same results than vu - paulraj s algorithm , except for low snrs for @xmath151 where our method gives better results : at these points , the vu - paulraj s algorithm seems not to have converge at the 10th iteration .",
    "[ table ]    [ cols=\"^,^,^,^\",options=\"header \" , ]",
    "in this paper we proposed a new approach to characterize the capacity achieving covariance matrix of bi - correlated rician mimo channels .",
    "we proposed to approximate the average mutual information by its large system limit and derived an attractive iterative optimization algorithm which does not need the use of intricate numerical techniques .",
    "we have shown that the algorithm ( when it is convergent ) converges to the maximum of the approximate mutual information .",
    "numerical simulation results show that the new approach provides the same results than direct maximization approaches of the mutual information , while being much more computationally attractive ."
  ],
  "abstract_text": [
    "<S> we determine the capacity - achieving input covariance matrices for coherent block - fading correlated mimo rician channels . </S>",
    "<S> in contrast with the rayleigh and uncorrelated rician cases , no closed - form expressions for the eigenvectors of the optimum input covariance matrix are available . </S>",
    "<S> both the eigenvectors and eigenvalues have to be evaluated by using numerical techniques . </S>",
    "<S> as the corresponding optimization algorithms are not very attractive , we evaluate the limit of the average mutual information when the number of transmit and receive antennas converge to @xmath0 at the same rate . </S>",
    "<S> we propose an attractive optimization algorithm of the large system approximant , and establish some convergence results . </S>",
    "<S> numerical simulation results show that , even for a quite moderate number of transmit and receive antennas , the new approach provides the same results than direct maximization approaches of the average mutual information , while being much more computationally attractive . </S>"
  ]
}