{
  "article_text": [
    "graph modification problems lie in the intersection of algorithmics , graph theory , and network analysis .",
    "formally , a graph modification problem is given as follows .",
    "herein , graph modification operations include edge deletions , insertions , and contractions , and vertex deletions .",
    "classic examples for  @xmath1 are `` being edgeless '' ( this is known as vertex cover when the allowed modification operation is vertex deletion ) and `` being a disjoint union of cliques '' ( this is known as cluster editing when the allowed modification operations are edge deletion and insertion ) .",
    "we will deal with simple and natural graph modification problems that are motivated by real - world applications . in these applications ,",
    "the common way of solving these problems is via heuristics .",
    "we present four main themes on how the interaction between parameterized algorithmics and heuristics can take place , each time illustrated by some `` key '' graph modification problems .    in section  [ sec : hcd ] , we consider a graph - based clustering problem that has been defined only implicitly by means of a greedy heuristic  @xcite .",
    "we describe how a natural np - hard parameterized problem ( referred to as highly connected deletion ) can be derived from this , and how this leads to further insight into the corresponding clustering approach  @xcite .    in section  [ sec : deganon ] , starting with a practically successful heuristic for anonymizing social networks  @xcite ( the corresponding np - hard problem is known as  degree anonymity ) , we describe how a closer inspection yields that either the corresponding approach provides optimal solutions in polynomial time or one can derive a polynomial - size problem kernel with respect to the parameter maximum vertex degree of the underlying graph  @xcite .",
    "moreover , we briefly indicate how this led  in a feedback loop , so to speak  to improvements also for the heuristic approach  @xcite .    in section  [ sec :",
    "fast ] , we study parameterized local search  the parameter is the degree of locality  @xcite .",
    "local search is a key technique in combinatorial optimization and the design of `` improvement heuristics '' .",
    "we address both limitations and prospects of this approach .",
    "we discuss , among others , the np - hard example problems vertex cover and feedback arc set in tournaments .    in section  [ sec : pbo ]",
    ", we finally discuss how one may speed up parameterized algorithms by a clever use of heuristics . in particular , we discuss parameterization above lower bounds derived from linear programming relaxations  @xcite ( here the key example is the np - hard vertex cover problem ) , and the idea of programming by optimization  @xcite ( here the key example is the np - hard cluster editing problem ) .",
    "we draw some final conclusions in section  [ sec : concl ] .    [",
    "[ preliminaries . ] ] preliminaries .",
    "+ + + + + + + + + + + + + +    we assume familiarity with fundamental concepts of graph theory , algorithms , and complexity .",
    "a _ parameterized problem _ is a set of instances of the form @xmath2 , where @xmath3 for a finite alphabet @xmath4 , and @xmath5 is the _ parameter_. a parameterized problem  @xmath6 is _ fixed - parameter tractable _ , shortly , if there exists an algorithm that on input @xmath2 decides whether @xmath2 is a yes - instance of  @xmath6 in time @xmath7 , where @xmath8 is a computable function independent of @xmath9 . a parameterized problem @xmath6 is _ kernelizable",
    "_ if there exists a polynomial - time algorithm that maps an instance @xmath10 of @xmath6 to an instance @xmath11 of @xmath6 such that @xmath12 for some computable function @xmath13 , @xmath14 , and @xmath10 is a yes - instance of @xmath6 if and only if @xmath11 is a yes - instance of @xmath6 .",
    "the instance @xmath11 is called a _ kernel _ of @xmath2 .    a problem that is w[1]-hard does not admit a fixed - parameter algorithm , unless the widely believed conjecture fpt@xmath15w[1 ] fails .",
    "in the following , we illustrate how the consideration of heuristic algorithms may lead to the definition of new interesting graph modification problems . our example concerns",
    "the interplay between two standard approaches for graph - based data clustering .",
    "one approach is to formalize desired properties of clusters and then to find a clustering of the graph such that the output clusters fulfill these properties .",
    "this clustering can be obtained by modifying the input graph for example by deleting edges so that all remaining edges are only inside clusters . starting with cluster editing  @xcite , there are by now numerous parameterized algorithmics studies on graph modification problems related to clustering , varying on the cluster graph definition  @xcite , the modification operation  @xcite , or both  @xcite .",
    "most of the examples of variants of cluster editing evolved primarily from a graph - theoretic interest .",
    "another approach is to define the clustering algorithmically , that is , to describe an algorithm that outputs a clustering and to analyze the properties of the clusters that are produced by the algorithm . in this section ,",
    "we discuss how the consideration of a popular and natural clustering algorithm due to  @xcite leads to the definition of the graph modification problem highly connected deletion .",
    "this is our key example for how to obtain practically motivated parameterized graph modification problems by a closer inspection of known heuristics .",
    "the study of this new problem then may yield new challenges for parameterized algorithmics and , furthermore , provide a better understanding of the strengths and weaknesses of the original heuristic algorithms .",
    "we will first discuss the original algorithm and then how we obtain the definition of highly connected deletion from this algorithm . posed the following connectivity demands on each cluster : the _ edge connectivity _",
    "@xmath16 of a graph  @xmath0 is the minimum number of edges whose deletion results in a disconnected graph , and a graph  @xmath0 with @xmath17 vertices is called _ highly connected _ if @xmath18 .",
    "@xcite . ] the algorithm by @xcite partitions the vertex set of the given graph such that each partition set is highly connected by iteratively deleting the edges of a minimum cut in a connected component that is not yet highly connected .",
    "the output clusters of the algorithm are the connected components of the remaining graph which are then highly connected .",
    "the definition of being highly connected ensures several useful cluster properties , for example that at least half of the possible edges are present within each cluster and that each cluster has diameter at most two  @xcite .",
    "while hartuv and shamir s algorithm guarantees to output a partitioning into _ highly connected _ subgraphs , it iteratively uses a greedy step to find small edge sets to delete . as a consequence",
    ", it is not ensured that the partitioning comes along with a _",
    "minimum number of edge deletions _ making the resulting graphs consist of highly connected components .",
    "this naturally leads to the edge deletion problem highly connected deletion where the goal is to minimize the number of edge deletions ; this optimization goal is addressed only implicitly by hartuv and shamir s algorithm .",
    "= 10000    ( input ) at ( -3.75 + 0.05,+ 0.75 - 0.05 ) * input : * ; ( input.north west)+(-0.05,+0.05 ) rectangle ( 1.75,-- 0.25 ) ; = [ circle , draw = black!80,minimum size=12pt , inner sep=0pt ]    at ( 0,+ 0.7 ) @xmath19 ; = [ circle , draw , fill = black!20,minimum size=5pt , inner sep=2pt ]    iin 1, ... ,3 ( t - i ) at ( 0.7 cos(360 * i/ 3 - 3*(180 / 3))-2.5,0.7 sin(360 * i/ 3 - 3*(180 / 3 ) ) ) ; ( t-1 ) edge[- ] ( t-2 ) ; ( t-2 ) edge[- ] ( t-3 ) ; ( t-3 ) edge[- ] ( t-1 ) ;    iin 1 , ... , ( k - i ) at ( cos(360 * i/ - 3*(180 / ) ) , sin(360 * i/ - 3*(180 / ) ) ) ; iin 2 , ... , ; ( k - i ) edge[- ] ( k- ) ; i/ in 1/4,1/5,2/5,3/5 ( k - i ) edge[- ] ( k- ) ;    ( t-1 ) edge[- ] ( k-5 ) ; ( t-2 ) edge[- ] ( k-3 ) ; ( t-1 ) edge[- ] ( k-4 ) ;    ;    ( solution ) at ( -3.75 + 0.05,+ 0.75 - 0.05 ) * solution : * ; ( solution.north west)+(-0.05,+0.05 ) rectangle ( 1.75,-- 0.25 ) ;    iin 1, ... ,3 ( t - i ) at ( 0.7 cos(360 * i/ 3 - 3*(180 / 3))-2.5,0.7 sin(360 *",
    "i/ 3 - 3*(180 / 3 ) ) ) ; ( t-1 ) edge[- ] ( t-2 ) ; ( t-2 ) edge[- ] ( t-3 ) ; ( t-3 ) edge[- ] ( t-1 ) ;    iin 1 , ... , ( k - i ) at ( cos(360 * i/ - 3*(180 / ) ) , sin(360 * i/ - 3*(180 / ) ) ) ; iin 2 , ... , ; ( k - i ) edge[- ] ( k- ) ; i/ in 1/4,1/5,2/5,3/5 ( k - i ) edge[- ] ( k- ) ; ( t-1 ) edge[dashed ] ( k-5 ) ; ( t-2 ) edge[dashed ] ( k-3 ) ; ( t-1 ) edge[dashed ] ( k-4 ) ;    interestingly , in the worst case the algorithm by @xcite does not give a good approximation for the optimization version of highly connected deletion .",
    "consider two cliques with vertex sets @xmath20 and @xmath21 , respectively , and the additional edges @xmath22 for @xmath23 .",
    "then these additional edges form a solution set of size @xmath24 ; however , hartuv and shamir s algorithm will ( with unlucky choices of minimum cuts ) transform one of the two cliques into an independent set by repeatedly cutting off one vertex , thereby deleting @xmath25 edges .",
    "the following theoretical results are known for highly connected deletion  @xcite .",
    "it is np - hard even on 4-regular graphs and , provided the exponential time hypothesis ( eth )  @xcite is correct , can not be solved in subexponential time . on the positive side",
    ", there is a kernelization that can in polynomial time reduce an instance to one containing at most  @xmath26 vertices , and an fpt  algorithm that solves highly connected deletion in @xmath27 time .    as to the relevance of parameterized algorithmics for highly connected deletion , one has to note that the mentioned fpt  algorithm is impractical . in terms of exact solutions , an integer linear programming formulation combined with data reduction rules ( partially coming from the kernelization results ) , however , performs reasonably well  @xcite .",
    "even when relaxing the goal to find exact solutions for highly connected deletion , data reduction turned out to be beneficial in combination with heuristics ( improving running time and solution quality )  @xcite . in a nutshell , the most practical contribution of parameterized algorithmics in this example is the development of efficient and effective data reduction rules , also helping to improve inexact solutions based on heuristics",
    ". a further benefit of considering a formally defined edge modification problem highly connected deletion is that the objective is now independent of a heuristic method used to find it .",
    "thus , it becomes possible to evaluate the biological quality of the objective  @xcite .",
    "as to potential for future research with respect to highly connected deletion , so far other modification operations combined with the used cluster graph model are unexplored",
    ". improvements on the known kernelization for highly connected deletion may have direct practical impact .",
    "moreover , a first step to make the fpt  algorithm more practical could be to devise a faster fpt  algorithm that relies only on branching ( the current algorithm uses dynamic programming in a subroutine ) . finally , besides striving for improvements with respect to the standard parameter `` number of edge deletions ''",
    ", the investigation of other parameterizations may be interesting as well .    from a more general perspective , however , it remains to `` remodel '' further heuristic algorithms into natural parameterized problems .",
    "while in the previous section we derived a natural parameterized problem ( highly connected deletion ) from a simple and effective greedy heuristic , in this section we demonstrate that the tools of parameterized complexity analysis and , in particular , kernelization , may be beneficial in understanding and improving a known heuristic on the one side , and in providing a rigorous mathematical analysis on the other side . here , we have examples in the context of graph completion problems , our key example here being the degree anonymity problem arising in the context of anonymizing social networks .    for many scientific disciplines , including the understanding of the spread of diseases in a globalized world or power consumption habits with impacts on energy efficiency ,",
    "the availability of social network data becomes more and more important . to respect privacy issues",
    ", there is a strong demand to anonymize the associated data in a preprocessing phase  @xcite .",
    "if a graph contains only few vertices with some distinguished feature , then this might allow the identification ( and violation of privacy ) of the underlying real - world entities with that particular feature .",
    "hence , in order to ensure pretty good privacy and anonymity behavior , every vertex should share its feature with many other vertices . in a landmark paper , @xcite ( also see @xcite for an extended version ) considered the vertex degrees as feature ; see @xcite for other features considered in the literature .",
    "correspondingly , a graph is called _ @xmath28-anonymous _ if for each vertex there are at least  @xmath29 other vertices of the same degree .",
    "therein , different values of  @xmath28 reflect different privacy demands and the natural computational task arises to perform few changes to a graph in order to make it @xmath28-anonymous .",
    "= 10000    ( input ) at ( -0.5 + 0.05,2.7 - 0.05 ) * input : * ; ( input.north west)+(-0.05,+0.05 ) rectangle ( 3.5,-0.25 ) ; = [ circle , draw = black!80,minimum size=12pt , inner sep=0pt ]    at ( 2.2,2.6 )    [ cols=\"^ \" , ]     ;    = [ circle , draw , fill = black!20,minimum size=5pt , inner sep=2pt ]    ( k-1 ) at ( 0,0 ) ; ( k-2 ) at ( 0,2 ) ; ( k-3 ) at ( 1,1 ) ; ( k-4 ) at ( 2,0 ) ; ( k-5 ) at ( 2,2 ) ; ( k-6 ) at ( 3,1 ) ;    i/ in 1/4 , 2/3 , 3/4 , 3/5 , 5/6 ( k - i ) edge[- ] ( k- ) ;    ;    ( solution ) at ( -0.5 + 0.05,2.7 - 0.05 ) * solution : * ; ( solution.north west)+(-0.05,+0.05 ) rectangle ( 3.5,-0.25 ) ;    = [ circle , draw , fill = black!20,minimum size=5pt , inner sep=2pt ]    ( k-1 ) at ( 0,0 ) ; ( k-2 ) at ( 0,2 ) ; ( k-3 ) at ( 1,1 ) ; ( k-4 ) at ( 2,0 ) ; ( k-5 ) at ( 2,2 ) ; ( k-6 ) at ( 3,1 ) ;    i/ in 1/4 , 2/3 , 3/4 , 3/5 , 5/6 ( k - i ) edge[- ] ( k- ) ; ( k-4 ) edge[-,thick ] ( k-6 ) ;    the central parameterized complexity result for degree anonymity is that it has a polynomial - size problem kernel when parameterized by the maximum vertex degree  @xmath30 of the input graph  @xcite . in other words , there is a polynomial - time algorithm that transforms any input instance into an equivalent instance with @xmath31  vertices . indeed , one encounters a `` win - win '' situation when proving this result : liu and terzi s heuristic strategy  @xcite finds an optimal solution when the size  @xmath32 of a minimum solution is larger than  @xmath33 . hence , either one can solve the problem in polynomial time or the solution size is `` small '' . as a consequence , one can bound  @xmath32 in @xmath34 and , hence , a polynomial kernel for the combined parameter  @xmath35 actually is also a polynomial kernel only for  @xmath30 .",
    "while this kernelization directly implies fixed - parameter tractability for degree anonymity parameterized by  @xmath30 , there is also an fpt  algorithm running in @xmath36 time .",
    "the ideas behind the `` win - win '' situation generalize to further graph completion problems where the task is to insert edges so that the degree sequence of the resulting graph fulfills some prescribed property  @xmath1  @xcite .",
    "furthermore , an experimental evaluation of the usefulness of the theoretical results on the `` win - win '' situation delivered encouraging results even beyond the theoretical guarantees , that is , when  @xmath37  @xcite .",
    "this led to an enhancement of the heuristic due to @xcite which substantially improves on the previously known theoretical and empirical running times .",
    "as for highly connected deletion , previously known heuristic solutions could be substantially improved in terms of solution quality .    finally , we mention in passing that making a graph @xmath28-anonymous was studied from a parameterized point of view using also several other graph modification operations  @xcite .",
    "all these studies are of purely theoretical nature and there are only little positive algorithmic results ; links with heuristic algorithm design are missing .    from a general perspective , the quest arising from the findings for degree anonymity is to provide further examples where parameterized complexity analysis sheds new light on known heuristics , both theoretically and practically .",
    "a good starting point might be the heuristic of @xcite which clusters the vertices and then anonymizes each cluster . here",
    ", the question is whether such a practical link between anonymization and clustering could be complemented with theoretical results .",
    "obviously , these studies should not be limited to problems arising in anonymization but to graph modification problems from different application areas .",
    "local search is a generic algorithmic paradigm that yields good heuristics for many optimization problems .",
    "the idea is to start with any feasible solution and then search for a better one in the local neighborhood of this solution .",
    "this search is continued until a locally optimal solution is found . for graph modification problems ,",
    "a feasible solution  @xmath38 is any set of modification operations that transforms the input graph into one that satisfies the graph property  @xmath1 .",
    "the local neighborhood of  @xmath38 is usually defined as the sets of modification operations that can be obtained by adding and removing at most  @xmath32 vertices from  @xmath38 .",
    "this type of neighborhood is called  @xmath32-exchange neighborhood .    an obvious approach to obtain more powerful local search algorithms is to reduce the running time needed for searching the local neighborhood .",
    "this could enable a local search algorithm to examine larger neighborhoods and reduce the likelihood to remain in a locally optimal but globally suboptimal solution .",
    "usually , the size of the @xmath32-exchange neighborhood in an @xmath17-vertex graph is upper - bounded by  @xmath39 for some function  @xmath8 . in parameterized algorithmics ,",
    "a natural question is whether it is necessary to consider all elements of this neighborhood or whether the neighborhood can be searched faster , that is , in  @xmath40 time .    for many vertex deletion problems",
    "this is not the case  @xcite .",
    "for example , in the local search variant of vertex cover , one is given a _",
    "vertex cover _",
    "@xmath38 , that is , a vertex set  @xmath38 such that deleting  @xmath38 from a graph  @xmath0 results in an independent set . the task is to find a smaller vertex cover  @xmath41 by adding and removing at most  @xmath32 vertices from  @xmath38 .",
    "= 10000    unfortunately , unless w[1]@xmath42fpt , there is no fpt  algorithm for local search vertex cover parameterized by  @xmath32  @xcite .",
    "positive results were obtained for special cases .",
    "for example , local search vertex cover and many other local search variants of vertex deletion problems are fixed - parameter tractable on planar graphs  @xcite .",
    "these results , however , are based on the technique of locally bounded treewidth . as a consequence",
    ", the resulting algorithms might not be useful in practice .",
    "positive results were obtained for  feedback arc set in tournaments which is the problem of transforming a tournament , that is , a directed graph in which every pair of vertices is connected by exactly one of the two possible arcs , into an acyclic graph by a minimum number of arc deletions . here , the local search problem is fixed - parameter tractable .",
    "more precisely , given a set  @xmath38 of arc deletions that makes a given tournament acyclic , it can be decided in  @xmath43 time whether there is a set  @xmath41 that can be obtained from  @xmath38 by adding and removing at most  @xmath32 arcs  @xcite .",
    "this positive result seems to be rooted in the combinatorially restricted nature of tournaments and _ not _ in the fact that feedback arc set in tournaments is an arc modification problem : the local search variant of the similarly simple cluster editing problem is not fixed - parameter tractable unless w[1]@xmath42fpt  @xcite .",
    "summarizing , the natural idea of parameterized local search faces two major obstacles .",
    "the first obstacle is that , as discussed above , many local search problems are probably not fixed - parameter tractable .",
    "the second obstacle is that , so far , none of the parameterized local search algorithms for graph modification problems have been shown to be useful in practice .",
    "one encouraging result was obtained for incremental list coloring  @xcite . here",
    ", the input is a graph with a list - coloring that colors all graph vertices except one .",
    "the task is to obtain a list - coloring that also colors  @xmath44 and disagrees with the old list - coloring on at most  @xmath45 vertices .",
    "thus , the new solution is searched within the neighborhood of the old solution . this problem can be solved in  @xmath46 time where  @xmath32 is the maximum size of any color list in the input .",
    "the crucial observation is that this local search - like approach can be embedded in a coloring heuristic that outperforms the standard greedy coloring algorithm in terms of the coloring number .",
    "since incremental list coloring is w[1]-hard with respect to the parameter  @xmath45 , the key to success seems to be the consideration of the combined parameter  @xmath47 .",
    "a goal for future research should thus be to obtain similar success stories for local search variants of graph modification problems . as demonstrated by incremental list coloring ,",
    "one promising route is the consideration of combined parameters . from a more general perspective",
    ", the fpt algorithm for incremental list coloring and parameterized local search have in common that they use the power provided by allowing fpt running time  instead of polynomial running time  to improve known heuristics .",
    "this approach , which has been coined `` turbo - charging heuristics ''  @xcite , has close connections to dynamic versions of hard graph problems  @xcite .",
    "heuristics are often used to boost the performance of exact algorithms in practice .",
    "a prominent example here is the branch - and - bound concept where heuristic lower and upper bounds restrict the search space for search - tree algorithms  @xcite .",
    "better heuristic bounds give a smaller search space and thus faster exact algorithms . when analyzed in the classic complexity framework , the theoretical running time improvements due to the heuristic bounds are ( if at all ) marginal compared to the speed - ups observed in practice . here , parameterized algorithmics can be used to give some theoretical explanation for experimental observations by using the above - guarantee parameterization  @xcite . as the name suggests , the parameter is the difference between the size of an optimal solution and a given lower bound .",
    "fixed - parameter tractability with respect to the above - guarantee parameter then shows that the problem of finding a solution close to the lower bound is `` easy '' .",
    "thus , if the corresponding lower bound is close to the optimum , then the corresponding algorithm using this lower bound is fast  in practice _ and _ in theory .",
    "an example for above - lower bound parameterization is vertex cover .",
    "one lower bound on the size of a vertex cover is the value  @xmath28 of a linear programming ( lp ) relaxation .",
    "the well - known lp relaxation is as follows : @xmath48    it is known that in an optimal solution for the lp relaxation each variable has value 0 , , or 1  @xcite .",
    "= 10000    ( input ) at ( -0.5 + 0.05,2.7 - 0.05 ) * input : * ; ( input.north west)+(-0.05,+0.05 ) rectangle ( 3.5,-0.25 ) ; = [ circle , draw = black!80,minimum size=12pt , inner sep=0pt ]    at ( 1,2.6 ) @xmath19 , @xmath49 ;    = [ circle , draw , fill = black!20,minimum size=5pt , inner sep=2pt ]    / / / in 0/0.5//0 , 1/0//-0.9 , 1/1//0 , 2/0.5/1/0 , 3/0/0/-0.9 , 3/1/0/0 ( k - i ) at ( , + 0.5 ) ;    i/ in 1/2 , 1/3 , 2/3 , 3/4 , 2/4 , 4/5 , 4/6 ( k - i ) edge[- ] ( k- ) ;    ;    ( solution ) at ( -0.5 + 0.05,2.7 - 0.05 ) * solution : * ; ( solution.north west)+(-0.05,+0.05 ) rectangle ( 3.5,-0.25 ) ;    = [ circle , draw , minimum size=5pt , inner sep=2pt ]    / / in 0/0.5/black!20 , 1/0/black , 1/1/black , 2/0.5/black , 3/0/black!20 , 3/1/black!20 ( k - i ) at ( , + 0.5 ) ;    i/ in 1/2 , 1/3 , 2/3 , 3/4 , 2/4 , 4/5 , 4/6 ( k - i ) edge[- ] ( k- ) ;    @xcite presented an algorithm solving vertex cover above lp in  @xmath50 time . on a high level , this algorithm starts with the lower bound and uses , after some preprocessing , a standard search - tree algorithm .",
    "thus , a good lower bound allows not only in practice , but also in theory for an efficient algorithm solving vertex cover .",
    "moreover , the fixed - parameter tractability result now may help explaining why heuristics can successfully exploit the lower bound provided by the lp relaxation .",
    "another example for heuristic tuning of algorithms is programming by optimization  @xcite .",
    "this is a helpful and powerful tool for developing fast implementations . here",
    ", the basic idea is that the implementation leaves open several design choices for different parts of the algorithm  these are settled later when training the algorithm with real - world instances .",
    "then , for the final configuration of the implementation , let a program choose from the alternatives in such a way that the performance is optimized on a representative set of instances . here , the automated optimizer can give an answer to the following questions :    * given several alternative implementations for one subproblem ( for example different sorting algorithms or different lower bounds ) , which one should be chosen ?",
    "* should a certain data reduction rule be applied ? * what are the `` best '' values for certain `` magic '' or `` hidden '' constants ?",
    "for example , should a data reduction rule be applied in every second level of the search tree or every fourth level ?    the programming by optimization approach has led to a state - of - the - art solver for cluster editing  @xcite .",
    "this solver combines one sophisticated data reduction rule and a branch - and - bound algorithm .",
    "the solver outperforms previous algorithms which are based on integer linear programming ( ilp ) and pure branch - and - bound .",
    "thus , with the help of programming by optimization , implementations of parameterized algorithms may successfully compete with ilp - based algorithms .    on a high level ,",
    "programming by optimization can be seen as a heuristic counterpart to parameterized algorithmics : parameterized algorithmics provides theoretical bounds on the running time of algorithms and the effectiveness of data reduction rules .",
    "these bounds depend on the parameter .",
    "thus , to solve a problem for a specific type of data , one should measure different parameters and choose , based on this measurement , the most promising data reduction rules and algorithms . with programming by optimization ,",
    "this choice is made automatically , based on the performance of the algorithm on a given representative set of test instances .",
    "furthermore , the choice is not based on the values of parameters but directly on the efficiency of the corresponding algorithms on the test data .",
    "a goal for future research is to further increase the benefit obtained by combining the strengths of programming by optimization and parameterized algorithmics .",
    "this could be done , for example , by first providing several fpt algorithms for the same problem with different parameters and then using programming by optimization to find a good strategy to pick the best algorithm depending on the structure of an input instance .",
    "as karp  @xcite pointed out , one of the most pressing challenges in theoretical computer science is to contribute to a better understanding why many heuristics work so well in practice . in particular , a formal footing of the construction of heuristic algorithms",
    "is considered highly desirable .",
    "this task is also closely connected to ( hidden ) structure detection in real - world input instances .",
    "we discussed several routes to a beneficial interaction between heuristic and parameterized algorithm design    to date , a clear majority of research results in parameterized algorithmics is of purely theoretical nature . a natural way to increase",
    "the practical impact of parameterized algorithmics is to seek fruitful interactions with the field of heuristic algorithm design .",
    "we believe that particularly graph ( modification ) problems may be a forerunner in offering numerous fruitful research opportunities in this direction .",
    "so far the strongest impact achieved by parameterized algorithmics on practical computing and heuristics is due to kernelization , and polynomial - time data reduction techniques in general .",
    "notably , often data reduction rules seemingly not strong enough to provide kernelization results may still have strong practical impact .",
    "moreover , a general route for future research is to develop heuristic algorithms in parallel with performing a parameterized complexity analysis ( particularly , in terms of kernelization ) . as results for",
    "graph modification problems in this direction demonstrate , there are good prospects to win something in both worlds .    finally , in this paper we focused on np - hard graph modification problems for illustrative examples .",
    "it goes without saying that our general remarks and observations are not limited to graph modification problems only but clearly extend to further graph problems and fields beyond , e.g.  string algorithms  @xcite or computational social choice  @xcite ."
  ],
  "abstract_text": [
    "<S> in graph modification problems , one is given a graph  @xmath0 and the goal is to apply a minimum number of modification operations ( such as edge deletions ) to  @xmath0 such that the resulting graph fulfills a certain property . </S>",
    "<S> for example , the cluster deletion problem asks to delete as few edges as possible such that the resulting graph is a disjoint union of cliques . </S>",
    "<S> graph modification problems appear in numerous applications , including the analysis of biological and social networks . </S>",
    "<S> typically , graph modification problems are np - hard , making them natural candidates for parameterized complexity studies . </S>",
    "<S> we discuss several fruitful interactions between the development of fixed - parameter algorithms and the design of heuristics for graph modification problems , featuring quite different aspects of mutual benefits . </S>"
  ]
}