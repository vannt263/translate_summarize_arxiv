{
  "article_text": [
    "sound - source localization ( ssl ) is an important task for many applications , e.g. , robot audition , video conferencing , hearing aids , to cite just a few . in the framework of human - inspired binaural hearing ,",
    "two interaural cues are widely used for ssl , namely the interaural phase difference ( ipd ) and the interaural level difference ( ild ) @xcite .",
    "when the short - time fourier transform ( stft ) is used , the ild and ipd correspond to the magnitude and argument , respectively , of the relative transfer function ( rtf ) , which is the ratio between the acoustic transfer functions ( atf ) of the two channels @xcite . in a reverberant environment , the rtf contains both direct - path information , namely the direct wave propagation path from the source location to the microphone locations , and information representing early and late reverberations . extracting the direct path is of crucial importance for ssl . in an anechoic and noise - free environment",
    "the source direction can be easily estimated from the rtf . however , in practice , noise and reverberations are often present and contaminate ssl estimation .    in the presence of noise , based on the stationarity of the noise and the non - stationarity of the desired signal ,",
    "the rtf was estimated in @xcite by solving a set of linear equations , and in @xcite by solving a set of nonlinear decorrelation equations . in @xcite , the time difference of arrival ( tdoa )",
    "was estimated based on rtf , and a tdoa tracking method was also proposed .",
    "these methods have the limitation that a significant amount of noisy frames are included in the estimation .",
    "an rtf identification method based on the probability of speech presence and on spectral subtraction was proposed in @xcite : this method uses only the frames which are highly likely to contain speech .",
    "the unbiased rtf estimator proposed in @xcite is based on segmental power spectral density matrix subtraction , which is a more efficient method to remove noise compared with the approaches just mentioned .",
    "the performance of these spectral subtraction techniques was analyzed and compared with eigenvalues decomposition techniques in @xcite .",
    "the rtf estimators mentioned above assume a multiplicative transfer function ( mtf ) approximation @xcite , i.e. , the source - to - microphone filtering process is assumed to be represented by a multiplicative process in the stft domain .",
    "unfortunately , this is only justified when the length of the filter impulse response is shorter than the length of the stft window , which is rarely the case in practice .",
    "moreover , the rtf is usually estimated from the ratio between two atfs that include reverberation , rather than from the ratio between atfs that only correspond to the direct - path sound propagation",
    ". therefore , currently available rtf estimators are poorly suitable for ssl in reverberant environments .",
    "the influence of reverberation on the interaural cues is analyzed in @xcite .",
    "the relative early transfer function was introduced in @xcite to suppress reverberation .",
    "several techniques were proposed to extract the rtf that corresponds to the direct - path sound propagation , e.g. , based on detecting time frames with less reverberations .",
    "the precedence effect , e.g. , @xcite , widely used for ssl , relies on the principle that signal onsets are dominated by the direct path .",
    "based on band - pass filter banks , the localization cues are extracted only from reliable frames , such as the onset frames in @xcite , the frames preceding a notable maximum @xcite , the frames weighted by the precedence model @xcite , etc .",
    "interaural coherence was proposed in @xcite to select binaural cues not contaminated by reverberations .",
    "based on fourier transform , the coherence test @xcite , and the direct - path dominance test @xcite are proposed to detect the frames dominated by one active source , from which localization cues can be estimated . however , in practice , there are always reflection components in the frames selected by these methods , due to an inaccurate model or an improper decision threshold . * contributions and method overview : * in this paper , we propose a direct - path rtf estimator suitable for the localization of a single speech - source in noisy and reverberant environments .",
    "we build on the cross - band filter proposed in @xcite for system identification in the stft domain .",
    "this filter represents the impulse response in the stft domain by a cross - band convolutive transfer function instead of the multiplicative ( mtf ) approximation . in practice",
    "we consider the use of a simplified convolutive transfer function ( ctf ) approximation , as used in @xcite .",
    "the first coefficient of the ctf at different frequencies represents the stft of the first segment of the channel impulse response , which is composed of the direct - path impulse response , plus possibly few early reflections .",
    "in particular , if the time delay between the direct - path wave and the first notable reflection is large , less reflections are included .",
    "therefore , we refer to the first coefficient of the ctf as the direct - path acoustic transfer function , and the ratio between the coefficients from two channels is referred to as the _ direct - path relative transfer function _",
    "( dp - rtf ) .",
    "inspired by @xcite and based on the relationship of the ctfs between the two channels , we use the auto- and cross - power spectral densities ( psd ) estimated over multiple stft frames , to construct a set of linear equations in which the dp - rtf is the unknown variable .",
    "therefore , the dp - rtf can be estimated via standard least squares . in the presence of noise , an inter - frame spectral subtraction technique",
    "is proposed , extending our previous work @xcite .",
    "the auto- and cross - psd estimated in a frame with low speech power are subtracted from the psds estimated in a frame with high speech power . after subtraction , low noise power and high speech power are left due to the stationarity of the noise and the non - stationarity of the speech signal .",
    "the dp - rtf is estimated using the remaining signal s auto- and cross - psd .",
    "this psd subtraction process does not require an explicit estimation of the noise psd , hence it does not suffer from noise psd estimation errors .",
    "finally , the estimated dp - rtfs are concatenated over frequencies and plugged into an ssl method , e.g. , @xcite .",
    "experiments with simulated and real data were conducted under various acoustic conditions , e.g. , different reverberation times , source - to - sensor distances , and signal - to - noise ratios .",
    "the experimental results show that the proposed method performs well , even in adverse acoustic conditions , and outperforms the mtf - based method @xcite , the coherence test method @xcite and the conventional srp - phat method in most of the tested conditions .",
    "the remainder of this paper is organized as follows .",
    "section  [ sec : ctf ] formulates the sensor signals based on the crossband filter .",
    "section  [ sec : dprtf ] presents the dp - rtf estimator in a noise - free environment .",
    "the dp - rtf estimator in the presence of noise is presented in section  [ sec : dprtfn ] . in section  [ sec : ssl ] , the ssl algorithm is described .",
    "experimental results are presented in section  [ sec : experiments1 ] and [ sec : experiments2 ] , and section  [ sec : conclusion ] draws some conclusions .",
    "we consider first a non - stationary source signal @xmath0 , e.g. , speech , emitted in a noise - free environment .",
    "the received binaural signals are @xmath1 where @xmath2 denotes convolution , and @xmath3 and @xmath4 are the binaural room impulse responses ( brir ) from the source to the two microphones . applying the stft , ( [ xn ] )",
    "is approximated in the time - frequency ( tf ) domain as @xmath5 where @xmath6 , @xmath7 and @xmath8 are the stft of the corresponding signals ( @xmath9 is the time frame index and @xmath10 is the frequency bin index ) , and @xmath11 and @xmath12 are the atfs corresponding to the brirs .",
    "let @xmath13 denote the length of a time frame or , equivalently , the size of the stft window .",
    "( [ xpk ] ) corresponds to the mtf approximation , which is only valid when the impulse response @xmath3 is shorter than the stft window . in the case of non - stationary acoustic signals , such as speech",
    ", a relatively small value for @xmath13 is typically chosen to assume _ local _ stationarity , i.e. , within a frame .",
    "therefore , the mtf approximation ( [ xpk ] ) is questionable in a reverberant environment , since the room impulse response could be much longer than the stft window .    to address this problem cross - band filters were introduced @xcite to represent more accurately a linear system with long impulse response in the stft domain .",
    "let @xmath14 denote the frame step .",
    "the cross - band filter model consists in representing the stft coefficient @xmath6 in ( [ xpk ] ) as a summation over multiple convolutions across frequency bins ( there is an equivalent expression for @xmath7 ) : @xmath15 from @xcite , if @xmath16 , then @xmath17 is non - causal , with @xmath18 non - causal coefficients .",
    "the number of causal filter coefficients @xmath19 is related to the reverberation time at the @xmath10-th frequency bin , which will be discussed in detail in section  [ sec : experiments1 ] .",
    "the tf - domain impulse response @xmath17 is related to the time - domain impulse response @xmath3 by : @xmath20 which represents the convolution with respect to the time index @xmath21 evaluated at frame steps , with @xmath22 where @xmath23 and @xmath24 denote the stft analysis and synthesis windows , respectively . a convolutive transfer function ( ctf )",
    "approximation is further introduced and used in @xcite to simplify the analysis , i.e. , only band - to - band filters are considered , @xmath25 .",
    "hence , ( [ xpk2 ] ) is rewritten as @xmath26 where we assumed @xmath27 such that non - causal coefficients are disregarded .",
    "note that @xmath17 is replaced with @xmath28 to simplify the notations . the cross - band filter and ctf formalism will now be used to extract the impulse response of the direct - path propagation .",
    "from ( [ hp ] ) and ( [ phik ] ) , with @xmath29 and @xmath30 , the first coefficient of @xmath28 in the ctf approximation can be derived as @xmath31 where @xmath32 is the length of the brir and @xmath33 therefore , @xmath34 ( as well as @xmath35 ) can be interpreted as the @xmath10-th fourier coefficient of the impulse response segment @xmath36 windowed by @xmath37 . without loss of generality , we assume that the room impulse responses @xmath3 and @xmath4 begin with the impulse responses of the direct - path propagation . if the frame length @xmath13 is properly chosen , @xmath36 and @xmath38 are composed of the impulse responses of the direct - path and a few reflections .",
    "particularly , if the initial time delay gap ( itdg ) , i.e. the time delay between the direct - path wave and the first notable reflection , is large compared to @xmath13 , @xmath36 and @xmath38 mainly contain the direct - path impulse response . therefore we refer to @xmath34 and @xmath35 as the direct - path atfs . by definition",
    ", the dp - rtf is given by ( we remind that the direct path is relevant for sound source localization ) : @xmath39      since both channels are assumed to follow the ctf model , we can write : @xmath40 this relation was proposed in @xcite for the time - domain tdoa estimation and is here extended to the ctf domain . in vector form can be written as @xmath41 where @xmath42 denotes vector or matrix transpose , and @xmath43\\tp , \\nonumber \\\\",
    "\\mathbf{y}_{p , k } & = [ y_{p , k},y_{p-1,k},\\dots , y_{p - q_k+1,k}]\\tp , \\nonumber \\\\",
    "\\mathbf{b}_k & = [ b_{0,k},b_{1,k},\\dots , b_{q_k-1,k}]\\tp , \\nonumber \\\\",
    "\\mathbf{a}_k & = [ a_{0,k},a_{1,k},\\dots , a_{q_k-1,k}]\\tp .",
    "\\nonumber\\end{aligned}\\ ] ] dividing both sides of ( [ mxa ] ) by @xmath34 and reorganizing the terms , we can write : @xmath44 where @xmath45\\tp , \\nonumber \\\\",
    "\\mathbf{g}_k & = \\left[\\frac{b_{0,k}}{a_{0,k}},\\dots,\\frac{b_{q_k-1,k}}{a_{0,k}},-\\frac{a_{1,k}}{a_{0,k}},\\dots,-\\frac{a_{q_k-1,k}}{a_{0,k}}\\right]\\tp . \\nonumber\\end{aligned}\\ ] ] we see that the dp - rtf appears as the first entry of @xmath46 .",
    "hence , in the following , we base the estimation of the dp - rtf on the construction of @xmath7 and @xmath47 statistics . more specifically , multiplying both sides of ( [ zpk ] ) by @xmath48 ( the complex conjugate of @xmath7 ) and taking the expectation , @xmath49 , we obtain : @xmath50 where @xmath51 is the psd of @xmath52 at tf bin @xmath53 , and @xmath54\\tp \\nonumber\\end{aligned}\\ ] ] is a vector composed of cross - psd terms between the elements of @xmath47 and @xmath7 . is composed of @xmath55 psd ` cross - terms ' , i.e. , @xmath55 taken at frame @xmath9 and previous frames , and of @xmath56 cross - psd terms for @xmath55 taken at frame @xmath9 and @xmath57 taken at previous frames . ] in practice , these auto- and cross - psd terms can be estimated by averaging the corresponding auto- and cross - stft spectra over @xmath58 frames : @xmath59 the elements in @xmath60 can be estimated by using the same principle .",
    "consequently , in practice ( [ phi ] ) is approximated as @xmath61 let @xmath62 denote the total number of the stft frames .",
    "@xmath19 is the minimum index of @xmath9 to guarantee that the elements in @xmath47 are available from the stft coefficients of the binaural signals . for psd estimation ,",
    "the previous @xmath63 frames of the current frame are utilized as shown in ( [ hphi ] ) .",
    "therefore , @xmath64 is the minimum index of @xmath9 to guarantee that all the frames for computing @xmath65 are available from the stft coefficients of the binaural signals . by concatenating the frames from @xmath66 to @xmath62 , ( [ hatphi ] )",
    "can be written in matrix - vector form : @xmath67 with @xmath68\\tp , \\nonumber \\\\    & \\hat{\\phimat}_{zy}(k)=[\\hat{\\phivect}_{zy}(p_f , k),\\dots,\\hat{\\phivect}_{zy}(p , k),\\dots,\\hat{\\phivect}_{zy}(p , k)]\\tp .",
    "\\nonumber \\end{aligned}\\ ] ] note that @xmath69 is a @xmath70 vector and @xmath71 is a @xmath72 matrix . in principle , an estimate @xmath73 of @xmath74 can be found be solving this linear equation .",
    "however , in practice , the sensor signals contain noise and thus the estimated psd contain noise power .",
    "therefore , we have to remove this noise power before estimating @xmath74 .",
    "noise always exists in real - world configurations . in the presence of noise ,",
    "some frames in ( [ phi ] ) are dominated by noise . besides , the psd estimate of speech signals is deteriorated by noise . in this section ,",
    "an inter - frame subtraction technique enabling to improve the dp - rtf estimation in noise is described , based on a speech frame selection process .      in the presence of additive noise ( [ xn ] )",
    "becomes @xmath75 where @xmath76 and @xmath77 , the noise signals , are assumed to be applying the stft to the binaural signals in ( [ xnu ] ) leads to @xmath78 in which each quantity is the stft coefficient of its corresponding time - domain signal . similarly to @xmath79 , we define @xmath80\\tp \\nonumber \\\\   & = \\mathbf{z}_{p , k}+\\mathbf{w}_{p , k } \\nonumber\\end{aligned}\\ ] ] where @xmath81\\tp .",
    "\\nonumber\\end{aligned}\\ ] ] the psd of @xmath82 is @xmath83 .",
    "we define the psd vector @xmath84 composed of the auto- and cross - psds between the elements of @xmath85 and @xmath82 . following ( [ hphi ] )",
    ", these psds can be estimated as @xmath86 and @xmath87 by averaging the auto- and cross - stft spectra of input signals over @xmath58 frames .",
    "since the speech and noise signals are uncorrelated , we can write @xmath88 where @xmath89 is an estimation of the psd of @xmath90 , and @xmath91 is a vector composed of the estimated auto- or cross- psds between the entries of @xmath92 and @xmath93 .      from ( [ hatphi ] ) and ( [ hatphin ] )",
    ", we have for any frame @xmath9 : @xmath94 or alternately : @xmath95 by subtracting the estimated psd @xmath86 of one frame , e.g. @xmath96 , from the estimated psd of another frame , e.g. @xmath97 , we obtain @xmath98 with @xmath99 applying the same principle to @xmath87 , we have : @xmath100 with @xmath101 applying ( [ linear_noisy ] ) to frames @xmath97 and @xmath96 and subtracting the resulting equations , we obtain : @xmath102 where @xmath103 because @xmath77 is stationary , @xmath104 is small .",
    "conversely , the fluctuations of speech signals are much larger than the fluctuations of the noise signal because the speech signals are both non - stationarity and sparse , i.e. , speech power spectrum can vary significantly over frames .",
    "thence , by properly choosing the frame indexes @xmath97 and @xmath96 , for instance in such a way that the speech power @xmath105 is high and the speech power @xmath106 is low , we have @xmath107 , or equivalently @xmath108 .",
    "the choice of the frame index necessitates to classify the frames into two sets , @xmath109 and @xmath110 , which have high speech power and very low speech power , respectively .",
    "this is done in subsection  [ sec : dprtfn : fc ] using the minimum and maximum statistics of noise spectrum . before that , we finalize the estimation of the dp - rtf in the noisy case , based on ( [ hatphis ] ) .",
    "let @xmath111 denote the cardinality of @xmath109 . the psd subtractions ( [ sub1 ] ) and ( [ sub2 ] ) are applied to all the frames @xmath112 using their corresponding frames @xmath113 , denoted as @xmath114 . in practice , @xmath114 is the frame in @xmath110 that is nearest to @xmath97 , since the closer the two frames , the smaller the difference of their noise psd and the difference of their transfer function .",
    "the resulting psds and cross - psd vectors are gathered into a @xmath115 vector and a @xmath116 matrix , respectively , as : @xmath117\\tp , \\nonumber \\\\",
    "\\nonumber\\end{aligned}\\ ] ] let us denote @xmath118\\tp$ ] the @xmath115 vector that concatenates the residual noise for the @xmath119 frames .",
    "then , from ( [ hatphis ] ) we obtain the following linear equation , which is the `` noisy version '' of ( [ phi ] ) : @xmath120 where @xmath121 denotes matrix conjugate transpose .",
    "finally , the estimation of the dp - rtf @xmath122 defined in is provided by the first element of @xmath123 , denoted as @xmath124 .",
    "note that if two frames in @xmath109 are close to each other , their corresponding elements in vector @xmath125 ( or corresponding rows in matrix @xmath126 ) will be correlated .",
    "this correlation yields some redundancy of the linear equations .",
    "however , in practice , we keep this redundancy to make full use of data and give a more robust solution to ( [ phin ] ) .    still assuming that @xmath127 is i.i.d and denoting its variance by @xmath128 , the covariance matrix of @xmath123 is given by @xcite : @xmath129 the statistical analysis of the auto- and cross - psd estimates show that @xmath128 is inversely proportional to the number of smoothing frames @xmath58 @xcite .",
    "thence using a large @xmath58 leads to a small error variance @xmath128 .",
    "however , increasing @xmath58 decreases the fluctuation of the estimated speech psd among frames and thus makes the elements in the matrix @xmath130 smaller , which results in a larger variance of @xmath123 .",
    "therefore , an appropriate value of @xmath58 should be chosen to achieve a good tradeoff between smoothing the noise spectrum and preserving the fluctuation of speech spectrum .",
    "@xmath131      we adopt the minimum - maximum statistics for frame classification , which was first introduced in @xcite , and is applied to a different feature in this paper .",
    "frame classification is based on the estimation of @xmath132 psd , i.e. , @xmath86 .",
    "the frame @xmath97 is selected such that @xmath133 in ( [ hatphis ] ) is large compared to @xmath127 , and thus ( [ hatphis ] ) matches well the noise - free case .",
    "as shown in ( [ hatphin ] ) , the psd estimation @xmath86 is composed of both speech and noise powers .",
    "a minimum statistics formulation was proposed in @xcite , where the minimum value of the smoothed periodograms with respect to the index @xmath9 , multiplied by a bias correction factor , is used as the estimation of the noise psd . here",
    "we introduce an equivalent sequence length for analyzing the minimum and maximum statistics of noise spectra , and propose to use two classification thresholds ( for two classes @xmath109 and @xmath110 ) defined from the ratios between the maximum and minimum statistics . in short , we classify the frames by using the minimum controlled maximum border .    formally , the noise power in @xmath86 is @xmath134 for a stationary gaussian signal , the probability density function ( pdf ) of periodogram @xmath135 obeys the exponential distribution @xcite @xmath136 where @xmath137 is the noise psd .",
    "assume that the sequence of @xmath135 values at different frames are i.i.d .",
    "random variables .",
    "the averaged periodogram @xmath138 obeys the erlang distribution @xcite with scale parameter @xmath139 and shape parameter @xmath58 : @xmath140 we are interested in characterizing and estimating the ratio between the maximum and minimum statistics of the sequence @xmath138 .",
    "since the maximum and minimum statistics are both linearly proportional to @xmath141 @xcite , we assume , without loss of generality , that @xmath142 . consequently the mean value of @xmath138 is equal to @xmath58 .    as mentioned in section [ sec : dprtf : estimation ] , the frame index of the estimated psds @xmath143 and @xmath138 is confined to the range @xmath66 to @xmath62 .",
    "let @xmath144 denote the increment of the frame index @xmath9 of the estimated psds .",
    "if @xmath144 is equal to or larger than @xmath58 , for two adjacent estimated psd @xmath138 and @xmath145 , there is no frame overlap .",
    "the sequence @xmath146 is then an independent random sequence .",
    "the length of this sequence is @xmath147 .",
    "the pdfs of the minimum and maximum of these @xmath148 independent variables are @xcite : @xmath149 where @xmath150 denotes the cumulative distribution function ( cdf ) associated with the pdf ( [ erl ] ) .",
    "conversely , if @xmath151 , @xmath138 is a correlated sequence , and the correlation coefficient is linearly proportional to the frame overlap .",
    "then , the expectation of the minimum can be approximately computed as @xmath152 where @xmath153 is a grid used to approximate the integral operation , which well covers the support of the erlang distribution with shape @xmath58 and scale 1 .",
    "similarly , the cdf of the maximum can be estimated as @xmath154 finally , we define two classification thresholds that are two specific values of the maximum and minimum ratios , namely @xmath155 where @xmath156 and @xmath157 are the values of @xmath158 for which the cdf of the maximum is equal to 0.95 and 0.5 , respectively . classes @xmath109 and @xmath110 are then obtained with @xmath159 these two thresholds are set to ensure that the frames in @xmath109 contain large speech power and the frames in @xmath110 contain negligible speech power .",
    "the speech power for the other frames are probabilistically uncertain , making them unsuitable for either @xmath109 or @xmath110 .",
    "using two different thresholds evidently separates speech region and noise - only region . in other words",
    ", there is a low probability to have a frame classified into @xmath109 in the proximity of @xmath110 frames , and vice versa .",
    "therefore , in general , the psd of a frame in @xmath109 is estimated using @xmath58 frames that are not included in the noise - only region , and vice versa .",
    "note that if there are no frames with speech content , e.g. , during long speech pauses , class @xmath109 will be empty with a probability of 0.95 due to threshold @xmath160 .        as an illustration of ( [ f12 ] ) , fig . [ figmcmt ] shows the cdf for @xmath161 .",
    "the empirical curves are simulated using wgn , and the analytical curves are computed using the equivalent sequence length in ( [ f12 ] ) .",
    "the minimum cdf and maximum cdf of two groups of simulations are shown , for which the equivalent sequence lengths @xmath162 are fixed at 20 and 100 , respectively . for each equivalent sequence length @xmath162 , two empirical curves with frame increment @xmath163 and @xmath164",
    "are simulated using wgn , whose corresponding original sequence lengths are @xmath165 and @xmath166 for @xmath167 , and @xmath168 and @xmath169 for @xmath170 , respectively .",
    "this shows that the equivalent sequence length in ( [ f12 ] ) is accurate for the minimum and maximum statistics .",
    "the amplitude and the phase of dp - rtf represent the amplitude ratio and phase difference between two source - to - microphone direct - path atfs . in other words , in case of two microphones , the dp - rtf is equivalent to the interaural cues , ild and ipd , associated to the direct path .",
    "more generally , we consider here @xmath171 microphones .",
    "this is a slight generalization that will directly exploit the previous developments , since we consider these @xmath171 microphones pair - wise . as in @xcite , we consider the normalized version of the dp - rtf estimate between microphones @xmath172 and",
    "@xmath173 : @xmath174 compared to the amplitude ratio , the normalized dp - rtf is more robust . in particular , when the reference transfer function @xmath34 is much smaller than @xmath35 , the amplitude ratio estimation is sensitive to noise present in the reference channel . by concatenating across @xmath175 frequencies and across @xmath176 microphone pairs , we obtain a high - dimensional feature vector @xmath177 .",
    "since speech signals have a sparse stft representation , we denote by @xmath178 an indicator vector whose elements are either equal to 1 if the energy at the corresponding frequency is significant , or equal to 0 if the energy is negligible .    in order to perform ssl based on the feature vector @xmath179 , we adopt here a supervised framework : a training set @xmath180 of @xmath181 pairs @xmath182 is available , where @xmath183 is a dp - rtf feature vector generated with an anechoic head - related impulse response ( hrir ) , and @xmath184 is the corresponding source - direction vector .",
    "then , for an observed ( test ) feature vector @xmath179 that is extracted from the microphone signals , the corresponding direction is estimated using either ( i )  nearest - neighbor search in the training set ( considered as a look - up table ) or ( ii )  a regression whose parameters have been tuned from the training set .",
    "nearest - neighbor search corresponds to solving the following minimization problem ( ): @xmath185 } \\parallel \\hvect \\odot ( \\mathbf{c}-\\mathbf{c}_i )   \\parallel.\\ ] ] because of the sparse nature of the test feature vectors , not any regression technique could be used .",
    "indeed , one needs a regression method that allows training with full - spectrum signals and testing with sparse - spectrum signals .",
    "moreover , the input dp - rtf vectors are high dimensional and not any regression method can handle high - dimensional input data . for these reasons we adopted the probabilistic piece - wise linear regression technique of @xcite .",
    "we report results with experiments carried out in order to evaluate the performance of the proposed method .",
    "we simulated various experimental conditions in terms of reverberation and additive noise .",
    "the brirs are generated with the roomsim simulator @xcite and with the head related transfer function ( hrtf ) of a kemar dummy head @xcite .",
    "the responses are simulated in a rectangular room of dimension @xmath186  m  @xmath187  @xmath188  m  @xmath187  @xmath189  m. the kemar dummy head is located at @xmath190  m. the sound sources are placed in front of the dummy head with azimuths varying from @xmath191 to @xmath192 , spaced by 5@xmath193 , an elevation of 0@xmath193 , and distances of @xmath194  m , @xmath195  m , and @xmath189  m. , see fig.[figroom ] .",
    "the absorption coefficients of the six walls are equal , and adjusted to control @xmath196 at 0.22  s , 0.5  s and 0.79  s , respectively .",
    "two other quantities , i.e. the itdg and the direct - to - reverberation ratio ( drr ) , are also important to measure the intensity of the reverberation . in general , the larger the source - to - sensors distance is , the smaller the itdg and drr are .",
    "for example , when @xmath196 is 0.5  s , the drrs for @xmath194 , @xmath195 , @xmath189  m are about @xmath197 , @xmath198 and @xmath199 db , respectively .",
    "speech signals from the timit dataset @xcite are used as the speech source signals , which are convolved with the simulated brirs to generate the sensor signals .",
    "each brir is convolved with 10 different speech signals from timit to achieve reliable ssl results .",
    "note that the elevation of the speech sources is always equal to @xmath200 in the brir dataset , thence in these simulated - data experiments the source direction corresponds to the azimuth only .",
    "the feature vectors in the training set @xmath201 are generated with the anechoic hrirs of the kemar dummy head from the azimuth range @xmath202 $ ] , spaced by 5@xmath193 , i.e. @xmath203 . in this section ,",
    "the nearest - neighbor search is adopted for localization .",
    "two types of noise signals are generated : ( i )  a `` directional noise '' is obtained by convolving a single channel wgn signal with a brir corresponding to position beside the wall with azimuth of @xmath204 , elevation of @xmath205 and distance of @xmath206  m , see fig .",
    "[ figroom ] ; ( ii )  an `` uncorrelated noise '' consists of an independent wgn signal on each channel .",
    "noise signals are added to the speech sensor signals with various signal - to - noise ratios .        [",
    "cols=\"^,^,^,^,^,^,^,^,^,^ \" , ]",
    "we proposed a method for the estimation of the direct - path relative transfer function ( dp - rtf ) . compared with the conventional rtf",
    ", the dp - rtf is defined as the ratio between two direct - path acoustic transfer functions .",
    "therefore , the dp - rtf definition and estimation implies the removal of the reverberations , and it provides a more reliable feature , in particular for sound source localization . to estimate the dp - rtf",
    ", we adopted the convolutive transfer function ( ctf ) model instead of the multiplicative transfer function ( mtf ) approximation . by doing this ,",
    "the dp - rtf can be estimated by solving a set of linear equations constructed from the reverberant sensor signals .",
    "moreover , an inter - frame spectral subtraction method was proposed to remove noise power .",
    "this spectral subtraction process does not require explicit estimation of the noise psd , hence it does not suffer from noise psd estimation errors .",
    "based on the dp - rtf we proposed a supervised sound - source localization algorithm . in practice",
    "we implemented two supervised methods , namely a nearest - neighbor search and a mixture of linear regressions .",
    "experiments with both simulated data and real data recorded with four microphones embedded in a robot head , showed that the proposed method outperforms an mtf - based method and a method based on a coherence test , in reverberant environments .    in the presented experiments",
    "the model parameters @xmath207 , @xmath58 and @xmath13 ( section [ sec : experiments1:parameter ] ) were set to constant values which were chosen as a tradeoff yielding good results in a variety of acoustic conditions . in the future , to improve the robustness of dp - rtf , we plan to estimate the acoustic conditions using the microphone signals , such that an optimal set of parameters can be adaptively adjusted .",
    "we also plan to extend the dp - rtf estimator and its use in ssl to the more complex case of multiple sound sources .",
    "v.  willert , j.  eggert , j.  adamy , r.  stahl , and e.  korner , `` a probabilistic model for binaural sound localization , '' _ ieee trans . on systems ,",
    "man , and cybernetics , part b : cybernetics _ , vol .",
    "36 , no .  5 , pp .",
    "982994 , 2006 .",
    "r.  m. stern , g.  j. brown , and d.  wang , `` binaural sound localization , '' in _ computational auditory scene analysis : principles , algorithms and applications _ ( d.  wang and g.  j. brown , eds . ) , pp .",
    "147185 , 2006 .",
    "m.  raspaud , h.  viste , and g.  evangelista , `` binaural source localization by joint estimation of ild and it d , '' _ ieee / acm transactions on audio , speech , and language processing _ , vol .",
    "18 , no .  1 ,",
    "pp .  6877 , 2010 .",
    "j.  woodruff and d.  wang , `` binaural localization of multiple sources in reverberant and noisy environments , '' _ ieee / acm transactions on audio , speech , and language processing _ , vol .  20 , no .  5 , pp .",
    "15031512 , 2012 .",
    "a.  deleforge , r.  horaud , y.  y. schechner , and l.  girin , `` co - localization of audio sources in images using binaural features and locally - linear regression , '' _ ieee / acm transactions on audio , speech and language processing _ ,",
    "23 , no .  4 , pp .",
    "718731 , 2015 .",
    "s.  gannot , d.  burshtein , and e.  weinstein , `` signal enhancement using beamforming and nonstationarity with applications to speech , '' _ ieee transactions on signal processing _ ,",
    "49 , no .  8 , pp .  16141626 , 2001 .",
    "x.  li , l.  girin , r.  horaud , and s.  gannot , `` estimation of relative transfer function in the presence of stationary noise based on segmental power spectral density matrix subtraction , '' in _ ieee international conference on acoustics , speech and signal processing _ , pp .",
    "320324 , 2015 .",
    "s.  markovich - golan and s.  gannot , `` performance analysis of the covariance subtraction method for relative transfer function estimation and comparison to the covariance whitening method , '' in _ ieee international conference on acoustics , speech and signal processing _",
    ", pp .  544548 , 2015 .",
    "o.  schwartz , s.  gannot , e.  habets , _",
    "et  al . _ ,",
    "`` multi - microphone speech dereverberation and noise reduction using relative early transfer functions , '' _ ieee / acm transactions on audio , speech , and language processing _ , vol .  23 , no .  2 , pp .",
    "240251 , 2015 .",
    "d.  bechler and k.  kroschel , `` reliability criteria evaluation for tdoa estimates in a variety of real environments , '' in _ ieee international conference on acoustics , speech , and signal processing _",
    ", vol .  4 , 2005 .",
    "m.  heckmann , t.  rodemann , f.  joublin , c.  goerick , and b.  scholling , `` auditory inspired binaural robust sound source localization in echoic and noisy environments , '' in _ 2006 ieee / rsj international conference on intelligent robots and systems _ , pp .",
    "368373 , 2006 .    c.  hummersone , r.  mason , and t.  brookes , `` a comparison of computational precedence models for source separation in reverberant environments , '' _ journal of the audio engineering society _ , vol .",
    "61 , no .",
    "7/8 , pp .  508520 , 2013 .",
    "c.  faller and j.  merimaa , `` source localization in complex listening situations : selection of binaural cues based on interaural coherence , '' _ the journal of the acoustical society of america _ , vol .",
    "116 , no .  5 , pp .",
    "30753089 , 2004 .",
    "s.  mohan , m.  e. lockwood , m.  l. kramer , and d.  l. jones , `` localization of multiple acoustic sources with small arrays using a coherence test , '' _ the journal of the acoustical society of america _ , vol .",
    "123 , no .  4 , pp .",
    "21362147 , 2008 .",
    "o.  nadiri and b.  rafaely , `` localization of multiple speakers under high reverberation using a spherical microphone array and the direct - path dominance test , '' _ ieee / acm transactions on audio , speech , and language processing _ ,",
    "22 , no .",
    "10 , pp .  14941505 , 2014 .",
    "y.  avargel and i.  cohen , `` system identification in the short - time fourier transform domain with crossband filtering , '' _ ieee transactions on audio , speech , and language processing _ ,",
    "15 , no .  4 , pp .",
    "13051319 , 2007 .",
    "r.  talmon , i.  cohen , and s.  gannot , `` relative transfer function identification using convolutive transfer function approximation , '' _ ieee / acm transactions on audio , speech , and language processing _ ,",
    "17 , no .  4 , pp .",
    "546555 , 2009 .",
    "j.  benesty , f.  amand , a.  gilloire , and y.  grenier , `` adaptive filtering algorithms for stereophonic acoustic echo cancellation , '' in _ ieee international conference on acoustics , speech , and signal processing _",
    ", vol .  5 , pp .",
    "30993102 , 1995 .",
    "d.  g. manolakis , v.  k. ingle , and s.  m. kogon , _ statistical and adaptive signal processing : spectral estimation , signal modeling , adaptive filtering , and array processing _ ,",
    "artech house norwood , 2005 .",
    "j.  s. garofolo , l.  f. lamel , w.  m. fisher , j.  g. fiscus , d.  s. pallett , and n.  l. dahlgren , `` getting started with the darpa timit cd - rom : an acoustic phonetic continuous speech database , '' _ national institute of standards and technology ( nist ) , gaithersburgh , md _",
    "107 , 1988 .    a.  schwarz and w.  kellermann , `` coherent - to - diffuse power ratio estimation for dereverberation , '' _ audio , speech , and language processing , ieee / acm transactions on _ , vol .",
    "23 , no .  6 , pp .",
    "10061018 , 2015 .",
    "c.  zheng , a.  schwarz , w.  kellermann , and x.  li , `` binaural coherent - to - diffuse - ratio estimation for dereverberation using an it d model , '' in _ signal processing conference ( eusipco ) , 2015 23rd european _ , pp .  10481052 , ieee , 2015 .",
    "h.  do , h.  f. silverman , and y.  yu , `` a real - time srp - phat source location implementation using stochastic region contraction ( src ) on a large - aperture microphone array , '' in _ acoustics , speech and signal processing , 2007 .",
    "icassp 2007 .",
    "ieee international conference on _ , vol .  1 ,",
    "i121 , ieee , 2007 .",
    "h.  w. loellmann , h.  barfuss , a.  deleforge , s.  meier , and w.  kellermann , `` challenges in acoustic signal enhancement for human - robot communication , '' in _ proceedings of speech communication _",
    ", pp .  14 , vde , 2014 ."
  ],
  "abstract_text": [
    "<S> this paper addresses the problem of binaural localization of a single speech source in noisy and reverberant environments . in practice , this response is contaminated by noise and reverberations . the direct - path relative transfer function </S>",
    "<S> ( dp - rtf ) is defined as the ratio between the direct - path acoustic transfer function of the two channels . </S>",
    "<S> we propose a method to estimate the dp - rtf from the noisy and reverberant microphone signals in the short - time fourier transform domain . </S>",
    "<S> first , the convolutive transfer function approximation is adopted to accurately represent the impulse response of the sensors in the stft domain . </S>",
    "<S> second , the dp - rtf is estimated by using the auto- and cross - power spectral densities at each frequency and over multiple frames . in the presence of stationary noise , an inter - frame spectral subtraction algorithm is proposed , which enables to achieve the estimation of noise - free auto- and cross - power spectral densities . finally , the estimated dp - rtfs are concatenated across frequencies and used as a feature vector for the localization of speech source . </S>",
    "<S> experiments with both simulated and real data show that the proposed localization method performs well , even under severe adverse acoustic conditions , and outperforms state - of - the - art localization methods under most of the acoustic conditions .    </S>",
    "<S> binaural source localization , direct - path relative transfer function , inter - frame spectral subtraction . </S>"
  ]
}