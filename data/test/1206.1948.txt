{
  "article_text": [
    "a two - user interference channel ( ic ) is a network consisting of two transmitter - receiver pairs , communicating over the same channel , and thus interfering each other . in certain communication scenarios , e.g. ,",
    "cognitive radio , one transmitter ( the cognitive transmitter ) is able to sense the environment and obtain side information about the incumbent transmitter ( the primary transmitter ) .",
    "such a communication channel is called interference channel with cognition or simply the _ cognitive channel_. motivated by cognitive radio s promise for increasing the spectral efficiency in wireless systems , the study of interference channel with cognitive users has been receiving increasing attention during the past years .",
    "fundamental limits of the cognitive interference channel , in which the cognitive transmitter non - causally knows the the full message of the the primary user , has been studied in @xcite .",
    "this channel was first introduced in @xcite where the authors obtained achievable rates by applying gelfand - pinsker coding to the celebrated han - kobayashi encoding @xcite for the ic .",
    "the capacity of this channel remains unknown in general ; however , it is known in several special cases , both in the discrete memoryless and gaussian channels .",
    "capacity of the gaussian cognitive interference channel ( gcic ) is known at low interference @xcite and @xcite , as well as strong interference @xcite . besides , capacity of gaussian cognitive z - interference channel ( gczic ) in which the primary receiver is interfered by the cognitive transmitter is known for several ranges of interference gain @xcite . while at low interference dirty paper coding @xcite is capacity - achieving scheme , at high interference superposition coding is the optimal technique . for the discrete memoryless channel",
    ", capacity is known for `` strong interference '' @xcite , `` weak interference '' @xcite , and `` better cognitive decoding '' @xcite regimes .",
    "effectively , superposition coding is the capacity - achieving technique in all above cases although several other techniques , including rate - splitting , simultaneous coding , and gelfand - pinsker coding ( binning ) are used to find achievable rate regions .    in this paper",
    ", we consider the _ discrete memoryless _ cognitive interference channel ( dm - cic ) .",
    "we first introduce the notion of _ less noisy _ dm - cic and show that there are two different less noisy cognitive channels : the _ primary - less - noisy _ and _ cognitive - less - noisy _ dm - cic . in the former ,",
    "the primary receiver is less noisy than the secondary receiver , whereas it is the opposite in the latter .",
    "afterward , we propose two inner bounds for the dm - cic ; one based on superposition coding , and another one using independent coding . obviously , these inner bounds are also valid for less noisy dm - cic ; in fact , one of these inner bounds is more suitable for the primary - less - noisy dm - cic whereas the other one is better for the cognitive - less - noisy dm - cic .",
    "we also prove an outer bound on the capacity of this channel .",
    "finally , we show that for the cognitive - less - noisy dm - cic the inner and outer bounds coincide , and therefore we establish the capacity region for this class of dm - cic .",
    "this proves that superposition coding is the capacity - achieving scheme in the less noisy dm - cic , as it is in the less noisy bc .",
    "although for the primary - less - noisy dm - cic capacity remains unknown , corresponding inner bound simplifies to an achievable region that has already been proved to be capacity - achieving in the special case of gczic @xcite , @xcite .",
    "this paper is organized as follows . in section [ sec : models ] , we introduce the system model and define the less noisy dm - cic . in section [ sec : dm - cic ] , we propose an outer bound and two inner bounds for the dm - cic .",
    "then , in section [ sec : cap ] , we show that one of the inner bounds is tight for the cognitive - less - noisy channel , and thus provides capacity for this class of the dm - cic .",
    "new capacity result is compared with the existing ones in section  [ sec : dis ] .",
    "the two - user discrete memoryless cognitive interference channel ( dm - cic ) is an interference channel @xcite that consists of two transmitter - receiver pairs , in which one transmitter ( the cognitive user ) knows the message of the other transmitter ( the primary one ) , in addition to its own message . in what follows",
    ", we formally define this channel and a special class of that .      the discrete memoryless cognitive interference channel ( dm - cic ) is depicted in figure  [ fig : dm - czic ] .",
    "let @xmath0 and @xmath1 be two independent messages which are uniformly distributed on the set of all messages for the first and second users , respectively .",
    "transmitter @xmath2 wishes to transmit message @xmath3 to receiver @xmath4 , in @xmath5 channel use at rate @xmath6 .",
    "message @xmath1 is available only at transmitter 2 , while both transmitters know @xmath0 .",
    "this channel is defined by a tuple @xmath7 where @xmath8 and @xmath9 are input and output alphabets , and @xmath10 is channel transition probability density functions .",
    "the capacity of the dm - cic is known in `` strong interference '' @xcite , `` weak interference '' @xcite , and `` better cognitive decoding '' @xcite regimes .",
    "these capacity results are listed in table  [ table1 ] , and labeled @xmath11 , @xmath12 , and @xmath13 , respectively . in the first case , both receivers can decode both messages . in all above cases , the cognitive receiver has a better condition ( more information ) than the primary one , in some sense , as it is evident from corresponding conditions in table  [ table1 ] .",
    "since the second transmitter has complete and non - causal knowledge of both messages , it can act like a bc transmitter .",
    "particularly , in the absence of the first transmitter this channel becomes the well - known dm - bc @xcite . in the presence of that",
    ", this channel is no longer a bc ; however , one can define conditions , similar to that in the bc , showing that one receiver is in a `` better '' condition than the other to decode the messages , e.g. , one receiver is _ less noisy _ or _ more capable _ than the other @xcite , @xcite .    in @xcite , @xcite , the authors extended this notion to the dm - cic , and studied the case where the primary receiver is more capable than the secondary receiver .",
    "this led to the capacity of the gczic at very strong interference . in what follows ,",
    "we introduce the notion of less noisy cognitive interference channel , and show that two different less noisy dm - cic arises , depending on which receiver is in a better condition .",
    "these are formally defined in the following .",
    "the dm - cic is said to be _ primary - less - noisy _ if @xmath14 [ cond1 ] for all @xmath15 .",
    "the dm - cic is said to be _ cognitive - less - noisy _ if @xmath16 [ cond2 ] for all @xmath15 .",
    "it is clear that in the first case the primary receiver is less noisy than the cognitive receiver whereas in the second case the cognitive receiver is less noisy than the primary receiver .",
    "therefore , given the channel condition , a dm - cic can be _ primary - less - noisy _ , _ cognitive - less - noisy _ , neither of them or both .",
    "in this section , we first introduce an outer bound on the capacity of the dm - cic ; we then derive two achievable rate regions for this channel .",
    "the first achievable region is based on superposition coding technique ; it is inspired by the capacity - achieving superposition coding in the less noisy and more capable dm - bc , or the inner bound introduced for the more capable dm - cic in @xcite .",
    "the idea of outer bound also comes from the capacity of the less noisy dm - bc .",
    "however , we combine two different bounds to find a unified one .",
    "inspired by capacity of less noisy bc @xcite , and definitions and for less noisy cognitive interference channels , we present a simple outer bound on the capacity of the dm - cic .",
    "this outer bound is in fact a combination of two simpler outer bounds as we describe later in this section .",
    "each outer bound can be tight in specific cases of less noisy dm - cic , as it will be shown later .",
    "the following provides an outer bound on the capacity of the dm - cic .",
    "the union of rate pairs @xmath17 such that @xmath18 for some joint distribution @xmath19 gives an outer bound on the capacity region of the dm - cic .",
    "[ thm1 ]    the proof of the second and last inequalities follows the same line of argument as in the outer bound of the more capable dm - cic ( * ? ? ?",
    "* theorem 2 ) , or similarly the converse of the more capable bc @xcite .",
    "the other two inequalities , by symmetry , follow the same line of proof .",
    "the essence of the proof in and is to use the csiszar sum identity and the auxiliary random variables @xmath20 and @xmath21 .",
    "the choice of @xmath22 indicates that they are correlated ; hence , the outer bound is over the joint distribution @xmath23 .",
    "the symmetry of the outer bound indicates how it consists of two simpler outer bounds .",
    "one including and , and the other including and .",
    "each outer bound is resembling the capacity of less noisy dm - bc @xcite .",
    "we next provide two achievable rate regions for the dm - cic .",
    "the first achievable region uses superposition encoding at the cognitive transmitter whereas the second one encodes independently .",
    "the decoding is based on the joint typicality in both cases .",
    "the union of rate regions given by @xmath24 is achievable for the dm - cic , where the union is over all probability distributions @xmath25 .",
    "[ thm2 ]    the proof of theorem  [ thm2 ] uses the superposition coding idea in which @xmath26 can only decode @xmath0 while @xmath27 is intended to decode both @xmath0 and @xmath1 .",
    "considering the space of all codewords , one can view the @xmath28 as _ cloud centers _",
    ", and the @xmath29 as _ satellites _ @xcite . for completeness",
    ", the details of the proof are provided in section  [ anx1 ] .    in light of the above discussion",
    ", we expect the encoding scheme in theorem  [ thm2 ] be more favorable when the second receiver is in a better situation than the first one , because it can decode both cloud centers and satellites . if the channel condition is the reverse , i.e. , the first receiver has a better situation than the second receiver , it makes sense to reverse the order of encoding .",
    "however , at the first transmitter , we can not do superposition encoding against the codeword of the secondary transmitter because the first transmitter does not know the massage of the cognitive user . as a result",
    ", the input distribution needs to be independent as proposed in the following theorem .",
    "the union of rate regions given by @xmath30 is achievable for the dm - cic , where the union is over all probability distributions @xmath25 that factors as @xmath31 .",
    "[ thm3 ]    the proof of theorem  [ thm3 ] uses independent encoding of @xmath32 and @xmath33 ; however , @xmath26 is intended to decode both messages whereas @xmath27 can only decode @xmath1 .",
    "the proof of theorem  [ thm3 ] follows a similar footsteps as theorem  [ thm2 ] , but the input distributions are different .",
    "the details of the proof can be found in section  [ anx2 ] .",
    "in this section , we simplify the inner bounds in theorem  [ thm2 ] and theorem  [ thm3 ] , respectively for the cognitive - less - noisy and primary - less - noisy dm - cic defined in and .",
    "then , by comparing the fist inner bound with the outer bound in theorem  [ thm1 ] , we establish capacity region for the cognitive - less - noisy dm - cic .      for the cognitive - less - noisy dm - cic , the capacity region is given by the set of all rate pairs @xmath34 such that @xmath35 for some @xmath36 .",
    "[ thm4 ]    consider the achievable region in theorem  [ thm2 ] and define @xmath37 . from",
    "we know that , for the cognitive - less - noisy dm - cic , @xmath38 .",
    "then , it can be simply verified that , the third inequality in theorem  [ thm2 ] becomes redundant for this channel .",
    "thus , the achievability of the rate region in theorem  [ thm4 ] immediately follows . to prove the converse",
    ", we consider inequalities and from the outer bound in theorem  [ thm1 ] , which are @xmath39 clearly , these two inequalities make an outer bound on the capacity of any dm - cic for some joint distributions @xmath40 .",
    "an alternative representation of this outer bound is given by @xcite , @xcite , @xmath41 which is equal to the achievable region given in theorem  [ thm4 ] .",
    "hence , the rate region in theorem  [ thm4 ] is the capacity of the cognitive - less - noisy dm - cic .",
    "note that the regions characterized by and are not necessarily equal for fixed @xmath42 ; however , their convex hull over all @xmath43 becomes the same .",
    "we further observe that the auxiliary random variable @xmath44 in the capacity region , can be replaced by @xmath28 , which results in the following corollary .",
    "the capacity region of the cognitive - less - noisy dm - cic can be expressed as @xmath45 for some @xmath46 .",
    "[ cor1 ]    the achievability of this region is obvious from theorem  [ thm2 ] and the condition in . to prove the converse",
    ", we use the last two constraints of the outer bound in ( * ? ? ?",
    "* theorem 3.2 ) , which are ( note the reversal of indices ) , @xmath47 for some @xmath46 .",
    "however , with a similar argument used in the proof of theorem  [ thm4 ] , the outer bound in can be alternatively represented as the constraints in .",
    "the capacity - achieving technique in theorem  [ thm4 ] is the well - known superposition coding , similar to that in the less noisy bc @xcite .",
    "superposition coding has been proved to be optimal encoding in several other cases , both for the dm - cic ( see table  [ table1 ] ) and the gczic @xcite .",
    "one may expect a similar result for the primary - less - noisy dm - cic , by applying the corresponding condition in to the rate region in theorem  [ thm3 ] .",
    "however , since theorem  [ thm3 ] holds only for independent @xmath48 and @xmath49 , capacity region can not be established in general .",
    "instead , we can write    the union of all rate pairs @xmath50 satisfying @xmath51 over all probability distributions @xmath52 that factors as @xmath53 is achievable for the primary - less - noisy dm - cic .",
    "[ cor2 ]    by symmetry , the proof of this theorem follows the same line of argument as the proof of theorem  [ thm4 ] . to prove the achievability , define @xmath54 and apply the condition of the primary - less - noisy dm - cic in to theorem  [ thm3 ] ;",
    "this makes the third inequality of theorem  [ thm3 ] redundant and completes the proof of the achievability .",
    "note that , from and a outer bound that resembles the rate region in corollary  [ cor2 ] can be built , but this outer bound is over @xmath55 which is , in general , larger than the inner bound in corollary  [ cor2 ] .",
    "nevertheless , in the following section we discuss that this region can result in capacity region for a particular channel .",
    "^*^ it should be emphasized that the technique used to achieve @xmath13 effectively is superposition coding , although it is derived ( simplified ) from a scheme + that uses rate - splitting , binning , and superposition coding .",
    "in fact , @xmath13 is only a different representation @xmath12 , as shown in @xcite",
    "in this section we compare the capacity region obtained in theorem  [ thm4 ] with the existing capacity results for the dm - cic .",
    "table i summarizes the capacity results for the dm - cic in the chronological order .",
    "we show that the capacity of the cognitive - less - noisy dm - cic is a subset of the capacity region derived in @xcite , which is labeled as @xmath12 in table  [ table1 ] . to this end , we first show that the condition of the cognitive - less - noisy implies both conditions required for @xmath12 .",
    "first , since @xmath56 holds for any @xmath15 , it will result in @xmath57 for @xmath58 .",
    "the other condition is also achieved by the following lemma .    if @xmath56 holds for all joint distributions @xmath15 , then @xmath59 for all @xmath15 .",
    "[ lem1 ]    see appendix  [ anx3 ] .    thus , the condition required for @xmath60 is more demanding than that of @xmath12 . in other words ,",
    "if the cognitive receiver , in a dm - cic , is less noisy than the primary one , the dm - cic will satisfy the `` weak interference '' conditions .",
    "further , we observe that , for @xmath61 the capacity regions @xmath60 becomes the same as @xmath12 .",
    "this is also evident from corollary  [ cor1 ] .",
    "it is also worth mentioning that , for @xmath58 , with further assumption that @xmath62 , @xmath60 becomes equivalent to @xmath11 .",
    "this indicates that we can use superposition coding to achieve the capacity of the dm - cic in the `` strong interference '' regime .",
    "note that , the capacity region in the `` strong interference '' ( @xmath11 in table  [ table1 ] ) , can be reexpressed as @xmath63 in this setting , @xmath32 and @xmath29 , respectively , can be viewed as cloud centers and satellites of superposition coding .",
    "originally , the achievability of @xmath11 is proved by using the capacity of compound multiple accesses channels @xcite which is based on transmitting private and common messages .",
    "it should be highlighted that , the technique used to achieve @xmath13 is also effectively superposition coding although it is derived ( simplified ) from a scheme that uses rate - splitting , binning , and superposition coding collectively . this can be verified by looking at the simplified encoding in the proof of the achievability in @xcite .",
    "therefore , we can see that all capacity results in table  [ table1 ] ( @xmath64 ) can be achieved using superposition coding . is just a different representation of @xmath12 ; this is because the conditions required for these two capacity regions are equal .",
    "this is proved in @xcite . ]    finally , consider the primary - less - noisy dm - cic .",
    "the condition required for this channel is rather different from that in all other cases that we know the capacity region , and listed in table  [ table1 ] . to appreciate this , from table  [ table1 ]",
    ", one can see that in all those cases ( @xmath64 ) the cognitive receiver has , in some sense , more information than the primary one .",
    "nevertheless , in a primary - less - noisy dm - cic , the primary receiver is assumed to have more information than the cognitive receiver , as implies .",
    "this condition could particularly arise in the cognitive z - interference channel in which the link from the primary user to the cognitive receiver is absent .",
    "for example , one can verify that the capacity result for the gczic at very strong interference ( * ? ? ?",
    "* corollary 4 ) is the counterpart of corollary  [ cor2 ] , for gaussian inputs .",
    "this is also shown independently in ( * ? ? ?",
    "* theorem v.2 ) .",
    "we prove this theorem by showing the code construction , encoding , decoding , and error analysis .",
    "fix @xmath65 and @xmath66 .",
    "randomly and independently generate @xmath67 sequences @xmath68 , @xmath69 $ ] _ i.i.d .",
    "_ according to @xmath70 .",
    "next , for each sequence @xmath71 , randomly and conditionally independently generate @xmath72 sequences @xmath73 , @xmath74 $ ] , with _ i.i.d . _",
    "elements according to @xmath75 .      to send messages @xmath76",
    ", the primary transmitter sends the codeword @xmath77 whereas the secondary transmitter sends the codeword @xmath78 .",
    "we use _ joint typicality _ for decoding . the cognitive receiver ( @xmath27 )",
    "can decode both messages whereas the other receiver can only decode one of them , namely @xmath79 .",
    "decoder 1 declares that message @xmath80 is sent if it is the unique message such that @xmath81 .",
    "likewise , decoder 2 declares that message @xmath82 is sent if it is the unique message such that @xmath83 , for some @xmath84 .",
    "in other cases , as analyzed below , the decoders declare error .      without loss of generality , we assume that @xmath85 is sent in order to analyze the probability of error . to evaluate the average probability of error for decoder 1 ,",
    "we define the following error events @xmath86 then , by using union bound , the probability of error for decoder 1 is upper bounded by @xmath87 but , @xmath88 , by the law of large numbers ( lln ) .",
    "moreover , since for @xmath89 , @xmath90 is independent of @xmath91 , by the _ packing lemma _ @xcite , @xmath92    to evaluate the average probability of error for decoder 2 , we define the following error events @xmath93 using union bound , the probability of error for decoder 1 is bounded as @xmath94 now , we evaluate the terms in the right - hand side ( rhs ) of this inequality when @xmath95 .",
    "first , by the lln @xmath96 then , for @xmath97 , @xmath98 is conditionally independent of @xmath99 given @xmath100 .",
    "thus , by the packing lemma @xmath101 . finally consider @xmath102 ; for @xmath89 and @xmath97 , @xmath103 is independent of @xmath99 .",
    "again , by the packing lemma @xmath104 ; the equality follows since @xmath105 forms a markov chain .",
    "the proof of achievability is completed by the above analysis .",
    "that is , if is satisfied , both receivers can decode corresponding messages with the total probability of error tending to zero .",
    "therefore , there exists a sequence of good codes for which error probability goes to 0 .",
    "we prove this theorem by showing the code construction , encoding , decoding , and error analysis .",
    "fix @xmath106 and @xmath107 .",
    "randomly and independently generate @xmath67 sequences @xmath77 , @xmath69 $ ] _ i.i.d .",
    "_ according to @xmath108 . also , for each @xmath48 , randomly and independently generate @xmath72 sequences @xmath109 , @xmath74 $ ] , with _ i.i.d .",
    "_ elements according to @xmath110 .      to send messages @xmath76 , the primary and cognitive transmitters , respectively ,",
    "send the codewords @xmath77 and @xmath78 .",
    "we use _ joint typicality _ for decoding , where the primary receiver can decode both messages whereas the cognitive receiver can only decode @xmath111 .",
    "decoder 2 declares that message @xmath112 is sent if it is the unique message such that @xmath113 , for some @xmath84 .",
    "similarly , decoder 1 declares that message @xmath114 is sent if it is the unique message such that @xmath115 .",
    "in other cases , the decoders declare error .",
    "error analysis is very similar to that of theorem  [ thm2 ] and is omitted here .",
    "the lemma is similar to ( * ? ? ?",
    "* lemma 5 ) .",
    "we can write @xmath116 the inequality follows because @xmath56 holds for all joint distributions @xmath15 .",
    "the author would like to thank fabrice labeau for his invaluable support and comments .",
    "w. wu , s. vishwanath , and a. arapostathis , `` capacity of a class of cognitive radio channels : interference channels with degraded message sets , '' _ ieee transactions on information theory _ ,",
    "43914399 , november 2007 .",
    "i. maric , a. goldsmith , g. kramer , and s. shamai ( shitz ) , `` on the capacity of interference channels with one cooperating transmitter , '' _",
    "european transactions telecommunications _ , vol .",
    "4 , pp . 405420 , april 2008 .",
    "s. rini , d. tuninetti , and n. devroye , `` new inner and outer bounds for the memoryless cognitive interference channel and some new capacity results , '' _ ieee transactions on information theory _ , vol .",
    "57 , no . 7 , pp .",
    "40874109 , july 2011 .",
    "j. jiang , i. maric , a. goldsmith , s. shamai ( shitz ) , and s. cui , `` on the capacity of a class of cognitive z - interference channels , '' _ in proc .",
    "_ ieee international conference on communications ( icc ) , pp . 16 , june 2011 .",
    "s. rini , d. tuninetti , and n. devroye , `` inner and outer bounds for the gaussian cognitive interference channel and new capacity results , '' _ ieee transactions on information theory _ , vol .",
    "2 , pp . 820848 , february 2012 .",
    "n. liu , i. maric , a. goldsmith , and shlomo shamai ( shitz ) , `` bounds and capacity results for the cognitive z - interference channel , '' _ in proc .",
    "_ ieee int .",
    "theory , ( isit ) , seoul , korea , june 2009 ."
  ],
  "abstract_text": [
    "<S> fundamental limits of the _ cognitive interference channel _ ( cic ) with two pairs of transmitter - receiver have been under exploration for several years . in this paper , we study the discrete memoryless cognitive interference channel ( dm - cic ) in which the cognitive transmitter non - causally knows the full message of the primary transmitter . the capacity of this channel is not known in general ; it is only known in some special cases . </S>",
    "<S> inspired by the concept of less noisy broadcast channel ( bc ) , in this work we introduce the notion of _ less noisy _ cognitive interference channel . </S>",
    "<S> unlike bc , due to the inherent asymmetry of the cognitive channel , two different less noisy channels are distinguishable ; these are named the _ primary - less - noisy _ and _ cognitive - less - noisy _ channels . </S>",
    "<S> we derive capacity region for the latter case by introducing inner and outer bounds on the capacity of the dm - cic and showing that these bounds coincide for the cognitive - less - noisy channel . </S>",
    "<S> having established the capacity region , we prove that superposition coding is the optimal encoding technique . </S>"
  ]
}