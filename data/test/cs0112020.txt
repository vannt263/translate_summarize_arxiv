{
  "article_text": [
    "are concurrent computing machines equivalent to turing machines ?",
    "this question , which amounts to confront two fundamental notions like time and computation may be treated in a purely mathematical framework .",
    "practical consequences however can not be independent of concrete realizations , that is concrete machines performing actual computations in physical time .",
    "this remark may seem curious , if one aims at showing theorems , which can not depend on the physical properties of time or machines .",
    "but , even in a mathematical treatment of concurrent computation , one needs a representation of time .",
    "usually , time is modelized as a real parameter , shared by all parts of the computation .",
    "unfortunately , such a representation does not correspond to the observable time that can be obtained from physical systems like clocks , neither to the reference time that is defined by metrology , nor to the operational time that occurs in practical realizations of logical circuits . without questioning the validity of demonstrated theorems",
    ", difficulties may emerge when trying to find practical applications .",
    "the distinction just made between abstract and concrete machines raises related questions .",
    "when a machine @xmath0 can be simulated by a program @xmath1 running on another machine , how can one identify the concrete machine @xmath0 and the program @xmath1 ? and in case a machine can not be simulated on another one , indicating some greater expressive power , is the latter due to computation or to some fundamental physical property ? before entering such questions , one must first consider the sequential machines that are presently realized .",
    "these machines which we get from a constructor , which are made of matter , which transform electric energy into heat , which we communicate with through a keyboard and a screen , why do we need them ? let us note that all the features that make them concrete are inconveniences : we would prefer them lighter , smaller , less power consuming and less dissipating",
    ". it would be ideal to make all these parameters equal to zero .",
    "in fact , we need them for their logical function , their ability to compute .",
    "but then , since this function is mathematically known , modelized and even simulated , where is the need for a concrete machine , whose features are mainly inconveniences ?",
    "the natural answer is that these machines compute faster than humans can do , with just a pencil and paper . and yet , pencil and paper are already rudimentary elements of a concrete machine , using physical objects to memorize different steps of computations .",
    "the interest in concrete machines comes from their intimate relation with physical time .",
    "if computing machines go faster than humans , then one must be confident in their action , as in most cases one is unable to check their output .",
    "indeed , in very specific cases , one can verify the correctness of a result in much less time than is needed to obtain it .",
    "this is the case for instance of the prime factorization of integers .",
    "but few concrete applications have this property . in most cases",
    ", one can not check the result in much less time than the computation itself .",
    "if the result is important , and no other way is available to obtain it , then one must be confident in the machine .",
    "what can support such a confidence ?",
    "necessarily reasoning , founded on correct functioning of the machine at a given time on some particular computations , generalized to other times and other computations .",
    "a computing machine can not be tested for all computations it can do , at any time . even for a finite machine ,",
    "the number of possible computations increases exponentially with the memory size , and a memory of one hundred bits already allows a number of configurations that can not be tested in less time than the age of the universe . to establish a reasoning leading to confidence",
    ", one must :    - check that each elementary component effectively realizes the function it has been designed for ( physical validation ) .",
    "- prove in a deductive way that the particular composition of these elementary components building the machine effectively leads to the global function used ( logical validation ) .",
    "the first condition is ensured by choices in implementation design and by tests made by the constructor .",
    "the second condition is obtained from a mathematical representation of the machine and from the logics of computation .",
    "these two steps of validation require good representations of all components at the physical level , and of the global machine at the logical level .",
    "if the confidence one can put in a machine relies on good modelizations of both its physical and logical functioning , how could such a machine perform more than it has been designed for , more than our present theories can modelize ?",
    "even if the existence of a new type of calculus , still unknown today , can be envisaged , with machines performing this new type of calculus , how could one build such machines without having for them good modelizations ?",
    "in such a case , one could not ensure the two validation steps , and one could not say that these machines operate correctly neither be confident in their ouput .",
    "one consequence is that realistic models are necessary , both of the computational structure and of the physical implementation of logical operators .",
    "modelization is made easier when logical and physical constraints can be separated .",
    "this is the reason for developing sequential machines or synchronous concurrent machines . in that case , the logical validation of the machine can be made , whilst ignoring the implementation characteristics of its components .",
    "the latter will finally and mainly limit the performance of the machine through the value of the clock frequency .",
    "the machine can equivalently be simulated on another concrete machine with identical clock frequency , at the expense of slower performances .",
    "however , in the case of asynchronous concurrent machines , logical and physical constraints are more involved .",
    "although machines built with asynchronous circuits are less widely used , much effort has been devoted to their understanding and modelization @xcite .",
    "in fact , they may even appear as an unavoidable evolution of computing machines . on one hand , clock timed circuits are reaching limits where clock signal distribution consumes too many resources and progress in performances approaches saturation point . on the other hand ,",
    "asynchronous circuits constitute the most general class of circuits , and thus allow one to express in the most general way the questions raised by the implementation of computation on physical systems , and the solutions that may be brought .    in this article",
    ", we shall be concerned with the relation of concrete computing machines with physical time . after recalling the general characteristic properties of physical time and of computing machines which are presently realized",
    ", we shall compare the solutions provided by synchronous and asynchronous systems to the implementation of logical operations .",
    "we shall show that they give different implementations of causal relations , reflecting in that way different causal structures for space - time .",
    "the notion of time may be seen to follow from two necessities . from a logical point of view",
    ", time can be considered as the concept which allows one to make a distinction between two different types of propositions : general and universal propositions ( like mathematical ones ) which are eternal , and particular propositions which are related to changing reality ( like those describing physical systems ) . moreover ,",
    "time is also rendered necessary by the formulation of physics : time is the concept which allows one to give a formal expression to movement , and hence to the laws of physics .    properties of time are in fact imposed by the functions that this notion must fulfill . from the logical side",
    ", time allows one to conceive a same object by characterizing it by its different states , these states being asssociated with the object at different times .",
    "a time parameter can then be used not only to index the different states characterizing a same object , but also to organize the states of different objects into classes of simultaneity .",
    "the relation of order that can be introduced on the time parameter allows one to define a relation of logical causality between the state transitions affecting different objects .",
    "however , in order to be realized physically , for instance on real machines , the causal relation between states can not be independent of the real motions affecting physical systems .",
    "in particular , the simultaneity classes defined with the help of the time parameter must coincide with those that are associated with real events occuring in physical space , hence with the physical time .",
    "the notion of physical time is intimately related to the laws of physics . after having remarked that pendulum oscillations are isochronous",
    ", galileo galilei could give a mathematical representation of motion induced by free fall , by relating the undergone distance to the elapsed time , the latter being understood as a universal reference for all motions .",
    "the existence of such a reference is made possible by the existence of physical laws governing all movements , and in particular by the existence of regular movements like inertial motions .",
    "this introduction of time leaves an important conventional part in the definition of a time reference , even if a natural choice is provided by motions which appear as most regular , like the earth motion around the sun .",
    "this leads in fact to distinguish two types of time .",
    "thus , leibniz @xcite , relying on logical arguments , could consider that space and time are mere relations between objects or events , which are fixed by an observer in a conventional way , thus building subjective space and time .",
    "still , one is also bound to admit the existence of objective space and time , as the only way to understand how physical laws governing displacements of objects and time ordering of events can be formulated in a universal way , independently of the observer .",
    "the formulation of the universal law of gravitation led newton @xcite to fix the role played by time in physical laws , and to endow it with the mathematical representation that we still use nowadays : that of a real parameter which all physical quantities depend on",
    ". in fact , newton introduced two different notions of time , which he distinguished both in their conception and in their usage .",
    "the first one , which he called `` absolute and mathematical '' , allowed him to write mathematical equations for the laws of mechanics and gravitation .",
    "the second notion , which he called `` common and sensible '' , allowed him to relate the motions of different physical systems , including clocks .",
    "even if newton privileged the first notion , which he considered as representing absolute space and time , seeing clocks as systems to be improved in order to make them as close as possible to ideal space and time , he nevertheless made two distinct uses of these notions .",
    "the first one , which identifies with the curvilinear coordinate on the planet s trajectory , he used as a mathematical tool to deal with infinitesimals of different orders .",
    "the second one , which is the physical time as can be defined by kepler s area law , he used as a measure of inertial motions , which he compared planetary motions with .",
    "the theory of relativity @xcite has led to question the a priori and absolute character of physical space and time .",
    "according to relativity , the notion of time relies on clocks , the date of an event being defined by coincidence of this event with a top delivered by a clock located at the same place .",
    "but in order to be defined in whole space , the notion of time also relies on the exchange of light signals , which are necessary to compare and synchronize the indications of remote clocks .",
    "the universal and finite velocity of light propagation then leads to a definition of time simultaneity which depends on the observer s motion .",
    "in other words , time simultaneity is not given a priori but results from a construction , or clock synchronization . by exchanging light signals ,",
    "on which time references provided by clocks are encoded , one can compare these references and synchronize clocks .",
    "then , time allows one to construct space . by comparing the light signals received from several remote clocks , one can",
    ", by quadrangulation , determine positions both in time and space . this relativistic definition of time and space is rendered necessary as soon as a high precision must be attained .",
    "this is the case for instance when corrections linked to the finite velocity of light , or relativistic effects , must be taken into account @xcite .",
    "hence , this relativistic definition is the one used in physics for high precision space - time measurements @xcite , and in metrology to define time and space standards @xcite and to construct the space - time reference systems required by physics @xcite .",
    "it is also the one used in modern practical positioning systems at the surface of the earth , like gps @xcite . finally , as it will appear in the following , it is also the notion of time which is implicitly used by asynchronous communicating and computing systems @xcite .",
    "the consequences of the theory of relativity on our conception of space and time have been remarkably discussed at the logical level by russell @xcite . our representation in terms of permanent material structures located in space and evolving according to a unique external time , must be replaced by that in terms of events which are located both in space and time .",
    "this conception of space - time not only affects the formulation of modern theories in a fundamental way @xcite , but also underlies present applications in physics and metrology @xcite .    when refering to physical time , simultaneity classes can not be defined a priori any more , and rely on a physical implementation by means of propagating light signals .",
    "this constructive character of time has important consequences on the functioning of devices which rely on the physical exchange of information .",
    "causal relations between events can not be derived by simple comparison with an external , a priori given , parameter . for systems which are unlocalized in space , like communicating processors",
    ", this means that the time order relation of occuring events , even if it can be defined unambiguously at the local level of each processor , nevertheless requires a more complete representation to be defined over the whole system in a consistent way @xcite . in the following",
    ", we shall analyse how the functioning of actual devices depends on the causal structure of physical space - time .",
    "to discuss the intimate relation between time and computation , one must first recall some general principles which underly the physical implementation of computing systems , and which are applied in concrete machines realized with present technologies .    *",
    "3.1 implementation of logical operations *    in cmos ( complementary mos ) technology , logical gates are implemented using two electrical networks @xmath2 and @xmath3 , as represented on figure  1 .",
    "@xmath4 describe input channels , and @xmath5 the output channel . @xmath2 and @xmath3 are built with electrical switches which are combined in series / parallel networks , thus allowing to implement the logics of propositions @xcite .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 1530,2808)(856,-2635 ) ( 2341,-1051)(0,0)[lb ] ( 1711,-826)(0,0)[lb ] ( 1036,-1816)(0,0)[lb ] ( 856,-1276)(0,0)[lb ] ( 2386,-1276)(0,0)[lb ] ( 1711,-1816)(0,0)[lb ] ( 1396,-151)(0,0)[lb ] ( 1036 , 29)(0,0)[lb ] ( 1036,-2401)(0,0)[lb ] ( 1396,-2581)(0,0)[lb ] ( 1036,-781)(0,0)[lb ]    fig .",
    "1 . a logical gate .",
    "each switch is implemented with a transistor . a function implemented by @xmath6",
    "will be said to be true , for a particular set of values of @xmath4 , if and only if there is a path that connects extreme connections of @xmath6 .",
    "for instance , for the network represented by figure  1 :    - when @xmath2 is _ true _ , output @xmath5 is forced to value _",
    "true_.    - when @xmath3 is _ true _",
    ", output @xmath5 is forced to value _",
    "false_.    the possibility that ( @xmath7 ) for some values of @xmath4 must be excluded , otherwise current could flow both through @xmath2 and @xmath3 , resulting in a short circuit between voltage sources . in the following , we shall always impose that ( @xmath8 ) is verified for all configurations of variables @xmath4 ( @xmath9 , @xmath10 and @xmath11 define as usual negation , logical disjunction and logical conjunction ) .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 3117,2025)(1126,-2401 ) ( 2476,-1141)(0,0)[lb ] ( 1801,-2401)(0,0)[lb ] ( 1306,-1861)(0,0)[lb ] ( 4006,-781)(0,0)[lb ] ( 1306,-1501)(0,0)[lb ] ( 1126,-826)(0,0)[lb ] ( 1666,-826)(0,0)[lb ] ( 3151,-646)(0,0)[lb ] ( 1531,-511)(0,0)[lb ] ( 2026,-511)(0,0)[lb ] ( 3151,-1051)(0,0)[lb ]    fig .",
    "2 . nand gate .",
    "two cases must be considered .",
    "1- @xmath2 and @xmath3 are always opposite , for all values of variables @xmath4 , ( @xmath12 ) .",
    "this case implements propositions of classical logic ( complementary mos ) .",
    "the simple example of the _ nand _ gate is represented on figure  2 ( a bubble represents negation ) : @xmath13    2- @xmath2 and @xmath3 can be simultaneously _ false _ , i.e. ( @xmath14 ) can be _",
    "true_. in such configurations , the output @xmath5 is not connected to any voltage source . then , because of electrical capacities , @xmath5 memorizes its previous value .",
    "this allows one to realize memories , like the _ latch _ represented in figure  3 : @xmath15    ( 0,0 )    # 1#2#3#4#5 @font    ( 1620,1179)(631,-2761 ) ( 2251,-1951)(0,0)[lb ] ( 946,-1951)(0,0)[lb ] ( 946,-2536)(0,0)[lb ] ( 1981,-1726)(0,0)[lb ] ( 721,-2761)(0,0)[lb ] ( 1576,-2131)(0,0)[lb ] ( 631,-1726)(0,0)[lb ]    fig .",
    "3 . transparent latch . in practice , in order to have memorization last for long enough , and quite generally for all memories , one must ensure memory stability by using some feed - back , by means of a looped amplifier .",
    "this feed - back can be permanent ( static ) or recurrent ( dynamic logic ) .",
    "one possibility of electrical feed - back is shown in figure  4 , where two looped amplifiers have been added on output @xmath5 , one of them being weak , in the sense that it can not create any serious short circuit when it conflicts with any of the two networks @xmath2 and @xmath3 .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 1992,2385)(1126,-2401 ) ( 1801,-151)(0,0)[lb ] ( 1126,-781)(0,0)[lb ] ( 1711,-871)(0,0)[lb ] ( 1711,-1816)(0,0)[lb ] ( 1801,-2401)(0,0)[lb ] ( 2566,-826)(0,0)[lb ] ( 1126,-1816)(0,0)[lb ] ( 2971,-1141)(0,0)[lb ]    fig .",
    "4 . electrical feed - back . another way to realize a stable memory is to implement a static feed - back on a logical gate corresponding to the first case .",
    "then , the quoted _ latch _ can be realized with a looped multiplexer ( _ mux _ ) , as shown in figure  5 : @xmath16    ( 0,0 )    # 1#2#3#4#5 @font    ( 1632,1497)(991,-2491 ) ( 2611,-1501)(0,0)[lb ] ( 991,-1681)(0,0)[lb ] ( 991,-2491)(0,0)[lb ] ( 1711,-1186)(0,0)[lb ]    fig .",
    "transparent latch with multiplexer .",
    "this exhibits a very general difficulty which characterizes looped systems : variable @xmath5 appears on both sides of its defining equation ( [ latchdef ] ) .",
    "this equation does not mean that an equality must be realized , for instance with electric voltages , but that the following assignment must be realized : @xmath17 @xmath18 in other words , two values of the variable @xmath5 must be distinguished , which correspond to successive times : @xmath19 ( after ) and @xmath20 ( before ) are linked by equation ( [ latche ] ) .",
    "it is required that the two values @xmath19 and @xmath20 do not interfere , and that variable @xmath5 change from @xmath20 to @xmath19 .",
    "the assignment represented by equation ( [ latcha ] ) expresses a causality requirement that must be implemented in order to realize computations .    in the particular case of the _ latch _ just described ,",
    "operation may only cause problem in case @xmath21 is falling . indeed , in other cases :    - when @xmath21 is low , @xmath5 is memorized    - when @xmath21 is high , @xmath5 copies @xmath22    - when @xmath21 rises , @xmath5 begins to copy @xmath22    so that the circuit operates correctly in these three cases .",
    "however , if @xmath21 falls down while @xmath22 changes , @xmath5 will hesitate between two values of @xmath22 .",
    "the whole circuit may enter a metastable state which is invalid ( electric voltage will stay in metastable balance at an intermediate level ) and which may last for an unbounded time .",
    "it may leave this state for any of the two possible values of @xmath5 , and this in an undeterministic way , which may not be eventually acceptable for the type of computation envisaged .",
    "let us note that the circuit of figure  4 shows the same defects , for it involves a feed - back , although this may be less apparent when treated at the electrical level .",
    "although chosen here as an example , the _ latch _ shows properties which are encountered quite generally in looped devices .",
    "this brief discussion shows that the correct operation of a circuit can not be analysed without taking its environment into account , in particular the time ordering relations of input and output signals .",
    "this is entailed by the existence of loops and must be dealt with quite generally , for computing machines are naturally looped systems . in all cases , time constraints must be implemented in order to ensure the causality relations which are necessary for computation .",
    "these constraints will take very different forms , according to the type of implementation chosen , whether by means of synchronous or asynchronous systems . before discussing separately these two classes of systems",
    ", we shall first recall one important property they share , as it is also imposed by implementation of complex computations , the property of modularity .    *",
    "*    there exist many various ways to organize electronic components into logical circuits , in order to realize machines performing computations .",
    "usually and quite generally , one defines complex circuits as hierarchies built with elementary circuits called primitives .",
    "this method , imposed by practical considerations , indeed hints at a logical necessity : one must be able to design and realize with the same rigour circuits of increasing complexity .",
    "more precisely , one must insure that circuits implementing logical functions of high complexity level behave as they should , and one must obtain this confidence in a rather short time .",
    "because of the exponential increase of the number of configurations to check , this requirement implies that a direct physical test of the circuit s behaviour soon becomes impossible when the complexity of the logical function increases .",
    "this aim can then only be attained with the help of modular implementations , by taking advantage both of their composite logical structure , and of the logical simplicity of chosen primitives @xcite .",
    "proofs relying on known properties of composition of primitives may be developed , which allow one to deduce the correct functioning of a whole modular complex from that of its constituent primitives .",
    "then , a test of the whole complex reduces to that of some of its constituents , which are logically simple .",
    "although efficient , such strategy may not reveal itself so straightforward . according to the type of physical implementation chosen for the primitives , problems may appear which prevent the systematic development of complex circuits operating correctly , and which do not occur when the choice of primitives is modified , or when pecular constraints are put on their composition .",
    "then , there results that logical and physical aspects of modular implementations must be analysed concurrently .",
    "time appears in computing systems very early , already in the definition of the electronic circuits which implement logical functions .",
    "most circuits which are known and used are synchronous .",
    "synchronous circuits may be defined as automata whose transitions between successive states are triggered by pulses delivered by a global clock .",
    "an alternative class of circuits is provided by asynchronous circuits . in this section ,",
    "we introduce the strategies followed by these two main classes of circuits for making the implementation of computation effective , and , in particular , for dealing with problems of computation interferences .    *",
    "4.1 synchronous circuits *    vlsi circuits which are produced nowadays are highly concurrent devices ( a microprocessor can contain up to @xmath23 transistors , i.e. @xmath24 logical gates ) , and yet most of them can be modelized as non concurrent devices and can be considered as single finite automata .",
    "this property comes from their synchronous character , which means that all operations on internal memories are simultaneously activated by a single pulse of a global clock shared by the whole circuit .",
    "synchronous implementations use a global clock to avoid the stability problem which has been discussed in previous section .",
    "more precisely , with same notations , all _ latches _ are systematically operated in such a way to ensure that logical variables @xmath22 be stable when variables @xmath21 are falling . there",
    "exist many different types of memories , but all present the same problem , reflecting the time character of logical assignment . for the sake of simplicity",
    ", we shall only discuss the case of the previous _ latch _ , and consider it as a generic example .",
    "a synchronous device using two items of this _ latch _ for each register bit ( master - slave _ flip - flop _ ) is sketched on figure   6 .",
    "the enabling signals @xmath25 and @xmath26 are mutually excluded in time , and are derived systematically from a common clock .",
    "the output is fed back under the form of input variables @xmath27 into a combinatorial operator .",
    "if the clock period is larger than the feedback time , then variables @xmath28 are always stable when @xmath25 is falling and the _ latches _ act as required , i.e. , they make the iteration of the combinatorial function effective .",
    "the global state @xmath29 is encoded by the state of all memory bits , and can only change at the arrival of a clock pulse . regarding specification and design ,",
    "synchronous circuits may be considered as modular composites , where primitives , and other modules as well , are finite automata of the type described by figure  6 .",
    "the register encodes the state of the circuit , while the combinatorial operator represents the implementation of its transition function .",
    "all registers are activated by a single clock pulse . by connecting several",
    "automata of this type , one obtains another automaton of the same type , only with a larger memory and a more complex combinatorial function .",
    "in such a representation , and from a logical point of view , neither time nor space are involved .",
    "one only needs to consider the successive logical steps associated with successive clock periods .",
    "the logical time of a computation reduces to a mere integer , which one only relates to physical time by multiplying it by the mean clock period .",
    "in other words , time is discretized .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 3072,5916)(946,-6010 ) ( 1711,-3031)(0,0)[lb ] ( 2926,-2401)(0,0)[lb ] ( 3331,-1411)(0,0)[lb ] ( 946,-1951)(0,0)[lb ] ( 2746,-1411)(0,0)[lb ] ( 3241,-2176)(0,0)[lb ] ( 2746,-646)(0,0)[lb ] ( 2881,-2176)(0,0)[lb ] ( 1666,-1276)(0,0)[lb ] ( 1846,-1411)(0,0)[lb ] ( 3511,-1816)(0,0)[lb ] ( 1621,-5281)(0,0)[lb ] ( 1621,-4921)(0,0)[lb ] ( 3376,-5551)(0,0)[lb ] ( 1936,-5956)(0,0)[lb ] ( 3376,-3391)(0,0)[lb ] ( 1261,-3391)(0,0)[lb ] ( 1936,-3616)(0,0)[lb ] ( 2746,-3616)(0,0)[lb ] ( 2116,-4201)(0,0)[lb ] ( 2926,-4201)(0,0)[lb ]    fig",
    "synchronous circuit .",
    "the only physical constraint one must impose is that the clock frequency be smaller than the limit value necessary for all internal propagations to be performed in less time than the clock period .",
    "space neither plays a role in the logical function .",
    "the whole circuit may be considered as local , i.e. propagation times need only to be taken into account when circuits are connected on large distances , that is when propagation times are large when compared to the clock period , as is the case when computers are connected .",
    "implementation on a silicon chip must take into account and control all propagation times within a circuit , so that to insure that all inputs become stable before the end of each clock period .",
    "the clock signal must be implemented so that it arrives simultaneously at all _ latches _ , that is with negligible delays when compared to the clock period .",
    "clearly , such properties can only be checked once the whole circuit has been specified .",
    "such type of circuit can not be implemented incrementally , i.e. by implementing a part without any knowledge on its connections with other parts and on the clock frequency of the whole circuit . in other words ,",
    "all parts must be local at every scale , from primitives to the whole circuit .",
    "the synchronous approach is however questioned in present vlsi designs .",
    "this arises mainly because of difficulties which are encountered when distributing simultaneously a same clock signal to millions of _ latches _ , over several @xmath30 , and at a frequency of the order of a gigaherthz .",
    "clock distribution results in using an important part of the chip surface and in producing an important part of the overall dissipation .    *",
    "4.2 asynchronous circuits *    asynchronous circuits may be defined in opposition to synchronous circuits , by the requirement of not using a global clock .",
    "but , rather than being complementary , the class they build includes synchronous circuits .",
    "usual models represent asynchronous circuits as general devices which are distributed and communicate along connecting channels , as shown on figure  7 .",
    "the activity of such circuits is not ruled by the pulses of a global clock , but proceeds with communications distributed between many concurrent parts .",
    "these devices can be simple logical gates ( a few transistors ) or , at the opposite , complex processors .",
    "communications can be realized through a single wire or through a complex network .",
    "clearly , concurrency can not be ignored any more .",
    "indeed , one can no more define a logical state which would be associated with the global circuit at a definite time . for",
    "each device can change its state following a communication , without being synchronized with most other devices .",
    "the notion of computing step itself must be revised , as it relies on a total ordering of all logical events .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 2319,1374)(1024,-2008 ) ( 2071,-916)(0,0)[lb ] ( 1081,-1411)(0,0)[lb ] ( 2971,-1141)(0,0)[lb ] ( 2206,-1861)(0,0)[lb ]    fig .",
    "asynchronous circuit .",
    "problems of computation interference may then arise at two different levels . at lowest level",
    ", functioning of a single component may be endangered by computing interferences within the component itself , due to internal loops and instabilities of internal variables . at highest level",
    ", composition of asynchronous circuits may induce computation interferences due to exchanges between one module and its environment , the latter sending signals which conflict with the module operation .",
    "we shall discuss the second case only and shall assume that primitives may be defined which are free from internal computing interferences ( see for instance @xcite ) .",
    "we first briefly describe those that are most frequently used in asynchronous circuits . in some examples",
    ", logical functions are defined in a way which does not distinguish between rising and falling edges .",
    "these undistinguished transitions are called events , and the logical function operates on these events .",
    "but the events are still transitions between different levels ( or boolean variables ) , so that each primitive can be considered in both ways , either as an operation on boolean variables or as ( another ) operation on events .",
    "a most frequently used primitive is the _",
    "join _ element , or muller s _",
    "c - element_. it has two inputs @xmath31 and @xmath32 and one output @xmath5 , and its logical function can be described in the following way :    - if @xmath33 , then @xmath34    - if inputs become different from one another , then @xmath5 keeps its previous value .",
    "then , ouput @xmath5 only changes after both inputs @xmath31 and @xmath32 have changed .",
    "this allows a rendez - vous to be realized between levels ( wait until two inputs acquire the same value ) or between events ( wait until two inputs have received the same number of rising or falling edges , after proper initialization ) .",
    "the primitive _ c - element _ can be realized using an electrical feed - back analogous to that of figure  4 . along this line",
    ", a frequent realization is represented on figure  8 .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 2352,2004)(451,-1738 ) ( 2656,-646)(0,0)[lb ] ( 1711,-1681)(0,0)[lb ] ( 1711 , 74)(0,0)[lb ] ( 2161,-331)(0,0)[lb ] ( 451,-466)(0,0)[lb ] ( 451,-826)(0,0)[lb ]    fig . 8",
    ". simplified c - element .",
    "another primitive is the _ toggle _ , represented in figure  9 , which possesses one input @xmath22 and two ouputs @xmath35 and @xmath36 .",
    "successive events on the input are alternatively sent to outputs @xmath35 and @xmath36 .",
    "the first event after initialization is sent to the marked output @xmath35 .    the _ or _ operation between events , also called _ merge _ , can be realized with a classical _ exclusive _ _ or _ gate ( _ xor _ between levels ) .",
    "the _ sequencer _ , represented in figure  9 , possesses three inputs @xmath31 , @xmath32 and @xmath37 and two outputs @xmath35 and @xmath36 .",
    "its role is to grant a given resource to one of two different processes which can make requests on inputs @xmath31 and @xmath32 .",
    "when an event is received on @xmath37 , a granting event is produced either on @xmath35 or @xmath36 according to an existing request respectively on @xmath31 or @xmath32 .",
    "when two requests are present , the _ sequencer _ arbitrates between the two , and thus introduces some part of indeterminism .",
    "the _ sequencer _ may take an unbounded time to arbitrate , but it is required to realize the mutual exclusion of the two grant signals .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 1947,3435)(901,-3661 ) ( 1891,-1276)(0,0)[lb ] ( 2476,-3661)(0,0)[lb ] ( 2791,-2131)(0,0)[lb ] ( 2791,-1231)(0,0)[lb ] ( 2746,-2806)(0,0)[lb ] ( 2791,-1456)(0,0)[lb ] ( 2746,-3076)(0,0)[lb ] ( 1936,-1951)(0,0)[lb ] ( 1936,-2176)(0,0)[lb ] ( 1936,-2761)(0,0)[lb ] ( 1936,-3031)(0,0)[lb ] ( 2341,-691)(0,0)[lb ] ( 1891,-691)(0,0)[lb ] ( 1891,-421)(0,0)[lb ] ( 901,-691)(0,0)[lb ] ( 901,-1411)(0,0)[lb ] ( 901,-2221)(0,0)[lb ] ( 901,-2986)(0,0)[lb ] ( 2791,-601)(0,0)[lb ]    fig .",
    "9 . some asynchronous primitives .",
    "in this section , we discuss the composition of asynchronous circuits , and some solutions which have been brought to the problem of computing interferences .    compositions of asynchronous circuits correspond to distributed systems , where different parts communicate in a way which is not regularized by a global clock .",
    "then various and arbitrary time delays affect successive transitions at the input of a module .",
    "inputs may then conflict with the correct operation of the module itself .",
    "the approaches followed in circuit design to deal with computing interferences fall into two main classes .",
    "one practical approach to timing problems consists in working directly on the physical implementation , by keeping track of all the delays occuring in the logical circuit , together with all the constraints which must be satisfied by these delays in order to make the whole circuit operate correctly .",
    "then , programs are developed to find and optimize solutions in a systematic way @xcite .",
    "although practically very efficient , this strategy rapidly attains such a complexity that it becomes very difficult to distinguish fundamental issues from practical choices . in the other class of approaches ,",
    "one attempts to separate as much as possible the logical issues related with timing from their physical manifestations , that is mainly from the values of time delays .",
    "this has led to different studies , focussing either on the determination of a best choice of logical primitives , satisfying criteria like speed - insensitivity or delay - insensitivity @xcite , or on a more restrictive definition of modular composition , like delay - insensitive compositions @xcite . in the following ,",
    "we shall only briefly discuss approaches related with delay - insensitivity , and focus on the fundamental relation they tend to exhibit between the occurence of computing interferences and the causal structure of physical space - time .    in order to make the analysis easier to follow ,",
    "we shall introduce a graphic representation of the communications occuring between modules of a composition ( see figure  11 ) .",
    "these graphs are analogous to those that can be used in relativistic physics to represent the space - time evolution of localized physical systems , together with the light signals they exchange . as discussed in a previous section ,",
    "an essential feature is the absence of an a priori given global and common time .",
    "only a local time ordering can be made between the successive events occuring on each module , reflecting the causal relations which can be made locally .",
    "although time is represented as the vertical axis , this only indicates the direction for increasing time on each module .",
    "different modules are displayed on the horizontal axis , which roughly corresponds to space .",
    "each module is then represented by a vertical line , indicating the causal succession of the local events occuring at its inputs or outputs .",
    "communications are then represented by inclined arrows leaving a module ( output ) to reach another module ( input ) .",
    "although they may vary , the slopes of theses arrows must always be greater than a strictly positive lower bound , which corresponds to light velocity .",
    "varying slopes indicate that varying speed and delays affect communications between modules .",
    "in the following , we shall denote by `` event '' each arrow corresponding to a communication , and shall call `` point '' the intersection of this event with the time evolution of a module ( following in that way the notation introduced by russell in his discussion of the causal structure of relativistic space - time @xcite ) .",
    "the logical specification of each module is translated into causal relations between the points which represent the occurence of events on the module .",
    "these local constraints may be given a precise expression using a formal language well suited to represent time ordered event structures @xcite .",
    "as propagation delays play an essential part , ordering constraints will be most conveniently visualized on graphic representations , which allow the analysis of global causal relations within distributed systems .    *",
    "5.1 delay - insensitivity *    in order to discuss the role of delays in computation interferences , let us first analyse the illustrating example of the _ q - element _",
    "@xcite , which is represented in figure  10 .",
    "the formal expression describing the logical function of the _ q - element _ can be written in a language which is derived from csp ( communicating sequential processes ) @xcite : @xmath38 ; y_o\\uparrow ; [ y_i ] ; u\\uparrow ; [ u ] ; y_o\\downarrow ; [ \\lnot y_i ] ; x_o\\uparrow ; [ \\lnot x_i ] ; u\\downarrow ; [ \\lnot u ] ; x_o\\downarrow \\right]\\ ] ] each variable between brackets , which precedes a transition , represents a logical variable which must be true before the circuit can execute the transition which follows ( @xmath39 denotes time succession , and @xmath40 arbitrary repetition of the expresssion in brackets ) .",
    "thus , the circuit waits for @xmath4 to be true , then emits a rising edge on output @xmath41 , etc ...    this logical function can be implemented as a composition of a _ c - element _ with two _ and _ gates , as represented in figure  10 .",
    "output @xmath42 of the _ c - element _ is followed by a fork , which relates @xmath42 to one input of each of the _ and _ gates .",
    "two other forks also dispatch the event produced by the environment @xmath4 ( resp .",
    "@xmath43 ) on two inputs denoted by @xmath31 and @xmath32 ( resp . @xmath44 and @xmath45 ) .    ( 0,0 )    # 1#2#3#4#5 @font    ( 2712,1872)(1216,-2773 ) ( 2251,-2581)(0,0)[lb ] ( 2476,-1996)(0,0)[lb ] ( 3826,-1186)(0,0)[lb ] ( 3016,-1096)(0,0)[lb ] ( 2251,-1591)(0,0)[lb ] ( 3061,-1546)(0,0)[lb ] ( 3736,-2581)(0,0)[lb ] ( 1216,-1096)(0,0)[lb ] ( 1216,-2491)(0,0)[lb ] ( 1621,-2626)(0,0)[lb ] ( 3421,-1321)(0,0)[lb ] ( 2026,-2266)(0,0)[lb ] ( 2926,-2221)(0,0)[lb ]    fig .",
    "q - element .",
    "the logical operation of the circuit may be represented using a space - time graph , as in figure  11 .",
    "left and right parts of the circuit environment are respectively represented as @xmath46 and @xmath47 .",
    "the series of points corresponding to the definition of the logical function of each module can be followed on each vertical line .",
    "situations which correspond to rendez - vous , i.e. intervals where a primitive is waiting for the arrival of two events in any order , have been represented by a thick line .",
    "this is systematically the case for the _ c - element _ , but also for the _ and _ gates , when they are waiting for their two inputs to be true .",
    "pairs of points which can not occur in reverse order without ruining computation , have been signalized by dashed lines .",
    "the two cases involve the internal variable @xmath42 and one event , @xmath48 or @xmath49 produced by the environment ( @xmath47 or @xmath46 ) .",
    "event @xmath48 must reach the _ and _ gate b before event @xmath50 , recalling that the latter has been produced by the arrival of event @xmath51 on the _ c - element_. then , the fork which dispatches both events @xmath48 and @xmath51 plays a crucial role in determining the order of points on _ and _ gate b.    a few remarks are in order .",
    "concurrent computing is well illustrated by figure  11 .",
    "different computations proceed along paths involving vertical and propagation lines , each representing a causally ordered series of operations .",
    "causal order makes only sense either within each vertical line , where it is associated with the logical function of the module , or within propagating lines , where it connects the output of one module to the input of another module . but no a priori total order exists between all points of the graph .",
    "this is illustrated by the independence of computation on the order of some pairs of points .",
    "for instance , two events belonging to different branches of the fork on variable @xmath42 at the output of the _ c - element _ may have arbitrary relative order .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 2757,5487)(1384,-6418 ) ( 2071,-5416)(0,0)[lb ] ( 1891,-6181)(0,0)[lb ] ( 2971,-6181)(0,0)[lb ] ( 4051,-6181)(0,0)[lb ] ( 1441,-1096)(0,0)[lb ] ( 2431,-6181)(0,0)[lb ] ( 3511,-6181)(0,0)[lb ] ( 2026,-5956)(0,0)[lb ] ( 3241,-5956)(0,0)[lb ] ( 3151,-5506)(0,0)[lb ] ( 3736,-5281)(0,0)[lb ] ( 4141,-5056)(0,0)[lb ] ( 2566,-4966)(0,0)[lb ] ( 3151,-4381)(0,0)[lb ] ( 2656,-4381)(0,0)[lb ] ( 3736,-4291)(0,0)[lb ] ( 2566,-3796)(0,0)[lb ] ( 1621,-3211)(0,0)[lb ] ( 3106,-2491)(0,0)[lb ] ( 2656,-2491)(0,0)[lb ] ( 2026,-2356)(0,0)[lb ] ( 1621,-2041)(0,0)[lb ] ( 1621,-5731)(0,0)[lb ] ( 2116,-2896)(0,0)[lb ] ( 3106,-3031)(0,0)[lb ] ( 2026,-3481)(0,0)[lb ] ( 3196,-3526)(0,0)[lb ] ( 4141,-3976)(0,0)[lb ] ( 3691,-4786)(0,0)[lb ]    fig . 11 .",
    "space - time graph of the q - element . imposing a total",
    "ordering would amount to implement a global time , by means of clock distribution for instance , which would allow one to draw horizontal lines on the graph of figure  11 .",
    "but such condition is too restrictive , as computation only relies on causal relations imposed by vertical and propagation lines . the remaining freedom in the ordering of events , as the one related to the fork at the output of the _ c - element _ , is necessary for optimizing the circuit performance . for a definite implementation ,",
    "event ordering will depend on the relative spatial localization of modules , so that the remaining freedom may be used to find an optimal arrangement of modules on the chip .",
    "the property of delay - insensitivity @xcite is easily seen on the graph .",
    "it corresponds to the independence of causal ordering of computation on delays occuring in responses of modules or in propagations of signals , i.e. on vertical or horizontal displacements of the modules .",
    "such property is made possible by using primitives which wait for the arrival of events at their input before producing other events at their output .",
    "but this condition appears to be unsufficient . in that respect",
    ", it is instructive to compare the two kinds of forks used by the previous composition implementing the _ q - element_. no constraint affects the events produced by the fork at the output of the _ c - element _ ( thick lines in figure  11 ) .",
    "however , forks dispatching the events produced by the environment must be implemented in such a way to respect the causal order of the events which they generate and which finally arrive at the same _ and _ gate ( dashed lines in figure  11 ) .",
    "such forks , which are called _ isochronic forks _",
    "@xcite , must be isolated and given a special treatment at the implementation level , in order to satisfy the delay constraints which are necessary for preserving causal ordering .    the property of delay - insensitivity ( di ) has been introduced and much developed as a simple condition one can impose on primitives and logical circuits , with the aim to design in a systematical way asynchronous circuits of arbitrary complexity , without having to take time scales into account .",
    "one approach consists in defining di circuits as compositions of stable primitives devoid of internal loops ( only electrical loops being used for memorization ) @xcite . a primitive",
    "is defined to be stable , by imposing that an input which changes the output can not change before the output has been established .",
    "it can then be shown that only compositions of _ c - elements _ can be di according to this definition .",
    "but , it can also be shown that compositions using _ c - elements _ ( and generalized _ c - elements _ with more inputs ) exclusively , strongly limit the type of allowed computations , excluding most circuits of interest @xcite .",
    "the _ isochronic fork _ may then be advocated as a weakest compromise to delay insensitivity . adding the _ isochronic fork _ and using this extended class of elements , called quasi delay - insensitive ( qdi ) , complex and efficient asynchronous circuits",
    "have been realized @xcite .",
    "however , as illustrated by the example of the _ q - element _ , _ isochronic forks _ need to be identified at the logical level and their implementation must be given a special treatment , which may reveal itself intricate for very complex circuits .",
    "* 5.2 delay insensitive composition *    another approach for avoiding computation interferences @xcite , consists in defining a less restrictive set of di primitives , together with a notion of di composition of these primitives .",
    "circuits are represented in a formal language , called trace theory , similar to the one used in equation ( [ qelement ] ) , with further syntax rules on logical operations .",
    "computing interferences are avoided by imposing structural constraints under the form of simple rules .",
    "let us first recall definitions and some properties of trace structures @xcite .",
    "trace structures are defined as triples @xmath52 , where @xmath53 and @xmath54 are finite sets of symbols , respectively the input alphabet and the output alphabet , and @xmath55 is the set of traces , which is a subset of @xmath56 , the set of all finite - length sequences of symbols taken in the union set @xmath57 .",
    "trace structures are traditionally denoted by capital letters , while lower case letters @xmath58 , @xmath59 , @xmath60 denote symbols and @xmath61 , @xmath62 traces .",
    "the following short notations are also frequently used : & & a ?",
    "< a , , a > + & & b !    operations of concatenation , union , repetition , prefix - closure , projection and weaving are defined on trace structures : [ operations ] & & r;s + & & r|s + & & * [ r ] + & & * pref*r + & & ra < * i*r a , * o*r a , ta| t r > + & & r||s    where , for convenience , notation @xmath63 has been introduced for the total alphabet of @xmath64 , where @xmath65 denotes the projection of trace @xmath62 on alphabet @xmath66 and @xmath67 is the set of all finite - length concatenations of traces in @xmath55 ( symbols @xmath68 , @xmath69 , @xmath70 , @xmath71 and @xmath72 denote as usual , existence , universality , set belonging , set intersection and set union ) .",
    "the @xmath73 operator constructs prefix - closed structures , while the projection operator hides internal symbols ; finally , the weave operator expresses instantaneous synchronization .",
    "a circuit is specified by a prefix - closed , non empty , trace structure @xmath64 with @xmath74 .",
    "the trace structure representing the environment of a circuit with trace structure @xmath64 is the reflection of the latter , and may also be given a compact notation : = < * o*r , * i*r , * t*r > a trace structure @xmath64 may be physically implemented by letting each symbol @xmath58 in the alphabets @xmath53 and @xmath54 correspond to a channel , and each occurence of this symbol in a trace of @xmath55 correspond to an event , i.e. a high or low transition , on the corresponding channel .",
    "symbols in @xmath53 or @xmath54 describe communication actions that are respectively produced by the environment or ( exclusive or ) by the circuit .    in order to be able to ignore transmission delays while avoiding transmission and computing interferences ,",
    "the following rules may be imposed @xcite .",
    "& & * r_0 * sr , ar s a a r + & & * r_1 * s , t r , ( a , br ) ( a , br ) + & & s a b t r s b a t r + & & * r_2 * s , t r , ( ar br ) ( ar br ) + & & ( s a b r s b a r ) ( s a b t r s b a t r ) rule @xmath75 excludes two consecutive transitions on the same wire , and hence transmission interferences that may result .",
    "rule @xmath76 expresses independence of computation on the order of signals travelling in the same direction , as this order may depend on suffered delays .",
    "the _ c - element _ is easily seen to satisfy this rule .",
    "however , the _ and _ gate only complies with the rule when it is waiting for a rising edge on its two inputs , and does not in all other cases .",
    "thus the _ and _ gate , and also the _ or _ gate are excluded by this rule , although the _ toggle _ , the _ merge _ and the _ sequencer _ are compatible .",
    "rule @xmath77 expresses the same property for signals travelling in opposite directions , in case their order does not change the result locally .",
    "note that due to the necessary symmetric treatment of a circuit and its environment , all rules are symmetric in the exchange of input and output symbols .",
    "one must exclude the possibility for a symbol of one type to disable a symbol of another type ( symbol @xmath58 is said to disable symbol @xmath59 in trace structure @xmath64 , if there is a trace @xmath61 with @xmath78 ) .",
    "such exclusion is necessary to prevent an admissible input symbol to get disabled by an output signal , depending on the delay the former has suffered on its way to the circuit ( by symmetry the same property must also hold for the environment and output signals ) . depending on the level of exclusion , this property leads to define three classes , with rules @xmath79 , @xmath80 and @xmath81 : & & * r_3^ * s , a= br + & & ( s a r s b r ) s a b r & & * r_3^ * s , a= br ar br + & & ( s a r s b r ) s a b r & & * r_3^ * s , ( ar br ) ( ar br ) + & & ( s a r s b r ) s a b r these rules successively allow for more decision possibility .",
    "rule @xmath79 does not permit data transmission and is called synchronization class ( an example is provided by the _ c - element _ ) .",
    "rule @xmath80 allows for two inputs to disable each other and is called data communication class . with rule @xmath81 , a circuit may choose between two output symbols and belongs to the arbitration class .",
    "finally , rule @xmath77 appears on specific examples to be too restrictive @xcite .",
    "an alternative and more generally efficient rule is provided by : & & * r_2^ * s , t r , ( a , cr br ) ( a , cr br ) + & & ( s a b t cr s b a tr ) s b a t c r this rule , which is conveniently expressed on a space - time graph , as shown in figure  12 , concerns three events @xmath58 , @xmath59 , @xmath60 connecting one module m and its environment @xmath82 .",
    "it stipulates that , if two time orders are allowed for the occurences of two events of different types ( i.e. one input and one output ) @xmath58 and @xmath59 , then if the event @xmath60 , of the same type as @xmath58 , is a consequence of the order `` @xmath58 then @xmath59 '' , it should also be a consequence of the other order `` @xmath59 then @xmath58 '' .",
    "this rule imposes that if an order on events is differently seen by a module and its environment , due to propagation time delays , then this order should have no consequence on the logical behavior of the module .",
    "as illustrated by figure  12 , this rule only affects the case on the left part of the figure , that is , only the case when propagation can change the order of events .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 2104,1932)(1159,-2368 ) ( 1216,-601)(0,0)[lb ] ( 1576,-2311)(0,0)[lb ] ( 2071,-2311)(0,0)[lb ] ( 2701,-2311)(0,0)[lb ] ( 3196,-2311)(0,0)[lb ] ( 1756,-1141)(0,0)[lb ] ( 2881,-1051)(0,0)[lb ] ( 1756,-1951)(0,0)[lb ] ( 1756,-1501)(0,0)[lb ] ( 2881,-1906)(0,0)[lb ] ( 2881,-1546)(0,0)[lb ]    fig .",
    "space - time graph for rule @xmath83 .",
    "the set of di components is given by trace structures , defined according to definitions 1 and 2 , which satisfy the weakest form of the rules , i.e. @xmath84 , @xmath85 , @xmath86 and @xmath87 @xcite .",
    "a set of di primitive components for asynchronous circuits can thus be obtained with the following list of specifications in terms of trace structures ( see table  1 ) .",
    ".di primitive components [ cols=\"^,^\",options=\"header \" , ]     [ table1 ]    the _ wire _ corresponds to a component which waits for an event to occur on its input , then sends an event on its output , and repeats this sequence indefinitely .",
    "the inverted wire ( _ iwire _ ) behaves similarly , but begins by sending an event on its output .",
    "the _ fork _ duplicates one input . as can be seen from definitions ( [ operations ] ) , weaving not only consists in putting in parallel , but also in synchronizing common output symbols . in the particular case of two _",
    "wires _ with a common output , weaving leads to the _ c - element_. the other components correspond to the primitive circuits which have been previously introduced ( see figure  9 ) .    the objective is to realize circuits corresponding to given complex specifications by combining simple di primitive circuits . this aim may be attained by making use of operations such as decomposition and substitution , together with two theorems setting the conditions for performing these operations .",
    "a component @xmath84 is said to be decomposed into components @xmath88 ( for @xmath89 if the following conditions are satisfied .",
    "letting @xmath90 [ decomposition ] & & ( i ) _ 0i < n ( * o*s_i ) = _ 0i",
    "< n ( * i*s_i ) + & & ( ii ) * o*s_i s_j = , 0i , j < n i= j + & & ( iii ) t , x , i ( 0i < n ) + & & tt xs_i txs_i s_i txt + & & ( iv)*t*ts_0 = * t*s_0    conditions in ( [ decomposition ] ) respectively describe a closed network ( each input is connected to an output and conversely ( i ) ) , absence of output interferences ( two outputs can not be connected ( ii ) ) , absence of computing interferences ( any event produced by a component is compatible with the behavior of the component which receives it ( iii ) ) and correct behavior at circuit boundary ( network behaves as prescribed ( iv ) ) .",
    "decomposition will be denoted by @xmath91 .",
    "let us now state two useful theorems ( proofs may be obtained in @xcite ) .    for components @xmath84 , @xmath85 , @xmath92 , @xmath93 and @xmath94 & & r_0 ( r_1 , s ) s ( r_2 , r_3 )",
    "+ & & r_0 ( r_1 , r_2 , r_3)holds if ( * a*r_0 r_1 ) ( * a*r_2 r_3 ) = * a*s    the latter condition stipulates that internal symbols of @xmath94 , i.e. symbols in @xmath95 , where @xmath96 means set deletion , should not appear in @xmath97 .",
    "it can be realized by an appropriate renaming of internal symbols of @xmath94 .",
    "[ theorem]separation theorem    for components @xmath98 and @xmath99 ( @xmath100 ) & & r_0 ( r_i)_1i < n s_0 ( s_i)_1i < n + & & r_0||s_0 ( r_i||s_i)_1i < n holds if & & ( _ 1i < n(*a*r_i ) \\*a*r_0 ) ( _ 1i",
    "< n(*a*s_i ) \\*a*s_0 ) = [ sep1 ] + & & , 1i= j <",
    "n + & & ( * o*r_i s_i ) ( * o*r_j s_j ) = + & & ( * o*r_i s_i ) ( * o*|r_0 ) = [ sep2 ]    condition ( [ sep1 ] ) stipulates that the internal symbols of the decompositions of @xmath84 and @xmath101 are disjoint ( this condition may be satisfied by renaming some of these symbols ) , and conditions ( [ sep2 ] ) stipulate that the outputs of any two components @xmath102 and @xmath103 are also disjoint when the components are different ( these conditions may also be satisfied by reordering the components ) .    with the help of these two theorems , the previously defined di",
    "primitives may be combined to give modular compositions which are delay insensitive , hence circuits where computing interferences can not be introduced by delay modifications only .",
    "we briefly describe an example of a circuit which can be obtained with such a composition of di primitives , the _ token - ring _",
    "interface @xcite . the _ token - ring _",
    "interface is a device allowing to connect several machines , which must share a common resource ( like a memory , or a bus ) .",
    "one item @xmath104 of this device will be associated with each machine @xmath105 , all items being identical and realizing the same function , as shown by figure  13 .",
    "item @xmath104 of this device is connected to two environments , the machine @xmath105 on top of the figure , and , at bottom , the ring @xmath64 where a token circulates .",
    "the arrival of the token at @xmath104 corresponds to an event on @xmath59 , its departure to an event on @xmath106 . the machine @xmath105 can make a request under the form of an event on @xmath107 . @xmath104",
    "grants the resource to the machine @xmath105 by an event on @xmath108 . the machine @xmath105 signals the end of its use of the resource by an event on @xmath109 , which is acknowledged by @xmath104 under the form of an event on @xmath110 .    initially ,",
    "the _ token - ring _",
    "interface is specified by the following trace structure : & & * [ a1?;p1!;a0?;p0 ! ] + & & || * pref**[b?;(q!|p1!;a0?;q ! ) ] this specification results from weaving two trace structures which respectively describe the communications of the token - ring interface with the machine @xmath105 and with the ring @xmath64 .",
    "the two trace stuctures interact through their common dependence on two events @xmath111 and @xmath112 .",
    "each trace structure may be decomposed into primitive elements .",
    "substitution and separation theorems may be applied , finally leading to a possible decomposition , as shown by figure  13 in a graphic way : ( & & * [ a1?;p1 ! ] + & & || * pref**[rq1?;q1 ! ] + & & || * pref**[b?;(q1!|p1!)],@xmath113,\\ ] ] @xmath114,\\ ] ] @xmath115,\\ ] ] * [ ( q1?|q0?);q ! ) ] ) [ token - dec ] the first component is a _ sequencer _ ( see table  1 ) , necessary for synchronizing the output @xmath111 shared by the two trace structures defining the _ token - ring_. the _ sequencer _ also arbitrates between corresponding inputs .",
    "other components describe an _ iwire _ , two _ wires _ and a _ merge_. although they do not appear explicitly in decomposition ( [ token - dec ] ) , two forks appear in figure  13 , as a consequence of double occurences of @xmath116 and @xmath117 in ( [ token - dec ] ) .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 2814,2953)(1564,-4169 ) ( 3646,-2536)(0,0)[lb ] ( 4186,-1726)(0,0)[lb ] ( 3241,-2311)(0,0)[lb ] ( 2341,-2311)(0,0)[lb ] ( 3151,-2536)(0,0)[lb ] ( 3556,-1726)(0,0)[lb ] ( 2161,-2356)(0,0)[lb ] ( 3691,-2986)(0,0)[lb ] ( 2341,-2896)(0,0)[lb ] ( 2521,-3886)(0,0)[lb ] ( 3961,-3886)(0,0)[lb ] ( 2116,-1726)(0,0)[lb ] ( 1621,-3481)(0,0)[lb ] ( 2116,-2581)(0,0)[lb ] ( 2611,-2761)(0,0)[lb ] ( 1576,-1726)(0,0)[lb ] ( 2611,-3301)(0,0)[lb ] ( 2926,-4111)(0,0)[lb ] ( 2386,-1411)(0,0)[lb ]    fig . 13 .",
    "token - ring interface .",
    "the di property of this implementation can be visualized on a space - time graph , as in figure  14 .",
    "two cases have been represented in figure  14 . in the first case ,",
    "the request @xmath107 done by the machine @xmath118 is not granted , the token being sent back to the ring . when the token arrives a second time , the resource is granted to the machine @xmath105 which was waiting .",
    "this illustrates the undeterministic behavior of the module @xmath119 , which depends on arbitration performed by _ sequencer _ b. the figure also shows that the two forks , that on @xmath120 ( output of b ) and that defined by d can not create computation interferences , so that no particular constraints are necessary .",
    "this results from the function of _ sequencer _ b , which is not perturbed whatever the order of the events on its inputs .",
    "_ sequencer _ b waits for an event on @xmath59 to make a decision , and then arbitrates between the different requests it has received .    as shown by the example of the _ token - ring _ interface , di primitives and di decomposition",
    "may be used to generate modular compositions which are delay insensitive , and , as shown with the help of space - time graphs , that remain free of computing interferences .",
    "delay - insensitivity appears as a simple criterion for escaping problems raised by computing interferences in a purely logically way , i.e. without recourse to a detailed analysis of the physical implementation of a circuit .",
    "the di criterion allows one to treat asynchronous circuits efficiently , like in the case of synchronous circuits , by allowing to represent them formally ( in terms of trace structures ) .",
    "although revealing a genuinely different underlying structure , the causal constraints on asynchronous circuits , as exhibited by space - time graphs , can nonetheless be embedded in a simple set of formal rules which limit the definition and composition of di circuits . in general , these rules allow di circuits to be decomposed into a number of di primitive components which increases linearly with the length of the circuit specification @xcite .",
    "( 0,0 )    # 1#2#3#4#5 @font    ( 3082,5532)(1306,-6418 ) ( 2071,-4606)(0,0)[lb ] ( 3421,-2086)(0,0)[lb ] ( 2296,-2401)(0,0)[lb ] ( 4051,-2761)(0,0)[lb ] ( 2296,-3436)(0,0)[lb ] ( 1756,-4381)(0,0)[lb ] ( 3421,-5281)(0,0)[lb ] ( 1756,-5281)(0,0)[lb ] ( 1621,-6181)(0,0)[lb ] ( 2161,-6181)(0,0)[lb ] ( 3241,-6181)(0,0)[lb ] ( 3781,-6181)(0,0)[lb ] ( 4321,-6181)(0,0)[lb ] ( 2656,-6181)(0,0)[lb ] ( 1486,-1051)(0,0)[lb ] ( 2926,-2761)(0,0)[lb ] ( 3466,-2806)(0,0)[lb ] ( 2971,-3391)(0,0)[lb ] ( 3421,-3931)(0,0)[lb ] ( 4006,-4561)(0,0)[lb ] ( 1891,-4741)(0,0)[lb ] ( 2341,-5731)(0,0)[lb ] ( 3376,-4561)(0,0)[lb ] ( 1606,-3706)(0,0)[lb ]    fig . 14 .",
    "space - time graph of the token - ring interface .",
    "without giving definite answers to the problems raised in the introduction , we have nethertheless tried to provide some hints on the essential role played by physical time in computation .",
    "the necessary reference to physical time in physical implementations of logical circuits forces one to give an explicit treatment of computation interferences . these arise as obstructions",
    "when trying to make the causality underlying logical circuits coincide with the physical causality of their implementations . for synchronous circuits ,",
    "these may be avoided by ruling the whole circuit with a single clock , which thus provides a global reference to a newtonian time . in general",
    "however , circuits must be considered as asynchronous and physical space - time as relativistic . in the latter ,",
    "not all points are causally related , but only those such that one point falls within the light cone issued from the other . in that respect ,",
    "asynchronous circuits and relativistic space - time share the same founding point of view .",
    "points derive from events and not the converse , propagating events being treated as primary entities and not as successions of points .",
    "the distinction between two classes of points can also be seen in a simple way : two points are causally related if and only if there exists a path between them using vertical or propagation lines ( in different spatial directions , but in the same time direction ) ; on another hand , points defined on two different events originating from the same point are not causally related @xcite .",
    "similarly for a concurrent computation , each computing path connects points which are causally related . avoiding computing interferences corresponds to impose that different computing paths respect a same time ordering , but only for pairs of causally related points .",
    "remedies to computing interferences in asynchronous circuits consist in recognizing paths which may conflict with a module specification , and in eventually delaying these paths , so that to respect a prescribed time ordering .",
    "this can be done either physically , at the implementation level by introducing explicit time delays , or at the logical level , by imposing specification rules which prevent the occurence of such conflicts .",
    "the latter solution , by imposing delay insensitivity both on circuits specification and decomposition in a consistent way , has the advantage of providing a purely logical characterization of the causal constraints .",
    "di circuits then build a class which may be seen as intermediate between synchronous circuits and general asynchronous circuits .",
    "they share with the former the possibility to be completely characterized by formal expressions and rules .",
    "but they rely on the same causal structure as the latter .",
    "synchronous circuits rely on time simultaneity classes , and thus on a causal structure which is typical of newtonian space - time .",
    "asynchronous circuits , on another hand , rely on a consistent treatment of propagation delays and time ordering , hence on a causal structure which characterizes relativistic space - time .",
    "delay - insensitivity provides an interesting transition between local properties , like those defining sequential processors , and global ones , like those exhibited by distributed systems .",
    "but di circuits hardly exhaust the computation potentialities brought by the introduction of asynchronous circuits",
    ". the critical consequences of delay sensitivity rather suggest to consider a further alternative when attempting to classify the different types of computations , i.e. those performed by synchronous , by di asynchronous and by ds ( delay - sensitive ) asynchronous circuits .",
    "similarly , in the same way as asynchronous computing machines may not always allow simulation by synchronous computing machines , one may infer that physical processes and physical laws , which intrinsically obey relativistic causality , may be simulated by synchronous machines in particular cases only .",
    "this hints at another advantage of computations based on asynchronous circuits , i.e. the ability to simulate in a universal way real physical processes .",
    "chakraborty ,  s. , yun ,  k.y . and dill ,  d.l .",
    "( 1988 ) practical timing analysis of asynchronous circuits using time separation of events .",
    "_ proceedings of the ieee custom integrated circuits conference _ , 455458 .",
    "ieee computer society press ( may ) .",
    "davis ,  a. and nowick ,  s.m .",
    "( 1995 ) asynchronous circuit design : motivation , background and methods .",
    "in g.  birtwistle and a.  davis ( editors ) , _ asynchronous digital circuit design , workshop in computing _ , 149 .",
    "bcs - springer .",
    "furber , s. ( 1995 ) computing without clocks : micropipelining the arm processor . in g.",
    "birtwistle and a.  davis ( editors ) , _ asynchronous digital circuit design , workshop in computing _",
    ", 211262 .",
    "bcs - springer .",
    "jaekel ,  m.t . and",
    "reynaud ,  s. ( 1998 ) quantum observables associated with einstein localisation . in e.",
    "zavattini , d.  bakalov and c.  rizzo ( editors ) , _ frontier tests of qed and physics of the vacuum ( sandansky , 1998 ) _",
    ", 389404 .",
    "heron press .",
    "mallon , w.c .",
    ", udding , j.t . and verhoeff , t. ( 1999 ) analysis and applications of the xdi model . in",
    "async99 , proc . international symposium on advanced research in asynchronous circuits and systems _ , 231242 .",
    "ieee computer society press .",
    "martin , a.j .",
    "( 1990b ) the limitations to delay - insensitivity in asynchronous circuits . in w.  j.",
    "dally ( editor ) _ advanced research in vlsi : proceedings of the sixth mit conference _ , 263278 .",
    "mit press , cambridge , ma .",
    "martin , a.j . , lines , a. , manohar , r. , nystrm , m. , penzes , p. , southworth , r. , cummings , u. and tak - kwan - lee ( 1997 ) the design of an asynchronous mips r3000 microprocessor . in _ proceedings of the seventeenth conference on advanced research in vlsi _ , 164181 .",
    "ieee computer society press .",
    "matherat , p. and jaekel , m.t .",
    "( 1996 ) dissipation logique des implmentations dautomates - dissipation du calcul .",
    "_ technique et science informatiques _ * 15*(8 ) , 10791104 .",
    "english translation at the url http://www.arxiv.org/abs/quant-ph/9805018 .",
    "mazurkiewicz , a. ( 1989 ) basic notions of trace theory . in j.  w. de  bakker , w.  p.",
    "de  roever , and g.  rozenberg ( editors ) _ linear time , branching time , and partial order in logics and models for concurrency .",
    "lncs 354 _ , 285 .",
    "springer - verlag .",
    "school / workshop , noordwijkerhout , the nederlands , may - june 1988 .",
    "stevens , k. , ginosar , r. and rotem , s. ( 1999 ) relative timing . in _",
    "async99 , proc . international symposium on advanced research in asynchronous circuits and systems _ , 208218 .",
    "ieee computer society press .",
    "winskel , g. ( 1989 ) an introduction to event structures . in j.",
    "w. de  bakker , w.  p. de  roever , and g.  rozenberg ( editors ) _ linear time , branching time , and partial order in logics and models for concurrency .",
    "lncs 354 _ , 364397 .",
    "springer - verlag .",
    "school / workshop , noordwijkerhout , the nederlands , may - june 1988 ."
  ],
  "abstract_text": [
    "<S> concrete computing machines , either sequential or concurrent , rely on an intimate relation between computation and time . </S>",
    "<S> we recall the general characteristic properties of physical time and of present realizations of computing systems . </S>",
    "<S> we emphasize the role of computing interferences , i.e. the necessity to avoid them in order to give a causal implementation to logical operations . </S>",
    "<S> we compare synchronous and asynchronous systems , and make a brief survey of some methods used to deal with computing interferences . using a graphic representation , we show that synchronous and asynchronous circuits reflect the same opposition as the newtonian and relativistic causal structures for physical space - time . </S>"
  ]
}