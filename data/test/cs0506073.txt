{
  "article_text": [
    "reed - solomon ( rs ) codes are one of the most popular error correction codes in many state - of - the - art communication and recording systems . in most of these existing systems ,",
    "rs codes are decoded via an algebraic hard decision decoding ( hdd ) algorithm . when soft information about the channel output is available , hdd can incur a significant performance loss compared to optimal soft decision decoding .",
    "for example , for the awgn channel , the loss is believed to be about 2 - 3  db . moreover , in some situations , it is desirable to obtain soft output from the decoder .",
    "a typical example is when turbo equalization is employed at the receiver and soft outputs from the decoder have to be fedback to the equalizer .",
    "consequently , soft - input - soft - output ( siso ) decoding algorithms for rs codes are of research interest both for theoretical and practical reasons .    in the literature",
    ", there are several classes of soft decision decoding algorithms .",
    "enhanced hdd algorithms such as generalized minimum distance ( gmd ) decoding @xcite , chase decoding @xcite and a hybrid of chase and gmd algorithms ( cga ) @xcite use reliability information to assist hdd decoding .",
    "enhanced hdd usually gives a moderate performance improvement over hdd with reasonable complexity .",
    "recently , algebraic soft interpolation based decoding ( the koetter - vardy ( kv ) algorithm @xcite ) , which is a list decoding technique that uses the soft information from the channel to interpolate each symbol , has become popular @xcite @xcite @xcite .",
    "the kv algorithm can significantly outperform hdd for low rate rs codes .",
    "however , to achieve large coding gain , the complexity can be prohibitively large . for detailed discussions of the complexity performance tradeoff of the kv algorithm",
    ", we refer interested readers to @xcite .",
    "another approach is decoding rs codes using their binary image expansions .",
    "vardy and beery showed that rs codes can be decomposed into bch subfield subcodes which are glued together using glue vectors @xcite .",
    "even though this decomposition significantly reduces the trellis complexity of maximum likelihood ( ml ) decoding of rs codes , the complexity still grows exponentially with the code length and @xmath0 and it is thus infeasible for practical long codes .",
    "recent work @xcite reduces the complexity and modifies the algorithm in @xcite to generate soft output efficiently . by using the binary image expansion of rs codes",
    ", we can also use decoding algorithms for general linear block codes such as reliability based ordered statistics decoding ( osd ) @xcite and its variations @xcite for soft decision decoding of rs codes .",
    "previous such works include the hybrid algorithm by hu and shu lin @xcite and the box and match algorithm ( bma ) @xcite by fossorier and valembois .",
    "osd based algorithms are quite efficient for practical rs codes even though they do not take the structure of the rs codes into account .",
    "iterative decoding @xcite algorithms are of emerging interest for soft decision decoding of rs codes @xcite , @xcite , @xcite .",
    "the main difficulty in directly applying iterative decoding techniques to rs codes is that the parity check matrix of an rs code is in general not sparse . in order to deal with such dense parity check matrices , yedidia @xmath1",
    "@xcite proposed a `` generalized belief propagation '' ( gbp ) algorithm that introduces hidden states in iterative decoding .",
    "however , their results show that this technique does not work well for high density parity check ( hdpc ) codes ( such as rs codes ) over the awgn channel .",
    "we observe from the simulations that the iterative decoder fails mainly due to some of the unreliable bits `` saturating '' most of the checks which causes iterative decoding to be stuck at some pseudo - equilibrium points . in @xcite , the cyclic structure of rs codes",
    "is taken advantage of and a sum product algorithm ( spa ) is applied to a random shift of the received vector at each iteration to avoid pseudo - equilibrium points ( see @xcite for details ) .",
    "while significant improvement in performance over hdd was obtained for short codes , the performance improvement diminishes for long rs codes .    in this paper , we present an iterative siso decoding algorithm ( which is based on the spa ) for rs codes . the main novelty in the proposed scheme is to adapt the parity check matrix at each iteration according to the bit reliabilities such that the unreliable bits correspond to a sparse submatrix and the spa is then applied to the adapted parity check matrix .",
    "this adaptation prevents the iterative decoder from getting stuck at pseudo - equilibrium points and , hence , the convergence behavior of the iterative decoder is significantly improved .",
    "simulation results show that the proposed iterative decoding scheme performs well for rs codes with reasonable decoding complexity , even though the parity check matrices are not sparse . while the approach in @xcite is also one of adapting the parity check matrix , the adaptation there is restricted to be within the class of cyclic shifts of the parity check matrix , whereas we consider a more general adaptation procedure here which is based on the bit reliabilities .",
    "the proposed algorithm can be applied to any linear block code ; however , we restrict our attention to rs codes in this paper because of the practical interest in soft decision decoding of rs codes and the fact that the gain from this adaptive procedure is significant for codes with dense parity check matrices such as rs codes .    the rest of the paper is organized as follows : the generic iterative decoding algorithm is presented in section [ sec : algorithm ] .",
    "a geometric interpretation of the proposed algorithm is given in section [ sec : geometry ] .",
    "several variations of the generic algorithm are investigated in section [ sec : variations ] . in section [ sec : sim ] , simulation results of the proposed algorithm are presented and compared with popular rs soft decoding algorithms . discussions and conclusions are presented in section [ sec : conclusion ] .",
    "consider a narrow sense @xmath2 rs code over @xmath3 which has a minimum distance @xmath4 . the parity check matrix over @xmath3 can be represented as follows :    @xmath5    where @xmath6 is a primitive element in @xmath3 .",
    "let @xmath7 and @xmath8 be the length of the codeword and the information at the bit level , respectively .",
    "@xmath9 has an equivalent binary image expansion @xmath10 ( see @xcite for details ) , where @xmath10 is an @xmath11 binary parity check matrix .",
    "we will use underlined letters to denote vectors and bold face letters to denote matrices . let @xmath12",
    "$ ] be the binary representation of an rs codeword . in the description of the generic algorithm",
    ", we first assume that the bits are modulated using bpsk ( with @xmath13 mapped to @xmath14 and @xmath15 mapped to @xmath16 ) and transmitted over an awgn channel ( extension to other channels is straightforward ) .",
    "the received vector is given by    @xmath17    thus , the initial reliability of each bit in the received vector can be expressed in terms of the log - likelihood ratios ( llr ) as observed from the channel :    @xmath18    the proposed algorithm is composed of two stages : the matrix updating stage and the bit - reliability updating stage . in the matrix updating stage , the magnitude of the received llr s @xmath19 are first sorted and let @xmath20 denote the position of the bits in terms of ascending order of @xmath19 , i.e. , the bit @xmath21 is the least reliable and @xmath22 is the most reliable .",
    "we begin with the original parity check matrix * h@xmath23 * and first reduce the @xmath24 column of * h@xmath23 * to a form @xmath25^t$ ] .",
    "then , we reduce the @xmath26 column of * h@xmath23 * to a form @xmath27^t$ ] and so on .",
    "we can be guaranteed to proceed until the @xmath28 column , since there are at least @xmath29 independent columns in * h@xmath23*. then we try to reduce the @xmath30 column to @xmath31^t$ ] .",
    "however , there is no guarantee we can do this .",
    "if we are unable to do so , we will leave that particular column and try to reduce @xmath32 column to the above form and so on .",
    "finally , we can reduce @xmath33 columns among the @xmath34 columns of * h@xmath23 * to be the identity matrix , since the matrix is @xmath11 and is full rank .",
    "the matrix is thus reduced to a form as shown in fig .",
    "[ matrixform ] .",
    "we denote the set of unreliable bits corresponding to the sparse submatrix as @xmath35 .",
    "the proposed algorithm is iterative and during the @xmath36 iteration , we have a vector of llr s as :    @xmath37\\ ] ]    where initially @xmath38 is determined from the channel output .",
    "then , the parity check matrix is reduced to a desired form based on @xmath39 :    @xmath40    in the bit - reliability updating stage , the extrinsic llr vector @xmath41 is first generated according to @xmath39 using the spa @xcite based on the adapted parity check matrix @xmath42 :    @xmath43    that is for each bit , the extrinsic llr is updated according to : @xmath44    the bit - reliability is then updated as : @xmath45 where @xmath46 is a damping coefficient .",
    "this is continued until a predetermined number of times @xmath47 or until all the parity checks are satisfied .",
    "a detailed description of the algorithm is given in algorithm [ alg : generic ] .",
    "* : :    initialization : set @xmath48 , @xmath47 ,    @xmath49 and the llr s for the coded bits from the channel    observation :    @xmath50 * step2 . * : :    reliability based parity check matrix adaptation :    @xmath51 .",
    "+    \\a ) order the coded bits according to the absolute value of the llr s",
    "@xmath52 and record the ordering    indices .",
    "+    \\b ) implement gaussian elimination to systematize the    @xmath33 unreliable positions which are independent in the    parity check matrix .",
    "( the submatrix can also be made to be degree-2    connected , see section [ subsec : deg2 ] ) .",
    "* : :    extrinsic information generation : apply spa to generate the extrinsic    llr for each bit using the adapted parity check matrix    @xmath42 :    +    @xmath53    ( according to ( [ ext_update ] ) ) .",
    "* : :    bit - level reliabilities update :    +    @xmath54 , where    @xmath55 .",
    "* : :    hard decision : @xmath56 * step6 . *",
    ": :    termination criterion : if all the checks are satisfied , output the    estimated bits ; else if @xmath57 , declare a decoding    failure ; otherwise set @xmath58 and go to    * step2 * for another iteration .",
    "the proposed adaptive algorithm is inspired by the osd @xcite .",
    "however , instead of reprocessing the most reliable basis ( mrb ) , we adapt the parity check matrix according to the least reliable basis ( lrb ) .",
    "it can also be viewed as a generalization of the iterative _ a posteriori _ probability ( app ) decoding algorithm based on a set of minimum weight parity check vectors by lucas _",
    "_ @xcite . in @xcite ,",
    "the iterative algorithm is interpreted as a gradient descent .",
    "the adaptive algorithm generalizes the idea of gradient descent and extends it to be a two - stage gradient descent algorithm with an adaptive potential function .",
    "the damping coefficient @xmath48 serves as the step size in the gradient descent process to control the dynamics of convergence . in the following section",
    ", we look into a geometric interpretation of this algorithm .",
    "in this section , a geometric interpretation of the proposed algorithm as a two - stage optimization procedure is presented .",
    "the idea of using optimization methods , such as gradient descent , to solve decoding problems can be dated back to farrell _ et al .",
    "_ @xcite . the belief propagation ( bp ) based algorithms by gallager @xcite and pearl @xcite",
    "were also shown to be special cases of the gradient descent algorithm .",
    "the bit reliability updating algorithm in this paper is more similar to that proposed by lucas _",
    "_ in @xcite .",
    "define the operator @xmath59\\rightarrow[-1,1]$ ] as a mapping from the llr domain to @xmath60 domain : @xmath61 where the mapping is one - to - one and onto .",
    "it is immediate that the inverse operator @xmath62\\rightarrow[-\\infty,+\\infty]$ ] can be expressed as : @xmath63\\ ] ]    we apply the one - to - one @xmath60 transform on the llr s and get the reliability measure of the received signal in the @xmath60 domain as : @xmath64 = [ \\nu(l(c_1 ) ) , \\cdots , \\nu(l(c_n))]\\ ] ] as in @xcite , we can measure the reliability of the @xmath65 parity check node as : @xmath66    following the concept of a generalized weighted syndrome proposed by lucas _",
    "( eqn . ( 20 ) in @xcite ) , we define a cost function @xmath67 , which characterizes the reliability of the received vector @xmath68 with a particular parity check matrix @xmath69 .",
    "[ defn : soft syndrome sum ] define the potential function @xmath67 as : @xmath70    where @xmath67 is a function of both the parity check matrix @xmath10 and the received soft information @xmath68 .",
    "the operator @xmath71 maps the original @xmath34-dimensional unbounded real space into an @xmath34-dimensional cube ( since the output of the @xmath60 function is confined to [ -1 , 1 ] ) .",
    "the potential function @xmath67 is minimized iff a valid codeword is reached , that is all the checks are satisfied and @xmath72 for @xmath73 , where @xmath74 . besides , points with all @xmath72 correspond to vertices of the @xmath34-dimensional cube .",
    "therefore , valid codewords correspond to the vertices of the @xmath34-dimensional cube at which the potential function has the minimum value of @xmath75 .",
    "the decoding problem can be interpreted as searching for the most probable minimum potential vertex given the initial point observed from the channel .",
    "note that the potential function @xmath67 is minimized iff a valid codeword is reached .",
    "it is quite natural to apply the gradient descent algorithm to search for the minimum potential vertex , with the initial value _ _ observed from the channel .",
    "consider the gradient of @xmath67 with respect to the received vector @xmath68 .",
    "from ( [ eqn : soft syndrome sum ] ) , it can be seen that : @xmath76 where the component wise partial derivative with respect to @xmath77 is given by : @xmath78 thus , the gradient descent updating rule can be written as : @xmath79 where @xmath48 is a damping coefficient as in standard gradient descent algorithms to control the step width .",
    "note that the reliabilities in @xmath60 domain are confined to @xmath80 $ ] .",
    "however , the updating rule ( [ eqn : gradient update ] ) does not guarantee this .",
    "therefore , we use the following modified updating rule to guarantee that the updated @xmath77 s @xmath81 $ ] : @xmath82\\right)\\ ] ] where @xmath83 .",
    "it can be seen that the above non - linear updating rule is exactly the same as step 3-step 4 in algorithm [ alg : generic ] .    when iterative decoding is applied to an hdpc code , with very high probability",
    ", the iterative algorithm will reach some local minimum points where @xmath84 is zero or is close to zero ( since a few unreliable symbols will render the components of @xmath85 to be small or close to zero ) .",
    "we refer to these as pseudo - equilibrium points since gradient descent gets stuck at these points while these points do not correspond to valid codewords .    from ( [ eqn : soft syndrome sum ] )",
    ", we observe that since @xmath67 is also a function of @xmath10 , different choices of the parity check matrices @xmath10 , though span the same dual space , result in different potential functions @xmath67 .",
    "more importantly , each @xmath10 results in a different gradient @xmath84 .",
    "the proposed algorithm exploits this fact and when a pseudo equilibrium point is reached , by adapting the parity check matrix based on the bit reliabilities , switches to another @xmath10 such that it allows the update in ( [ eqn : llr gradient update ] ) to proceed rather than getting stuck at the pseudo - equilibrium point .",
    "however , note that the potential function that we want to minimize does not involve the euclidean distance between the received codeword and current estimate at all . that is , the adaptive algorithm attempts merely to find a codeword that satisfies all the parity checks , without really enforcing that it be the one at minimum distance from the received word .",
    "since small steps are taken in the gradient descent , very often we converge to the codeword at small distance from the received vector as well . however , there is no guarantee of convergence to the nearest codeword .",
    "we use the following examples to show the operation of the adaptive algorithm and its difference from directly applying iterative decoding to an hdpc code .    consider decoding of a random linear block code where each entry of the parity check matrix is i.i.d and 0 or 1 with equal probability over an erasure channel .",
    "we first apply the gradient descent algorithm directly to hdpc codes without reliability based adaptation .",
    "assume that the erasure fraction is @xmath86 , therefore the number of erased bits is @xmath87 .",
    "consider a particular parity check , any code bit will participate in that check with probability 1/2 ( according to the i.i.d .",
    "equiprobable assumption ) .",
    "a check is not erased iff all the participated bits are not erased .",
    "therefore , the probability that the @xmath88 check is erased is    @xmath89    assume that the @xmath90 bit is erased and it participates in @xmath91 parity checks in the parity check matrix .",
    "the @xmath90 component of the gradient vector is zero ( i.e. , @xmath92 ) iff the extrinsic llr s from all the checks it participates in are erased .",
    "the probability that the @xmath90 component of the gradient is zero is : @xmath93^r\\\\ \\nonumber&\\doteq 1-r2^{-(n\\epsilon-1)}+o(2^{-(n\\epsilon-1)})\\\\ & \\doteq 1-r2^{-(n\\epsilon-1)}\\rightarrow 1 , n \\rightarrow \\infty\\end{aligned}\\ ] ] which suggests that unless the number of parity checks grows exponentially with @xmath87 , iterative decoding gets stuck at a pseudo - equilibrium point with high probability .    on the other hand , for the bec",
    ", it is known that by adapting the parity check matrix corresponding to less reliable bits ( i.e. the erased bits ) , ml decoding performance can be achieved @xcite in one iteration . if the gaussian elimination is successful , then all the erasures can be recovered .",
    "gaussian elimination will not be successful iff some of the columns corresponding to the erased bits are dependent . in this case",
    ", there is ambiguity between two or more valid codewords .",
    "that is , the ml decoder also fails .    in conclusion , for the bec , gradient descent without adaptation tends to get stuck at a pseudo - equilibrium point , while the reliability based adaptation will help gradient descent to converge to the ml solution in one iteration .    the idea of reliability based parity check matrix adaptation can naturally be extended to awgn channels and the insight remains the same .",
    "though adapting the parity check matrix based on the channel output does not guarantee convergence to the ml decision for awgn channels , it does avoid iterative decoding getting stuck at pseudo - equilibrium points and thus improves the convergence behavior .",
    "we give a numerical example of the convergence behavior of iterative decoding of an rs(31,25 ) code in figure [ fig : convergence ] . a typical realization of iterative decoding",
    "is simulated . the potential function @xmath67 is plotted against the number of iterations . since there are 30 parity checks for rs(31 , 25 ) , the minimum value of the potential function is @xmath94 ( corresponding to valid codewords ) .",
    "we can see that due to the high density of the parity check matrix of the rs code , iterative decoding without matrix adaptation ( algorithm [ alg : generic ] without step 2 ) gets stuck at some pseudo - equilibrium .",
    "on the other hand , when the iterative algorithm is applied in conjunction with reliability based parity check matrix adaptation ( algorithm [ alg : generic ] ) , the value of @xmath67 quickly goes to the global minimum as the number of iteration increases .",
    "consequently , reliability based parity check matrix adaptation improves the convergence behavior of iterative decoding significantly .",
    "we will show in section [ sec : sim ] that the adaptive algorithm also significantly improves the error performance .",
    "in this section , several variations of the proposed algorithm are discussed either to improve the performance or to reduce the decoding complexity .",
    "one problem with the proposed approach is that since each bit in the unreliable part @xmath35 participates in only one check , it receives extrinsic information from one check only .",
    "if there is a bit error in the dense part participating in that check , the bit in @xmath35 tends to be flipped and the decoder tends to converge to a wrong codeword . to overcome this drawback",
    ", we can reduce the matrix @xmath69 to a form where the submatrix corresponding to the less reliable bits is sparse ( say column weight 2 rather than 1 ) .",
    "this can improve the performance since each less reliable bit now receives more extrinsic information while the submatrix corresponding to the unreliable bits still does not form any loops ( i.e. , there is no loop involving only the unreliable bits ) .",
    "we can obtain this via a degree-2 random connection algorithm .",
    "the details are presented in algorithm [ alg : deg2 ] .",
    "* : :    apply gaussian elimination to the parity check matrix and obtain an    identity matrix in the unreliable part .",
    "* : :    generate a random permutation of numbers from 1 to n - k .",
    "record all the    indices , i.e. , @xmath95 .",
    "* : :    adapt the parity check matrix according to the follow rule : add    @xmath96 row to @xmath97 row , for i    = 1 to n - k-1 .    after the deg-2 random connection ,",
    "all the ( n - k-1 ) columns in the parity check matrix are of degree-2 except the @xmath98 column .",
    "the last column @xmath99 can be left of degree-1 , which will not significantly affect the performance .",
    "this appears to improve the performance of the proposed algorithm especially in the high snr s .",
    "another variation that can help to further improve the performance is to run the proposed algorithm several times each time with the same initial llr s from the channel but a different grouping of the less reliable bits .",
    "it is possible that some bits with @xmath100 close to those in the unreliable set @xmath35 are also of the wrong sign and vice - versa .",
    "hence , we can run the proposed algorithm several times each time with a different grouping of the less reliable bits .",
    "that is , we can swap some bits in the reliable part with those in the unreliable part near the boundary and run the matrix adaptation all over again , which gives a new @xmath69 .",
    "we then run the proposed algorithm on that new matrix @xmath69 . each time the proposed algorithm is run",
    ", a different estimate of codeword may be obtained due to the difference in the parity check matrix @xmath69 .",
    "all the returned codewords are kept in a list and finally the one that minimizes euclidean distance from the received vector is chosen .",
    "we will see from simulation results that this method can significantly improve the asymptotic performance , but also increases the worst case complexity .",
    "similar techniques have been used in conjunction with osd by fossorier @xcite and wu @xcite .",
    "the way of grouping reliable bits used here is similar to the grouping scheme by wu @xcite .",
    "we refer interested readers to @xcite for a detailed description and asymptotic performance analysis .",
    "a hard decision decoder can be used during each iteration in the proposed algorithm to improve the performance and accelerate decoding as well . since",
    "the hdd may return a codeword which is different from the ml codeword , we do not stop the decoder once a codeword is returned by the hdd .",
    "rather , we still iterate up to a maximum number of iterations to obtain all the codewords returned by hdd during each iteration and finally pick up the most likely codeword .",
    "this guarantees to perform no worse than the proposed algorithm or hdd . in practice ,",
    "error detection schemes such as a cyclic redundancy check ( crc ) or other test techniques as discussed in @xcite can serve as a practical stopping criterion to reduce the average decoding complexity . combining the adaptive scheme with other siho algorithms such as the kv algorithm",
    "has recently been investigated in @xcite .",
    "the complexity in the bit level reliabilities update part can be further reduced via `` partial reliable bits updating '' scheme .",
    "the main floating - point operation complexity comes from the computation of the extrinsic information in the reliable part ( where the submatrix is dense ) .",
    "however , in the adaptation of the parity check matrix , only some bits in the boundary will be switched from the reliable part to the unreliable part .",
    "therefore , in the bit reliability updating stage , we only update the bits in the unreliable set @xmath35 and some reliable bits with @xmath101 close to those in the unreliable set @xmath35 .",
    "for example , at each iteration , we may update the @xmath24 , @xmath102 , @xmath103 llr s rather than all of them ( where @xmath104 through @xmath105 are sorted in ascending reliability ) .",
    "the number of bits in the reliable part @xmath106 can be adjusted to control the complexity .",
    "in the computation of the @xmath60 of each check , we can also make approximations to reduce the complexity .",
    "for instance , min - sum can be used instead of spa in step 3 algorithm [ alg : generic ] @xcite .",
    "furthermore , since the bit reliabilities are first ordered , the minimum of the absolute value of the llr s in the dense part of the parity check matrix is known .",
    "thus , we can approximate the @xmath60 of all the bits in the reliable part using the @xmath60 of the minimum value",
    ". this modification can significantly reduce the floating point operation complexity while retaining most of the performance gain .",
    "more sophisticated updating schemes can also reduce the complexity of matrix adaptation .",
    "el - khamy and mceliece have proposed a scheme that adapts the parity check matrix from previous ones , which reduces the overall complexity by @xmath107 ( private communication ) .",
    "gaussian elimination requires serial update of the rows and is difficult to parallelize .",
    "here we propose an alternative algorithm that is parallelizable .",
    "the idea is to take advantage of the structure of rs codes and adapt the parity check matrix at the symbol level .",
    "let @xmath108 be a set of @xmath29 least reliable symbols ( symbol - level reliability can be computed by taking the @xmath60 product of bit - level reliabilities or taking the minimum of the bit - level reliabilities ) .",
    "in order to update the parity check matrix at the symbol level , we need to find a valid parity check matrix for which the submatrix corresponding to the symbols in @xmath109 is an identity matrix .",
    "the detailed procedure is as follows : first , the submatrix corresponding to the symbols in @xmath109 is filled with an @xmath110 identity matrix and the rest of the matrix with unknowns ( erasure ) .",
    "the key idea is that computing the unknown symbols in the parity check matrix is equivalent to finding @xmath29 valid codewords of the dual code which will be the rows of the parity check matrix for the original code . for the @xmath65 row ,",
    "the @xmath111 entry is 1 and the @xmath112 entries are 0s and all other entries are erasures @xmath113",
    "( i.e. , all the positions corresponding to the reliable symbols are erased ) .",
    "since the dual code is an @xmath114 rs code with @xmath115 and there are exactly @xmath116 erasures in each row , forney s algorithm @xcite can be used to compute the values in the erased positions .",
    "each decoded codeword corresponds to one row in the original parity check matrix . by repeating this procedure for all @xmath29 rows ,",
    "we can get a systematic parity check matrix over @xmath3 , where the submatrix corresponding to unreliable symbols is the identity matrix . using the binary expansion",
    ", we can then get the binary parity check matrix and thereafter apply the spa using it . unlike gaussian elimination , each element in the parity check matrix can be computed independently and , hence , the whole procedure can be parallelized .",
    "this provides a computationally efficient way to obtain a parity check matrix in the desired form for hardware implementation .",
    "related concepts such as re - encoding have also been used to reduce the complexity of kv decoding ( see @xcite ) .",
    "in this section , simulation results for iterative decoding of rs codes by adapting the parity check matrix and its variations over various channel models are presented .",
    "the following notations will be used in the legends .",
    "adp(@xmath117,@xmath118 ) refers to the proposed adaptive decoding scheme .",
    "@xmath117 refers to the maximum number of iterations of iterative decoding .",
    "@xmath118 refers to the number of decoding rounds with different groupings of the unreliable bits ( see section [ subsec : grouping ] ) .",
    "adp & hdd refers to the proposed algorithm with an hdd in each iteration ( see section [ subsec : hdd ] ) .",
    "sym adp refers to the proposed algorithm with symbol - level adaptation ( see section [ subsec : symbol ] ) .",
    "red(m ) adp refers to the reduced complexity partial updating schedule with m bits in the reliable part to be updated ( see section [ subsec : partial ] ) .",
    "ms adp refers to the proposed algorithm using `` min - sum '' in updating the llr s ( using min - sum rather than sum - product in step 3 in algorithm [ alg : generic ] @xcite ) .",
    "unless otherwise indicated , all the simulations adopt deg-2 random connection ( see section [ subsec : deg2 ] ) to improve the asymptotic performance . the damping coefficient @xmath48 is also specified on the plots . for comparison ,",
    "the simulation - based ml lower bounds and analytical ml upper bounds are also plotted in some figures . the details for obtaining the ml lower bound",
    "is described in @xcite and the ml upper bound will be discussed in detail in the following subsection .    to speed up simulation , a genie aided stopping",
    "criterion scheme has been used , i.e. , the decoding procedure stops when adp & hdd gives the correct codeword .",
    "this is mildly optimistic as can be seen from the following argument .",
    "assume that there is no genie , then the actual decoder will run a fixed number of @xmath117 iterations and may return a list of codewords ( since the hdd may generate different codewords at different iterations ) .",
    "the actual decoder will pick the most likely codeword from the list . thus",
    ", if the transmitted codeword is the most likely one , the result of the actual decoder will be the same as that of the genie aided decoder .",
    "only when the transmitted codeword is not the most likely codeword , i.e. , when the ml decoder would have made errors , the result of the actual decoder may be different from the genie aided decoder and , hence , the genie aided decoder may be optimistic .",
    "we first study the performance of rs codes under ml decoding .",
    "the intention is to show that rs codes are themselves good codes ( even for medium rate long codes ) and the performance loss is due to the suboptimal symbol - level bounded distance decoder .",
    "the weight enumerator of an rs code under a specific binary image expansion is in general unknown . in this paper",
    ", we study the performance of the averaged ensemble of rs codes @xcite under ml decoding using the divsalar bound @xcite .",
    "the averaged ensemble of the rs code is taken by averaging over all possible binary expansions .",
    "for details , we refer to @xcite and more recent work @xcite .",
    "we first investigate the performance of a widely used high rate code , i.e. , rs(255,239 ) . in figure",
    "[ fig : rs_bound239 ] , we plot the upper bound on the performance of rs ensemble under ml decoding , hdd with error correction radius @xmath119 and a hypothetical decoder which can correct up to @xmath120 symbol errors ( that is we assume the genie decoder can decode the received vector as long as it is within the distance of @xmath120 at symbol - level from the transmitted codeword ) .",
    "we can see that , the hdd is asymptotically 3db worse than the performance under ml decoding ( the largest gap is about 4db , which appears at around an fer @xmath121 ) .",
    "the hypothetical decoder is optimal for asymptotically large snr s .",
    "however , this happens only at very low fer ( say , at an fer = @xmath122 ) , which is impractical for most of the applications . for practical snr s ,",
    "there is a loss of approximately 2db compared to the performance of the ml decoder .",
    "we further investigate a medium rate code rs(255,127 ) @xmath123 in figure [ fig : rs255127 ] .",
    "we can see that the performance under ml decoding of the rs ensemble reaches an fer = @xmath124 at an @xmath125db and outperforms the hypothetical decoder and hdd by 2.5db and 5db , respectively .",
    "the ml performance of rs ensemble is only 0.6  db away from the sphere packing bound @xcite , making it comparable to the best known turbo and ldpc codes . note that for this code , all known decoders up to now are still away from the performance under ml decoding , making it difficult to obtain good simulation based lower bounds to estimate the ml performance of the rs code .",
    "the above examples show that the symbol - level bounded distance decoding does not fully exploit the error correction capability of the code .",
    "the hypothetical decoder , which decodes up to @xmath126 , still performs far away from ml decoding , which suggests that an alternative design principle should be adopted for rs soft decision decoding . besides , the analytical performance bounds of rs codes under ml decoding are of interest as benchmarks for suboptimal decoders as will be discussed in the following subsections",
    ".      we first present results for the rs ( 31,25 ) code over the awgn channel in fig .",
    "[ fig : rs3125 ] .",
    "for this code , standard belief propagation ( bp ) decoding ( either with or without the damping coefficient , not plotted in the figure ) has little gain ( within 0.5  db from algebraic hdd ) due to the large number of short cycles .",
    "however , the proposed adp(20,1 ) & hdd provides a 2.3  db gain over hdd and an 1.0  db over chase - gmd(3 ) at an fer = @xmath124 .",
    "using the grouping method , the proposed adp(20,3 ) & hdd can approach the ml lower bound within 0.25db at an fer = @xmath124 .",
    "the reduced complexity version red(20 ) adp(20,1 ) incurs 0.2db performance loss compared with the generic adp and outperforms ms adp by about 0.5db at an fer = @xmath127 .",
    "the ml upper bound over rs averaged ensemble is also plotted for comparison .",
    "it can be seen that the ml upper bound is 0.5db away from the ml lower bound at an fer = @xmath124 and these two bounds converge in the high snr region .",
    "now we consider the ( 63,55 ) rs code . the performance is shown in fig .",
    "[ fig : rs6355 ] . for this code ,",
    "standard bp performs even worse than hdd ( not plotted in the figure ) .",
    "however , the proposed algorithm adp(5,1 ) & hdd provides 1.95  db and 1.05  db gain over algebraic hdd and chase - gmd@xmath128 at an fer = @xmath124 .",
    "adp(20,3 ) performs about 0.7  db within ml lower bound at an fer = @xmath124 .",
    "it also provides another 0.3  db gain over adp(5,1 ) .",
    "similar to other gradient descent methods , the damping coefficient of the adaptive algorithm must be carefully chosen to control the updating step width .",
    "the performance curve of adp(100,1 ) without damping or deg-2 connection has a flat slope and the asymptotic gain diminishes , which is mainly due to the overshooting of the update scheduling such that the decoder tends to converge to a wrong codeword quickly .",
    "sym adp(20,1 ) & hdd also provides a non - trivial gain of about 0.7db over hdd at an fer = @xmath124 , which is comparable to chase - gmd(3 ) while the complexity is significantly smaller .",
    "the ml upper bound also converges to the ml lower bound in the high snr region as in the previous cases .",
    "simulation results for the rs @xmath129 code over the awgn channel are shown in fig .",
    "[ fig : rs255239 ] . when large complexity is tolerable , adp(80 , 50 ) & hdd outperforms the popular kv method proposed in @xcite ( with maximum multiplicity 100 ) by 1.0  db and algebraic hdd by 1.65  db respectively at an fer = @xmath124 .",
    "we also compare this algorithm with bma order-1 @xcite , adp(80 , 50 ) & hdd is also about 0.6  db better than bma ( 1 ) at an fer = @xmath124 . compared with the ml lower",
    "bound obtained by using a near ml decoding algorithm recently proposed in @xcite , the adaptive algorithm is still 0.6db away from ml lower bound at an fer = @xmath130 . with reasonable complexity , adp(5,1 ) & hdd outperforms the kv(100 ) at an fer = @xmath124 . using the `` min sum '' approximation",
    ", it will incur about 0.3db loss at an fer = @xmath124 . at the price of a slight increase in complexity , adp(20,3 ) & hdd",
    "can provide comparable performance with bma(1 ) at fer = @xmath124 .",
    "now we study the performance of the proposed iterative decoding of rs codes over rayleigh fading channels .",
    "it is assumed that perfect channel state information is available at the receiver ( csir ) .",
    "we first assume bpsk modulation where the coded bits are fully interleaved at symbol - level , so that fading remains constant over one symbol but changes from symbol to symbol . the performance of an rs(31,15 ) code is shown in fig . [",
    "fig : rs3115 ] , the proposed algorithm adp(40,1 ) & hdd outperforms algebraic hdd and gmd decoding by 6.5  db and 3.3  db respectively at an fer = @xmath124 .",
    "adp(40,3 ) & hdd can further improve the asymptotic performance",
    ". the performance of sym adp(40,1 ) & hdd is also plotted .",
    "we see that it also offers about 5  db gain over hdd and 1.8  db gain over gmd decoding respectively at an fer = @xmath124 .",
    "similar results are observed for long codes with rate @xmath131 .",
    "the performance of a shortened rs(128,64 ) over gf(256 ) is given in fig .",
    "[ fig : rs12864 ] .",
    "the proposed decoding scheme provides several db gain over hdd .",
    "this is a nontrivial gain considering the powerful burst error correction capability of hdd .",
    "we also study the performance of rs coded modulation system over a symbol - level fully interleaved channel .",
    "we show in fig .",
    "[ fig : rs204188 ] the performance of a shortened rs(204,188 ) code with 256qam modulation and gray mapping , which has similar settings as many existing standards .",
    "we can see from the figure that the proposed algorithm adp(20,1 ) & hdd outperforms algebraic hdd by more than 7db at an fer = @xmath130 . compared with kv decoder",
    ", there is also a 3 to 4db gain .",
    "though kv decoder takes the symbol - level soft information directly , its performance is mainly limited by the algebraic bounded distance decoding kernel .",
    "there are several potential extensions of the adaptive algorithm .",
    "firstly , the gain of the proposed scheme may diminish at high snr s for long codes",
    ". further improvement of the generic decoder without significantly increasing the complexity remains an challenging problem .",
    "it is favorable that the structure of the rs codes can be taken into account in conjunction with the adaptive algorithm .",
    "therefore , vardy and beery s coset decomposition @xcite seems to be a promising way to represent the @xmath69 using a relatively sparse form .",
    "it is also natural to apply some more sophisticated decoding techniques ( e.g. constructing some sub - trellis with reasonable complexity ) and adopt the idea of the adaptive algorithm to improve the decoding performance .",
    "secondly , from our simulation experience , when the channel has memory ( say isi channel or some fsk signaling ) , the performance gain of adaptive algorithm ( without turbo equalization ) diminishes .",
    "how to extend the adaptive scheme to detection and equalization such that they can generate good quality bit - level soft information is under investigation .",
    "thirdly , asymptotic performance analysis of the adaptive algorithm is also of interest . ahmed _",
    "@xcite showed that using a certain probabilistic model , the performance of the adaptive algorithm under min - sum approximation can be evaluated using the osd bound .",
    "however , the performance bounds for the exact scheme is still of interest especially in the high snr s .    in conclusion",
    ", we present a novel iterative siso decoding algorithm of rs codes by adapting the parity check matrix .",
    "the proposed algorithm can be geometrically interpreted as a two - stage gradient descent algorithm with an adaptive potential function .",
    "simulation results show that the proposed algorithm compares favorably with known rs codes soft decoding methods over various channels for a wide range of rs codes of practical interest . besides , the proposed algorithm and its variations also provide flexible performance - complexity trade - off for different applications .",
    "the authors wish to thank r.  koetter for pointing out the two - stage optimization essence of the proposed decoding algorithm .",
    "they are grateful to w.  jin and m.  fossorier for providing the simulation based ml lower bound and many other precious suggestions .",
    "the authors appreciate the constructive comments from three anonymous reviewers that have greatly improved the presentation of this paper .",
    "j.  jiang also would like to thank m.  el - khamy for many inspiring discussions .",
    "w.  j. gross , f.  r. kschischang , r.  koetter , and p.  g. gulak , `` towards a vlsi architecture for interpolation - based soft - decision reed - solomon decoders , '' _ journal of vlsi signal processing _",
    "93111 , jan .- feb . 2005 .",
    "r.  lucas , m.  bossert , and m.  breitbach , `` on iterative soft - decision decoding of linear binary block codes and product codes , '' _ ieee journal of selected areas in communication _",
    "276296 , feb .",
    "1998 .",
    "r.  j. mceliece , d.  j.  c. mackay , and j.  f. cheng .",
    ", `` turbo decoding as an instance of pearl s `` belief propagation '' algorithm , '' _ ieee journal on selected areas in comm .",
    "_ , vol .",
    "16 , no .  2 ,",
    "140152 , feb .",
    "1998 .",
    "a.  ahmed , r.  koetter , and n.  r. shanbhag , `` performance analysis of the adaptive parity check matrix based soft - decision decoding algorithm , '' in _ proc .",
    "asilomar conf .",
    "signals , systems , and computers _ , pacifi c grove , ca , nov . 2004 .",
    "jing jiang ( s02 ) received the b.s .",
    "degree from shanghai jiao tong university in 2002 and is currently working toward the m.s./ph.d .",
    "degree at texas a & m university in the department of electrical and computer engineering .",
    "his general research interests lie in the areas of channel coding , signal processing and information theory for wireless communication and digital storage channels .",
    "krishna r. narayanan ( s92-m98 ) received the ph.d .",
    "degree in electrical engineering from georgia institute of technology in 1998 and is currently an associate professor in the department of electrical and computer engineering at texas a  &  m university .",
    "his research interests are in coding theory with applications to wireless communications and digital magnetic recording and joint source - channel coding .",
    "he currently serves as an editor for the ieee transactions on communications ."
  ],
  "abstract_text": [
    "<S> an iterative algorithm is presented for soft - input - soft - output ( siso ) decoding of reed - solomon ( rs ) codes . </S>",
    "<S> the proposed iterative algorithm uses the sum product algorithm ( spa ) in conjunction with a binary parity check matrix of the rs code . </S>",
    "<S> the novelty is in reducing a submatrix of the binary parity check matrix that corresponds to less reliable bits to a sparse nature before the spa is applied at each iteration . </S>",
    "<S> the proposed algorithm can be geometrically interpreted as a two - stage gradient descent with an adaptive potential function . </S>",
    "<S> this adaptive procedure is crucial to the convergence behavior of the gradient descent algorithm and , therefore , significantly improves the performance . </S>",
    "<S> simulation results show that the proposed decoding algorithm and its variations provide significant gain over hard decision decoding ( hdd ) and compare favorably with other popular soft decision decoding methods .    adapting the parity check matrix , gradient descent , iterative decoding , soft decision decoding , reed - solomon ( rs ) codes . </S>"
  ]
}