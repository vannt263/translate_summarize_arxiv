{
  "article_text": [
    "a very common statistical procedure is obtaining a confidence interval for a physics parameter of interest , when there are uncertainties in quantities such as the acceptance of the detector and/or the analysis procedure , the beam intensity , and the estimated background .",
    "these are known in statistics as nuisance parameters , or in particle physics as sources of systematic uncertainty .",
    "we assume that estimates of these quantities are available from subsidiary measurements . ; that is not enough information for a bayesian approach . alternatively",
    "the data relevant for the physics and nuisance parameters could be bound up in the main measurement , and not require a subsidiary one . ] a variant of this procedure which is particularly relevant for particle physics is the extraction of an upper limit on the rate of some hypothesized process or on a physical parameter , again with systematic uncertainties .    to specify the problem in more detail , we assume that we are performing a counting experiment in which we observe @xmath0 counts , and that the acceptance has been estimated as @xmath1 and the background as @xmath2 . for a signal rate @xmath3 , @xmath0 is poisson distributed with mean @xmath4 . here",
    "@xmath5 contains factors like the intensity of the accelerator beam(s ) , the running time , and various efficiencies .",
    "it is constrained to be non - negative , but can be larger than unity .",
    "we aim to study and compare different approaches for determining confidence intervals for this problem .",
    "in general we are interested in pathologies in these areas :    * * coverage . * this is a measure of how often the limits that we deduce would in fact include the true value of the parameter .",
    "this requires consideration of an ensemble of experiments like the one we actually performed , and hence is an essentially frequentist concept .",
    "nevertheless , it can be applied to a bayesian technique .",
    "+ coverage is a property of the technique , and not of the particular limit deduced from a given measurement .",
    "it can , however , be a function of the true value of the parameter , which is in general unknown in a real measurement .",
    "+ undercoverage ( i.e.  the probability of containing the true value is less than the stated confidence level ) is regarded by frequentists as a serious defect . usually coverage is required for all possible values of the physical parameter .",
    "occur at values which are not fixed in @xmath3 , but which depend on the details of our experiment ( such as the values of @xmath5 and @xmath6 ) .",
    "these details vary from experiment to experiment .",
    "thus we could achieve ` no undercoverage for the ensemble of experiments measuring the parameter @xmath3 ' , even if the individual coverage plots did fall below the nominal coverage occasionally .",
    "thus in some sense ` average coverage ' would be sufficient ( see for example reference @xcite ) , although it is hard to quantify the exact meaning of ` average ' .",
    "it should be stated that this is not the accepted position of most high energy physics frequentists .",
    "] in contrast , overcoverage is permissible , but the larger intervals result in less stringent tests of models that predict the value of the parameter . for measurements involving quantised data ( e.g.  poisson counting ) ,",
    "most methods have coverage which varies with the true value of the parameter of interest , and hence if undercoverage is to be avoided , overcoverage is inevitable .",
    "+ frequentist methods by construction will not undercover for any values of the parameters .",
    "this is not guaranteed for other approaches .",
    "for example , even though the bayesian intervals shown here do not undercover , in other problems bayesian 95% credible intervals could even have zero coverage for some values of the parameter of interest.@xcite it should also be remarked that , although coverage is a very important property for frequentists , on its own exact coverage does not guarantee that intervals have desirable properties ( for many examples , see refs . @xcite and @xcite ) . * * interval length .",
    "* this is sometimes used as a criterion of accuracy of intervals , in the sense that shorter intervals have less probability of covering false values of the parameter of interest .",
    "however , one should keep in mind that short intervals are only desirable if they contain the true value of the parameter .",
    "thus empty intervals , which do occur in some frequentist constructions , are generally undesirable , even when their construction formally enjoys frequentist coverage .",
    "+ intervals that fill the entire physically allowed range of the parameter of interest may also occur in some situations .",
    "examples of this behavior are given in @xcite and @xcite .",
    "an experimenter who requests a 68% confidence interval , but receives what appears to be a 100% confidence interval instead , may not be satisfied with the explanation that he is performing a useful service in helping to keep the coverage probability  averaged over his measurement and his competitor s measurements  from dropping below 68% . *",
    "* bayesian credibility .",
    "* in some situations it may be relevant to calculate the bayesian credibility of an interval , even when the latter was constructed by frequentist methods .",
    "this would of course require one to choose a prior for all the unknown parameters .",
    "the question is one of plausibility : given the type of measurement we are making , the resolution of the apparatus , etc .",
    ", how likely is it that the true value of the parameter we are interested in lies in the calculated interval ? does this differ dramatically from the nominal coverage probability of the interval ?",
    "in fact for different values of the observable(s ) , frequentist ranges are very likely to have different credibilities",
    ". some examples of this behavior are noted in ref .  @xcite .",
    "+ when calculating the bayesian credibility of frequentist intervals , `` uninformative '' priors appear advisable .",
    "note that severe interval length pathologies will automatically produce a large inconsistency between the nominal coverage and the bayesian credibility of an interval .",
    "except in a handful of very special cases , it is not possible to construct an interval scheme that has simultaneously constant bayesian credibility and constant frequentist coverage , even if one has total freedom in choosing the prior(s ) .",
    "although it is not at all clear exactly how large a level of disagreement is pathological , nevertheless it may be instructive to know how severely an interval scheme deviates from constant bayesian credibility ( and how sensitive this is to the choice of prior ) . * * bias .",
    "* in the context of interval selection , this means having a larger coverage @xmath7 for an incorrect value @xmath8 of the parameter than for the true value @xmath9 .",
    "this requires plots of coverage versus @xmath8 for different values of @xmath9 . for upper limits ,",
    "@xmath10 if @xmath11 is less than @xmath12 , so methods are necessarily biassed for low @xmath8 .",
    "bias thus is not very interesting for upper limits .",
    "it will be discussed in later notes dealing with two - sided intervals . * * transformation under reparametrisation .",
    "* intervals that are not transformation - respecting can be problematic .",
    "for example , it is possible for the predicted value of the lifetime of a particle to be contained within the 90% interval determined from the data , but for the corresponding predicted value of the decay rate ( equal to the reciprocal of the predicted lifetime ) to be outside the 90% interval when the data is analysed by the same procedure , but in terms of decay rate .",
    "this would result in unwanted ambiguities about the compatibility of the data with the prediction . *",
    "* unphysical ranges . *",
    "the question here is whether the interval construction procedure can be made to respect the physical boundaries of the problem .",
    "for example , branching fractions should be in the range zero to one , masses should not be negative , etc .",
    "statements about the _ true _ value of a parameter should respect any physical bounds .",
    "in contrast , some methods give _ estimates _ of parameters which can themselves be unphysical , or which include unphysical values when the errors are taken into account .",
    "we do not recommend truncating ranges of _ estimates _ of parameters to obey such bounds .",
    "thus the fact that a branching fraction is estimated as @xmath13 conveys more information about the experimental result than does the statement that it lies in the range 0.9 to 1 . * * behavior with respect to nuisance parameter .",
    "* we would normally expect that the limits on a physical parameter would tighten as the uncertainty on a nuisance parameter decreases ; and that as this uncertainty tends to zero , the limits should agree with those obtained under the assumption that the `` nuisance parameter '' was exactly known .",
    "( otherwise we could sometimes obtain a tighter limit simply by pretending that we knew less about the nuisance parameter than in fact is the case . )",
    "these desiderata are not always satisfied by non - bayesian methods ( see @xcite and @xcite ) .",
    "although we are ultimately interested in comparing different approaches to this problem , in this note we investigate a bayesian technique for determining upper limits .",
    "our purpose is to spell out in some detail how this approach is used , and to discuss some of the properties of the resulting limits in this specific example .",
    "we believe that , for variants of this problem ( e.g.  different choice of prior for @xmath3 ; alternative assumptions about the information on the nuisance parameters ; etc . ) , the reader could readily adapt the techniques described here ( and the associated software ) to their particular situation .",
    "we will report on two - sided intervals and also compare with other methods ( e.g.  cousins  highland , pure frequentist , profiled frequentist ) in later notes .",
    "before dealing with the problem of extracting and studying the limits on @xmath3 as deduced from observing @xmath0 events from a poisson distribution with mean @xmath4 in the presence of an uncertainty on @xmath5 , we recall the way the bayesian approach works for the simpler problem of a counting experiment with no background and with @xmath5 exactly known .",
    "then @xmath0 is poisson distributed with mean @xmath14 , and bayes theorem s denote prior p.d.f.s , lower case @xmath15 s denote other p.d.f.s , upper case @xmath16 s denote prior probabilities , and upper case @xmath17 s denote other probabilities .",
    "equation  ( [ eqn : bayesth ] ) is true for probabilities , p.d.f.s , or mixtures depending on whether @xmath18 and/or @xmath19 are discrete or continuous variables . ]",
    "@xmath20 gives @xmath21 where @xmath22 is the prior probability density for @xmath3 ; @xmath23 is the posterior probability density function ( p.d.f . )  for @xmath3 , given the observed @xmath0 ; and @xmath24 is the probability of observing @xmath0 , given @xmath3 .",
    "we assume a constant prior for @xmath3 , . ) ] and that @xmath24 is given by the poisson @xmath25 then of the discrete distribution ( [ eqn : poisson ] ) and the integral over @xmath3 of the continuous distribution ( [ eqn : poisson2 ] ) are both equal to unity .",
    "this means that the probability @xmath24 and the probability density @xmath23 are correctly normalised . ]",
    "@xmath26 the limit is now obtained by integrating this posterior p.d.f .  for @xmath3 until we achieve the required fraction @xmath27 of the total integral from zero to infinity .",
    "if @xmath27 is @xmath28 , the upper limit @xmath29 is given by @xmath30 @xmath27 is termed the credible or bayesian confidence level for the limit .    for different observed @xmath0 ,",
    "the upper limits are shown in the last two columns of table  [ ltablex ] , for @xmath31 and for @xmath32 respectively .",
    "the gaussian approximation for the case @xmath31 , @xmath33 , would yield @xmath34 , which is roughly comparable to the corresponding @xmath35 of the table . for @xmath31",
    ", it coincidentally turns out that , for this particular example , the bayesian upper limits are identical with those obtained in a frequentist calculation with the neyman construction and a simple ordering rule ( see later note on the frequentist approach to this problem ) . in general this is not so .",
    "other priors sometimes used for @xmath3 are @xmath36 @xcite or @xmath37 @xcite . having a prior peaked at smaller values of @xmath3 in general results in tighter limits for a given",
    "observed @xmath0 .",
    "if the whole procedure is now repeated with a background @xmath6 and a flat prior , the upper limits not surprisingly decrease for increasing @xmath6 at fixed @xmath0 ( except for the case @xmath38 where the limits can trivially be seen to be independent of @xmath6 ) .",
    "this is not inconsistent with the fact that the mean limit for a series of measurements increases with @xmath6 , i.e.  experiments with larger expected backgrounds have poorer sensitivity .    .upper",
    "90% limits for @xmath0 observed events with @xmath6 background and @xmath39 ( @xmath40 and @xmath41 , as defined in section  [ submeas ] ) . also shown are limits for @xmath42 and @xmath43 with fixed @xmath44 .",
    "[ ltablex ] [ cols= \" > , > , > , > , > , > , > , > , > , > , > , > \" , ]      next we can investigate the frequentist coverage @xmath45 when the poisson variable is generated with @xmath46 .",
    "this differs from @xmath7 where the coverage is checked at @xmath47 when the generation value is @xmath9 . ] of this bayesian approach .",
    "that is , we can ask what the probability is , for a given value of @xmath9 , of our upper limit being larger than @xmath9 , and hence being consistent with it . this is equivalent to adding up the poisson probabilities of eqn .",
    "( [ eqn : poisson ] ) for those values of @xmath0 for which @xmath48 i.e. @xmath49 as @xmath9  increases through any of the values of @xmath29 of the last two columns of table  [ ltablex ] , the coverage drops sharply . for example , for the case of zero background and efficiency",
    "known to be unity , the 90% bayesian upper limits will include @xmath50 for @xmath51 or larger .",
    "but @xmath52 is no longer below the upper limit for @xmath51 .",
    "thus one term drops out of the summation of eqn .",
    "( [ csum ] ) for the calculation of the coverage at @xmath52 , while the remaining terms change but little for the small change in @xmath9 ; this produces the abrupt fall in coverage . the coverage is plotted in fig .  [ fig : bayes ] , where the drop at @xmath53 can be seen .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the calculation of @xmath45 can be done as follows : the identity @xmath54= -e^{-x}{x^n\\over n ! } \\qquad\\mathrm{for}\\qquad f(x)=e^{-x}\\sum_{k=0}^n{x^k\\over k!}\\ ] ] allows us to write ( integrating @xmath55 ) @xmath56 from this , it follows that `` relevant @xmath0 '' is equivalent to any one of these inequalities : @xmath57 and our expression for the coverage becomes @xmath58 where @xmath59 means `` sum until the next term would cause the sum to exceed @xmath60 '' .",
    "this result proves that @xmath61 for all values of @xmath9  in this simple example .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    it is seen that the coverage starts at @xmath62 for small @xmath9 .",
    "this is because even for @xmath38 the bayesian upper limit will include @xmath9 , and this is even more so for larger @xmath0 .",
    "bayesian methods can be shown to achieve average coverage . by this",
    "we mean that when the coverage is averaged over the parameter @xmath3 , weighted by the prior in @xmath3 , the result will agree with the nominal value @xmath27 , i.e. @xmath63 a proof of this theorem is given in the second appendix , section  [ ac ] of this note .",
    "for a constant prior , the region at large @xmath3 tends to dominate the average , while in general we will be interested in the coverage at small @xmath3 .",
    "thus the `` average coverage '' result is of academic rather than practical interest , especially for the case of a flat prior .",
    "indeed it is possible to have a situation where the average coverage is , say , @xmath28 , while the coverage as a function of @xmath3 is always larger than or equal to @xmath28 .",
    "our actual problem differs from the simple case of section [ bayes ] in that + ( a ) we have a background @xmath6 , assumed for the time being to be accurately known ; and ( b ) we have an acceptance @xmath5 estimated in a subsidiary experiment as @xmath1 .",
    "what we are going to do is to use a multidimensional version of bayes theorem to express @xmath64 in terms of @xmath65 and the priors for @xmath3 and @xmath5 .",
    "the relationship is and +   + @xmath66 .",
    "+   + so with @xmath67 , @xmath68 and @xmath69 identified with @xmath3 , @xmath5 and @xmath0 respectively , and with the prior for @xmath3 and @xmath5 factorising into two separate priors for @xmath3 and for @xmath5 , we obtain @xmath70 . ]",
    "@xmath71    to obtain the posterior p.d.f .  for @xmath3 , we now integrate this over @xmath5 : @xmath72 and finally we use this to set a limit on @xmath3 as in eqn .",
    "( [ eqn:0.9 ] ) .",
    "the coverage for this procedure needs to be calculated as a function of @xmath9  and @xmath73 .",
    "the average coverage theorem of the previous section must be generalized to @xmath74      to implement the above procedure we need priors for @xmath3 and @xmath5 . as in the simple example of section [ bayes ] , for simplicity",
    "we assume that the prior for @xmath3 is constant .",
    "it will be interesting to look at the way the properties of this method change as other priors for @xmath3 are used .",
    "we assume that the prior for @xmath5 is extracted from some subsidiary measurement @xmath75 .",
    "we do * not * assume that this implies that our belief about @xmath73  is represented by a * gaussian * distribution centred on @xmath76 , as this would give trouble with the lower end of the gaussian extending to negative @xmath5 .",
    "instead , we specify some particular form of the subsidiary experiment that provides information about @xmath5 , and then assume that a bayesian analysis of this yields a posterior p.d.f .  for @xmath5 .",
    "slightly confusingly , this posterior from the subsidiary experiment is used as the prior for the application of bayes theorem to extract the limit on @xmath3 ( see eqns.([eqn : extended ] ) and ( [ eqn : posterior ] ) ) .",
    "somewhat arbitrarily , we assume that , for a true acceptance @xmath73 , the probability for the measured value @xmath76 in the subsidiary experiment is given by a poisson distribution @xmath77 where @xmath78 , @xmath79 and @xmath80 is a scaling constant and @xmath81 as the mean and variance of the posterior p.d.f .  of eqn .",
    "( [ eqn : posterior_e ] ) . ] .",
    "we interpret this as the probability for @xmath76 .",
    "this is discrete because the observable @xmath82 is discrete , but the allowed values become closely spaced for large @xmath80 . for small @xmath83 ( i.e.  for large @xmath82 ) , these probabilities approximate to a narrow gaussian ( see fig .  [",
    "fig : comparison ] ) .    given our choice of probability in eqn .",
    "( [ eqn : pdf ] ) , the likelihood for the parameter @xmath5 , given measured @xmath76 , is @xmath84 this is the same function of @xmath5 and @xmath76 as eqn .",
    "( [ eqn : pdf ] ) , but now @xmath82 is regarded as fixed , and @xmath5 is the variable . the likelihood is a continuous function of @xmath5 . it is compared with a gaussian in fig .  [",
    "fig : comparison2 ] .    finally in the bayes approach , with the choice of a constant prior for @xmath5 , the posterior probability density for @xmath5 after our subsidiary measurement is @xmath85 which is obtained by multiplying the right - hand side of eqn .",
    "( [ eqn : likelihood ] ) by unity .",
    "this * posterior * probability density for @xmath5 will be used as our * prior * for @xmath5 in the next step of deducing the limit for @xmath3 .",
    "the details of the necessary analytical calculations are presented in the appendix of this note . in this section",
    "we investigate the behavior of the bayesian limits in this example , especially the shape of the frequentist coverage probability as a function of @xmath9 .",
    "the posterior p.d.f .  for @xmath3 has the form @xmath861\\,ds\\ ] ] where the likelihood , the prior for @xmath5 , the ( constant ) prior for @xmath3 , and the marginalization integral over @xmath5 are all prominently displayed .",
    "the posterior probability density for @xmath3 gives the complete summary of the outcome of the measurement in the bayesian approach .",
    "it is therefore important to understand its shape before proceeding to use it to compute a limit ( or extract a central value and error - bars ) .",
    "figure  [ pdfs ] illustrates the shape of the posterior for @xmath3 ( i.e.  marginalized over @xmath5 ) in the case of a nominal 10% uncertainty on @xmath5 , and an expectation of 3 background events .",
    "plots are shown for 1 , 3 , 5 , and 10 observed events .",
    "the posterior evolves gracefully from being strongly peaked at @xmath87 to a roughly gaussian shape that excludes the neighborhood near @xmath87 with high probability .",
    "technically , the posterior would be described as a mixture of @xmath88 beta distributions of the 2nd kind '' ( i.e.  `` beta prime '' ) , `` inverted beta '' , `` pearson type  vi '' , `` variance - ratio '' , `` gamma - gamma '' , `` f '' , `` snedecor '' , `` fisher - snedecor''  . ] , giving it a tail at high @xmath3 that is heavier than that of a gaussian .      in this note ,",
    "our main goal is to obtain a bayesian upper limit @xmath29 from our observation of @xmath0 events .",
    "it is by integrating the posterior p.d.f .",
    "out to @xmath89 that an upper limit is calculated : a @xmath90 upper limit is defined so that the integral of the posterior from @xmath87 to @xmath89 is 0.9 .",
    "the probability ( in the bayesian sense ) of @xmath91 is then exactly @xmath27 .",
    "table  [ ltablex ] shows the upper limits ( @xmath92 ) for @xmath9320 observed events with @xmath428 and @xmath39 .",
    "( integer values of @xmath6 are chosen for illustration purposes only ; @xmath6 can , of course , take any real value @xmath94 . )",
    "one notices that when @xmath93 , the limit is independent of the expected background @xmath6 .",
    "this is required in the bayesian approach : we know that exactly zero background events were produced ( when no events at all were produced ) , and this knowledge of what _ did _ happen makes what might have happened superfluous .",
    "an interesting corollary is , in the case of no events observed , uncertainties in estimating the background rate are of no consequence in the bayesian approach , and must not contribute any systematic uncertainty to the limit .",
    "this reasoning does not hold in the frequentist framework , where what might have happened definitely does influence the limit .    for comparison ,",
    "limits for fixed @xmath44 with @xmath42 or @xmath43 are also shown in table  [ ltablex ] .",
    "it is interesting that these two columns start out equal at @xmath93 and differ by almost exactly 3 for @xmath95 .",
    "in contrast , the difference between the @xmath42 and @xmath43 columns for @xmath39 is already greater than 3 at @xmath96 , and continues to grow as @xmath0 increases ; it is not clear whether the difference approaches a finite value as @xmath97 . in any case , the limits for @xmath44 exactly are all smaller than the corresponding limits for @xmath39 , as expected .",
    "the main quantity of interest in this subsection is the frequentist coverage probability @xmath19 as a function of @xmath9  ( for fixed @xmath73  and @xmath6 ) .",
    "because both the main and the subsidiary measurements involve observing a discrete number of events , the function @xmath45 will have many discontinuities . on the other hand",
    ", @xmath98 will be continuous ( for fixed @xmath9 ) .",
    "the explanation of this effect is as follows :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the measured data are @xmath0 events in the main measurement and @xmath82 events in the subsidiary measurement .",
    "for each observed outcome @xmath99 there is a limit @xmath100 .",
    "this limit includes the effect of marginalization over @xmath5 .",
    "all @xmath99 with @xmath101 and @xmath102 are possible , and the probability @xmath17 of observing @xmath99 can be calculated as the product of two poissons .",
    "( it will depend on @xmath9 , @xmath73 ,  ) if we look at all the possible limits we can obtain , @xmath103 and sort them in increasing @xmath29 , the @xmath29 are countably infinite in number and dense in the same way that rational numbers are dense in the reals .    to compute the coverage as a function of @xmath9 , we simply add up all the probabilities of obtaining @xmath99 with @xmath104 :",
    "@xmath105 this sum is over a countably infinite number of terms .",
    "if we increase @xmath106 slightly to @xmath107 and recalculate the coverage , we have to drop all the terms @xmath108 from the previous sum ( the @xmath109 for each term also changes continuously with @xmath106 , but this is no problem )",
    ". if there are @xmath110 such terms , there are @xmath111 discontinuities in the coverage in the interval @xmath112 $ ] , since @xmath109 for each of these is finite , and we lose them one by one as we sweep across the interval @xmath112 $ ] .",
    "but it seems that , in general , we can always find a solution to @xmath113 for finite @xmath114 by going out to larger and larger @xmath0 and @xmath82 .",
    "so , although the discontinuity may be tiny , we can always find a finite discontinuity in any finite interval of @xmath106 .",
    "on the other hand , if we keep @xmath106 fixed and vary @xmath115 , we always sum over the same set of @xmath99 , since the definition of @xmath116 does not involve @xmath73 , and @xmath109 is continuous in @xmath73 .",
    "so the coverage is continuous as a function of @xmath73  for @xmath9fixed . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    plotting a curve that is discontinuous at every point is somewhat problematical .",
    "the solution adopted here is to plot the coverage as straight line segments between the discontinuities , ignoring any discontinuities with @xmath117 .",
    "figure  [ l100 ] shows @xmath45 for the case @xmath90 , @xmath118 , nominal 10% uncertainty of the subsidiary measurement of @xmath5 , and @xmath43 .",
    "we observe that @xmath119 in this range , and it is not clear numerically whether @xmath120 as @xmath121 .",
    "the same conclusions hold for fig .",
    "[ l25 ] , which illustrates the same situation with a 20% nominal uncertainty for the @xmath5-measurement .",
    "figure  [ ecov ] shows @xmath98 for @xmath90 , @xmath122 , @xmath40 , and @xmath43continuous as advertised .",
    "the shape of the curve is quite similar to that of figs .",
    "[ l100 ] and [ l25 ] , so it seems that the coverage probability ( with @xmath6 fixed ) is approximately a function of just the product of @xmath73  and @xmath9 .",
    "this approximate rule is likely to fail in the limit as @xmath123 and @xmath121 , for example , but it seems to hold when @xmath73  and @xmath9  are at least of the same order of magnitude .    when @xmath124 is small , of order 1 or less , the coverage is @xmath125100% , as in the simple case of fig .",
    "[ fig : bayes ] . otherwise , the behavior of coverage in figs .  [ l100][ecov ] is superior to that of fig .",
    "[ fig : bayes ] , which has a much larger amplitude of oscillation .",
    "another frequentist quantity that characterizes the performance of a limit scheme is the sensitivity , defined as the mean of @xmath29 .",
    "figure  [ sens ] shows the sensitivity as a function of @xmath9  for the case of fig .",
    "[ l100 ] ; @xmath126 is observed to be nearly linearly dependent on @xmath9 .",
    "there is one complication here : when the subsidiary measurement observes @xmath127 events , and the prior for @xmath3 is flat , @xmath128 .",
    "since the poisson probability of obtaining @xmath127 is always finite , @xmath129 is consequently infinite .",
    "so we must exclude the @xmath127 case from the definition of @xmath129 .",
    "( in fig .",
    "[ sens ] the probability of obtaining @xmath127 is @xmath130 . )",
    "a weakness of the bayesian approach is that there is no universally accepted method to obtain a unique `` non - informative '' or `` objective '' prior p.d.f .",
    "reference  @xcite , for example , states :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ put bluntly : data can not ever speak entirely for themselves ; every prior specification has _",
    "some _ informative posterior or predictive implications ; and `` vague '' is itself much too vague an idea to be useful .",
    "there is no `` objective '' prior that represents ignorance . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    nevertheless , ref",
    ".  @xcite does derive a @xmath131 `` reference prior '' for the simple poisson case , which is claimed to have `` a minimal effect , relative to the data , on the final inference '' .",
    "this is to be considered a `` _ default _ option when there are insufficient resources for detailed elicitation of actual prior knowledge '' .",
    "reference  @xcite attempts to discover the optimal form for prior ignorance by considering the behavior of the prior under reparameterizations . for the case in question",
    ", the form @xmath37 clearly has the best properties in this respect .",
    "we are using an flat ( @xmath132 ) prior for this study , which seems to be the most popular choice , but the appendix works out the form of the posterior using an @xmath133 prior , so we can briefly here summarize the results for the @xmath37 and @xmath131 cases :    the @xmath37 prior leads to an unnormalizable posterior for all observed @xmath0 when @xmath134 .",
    "the posterior becomes a @xmath135-function at @xmath87 , @xmath136 for any @xmath27 , and the coverage is consequently zero for all @xmath137 .",
    "this clearly is a disaster .    the @xmath131 prior results in a posterior p.d.f .",
    "qualitatively similar in shape to those of fig  [ pdfs ] , except that the p.d.f.is always infinite at @xmath87 . for @xmath138 ,",
    "this produces an extremely thin `` spike '' at @xmath87 , which has a negligible contribution to the integral of the posterior p.d.f . a more significant difference ( for frequentists ) between the @xmath131 and the @xmath132 case",
    "is that the coverage probability is significantly reduced : for the case of fig .",
    "[ l100 ] the @xmath131 prior pushes the minimum coverage down to @xmath1250.87 .",
    "so the @xmath131 prior leads to violation of the frequentist coverage requirement ; it undercovers for some values of @xmath9 .",
    "one might also seek to further improve the coverage properties by adopting an intermediate prior .",
    "for example , an @xmath139 prior would reduce the level of overcoverage obtained with the @xmath132 prior .",
    "how acceptable this approach would be within the bayesian statistical community is an interesting question .",
    "it should be noted that all the prior p.d.f.s considered in this note are `` improper priors''they can not be correctly normalized : in the case of the @xmath132 and @xmath131 priors , the integral from 0 to any value @xmath140 is finite , while the integral from @xmath140 to infinity is infinite .",
    "the corresponding integrals of the @xmath37 prior are infinite on both sides for all @xmath141 .",
    "improper priors are dangerous but often useful ; `` improper posteriors '' are generally pathological .",
    "extra care must be taken when employing improper priors to verify the normalizability of the resulting posterior  when using a numerical method to obtain the posterior , it is very easy to miss the fact that its integral is infinite .",
    "we summarize here the restrictions forced on the priors for @xmath3 and @xmath5see the appendix for the analytical causes .",
    "the discussion below assumes @xmath134 .",
    "the prior for @xmath3 being of the form @xmath133 , we must require @xmath142 , as discussed above .",
    "as specified in this note , the prior for @xmath5 , being taken from the posterior from the subsidiary measurement with a flat prior , has been given no freedom .",
    "should the subsidiary measurement observe @xmath127 events , the posterior for @xmath3 is not normalizable when @xmath143 : @xmath128 when @xmath127 and @xmath143 .",
    "this behavior is due to a well known effect : the @xmath5 prior becomes @xmath144 when @xmath127 , which remains finite as @xmath145 .",
    "all such cases is the standard example . ]",
    "yield @xmath128 when @xmath143 ; any positive @xmath146 cuts off the posterior at large @xmath3 sufficiently rapidly to render it normalizable . from this point of view , a @xmath131 prior may seem preferable , but on the other hand , having @xmath128 when @xmath127 seems intuitively reasonable .",
    "( in general , we have @xmath128 for @xmath147 , but @xmath148 are not popular choices . )    there is another approach possible to the gamma prior for @xmath5 : we may simply specify by fiat the form of the prior as @xmath149 where @xmath150 is no longer required to be an integer . in practice , one then might obtain @xmath150 and @xmath80 from a subsidiary measurement whose result is approximated by the gamma distribution . in such cases , one must require @xmath151 to keep the posterior normalizable . note that in this form , @xmath152 is the mean of the @xmath5 prior , @xmath153 is the mode , and @xmath154 is the variance . the subsidiary measurement is often analysed by other experimenters , who chose statistics to quote for their central value and uncertainty ( omitting additional likelihood information ) .",
    "it is then important to obtain @xmath150 and @xmath80 in a consistent way from the information supplied by the subsidiary measurement .",
    "if @xmath5 , for example , were estimated by a maximum likelihood method , one would identify the estimate with @xmath153 rather than @xmath152 .",
    "results have been presented on the performance of a purely bayesian approach to the issue of setting upper limits on the rate of a process , when @xmath0 events have been observed in a situation where the expected background is @xmath6 and where the efficiency / acceptance factor @xmath155 has been determined in a subsidiary experiment .",
    "we find that this approach , when using a flat prior for the rate , results in modest overcoverage .",
    "plots of the expected sensitivity of such a measurement and of the coverage of the upper limits are given .",
    "it will be interesting to compare these with the corresponding plots for other methods of extracting upper limits , to be given in future notes .",
    "reference  @xcite provides the limit calculating software associated with this study in the form of c  functions .",
    "here we present the details of the analytical calculation of the posterior p.d.f .  for @xmath3 . for generality",
    ", we work through the calculation with a @xmath133 prior ; a flat prior is then the special case @xmath156 .",
    "we measure @xmath0 events from a process with poisson rate @xmath157 , and we want the bayesian posterior for @xmath3 , given improper prior @xmath133 .",
    "we compute the posterior for fixed @xmath5 and @xmath6 in this subsection ; the calculation with our prior for @xmath5 follows in the next subsection .",
    "we have @xmath158 where all factors not depending on @xmath3 have already been absorbed into the normalization constant @xmath159 , which is defined by @xmath160 where we have performed the indicated change of variable .",
    "expanding @xmath161 in powers of @xmath162 using the binomial theorem , we get @xmath163 recognizing this as of the general hypergeometric form , we write it as @xmath164\\ ] ] to make the hypergeometric nature more explicit . using the modern notation@xcite for the falling factorial @xmath165 this",
    "is expressed as @xmath166 where @xmath111 is the notation of @xcite .",
    "( @xmath111 , a confluent hypergeometric function , is often written @xmath167 , and the relation given here is only valid for integer @xmath101 . ) note that @xmath168 is a polynomial of order @xmath0 in @xmath6 ( for @xmath0 a non - negative integer ) , and is related to the laguerre polynomials .",
    "when @xmath156 , we get @xmath169 , which is related to the incomplete gamma function .",
    "when @xmath170 , we get @xmath171 , which is infinite , so we require that @xmath142 .    our posterior probability density for fixed @xmath5",
    "is then given by @xmath172      the subsidiary measurement observes an integer number of events @xmath82 , poisson distributed as : @xmath173 where @xmath80 is a real number ( connecting the subsidiary measurement to the main measurement ) whose uncertainty is negligible , so @xmath80 can safely be treated as a fixed constant .",
    "@xmath80 might be thought of , for example , as based on a cross section that is exactly calculable by theory .",
    "there is negligible ( i.e.  zero ) background in the subsidiary measurement .",
    "the prior for @xmath5 is specified to be flat .",
    "the bayesian posterior p.d.f .  for @xmath5",
    "is then @xmath174 ( or @xmath175 instead of @xmath176 in the denominator if you prefer ) .",
    "this is known as a gamma distribution .",
    "the mean and rms of this posterior p.d.f .",
    "summarize the result of the subsidiary measurement as : @xmath177 note that the observed data quantity in the subsidiary measurement is an integer @xmath82 , while the quantity being measured by the subsidiary measurement is a positive real number @xmath5 .",
    "next we compute the joint posterior @xmath178 using the @xmath133 prior for @xmath3 and our gamma distribution prior ( i.e.  the posterior derived from the subsidiary measurement ) for @xmath179 @xmath180 where it is convenient to write @xmath150 for @xmath181 .",
    "we have for the joint posterior p.d.f .",
    "@xmath182 where @xmath183 we calculated @xmath159 above , so we have @xmath184 @xmath185 @xmath186 the marginalized posterior for @xmath3 can then be expressed as @xmath187ds= { s^{\\alpha-1}\\kappa^{\\mu-\\alpha}\\mathcal{i}_\\epsilon\\over \\gamma(\\mu-\\alpha)\\gamma(\\alpha+n)m(-n,1-n-\\alpha , b)}ds\\ ] ] where the integral @xmath188 is given by @xmath189 the same procedure that was used for the normalization integral can be applied here , producing @xmath190 @xmath191^k\\ ] ] @xmath192 @xmath193 which has a particularly simple form when the background term is zero : @xmath194 a beta distribution of the 2nd kind .",
    "note that we must require @xmath195 to obtain a normalizable posterior .",
    "our posterior p.d.f .  for @xmath3 with @xmath5 ( and @xmath6 ) fixed is recovered exactly by taking the limit of @xmath196 as @xmath197 .",
    "this means that the limit of @xmath198 as @xmath197 is identical to the value of @xmath198 when @xmath5 is known exactly .",
    "this property may seem obvious , but it is violated by some frequentist methods of setting limits , so it is worth mentioning .",
    "we need to integrate @xmath196 up to some limit @xmath29 , which can be done analytically as follows .",
    "@xmath199 where the substitution @xmath200 has been performed .",
    "re - expanding the polynomial @xmath111 and integrating term by term yields @xmath201 where @xmath202 is the standard notation for the incomplete beta function @xmath203 which also satisfies the following recursion : @xmath204      using the same technique as above , we can calculate the @xmath205th moment of the posterior p.d.f .  as @xmath206 where we utilize the rising factorial notation@xcite @xmath207    the expression for the mean of the posterior when",
    "@xmath156 can be simplified using the identity @xmath208 obtaining @xmath209 note that the 2nd term is very small when @xmath138 .",
    "the recurrence relation@xcite @xmath210 leads to a recurrence relation between moments @xmath211 the special case @xmath156 then yields @xmath212\\ ] ] which leads to this approximation for the variance of the posterior @xmath213      here we very briefly consider the case where the background parameter @xmath6 also acquires an uncertainty .",
    "this case is more general than the fixed @xmath6 case that is the main subject of this note : the fixed @xmath6 case will be the subject of additional studies employing various popular frequentist techniques , with the goal of comparing their performance .",
    "we judge the more general case considered in this subsection to be more complicated than necessary for the purpose of comparing the various methods , but it is instructive to document the fact that the bayesian method can easily handle the more general case .",
    "we assume a 2nd subsidiary measurement observing @xmath214 events ( poisson , as was the case for @xmath5 ) , which , when combined with a flat prior for @xmath6 , results in a gamma posterior for @xmath6 of the form @xmath215 where @xmath216 is a calibration constant ( analogous to @xmath80 in the subsidiary measurement for  @xmath5 ) .",
    "the posterior for @xmath6 becomes the prior for @xmath6 in the measurement of @xmath3 . after determining the joint posterior @xmath217 by using our priors for @xmath3 , @xmath5 and @xmath6 , we marginalize with respect to @xmath5 and @xmath6 ,",
    "resulting in @xmath218 where we write @xmath219 for convenience , and @xmath220 is the hypergeometric function@xcite .",
    "as long as @xmath0 is a non - negative integer and @xmath142 , @xmath221 is a polynomial of order @xmath0 in @xmath222 ( closely related to jacobi polynomials ) .",
    "this marginalized posterior for @xmath3 can then be integrated , with the result @xmath223    these two equations closely resemble the main results of sections [ postpdf ] and [ intpostpdf ] : to recover the fixed @xmath6 results , simply substitute @xmath224 for @xmath225 above , and take the limit @xmath226 .",
    "in this appendix we prove that bayesian credible intervals have average frequentist coverage , where the average is calculated with respect to the prior density .",
    "we start from the bayesian posterior density : @xmath227 for a given observed value of @xmath0 , a credibility-@xmath27 bayesian interval for @xmath3 is any interval @xmath228 $ ] that encloses a fraction @xmath27 of the total area under the posterior density . such an interval must therefore satisfy : @xmath229 or , using the definition of the posterior density : @xmath230 now for coverage . given a true value @xmath231 of @xmath3 , the coverage @xmath232 of @xmath233 $ ] is the frequentist probability that @xmath231 is included in that interval .",
    "we can write this as : @xmath234                              s_\\mathrm{l}(n)\\le s\\le s_\\mathrm{u}(n ) } }    p(n\\,|\\,s_\\mathrm{t } ) .",
    "\\label{eq : acbci2}\\ ] ] next we calculate the average coverage @xmath235 , weighted by the prior @xmath22 :    @xmath236\\\\[6 mm ]          & \\;=\\ ;   \\int_{0}^{\\infty}\\sum_{\\substack{\\text{all $ n$ such that:}\\\\[1 mm ]                                                    s_\\mathrm{l}(n)\\le s\\le s_\\mathrm{u}(n ) } }                   p(n\\,|\\,s)\\,\\pi(s)\\ , ds ,                & & \\text{using equation ( \\protect\\ref{eq : acbci2 } ) , } \\displaybreak[0]\\\\[6 mm ]          & \\;=\\ ;   \\sum_{n=0}^{\\infty}\\;\\int_{s_\\mathrm{l}(n)}^{s_\\mathrm{u}(n)}\\ !",
    "p(n\\,|\\,s)\\,\\pi(s)\\,ds ,                & & \\text{interchanging integral and sum,\\protect\\footnotemark}\\displaybreak[0]\\\\[6 mm ]          & \\;=\\ ;   \\beta\\ ; \\sum_{n=0}^{\\infty}\\;\\int_{0}^{\\infty}\\ !",
    "p(n\\,|\\,s)\\,\\pi(s)\\,ds ,                & & \\text{using equation ( \\protect\\ref{eq : acbci1 } ) , } \\displaybreak[0]\\\\[6 mm ]          & \\;=\\ ;   \\beta\\ ; \\int_{0}^{\\infty}\\sum_{n=0}^{\\infty } p(n\\,|\\,s)\\,\\pi(s)\\,ds ,                & & \\text{interchanging sum and integral,}\\displaybreak[0]\\\\[6 mm ]          & \\;=\\ ;   \\beta\\ ; \\int_{0}^{\\infty}\\!\\pi(s)\\ , ds ,                & & \\text{by the normalization of } p(n\\,|\\,s ) , \\displaybreak[0]\\\\[6 mm ]          & \\;=\\ ;   \\beta ,                & & \\text{by the normalization of } \\pi(s ) .\\end{aligned}\\ ] ]    this completes the proof .",
    "we have assumed here that the prior @xmath22 is proper and normalized to 1 , but the proof can be generalized to improper priors such as those we considered in this note .",
    "a constant prior for example , can be regarded as the limit for @xmath237 of the proper prior : @xmath238 where @xmath239 is @xmath240 if @xmath241 and @xmath242 otherwise .",
    "we then _ define _ the average coverage for the constant prior as the limit : @xmath243 the previous proof can now be applied to the argument of the limit and leads to the same result .",
    "the average coverage theorem remains valid when @xmath3 is multidimensional , for example when it consists of a parameter of interest and one or more nuisance parameters . in that case one needs to average the coverage over _ all _ the parameters .",
    "m.  j.  bayarri and j.  o.  berger , `` the interplay of bayesian and frequentist analysis '' , statistical science 19 , p 58 ( 2004 ) , + projecteuclid.org/dienst/ui/1.0/summarize/euclid.ss/1089808273 , + www.isds.duke.edu/~berger/papers/interplay.html .",
    "peter clifford , `` interval estimation as viewed from the world of mathematical statistics '' , cern yellow report cern 2000 - 005 , p 157 ( 2000 ) , _ proceedings of the workshop on confidence limits at cern , 1718 january 2000 _ , edited by l.  lyons , y.  perrin , and f.  james , + doc.cern.ch/yellowrep/2000/2000-005/p157.pdf .",
    "giovanni punzi , `` a stronger classical definition of confidence limits '' , hep - ex/9912048 , www.arxiv.org/abs/hep-ex/9912048 .",
    "gnter zech , `` confronting classical and bayesian confidence limits to examples '' , cern yellow report cern 2000 - 005 , p 141 ( 2000 ) , _ proceedings of the workshop on confidence limits at cern , 1718 january 2000 _ , edited by l.  lyons , y.  perrin , and f.  james , doc.cern.ch/yellowrep/2000/2000-005/p141.pdf .",
    "d.  karlen , `` credibility of confidence intervals '' , in _ proceedings of the conference on advanced techniques in particle physics , durham , 1822 march 2002 _ , edited by m.  whalley and l.  lyons , p 53 , ( 2002 ) , + www.ippp.dur.ac.uk/workshops/02/statistics/proceedings/karlen.pdf .",
    "gary feldman , `` multiple measurements and parameters in the unified approach '' , _ fermilab workshop on confidence limits 2728 march , 2000 _ , p 11 , + conferences.fnal.gov/cl2k/copies/feldman2.pdf , + huhepl.harvard.edu/~feldman/cl2k.pdf .",
    "joel heinrich , `` user guide to bayesian - limit software package '' , cdf internal note 7232 , ( 2004 ) , + www-cdf.fnal.gov/publications/cdf7232_blimitguide.pdf ; + cdf statistics committee software page , + www-cdf.fnal.gov/physics/statistics/statistics_software.html .",
    "r.  l.  graham , d.  e.  knuth , and o.  patashnik , `` concrete mathematics : a foundation for computer science '' , 2nd ed . , ( addison - wesley , reading , ma , 1994 ) ; planetmath mathematics encyclopedia , + planetmath.org/encyclopedia/fallingfactorial.html .",
    "m.  abramowitz and i.a .",
    "stegun , editors , `` handbook of mathematical functions '' , ( united states department of commerce , national bureau of standards , washington , d.c .",
    "1964 ; and dover publications , new york , 1968 ) , chapter 13 .    m.  abramowitz and i.a .",
    "stegun , ibid . , chapter 15 ; william h. press , et al .",
    ",  `` numerical recipes '' , 2nd edition , ( cambridge university press , cambridge , 1992 ) ,  5.14 and  6.12 , lib-www.lanl.gov/numerical/bookcpdf/c5-14.pdf , + lib-www.lanl.gov/numerical/bookcpdf/c6-12.pdf .     for bayes 90% limits , for the simple case of no background and no uncertainty on @xmath244 . the dotted line at @xmath245 is given to show that the coverage never falls below 90% ( in this simple case ) .",
    "]         vs @xmath3 for @xmath246 , 3 , 5 , 10 . in each case ,",
    "@xmath43 and @xmath39 ( i.e.  @xmath40 and @xmath82=99).,title=\"fig:\",width=302]-0.2 in   vs @xmath3 for @xmath246 , 3 , 5 , 10 . in each case , @xmath43 and @xmath39 ( i.e.  @xmath40 and @xmath82=99).,title=\"fig:\",width=302 ] +   vs @xmath3 for @xmath246 , 3 , 5 , 10 . in each case ,",
    "@xmath43 and @xmath39 ( i.e.  @xmath40 and @xmath82=99).,title=\"fig:\",width=302]-0.2 in   vs @xmath3 for @xmath246 , 3 , 5 , 10 . in each case ,",
    "@xmath43 and @xmath39 ( i.e.  @xmath40 and @xmath82=99).,title=\"fig:\",width=302 ] +"
  ],
  "abstract_text": [
    "<S> we address the common problem of calculating intervals in the presence of systematic uncertainties . </S>",
    "<S> we aim to investigate several approaches , but here describe just a bayesian technique for setting upper limits . </S>",
    "<S> the particular example we study is that of inferring the rate of a poisson process when there are uncertainties on the acceptance and the background . </S>",
    "<S> limit calculating software associated with this work is available in the form of c  functions . </S>"
  ]
}