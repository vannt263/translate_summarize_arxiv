{
  "article_text": [
    "in this article we study a type of resampling procedure for markov chains .",
    "the procedure , called weighted ensemble ( we ) sampling  @xcite , simulates some replicas of a markov chain @xmath0 , resampling from the replicas at certain time intervals .",
    "the distinguishing feature of we sampling , compared to other resampling techniques , is that we is designed so that the replicas of @xmath0 are evenly distributed throughout state space .",
    "this is achieved by dividing state space into bins and resampling in each bin so that the number of replicas in a bin remains roughly constant .",
    "the replicas carry probabilistic weights so that the resulting statistical distribution is unbiased .",
    "this distribution can be used , in principle , to estimate any function of of @xmath0 at a fixed time  @xcite .",
    "our interest in we arises from longstanding problems in computational chemistry . in this",
    "setting , @xmath0 is a time discretization of some stochastic molecular dynamics ( md ) .",
    "md simulations have proven useful for understanding many chemical and biological processes ; see  @xcite for an overview . however , such simulations are limited by time scale separation . many phenomena of interest occur at the laboratory time scale of microseconds , while md simulations have time steps that correspond to femtoseconds . in this case ,",
    "straightforward md simulations are not practical .",
    "many methods exist for extending the time scale of md simulations ; we do not attempt to give a review of them here .",
    "however , we mention some related methods , including exact milestoning  @xcite , neus  @xcite , trajectory tilting  @xcite , transition interface sampling  @xcite , forward flux sampling  @xcite , and boxed molecular dynamics  @xcite .",
    "see for instance  @xcite for review and comparison of these methods .",
    "we will compare we to exact milestoning in section  [ sec : dynamics ] below .    in this article",
    "we give a mathematical framework for we based on martingale theory .",
    "the framework allows us to prove that we is exact even when the bins and the number of replicas per bin are chosen adaptively , as noted earlier in  @xcite . while we can be used with a broad range of stochastic processes , when the process is time homogenous and markovian  as in many models of md , such as langevin dynamics  we can be used to efficiently compute dynamical quantities like reaction rates without actually simulating the reactions  @xcite .",
    "these computations rely on hill s relation  @xcite , which we generalize in section  [ sec : dynamics ] below . from hill",
    "s relation , obtaining reaction rates and probabilities requires a calculation on the stationary distribution of a nonreversible process . to speed up this stationary calculation ,",
    "we is combined with a preconditioning step  @xcite in which a markov state model ( msm )  @xcite is used to approximate the stationary distribution .",
    "this is sometimes called accelerated we  @xcite .",
    "accelerated we begins with replicas evenly distributed in space , with weights chosen to match the stationary distribution of the msm .",
    "the replicas are then allowed to relax according to their exact dynamics , with we sampling ensuring that the replicas remain evenly distributed in state space .",
    "we show below that information from the msm can be used to optimize the we sampling in this relaxation step , in the sense that the variance in the appropriate stationary calculation is minimized .",
    "this optimization requires an adaptive number of replicas per bin , in contrast with traditional we sampling .",
    "we show in a simple model that this adaptive sampling can be significantly better than traditional we sampling .    this article is organized as follows . in section  [ sec : assumptions ] , we introduce notation for the replica processes , and we make assumptions on we sampling that we assume hold throughout .",
    "( we refer to the replica processes as `` point and weight '' processes , following familiar notation in the mathematical resampling literature . )",
    "we prove that we is unbiased in a general setting that includes adaptive binning procedures . in section",
    "[ sec : sampling ] , we introduce an explicit algorithm for we sampling ( algorithm  [ alg1 ] ) and prove that it is unbiased ( proposition  [ prop1 ] below ) .",
    "we give an exact formula for the mean squared error of this sampling ( proposition  [ prop2 ] ) .",
    "then , using this error formula , we produce a heuristic near - optimal adaptive strategy . in section  [ sec :",
    "stationary ] , we propose a version of accelerated we which uses this strategy ( algorithm  [ alg2 ] ) . in section",
    "[ sec : example ] , we implement the adaptive strategy on a simple model , and compare with traditional we sampling as well as naive sampling . in section  [ sec : dynamics ] , we show how to obtain certain dynamical averages , including mean first passage times and hitting probabilities , from the stationary distribution of a nonreversible markov chain .",
    "all proofs are in section  [ sec : proofs ] .",
    "in this section we introduce a general mathematical framework for unbiased we sampling . throughout @xmath1",
    "is a markov chain taking values in a measurable space @xmath2 , with transition kernels @xmath3 .",
    "we write @xmath4 for the expectation operator of @xmath1 .",
    "below we consider sampling schemes for @xmath1 of the following type .",
    "let @xmath5 and @xmath6 be a points and weights processes evolving by selection and mutation : @xmath7 here , each @xmath8 and @xmath9 .",
    "we refer to @xmath5 and @xmath6 as the points and weights at time @xmath10 .",
    "the expectation operator associated to the points and weights process will be denoted @xmath11 .    below",
    "we describe rules which guarantee the points and weights process is unbiased .",
    "readers interested only in explicit algorithms can skip to the next section . before describing this process in more detail",
    ", we need some notation . throughout , @xmath12 indicates denote equality in law of random variables or processes .",
    "consider the information generated by the process up to time @xmath10 , that is , the @xmath13-algebra generated by the points and weights up to time @xmath10 , prior to the selection step : @xmath14 consider also the larger @xmath13-algebra obtained when the information from the points and weights in the selection step at time @xmath10 is included : @xmath15    we assume the points and weights process obeys rules ( a1)-(a5 ) below .",
    "the rules do not uniquely define the selection and mutation procedure , but they ensure the points and weights process has certain properties , like being unbiased for the law of @xmath1 ; see theorem  [ thm1 ] below .",
    "we first consider the initialization of the process .",
    "the initial points and weights have the distribution of @xmath16 in the following sense :    * the initial collection of points and weights satisfies @xmath17 w.p . @xmath18 and @xmath19   = { \\mathbb e}[h(x_0)].\\ ] ] for every bounded measurable @xmath20 .",
    "for example , the initial condition could be an average of a fixed number of samples of @xmath16 , that is , @xmath21 is deterministic and @xmath22 , and @xmath23 for @xmath24 .",
    "notice we do not require that the @xmath25 s are independent , so they can be generated by , for example , markov chain monte carlo or other sequential samplers .",
    "next we consider the selection step . in we",
    "sampling , points are divided according to `` bins '' that partition state space .",
    "we do not require bins here , but we assume that the collection of points @xmath26 at time @xmath10 can be divided into @xmath27 different collections , and that these collections are identifiable at time @xmath10 .",
    "we make the same assumption for the selected points .",
    "* there are partitions @xmath28 of @xmath29 and @xmath30 of @xmath31 that can be determined at time @xmath10 .",
    "that is , @xmath27 and @xmath28 are @xmath32-measurable , and @xmath30 are @xmath33-measurable .",
    "note that the partitions above need not be associated with a partition of state space .",
    "all that is required is a classification of the point indices into disjoint collections .",
    "we assume that the selection is unbiased with respect to this classification :    * the selection in unbiased with respect to the partition in ( a2 ) , that is , @xmath34   = \\sum_{i \\in",
    "i_p^r }   { \\omega}_p^i h_p({\\xi_p^i})\\ ] ] for every bounded measurable @xmath35 .",
    "we now turn to the mutation step . in this step",
    ", each selected point evolves to form a point of the next generation , with its weight remaining the same .    *",
    "the number of mutated points is the same as the number of selected points : @xmath36 and moreover the weights do not change upon mutation : @xmath37    finally , we assume the mutations are independent and follow the law of @xmath1 .    *",
    "the mutations are obtained by independent draws from @xmath3 : @xmath38    at time @xmath10 , the points and weights process defines an empirical distribution @xmath39 consider the first time all the points have been killed , @xmath40 we adopt the convention that @xmath41 we will now show that @xmath42 is an unbiased approximation for the law of @xmath1 .",
    "this allows us to compute unbiased estimates of functions of @xmath1 at a fixed time @xmath10 .",
    "see the discussion after algorithm  [ alg1 ] below .",
    "[ thm1 ] @xmath43 is an unbiased estimator of the law of @xmath44 .",
    "that is , @xmath45   \\equiv { \\mathbb e}^{emp}[\\eta_n(f_n ) ]   = { \\mathbb e}[f_n(x_n)]\\ ] ] for every bounded measurable @xmath46 .",
    "we now present a we algorithm that is consistent with the assumptions in section  [ sec : assumptions ] . compared to the general setting above , our algorithm below has two specific features .",
    "first , we use bins to define the partition in ( a2 ) above . and second , the resampling in each bin is designed to produce points in the next generation that all have the same weight ( see also  @xcite ) .",
    "this ensures that the weights do not usually vary by large amounts in small regions of state space .",
    "[ alg1 ] pick initial points @xmath47 and weights @xmath48 as in ( a1 ) .",
    "then iterate :    * _ selection step : _ * choose bins @xmath49 forming a partition of @xmath50 , and a target number of points @xmath51 for each bin @xmath52 .",
    "the @xmath52 s and @xmath51 s must be deterministic functions of the points and weights up to and including the current time @xmath10 .",
    "* for @xmath53 , do the following . set a target weight in bin @xmath52 as @xmath54 for @xmath55 such that @xmath56 , let @xmath57 be a random variable with law @xmath58 let the number of selected points equal to @xmath56 be @xmath57 : @xmath59 assign the target weight @xmath60 to all the selected points in bin @xmath52 : @xmath61 let @xmath62 be the total number of selected points : @xmath63 * _ mutation step : _ * independently evolve the @xmath64 s to obtain the points at time @xmath65 : @xmath66 set the new weights equal to the selected weights : @xmath67 set the total number of new particles as @xmath68 .",
    "then update @xmath69 and return to 1 .",
    "some remarks are in order .",
    "* given the points and weights at time @xmath10 , the procedure in step 2 uniquely defines the law of the selected points and weights , up to index relabeling . from  ,",
    "each point @xmath26 in bin @xmath52 is selected on average @xmath70 times , that is ,",
    "@xmath71 = \\frac{\\omega_p^i}{{\\bar \\omega}_p^r},\\ ] ] so the expected number of selected points in bin @xmath52 is at time @xmath10 is @xmath72=   \\sum_{i:\\xi_p^i \\in b_p^r } \\frac{\\omega_p^i}{{\\bar \\omega}_p^r } = n_p^r.\\ ] ] thus , the @xmath51 can be seen as parameters controlling the average number of points per bin . as we have seen in theorem  [ thm1 ] , these numbers may be chosen adaptively . indeed , a key feature of algorithm  [ alg1 ] is that the bins @xmath52 and the numbers @xmath51 may be chosen adaptively . *",
    "the algorithm generates empirical approximations @xmath73 of the distribution of @xmath1 . in proposition  [ prop1 ] below , we show these empirical approximations are unbiased in the sense of theorem  [ thm1 ] . *",
    "recall that @xmath74 is the first time that all the points have been killed .",
    "if @xmath75 is such that @xmath76 $ ] is too large , then the variance of the estimator @xmath77 of @xmath78 $ ] can be large as well .",
    "this is because when @xmath76 $ ] is large , in many simulations the value of @xmath77 will be @xmath79 , which is uninformative . in practice , to avoid this , the values of @xmath51 can be given some lower threshold .",
    "see the remarks after algorithm  [ alg2 ] below . * in practice , the points may not be resampled at every time step .",
    "we have in mind the case where @xmath1 is obtained from an underlying markov chain at certain resampling times .",
    "that is , @xmath80 where @xmath0 is an underlying markov chain and @xmath81 are some resampling times .",
    "the @xmath81 can be deterministic times  for instance @xmath82 , where @xmath83 is a constant lag time  or they can be certain stopping times for @xmath0 . for stationary calculations based on hill s relation , the resampling times should be chosen so that @xmath1 is a time homogeneous markov chain .",
    "see the discussion in section  [ sec : dynamics ] below .    as noted above , algorithm  [ alg1 ] produces unbiased estimates of the law of @xmath44 :    [ prop1 ] algorithm  [ alg1 ] satisfies ( a1)-(a5 ) above when @xmath84 in particular , @xmath43 is an unbiased estimator of the law of @xmath44 in the sense of theorem  [ thm1 ] .    in proposition  [ prop2 ] below we present an explicit formula for the mean squared error in the estimate @xmath85 $ ] when @xmath43 is obtained from algorithm  [ alg1 ] . below proposition",
    "[ prop2 ] , we use the error formula to present an adaptive sampling strategy .",
    "this strategy uses some information from a coarse model ( for instance , a msm ) to guide the sampling .",
    "[ prop2 ] let @xmath75 be a fixed time and @xmath46 a bounded measurable function . in algorithm  [ alg1 ] , the mean squared error in the approximation @xmath77 of @xmath78 $ ] satisfies @xmath86\\right)^2\\right ]   = { \\mathbb e}^{emp}[(\\eta_0(f_0)-{\\mathbb e}[f_n(x_n)])^2]\\\\ & \\qquad \\qquad \\qquad\\qquad \\qquad\\qquad",
    "\\qquad + \\sum_{p=1}^n   { \\mathbb e}^{emp}\\left[\\left ( \\eta_p(f_p)-\\eta_{p-1}(f_{p-1})\\right)^2 \\right ] \\end{split}\\end{aligned}\\ ] ] where , writing @xmath87 $ ] and @xmath88 , we have @xmath89\\\\ & \\qquad   =   \\sum_{r=1}^{r_p } \\sum_{i:\\xi_p^i \\in b_p^r}\\left [ { \\bar \\omega}_p^r\\omega_p^i k_p g_{p+1}^2(\\xi_p^i)- \\left({\\bar \\omega}_p^r\\omega_p^i + \\left(\\omega_p^i\\right)^2 -\\left({\\bar \\omega}_p^r\\right)^2\\sigma_p^{r , i}\\right ) g_p(\\xi_p^i)^2\\right ] . \\end{split}\\end{aligned}\\ ] ]    given the points and weights at time @xmath10 , we may try to minimize the contributions to the mean squared error in   over choices of @xmath52 and @xmath51 .",
    "we pursue this idea , for fixed bins but an adaptive target number of points per bin .",
    "suppose for given bins @xmath52 we want to optimize over the allocation @xmath51 of points , subject to the constraint that the average total number of points is fixed at @xmath90 .    for the remainder of this section",
    ", we assume that @xmath1 is time homogeneous with transition kernel @xmath91 , that the bins @xmath92 do not change in time , with @xmath93 total bins , and that @xmath94 . using the mean squared error formula in proposition  [ prop2 ] , we heuristically derive an adaptive sampling strategy below .",
    "notice that @xmath57 are defined so that they have minimal variance .",
    "we estimate @xmath95 \\approx   { \\mathbb e}^{emp}\\left[\\left .",
    "c_p^{r , i}\\right| { \\mathcal f}_p\\right]^2   = \\left(\\frac{\\omega_p^i}{{\\bar \\omega}_p^r}\\right)^2.\\ ] ] suppose we have approximations @xmath96 of @xmath97 inside @xmath98 , that is , @xmath99 in this case ,   rewrites as @xmath100\\\\ & = \\sum_{r=1}^{r_p } \\sum_{i:\\xi_p^i \\in b_p^r}\\left [ { \\bar \\omega}_p^r\\omega_p^i k g_{p+1}^2(\\xi_p^i)-",
    "\\left({\\bar \\omega}_p^r\\omega_p^i + \\left(\\omega_p^i\\right)^2 -\\left({\\bar \\omega}_p^r\\right)^2\\sigma_p^{r , i}\\right ) g_p(\\xi_p^i)^2\\right ] \\\\ & \\approx \\sum_{r=1}^{r_p } \\sum_{i:\\xi_p^i \\in b_p^r } { \\bar \\omega}_p^r\\left[\\omega_p^i k g_{p+1}^2(\\xi_p^i)-   \\omega_p^i g_p(\\xi_p^i)^2\\right ] \\\\ & \\approx \\sum_{r=1}^{r_p } { \\bar \\omega}_p^r v_p^r \\sum_{i:\\xi_p^i \\in b_p^r } \\omega_p^i \\\\ & = \\sum_{r=1}^r \\frac{v_p^r \\left(\\sum_{i:\\xi_p^i \\in b_p^r } \\omega_p^i\\right)^2}{n_p^r}. \\end{split}\\end{aligned}\\ ] ] minimizing the last expression with the constraint @xmath101 leads to the formula @xmath102 the approximations @xmath96 can be obtained , for instance , by estimating a coarse probability @xmath103 of @xmath1 going from bin @xmath98 to bin @xmath104 in one time step .",
    "this essentially amounts to constructing a msm  @xcite for @xmath1 , with each state corresponding to a bin , and with time step @xmath18 .",
    "of course , as with any msm , there is error arising from the markov assumption , since the probability @xmath103 for @xmath1 to transition between bins @xmath98 and @xmath104 depends on the initial distribution of @xmath1 in @xmath98 .",
    "however , the msm can be seen as a coarse model for @xmath1 , and in particular , when @xmath1 has stationary distribution @xmath105 , we will use the stationary distribution of the msm as an initial guess of @xmath105 .",
    "some comments on the term @xmath106 are in order .",
    "it is not hard to see that @xmath107.\\ ] ] the heuristic strategy suggests the larger the value of @xmath108 , the more beneficial it is to select @xmath109 .",
    "it is also easy to check that for naive sampling  that is , sampling with no selection step  the contributions to the mean squared error are @xmath110    = \\sum_{i=1}^n \\left[k g_{p+1}^2(\\xi_p^i )    - g_p^2(\\xi_p^i)\\right],\\ ] ] with @xmath90 the ( constant ) total number of points .",
    "we explore the heuristic strategy above in section  [ sec : stationary ] below , showing how it can be combined with existing we technologies to efficiently sample the stationary distribution of @xmath1 in the time homogeneous case .",
    "in this section we present a procedure , algorithm  [ alg2 ] below , for computing stationary averages in the time homogeneous case . in this section , @xmath1 is a time homogeneous markov chain with values in a measurable space @xmath111 , and transition kernel @xmath112 .",
    "we assume @xmath1 has a unique stationary distribution  @xmath105 .",
    "the algorithm below is designed to efficiently compute @xmath113 for a fixed bounded measurable function @xmath114 .",
    "[ alg2 ] choose a relaxation time @xmath75 , a sampling measure @xmath109 on @xmath111 , and bins @xmath115 forming a partition of @xmath116 .",
    "choose a target number of total points @xmath117 .",
    "then iterate : _ preconditioning step : _    *",
    "let @xmath118 estimate the probability for @xmath1 to go from @xmath98 to @xmath104 in one step : @xmath119\\,\\xi(dx)\\ ] ] let @xmath120 estimate the value of @xmath121 inside bin @xmath98 : @xmath122 * let @xmath123 be the stationary distribution for the transition matrix @xmath124 .",
    "that is , @xmath125 is the left eigenvector of @xmath126 corresponding to the eigenvalue @xmath18 , normalized so that @xmath127 .",
    "* let @xmath96 be the @xmath128th entry of the vector @xmath129 , where @xmath130 is the vector estimate of @xmath121 and the squaring operations are entrywise .",
    "_ relaxation step : _",
    "* choose initial points so that the number of points in @xmath98 is @xmath131 : @xmath132 choose initial weights so that the total weight inside each bin @xmath98 is @xmath133 : @xmath134 * proceed through algorithm  [ alg1 ] from time @xmath135 to @xmath136 , with either @xmath137 or @xmath138 defining the target number of points in bin @xmath98 at time @xmath10 . *",
    "the output of the algorithm is @xmath139 .",
    "some remarks are in order .    *",
    "the purpose of the preconditioning step is to obtain a coarse approximation @xmath123 of @xmath105 , the stationary distribution of @xmath1 .",
    "this approximation is then used as the initial condition of the relaxation step .",
    "note that @xmath103 and @xmath120 can be estimated by running many short trajectories in parallel .",
    "the sampling measure @xmath109 is the initial distribution for these short trajectories .",
    "* @xmath103 is essentially the transition matrix of a msm for @xmath1 defined so that its states are the bins @xmath140 , and its time step is exactly @xmath18 .",
    "if @xmath1 is obtained from an underlying markov chain @xmath0 via @xmath141 , then this can be viewed as an msm for @xmath0 with time step @xmath83 . under suitable conditions ,",
    "the vector @xmath123 is the unique stationary distribution of the msm . to understand the expression for @xmath96 , note that since @xmath142 , @xmath143 thus , @xmath96 is defined using  , where the approximation is obtained by replacing @xmath112 with @xmath126 and @xmath121 with @xmath144 on the right hand side of that equation . in particular ,",
    "the definition of @xmath96 is consistent with the heuristic calculations in section  [ sec : sampling ] . *",
    "the purpose of the relaxation step is to allow the coarse approximation @xmath123 to relax to the stationary distribution @xmath105 .",
    "when the relaxation time @xmath75 is appropriately chosen , @xmath145 is a good approximation of @xmath113 .",
    "since the relaxation step starts at the coarse approximation @xmath123 of @xmath105 , the relaxation time @xmath75 can be much smaller than the typical time to converge from an arbitrary initial distribution .",
    "* when @xmath146 as in  , we recover the accelerated weighted ensemble technique of  @xcite . on the other hand , when @xmath147 satisfies   the sampling is adaptive . for comparisons of sampling with   and  ,",
    "see the simulations in section  [ sec : example ] below . in the adaptive case ,",
    "the choice of @xmath51 depends on the parameter @xmath75 .",
    "thus , a simulation at a given value of @xmath75 can not be easily extended to a larger value of @xmath75 with the same formula   defining @xmath51 .",
    "also , in the adaptive case the choice of @xmath51 depends on @xmath121 , and so separate simulations are likely needed for computing @xmath148 $ ] for different functions @xmath121 . *",
    "the @xmath149 is introduced so that @xmath150 with high probability .",
    "when @xmath149 is too small , it can happen that all the points are killed in a large fraction of simulations .",
    "in this situation , the variance can be large .",
    "this killing can occur if , for example , @xmath51 is nonzero only in regions where there are no points . on the other hand ,",
    "if @xmath149 is too large , we can lose the benefits of the adaptive sampling .",
    "here we consider an underlying markov chain @xmath0 on state space @xmath151 with transition matrix @xmath152 where @xmath153 and @xmath154 is chosen so that @xmath155 is stochastic .",
    "we take resampling intervals @xmath156 , so @xmath157 and the transition matrix of @xmath1 is @xmath158 .",
    "the bins will be @xmath159 thus , there are @xmath160 fixed bins .",
    "let @xmath105 be the stationary distribution of @xmath1 , and @xmath161 we also let @xmath162 be its normalized version .",
    "we use algorithm  [ alg2 ] to obtain empirical approximations @xmath145 of @xmath113 for a fixed relaxation time  @xmath75 . throughout",
    ", we use a sampling measure @xmath109 which is uniform : @xmath163 for all @xmath55 . in the relaxation step of algorithm  [ alg2 ] ,",
    "the initial empirical distribution of points and weights can be considered a sample from @xmath164    we will use three types of sampling .",
    "the first type of sampling uses the adaptive allocation of points from equation   above .",
    "we call this adaptive we sampling . in  , we take @xmath165 and @xmath166 .",
    "we found this @xmath149 to be sufficiently large that @xmath150 in all our simulations .    in the second type of sampling we used a fixed target number of points per bin .",
    "we call this traditional we sampling .",
    "it is the sampling method described in  @xcite .",
    "here we use equation  , taking @xmath167 .",
    "again , we had @xmath150 in all our simulations .",
    "notice for both adaptive and traditional we sampling , we have chosen @xmath90 so that the target number of points is @xmath168 .    [ fig1]-190pt     vs. @xmath75 from the example in section  [ sec : example ] from adaptive , traditional and naive sampling .",
    "the crosses are exact values corresponding to @xmath169 , and the dotted line is the stationary value @xmath113 .",
    "bottom right : empirical standard deviations @xmath170 of @xmath145 , obtained from @xmath171 independent simulations .",
    "( these are the error bar radii from the other plots . ) ]    -170pt    [ fig2]-195pt     at time @xmath172 , compared to @xmath173 , the normalized version of @xmath121 . here",
    ", @xmath174 is the total number of points at time @xmath75 .",
    "bottom right : stationary distribution @xmath105 .",
    "]    -170pt    the last type of sampling does not use resampling at all .",
    "we call this naive sampling . here , we skip steps ( ii ) and ( iii ) of the relaxation step of algorithm  [ alg2 ] . instead , after the points @xmath175 and weights @xmath176 are chosen , we simply evolve these points independently until time @xmath75 , without changing the weights . for this sampling",
    "we take @xmath165 total points , to facilitate comparison with the traditional and adaptive sampling described above .",
    "results comparing the different relaxation techniques are in figures  [ fig1]-  [ fig2 ] . in figure",
    "[ fig1 ] , we plot @xmath145 vs. @xmath75 for various values of @xmath75 , showing convergence to the stationary value @xmath113 .",
    "we compute error bars as empirical standard deviations from @xmath171 independent simulations .",
    "we found that the error bars for adaptive we sampling were significantly smaller than that of traditional we and naive sampling . in figure",
    "[ fig2 ] , we plot histograms representing the average distribution of the points @xmath177 at time @xmath75 .",
    "note that traditional we sampling distributes the points roughly uniformly in space , as expected , while adaptive we sampling guides the points towards the region in state space relevant for computing @xmath121 .",
    "meanwhile , naive sampling distributes the points according to the stationary distribution @xmath105 . in figure",
    "[ fig3 ] , we plot the estimates @xmath96 from the adaptive sampling strategy for @xmath178 and @xmath179 where @xmath180 is the relaxation time",
    ". note that by time @xmath181 , the sampling is focused near the support of @xmath121 .",
    "when @xmath121 is a function with large values in regions of low @xmath105 probability , as in this example , naive sampling performs poorly compared to both traditional and adaptive we sampling .",
    "when state space is very large compared to the region @xmath182 where @xmath121 has large values ( or is non - negligible ) , we expect adaptive we sampling to perform much better than traditional we sampling , due to the fact that traditional we sampling will distribute the points very thinly throughout space , including in @xmath182 , while adaptive we sampling will push most of the points towards @xmath182 .",
    "a possible drawback of adaptive we sampling is that it requires more computations at the resampling times , compared to traditional we sampling .",
    "however , in practice the resampling times may be large enough so that this extra effort contributes little to the overall computational cost .",
    "finally , we note that the adaptive sampling above can also be used more generally to estimate time marginals of @xmath44 , that is , expectations of the form @xmath148 $ ] at fixed finite times @xmath75 , from an arbitrary initial distribution of @xmath16 . in this case , a msm is still required to guide the sampling .",
    "one of the advantages of the adaptive sampling in the stationary case is that an msm has already been computed as part of a preconditioning step .",
    "[ fig3]-210pt     from   vs. @xmath10 for the example in section  [ sec : example ] . here",
    ", we take @xmath135 and @xmath183 , when @xmath180 is the final time . ]",
    "in this section we show how to compute certain dynamical averages of time homogeneous markov chains from stationary calculations on a related markov chain .",
    "the hill relation  @xcite shows that a mean first passage time can be reformulated as a certain stationary average .",
    "we will generalize this relation below .",
    "assume that @xmath1 is obtained from an underlying markov chain @xmath0 at some resampling times @xmath81 , that is , @xmath80 .",
    "we assume @xmath1 and @xmath0 have values in a measurable space @xmath111 .",
    "@xmath0 can be continuous or discrete in time . for simplicity , and since in simulations time discretization is required anyway , we assume here it is discrete in time . to obtain @xmath1 from @xmath0 , we need to define the resampling times @xmath81 .",
    "we will assume they satisfy the following :    * @xmath184 are stopping times for @xmath0 such that for all @xmath185 , @xmath186    informally , this means @xmath0 and the stopping time increments @xmath187 regenerate at each stopping time @xmath81 .",
    "for example , we can take @xmath81 to be @xmath10 multiplied by some deterministic lag time .",
    "alternatively , the @xmath81 can be a sequence of hitting times of coarse sets in state space , as in exact milestoning ; see the comments below .    to be able to compute dynamical averages from stationary ones",
    ", we must introduce a source and sink .",
    "let @xmath188 and @xmath189 be disjoint initial and final sets , such that when @xmath0 arrives in @xmath189 at one of the resampling times , it immediately returns to @xmath188 .",
    "when it returns to @xmath188 , it starts at a fixed source distribution @xmath190 on @xmath188 :    * there are disjoint measurable sets @xmath191 and a distribution @xmath190 on @xmath188 so that @xmath192 =   \\int { \\mathbb p}^x[y_1 \\in a]\\rho(dx).\\ ] ]    we are interested in computing , for example , the mean first passage time of @xmath0 from @xmath188 to @xmath189 .",
    "we want to compute this from a stationary average , using the source - sink .",
    "the following technical assumption guarantees this computation is well defined :    * with @xmath193 we have @xmath194 < \\infty , \\qquad \\text{for all } x \\in e.\\ ] ]    we assume ( b1)-(b3 ) hold throughout the remainder of this section . from ( b1 ) , it is easy to see @xmath195 is a stopping time for @xmath0 . since @xmath80 ,",
    "by the strong markov property , ( b1 ) guarantees @xmath1 is a time homogeneous markov chain . from ( b2)-(b3 )",
    ", @xmath1 has a unique stationary distribution @xmath105 .",
    "the latter can be proved by standard coupling arguments , based on @xmath1 reaching @xmath189 in finite expected time and then regenerating at @xmath190 .",
    "we omit proof .    for the resampling times @xmath81 , we could take @xmath82 where @xmath83 is a fixed resampling time interval , as in standard we sampling .",
    "more generally , we could take @xmath196 and @xmath197 where @xmath198 is a stopping time for @xmath0 starting at @xmath199 , as in exact milestoning . in that setting , @xmath198 is the first time for @xmath0 to reach a milestone starting at @xmath199 ; see  @xcite .",
    "we are now ready to generalize the hill relation  @xcite .",
    "[ thm_dynamic ] with @xmath105 the unique stationary distribution of @xmath1 , @xmath200 = \\frac{\\int_f g(y)\\pi(dy)}{\\pi(f)}\\ ] ] and @xmath201 =   \\frac{{\\mathbb e}^\\pi\\left[\\sum_{t=1}^{\\tau_1 } g(y_t)\\right ]   } { \\pi(f)}.\\ ] ]    in  , if @xmath202 is the disjoint union of @xmath203 and @xmath204 and @xmath205 , we have @xmath206 =   \\frac{\\pi(b)}{\\pi(a\\cup b)}.\\ ] ] this is the probability to hit @xmath204 before @xmath203 , starting at @xmath190 . in  , if @xmath207 , @xmath208 = \\frac{{\\mathbb e}^\\pi[\\tau_1]}{\\pi(f)}.\\ ] ] this is the mfpt from @xmath190 to @xmath189 . note that when @xmath209 is constant , this equation is simply the hill relation  @xcite .",
    "when @xmath210 is random , this is the expression recently proved for exact milestoning  @xcite .",
    "it is important to note that assumption ( b2 ) does not affect the averages on the left hand side of   and  .",
    "thus , @xmath0 can be any time homogeneous markov chain , and in particular it need not have a source and sink .",
    "the source and sink in ( b2 ) are only needed to define the stationary distribution @xmath105 used in the sampling .    since here @xmath105 is the stationary distribution of a time homogeneous markov chain , algorithm  [ alg2 ]",
    "can be used to compute the right hand side of  .",
    "see the example in section  [ sec : stationary ] above .",
    "although it is not obvious how to extend that algorithm to compute the right hand side of  , in some cases a simple modification may suffice .",
    "for instance , in exact milestoning , one can apply algorithm  [ alg2 ] to the function @xmath211 , where @xmath212 is the union of the milestones .",
    "the empirical distributions @xmath43 from the algorithm can be used as the initial distribution for computing the numerator of  .",
    "we begin with the following preliminary result .    [ lem1 ]",
    "suppose @xmath213 are iid random variables and @xmath90 is a nonnegative integer valued random variable independent of the @xmath214 s .",
    "then @xmath215   = { \\mathbb e}[n]{\\mathbb e}[\\xi_1]\\ ] ] and @xmath216 = \\left({\\mathbb e}[n^2]-{\\mathbb e}[n]\\right){\\mathbb e}[\\xi_1]^2 + { \\mathbb e}[n]{\\mathbb e}[\\xi_1 ^ 2].\\ ] ]    we omit the proof , which is straightforward .",
    "we will also use the following result .",
    "[ lem2 ] let @xmath217 where @xmath218 .",
    "then we have @xmath219 = g_p({\\hat \\xi}_p^i)\\ ] ] and @xmath220 =    \\begin{cases } g_p({\\hat",
    "\\xi}_p^i ) g_p({\\hat \\xi}_p^j ) , & i\\ne j\\\\ k_p g_{p+1}^2({\\hat \\xi}_p^i ) ,   & i = j\\end{cases}.\\ ] ]    first observe that , by ( a5 ) , @xmath221 \\\\ & = { \\mathbb e}^{emp}\\left[\\left .",
    "\\int k_{p+1}(\\xi_{p+1}^i , dy_{p+2})\\ldots   k_{n-1}(y_{n-1},dy_{n})f(y_{n})\\right|\\hat{{\\mathcal f}_p}\\right ] \\\\ &",
    "= \\int k_p({\\hat \\xi}_p^i , dy ) k_{p+1}(y , dy_{p+2})\\ldots   k_{n-1}(y_{n-1},dy_{n})f(y_{n})= g_p({\\hat \\xi}_p^i).\\end{split}\\end{aligned}\\ ] ] when @xmath222 , in the second equation , using ( a5 ) we have @xmath223   = \\int k_p({\\hat \\xi}_p^i , dy )   g_{p+1}(y)^2 = k_p g_{p+1}^2({\\hat \\xi}_p^i).\\ ] ] on the other hand , when @xmath224 , conditionally on @xmath225 , @xmath226 and @xmath227 are independent .",
    "thus , appealing to   completes the proof .",
    "we now turn to the proof of theorem  [ thm1 ] .",
    "let @xmath228 be as in lemma  [ lem2 ] and recall that @xmath229 to emphasize that @xmath230 when @xmath231 , we write @xmath232 let @xmath233 note that @xmath234 is @xmath235-measurable and @xmath236 using also @xmath237 we find that @xmath238   & = { \\mathbb e}^{emp}\\left[\\left.\\mathbbm{1}_{\\tau_{kill } > p+1}\\sum_{i=1}^{n_{p+1 } } \\omega_{p+1}^i g_{p+1}(\\xi_{p+1}^i)\\right|{\\mathcal f}_p\\right ] \\\\ & = \\mathbbm{1}_{\\tau_{kill } > p}{\\mathbb e}^{emp}\\left[\\left.{\\mathbb e}^{emp}\\left[\\left.\\sum_{i=1}^{n_{p+1 } } \\omega_{p+1}^i g_{p+1}(\\xi_{p+1}^i)\\right|{\\hat{\\mathcal f}}_p\\right]\\right|{\\mathcal f}_p\\right ] \\\\ & = \\mathbbm{1}_{\\tau_{kill } > p } { \\mathbb e}^{emp}\\left[\\left.\\sum_{i=1}^{{\\hat n}_{p } } { \\hat \\omega}_{p}^i   { \\mathbb e}^{emp}\\left[\\left .",
    "g_{p+1}(\\xi_{p+1}^i)\\right|{\\hat{\\mathcal f}}_p\\right]\\right|{\\mathcal f}_p\\right ] \\qquad \\textup { by ( a4 ) } \\\\ & = \\mathbbm{1}_{\\tau_{kill } >",
    "p}{\\mathbb e}^{emp}\\left[\\left.\\sum_{i=1}^{{\\hat n}_p } { \\hat \\omega}_p^i   g_p({\\hat \\xi}_p^i)\\right|{\\mathcal f}_p\\right ] \\qquad \\textup { by ( a5 ) and lemma~8}\\\\ & = \\mathbbm{1}_{\\tau_{kill } > p}\\sum_{r=1}^{r_p}{\\mathbb e}^{emp}\\left[\\left.\\sum_{i\\in { \\hat i}_p^r } { \\hat \\omega}_p^i   g_p({\\hat \\xi}_p^i)\\right|{\\mathcal f}_p\\right ] \\qquad \\text{by ( a2 ) }   \\\\ & = \\mathbbm{1}_{\\tau_{kill } > p}\\sum_{r=1}^{r_p}\\sum_{i\\in { i}_p^r } { \\omega}_p^i   g_p({\\xi}_p^i ) \\qquad \\text{by ( a3)}\\\\ & = \\mathbbm{1}_{\\tau_{kill } > p}\\sum_{i=1}^{n_p } { \\omega}_p^i   g_p({\\xi}_p^i ) = m_p \\qquad \\text{by ( a2)}.\\end{aligned}\\ ] ] it follows that @xmath239 is a martingale , so @xmath240   = { \\mathbb e}^{emp}[m_n]$ ] and @xmath241   & = { \\mathbb e}\\left[g_0(x_0)\\right ] \\qquad \\\\ & = { \\mathbb e}^{emp}[m_0 ]   \\qquad \\textup{by ( a1)}\\\\ & = { \\mathbb e}^{emp}[m_n ]   = { \\mathbb e}^{emp}[\\eta_n(f_n ) { \\mathbbm{1}}_{\\tau_{kill}>n}].\\end{aligned}\\ ] ]    clearly , algorithm  [ alg1 ] satisfies ( a1)-(a2 ) and ( a4)-(a5 ) .",
    "conditional on @xmath32 , for @xmath242 such that @xmath243 , the @xmath244 s are independent with expected value @xmath245 .",
    "conditional on @xmath32 , the expected number of such @xmath242 s is @xmath246 = { \\mathbb e}^{emp}\\left[\\left .",
    "c_p^{r , i}\\right|{\\mathcal f}_p\\right ] = \\frac{\\omega_p^i}{{\\bar \\omega}_p^r}.\\ ] ] thus , for any bounded measurable @xmath247 , @xmath248   & = { \\bar \\omega}_p^r{\\mathbb e}^{emp}\\left[\\left.\\sum_{i:{\\hat \\xi}_p^i \\in b_p^r } h_p({{\\hat \\xi}_p^i } ) \\right| { \\mathcal f}_p\\right ]   \\\\   & = { \\bar \\omega}_p^r \\sum_{i : \\xi_p^i \\in b_p^r}{\\mathbb e}^{emp}\\left[\\left .   \\sum_{j:{\\hat",
    "\\xi}_p^j = \\xi_p^i } h_p({{\\hat \\xi}_p^j } ) \\right| { \\mathcal f}_p\\right ]   \\\\    & = { \\bar \\omega}_p^r \\sum_{i : \\xi_p^i \\in b_p^r } \\frac{\\omega_p^i}{{\\bar \\omega}_p^r}h_p ( { \\xi}_p^i ) \\qquad \\text{by lemma } 7   \\\\ & = \\sum_{i \\in i_p^r }   { \\omega}_p^i h_p({\\xi_p^i}).\\end{aligned}\\ ] ]    define @xmath249 and @xmath250 as in the proof of theorem  [ thm1 ] .",
    "there it was shown @xmath239 is a martingale , which leads to equation  [ l2error ] .",
    "we turn to the expression in  . using @xmath251",
    "we find that @xmath252 \\\\ & = { \\mathbb e}^{emp}\\left[\\left.\\mathbbm{1}_{\\tau_{kill}>p+1}\\left(\\sum_{i=1}^{n_{p+1 } } \\omega_{p+1}^i g_{p+1}(\\xi_{p+1}^i)\\right)^2\\right|{\\mathcal f}_{p}\\right ] \\\\ & = \\mathbbm{1}_{\\tau_{kill}>p}{\\mathbb e}^{emp}\\left[\\left.\\sum_{i=1}^{n_{p+1 } } \\sum_{j=1}^{n_{p+1 } } \\omega_{p+1}^i   \\omega_{p+1}^j g_{p+1}(\\xi_{p+1}^i ) g_{p+1}(\\xi_{p+1}^j)\\right|{\\mathcal f}_{p}\\right ] \\\\ & = \\mathbbm{1}_{\\tau_{kill}>p}\\sum_{r=1}^{r_{p } } \\sum_{s=1}^{r_{p } } { \\bar \\omega}_{p}^r { \\bar \\omega}_{p}^s    { \\mathbb e}^{emp}\\left[\\left.\\sum_{i:{\\hat \\xi}_{p}^i \\in b_p^r } \\ , \\sum_{j:{\\hat \\xi}_{p}^j \\in b_p^s }   g_{p+1}(\\xi_{p+1}^i ) g_{p+1}(\\xi_{p+1}^j)\\right|{{\\mathcal f}}_{p}\\right]\\\\ & = \\mathbbm{1}_{\\tau_{kill}>p}\\sum_{r=1}^{r_{p } } \\sum_{s=1}^{r_{p}}{\\bar \\omega}_{p}^r { \\bar \\omega}_{p}^s \\sum_{i:{\\xi}_{p}^i \\in b_p^r } \\ , \\sum_{j:{\\xi}_{p}^j \\in b_p^s } { \\mathbb e}^{emp}\\left[\\left . \\sum_{k : { \\hat \\xi}_{p}^k = \\xi_{p}^i }   \\sum_{\\ell:{\\hat \\xi}_{p}^\\ell = \\xi_{p}^j }    g_{p+1}(\\xi_{p+1}^k ) g_{p+1}(\\xi_{p+1}^\\ell)\\right|{{\\mathcal f}}_{p}\\right].\\end{aligned}\\ ] ] from lemma  [ lem2 ] , @xmath253 = \\begin{dcases } g_p({\\hat",
    "\\xi}_p^k)g_p({\\hat \\xi}_p^\\ell ) , & k\\ne \\ell \\\\",
    "k_p g_{p+1}^2({\\hat \\xi}_p^k ) , & k = \\ell \\end{dcases}\\end{aligned}\\ ] ] and recall that @xmath254= { \\mathbb e}^{emp}\\left[\\left.\\#\\left\\{k:{\\hat \\xi}_p^k = \\xi_p^i \\in b_p^r\\right\\}\\right|{\\mathcal f}_p\\right ] = \\frac{\\omega_p^i}{{\\bar \\omega}_p^r}.\\ ] ] thus , for @xmath255 such that @xmath256 and @xmath257 , by lemma  [ lem1 ] , @xmath258 =   \\frac{\\omega_{p}^i}{{\\bar \\omega}_{p}^r } \\frac{\\omega_{p}^j}{{\\bar \\omega}_{p}^s }   g_p(\\xi_p^i)g_p(\\xi_p^j).\\end{aligned}\\ ] ] on the other hand , when @xmath222 and @xmath259 , this becomes @xmath260 \\\\   & \\qquad \\qquad = \\left(\\sigma_p^{r , i}-\\frac{\\omega_p^i}{{\\bar \\omega}_p^r}\\right ) g_p(\\xi_p^i)^2 + \\frac{\\omega_p^i}{{\\bar \\omega}_p^r } k_p g_{p+1}^2(\\xi_p^i).\\end{aligned}\\ ] ] where again we used lemma  [ lem1 ] , and we recall that @xmath261.\\ ] ] combining the above , @xmath252 = \\mathbbm{1}_{\\tau_{kill}>p}\\sum_{r=1}^{r_p } \\sum_{s=1}^{r_p}\\sum_{\\substack{i:\\xi_p^i \\in b_p^r\\\\ j:\\xi_p^j \\in b_p^s\\\\ i \\ne j } } \\omega_p^i \\omega_p^j g_p(\\xi_p^i)g_p(\\xi_p^j ) \\\\ & \\qquad \\qquad+\\mathbbm{1}_{\\tau_{kill}>p}\\sum_{r=1}^{r_p } \\sum_{i:\\xi_p^i \\in b_p^r}\\left [   \\left(\\left({\\bar \\omega}_p^r\\right)^2\\sigma_p^{r , i}-{\\bar \\omega}_p^r\\omega_p^i\\right ) g_p(\\xi_p^i)^2 + { \\bar \\omega}_p^r\\omega_p^i k_p g_{p+1}^2(\\xi_p^i)\\right],\\end{aligned}\\ ] ] and so , since @xmath262 we get @xmath263 \\\\ & =   { \\mathbb e}^{emp}\\left[\\left .",
    "m_{p+1}^2 \\right|{\\mathcal f}_p\\right]-m_p^2 \\\\",
    "& = \\mathbbm{1}_{\\tau_{kill}>p}\\sum_{r=1}^{r_p } \\sum_{i:\\xi_p^i \\in b_p^r}\\left [ { \\bar \\omega}_p^r\\omega_p^i k_p g_{p+1}^2(\\xi_p^i)- \\left({\\bar \\omega}_p^r\\omega_p^i + \\left(\\omega_p^i\\right)^2 -\\left({\\bar \\omega}_p^r\\right)^2\\sigma_p^{r , i}\\right ) g_p(\\xi_p^i)^2\\right].\\end{aligned}\\ ] ]    we begin with the proof of  .",
    "recall @xmath264 is the transition kernel of @xmath265 .",
    "conditioning on @xmath266 and using assumption ( b1 ) , the lhs of   rewrites @xmath267 & =   \\int { \\mathbb e}^x\\left[\\left.g(y_{\\tau_f})\\right|y_{\\tau_1 } = y\\right]k(x , dy ) \\\\ &",
    "= \\int_{e \\setminus f } { \\mathbb e}^x\\left[\\left.g(y_{\\tau_f})\\right|y_{\\tau_1 } = y\\right]k(x , dy ) + \\int_f g(y)k(x , dy)\\\\ & = \\int_{e \\setminus f }   { \\mathbb e}^y[g(y_{\\tau_f})]k(x , dy )   + \\int_f g(y)k(x , dy).\\end{aligned}\\ ] ] integrating against @xmath105 and using stationarity ,",
    "@xmath268 = \\int_{e \\setminus f } { \\mathbb e}^y[g(y_{\\tau_f})]\\pi(dy ) + \\int_f   g(y)\\pi(dy).\\ ] ] cancelling terms and using the fact that @xmath269 , @xmath270\\pi(dy ) =   \\pi(f ) { \\mathbb e}^\\rho[g(y_{\\tau_f})].\\ ] ] now we turn to the proof of  .",
    "conditioning on @xmath266 and using assumption ( b1 ) , @xmath271   & = \\int { \\mathbb e}^x\\left[\\left.\\sum_{t=1}^{\\tau_f } g(y_t)\\right|y_{\\tau_1 } = y\\right]k(x , dy ) \\\\ & = \\int { \\mathbb e}^x\\left[\\left.\\sum_{t=1}^{\\tau_1 } g(y_t)\\right|y_{\\tau_1 } = y\\right]k(x , dy ) \\\\ &",
    "\\qquad\\qquad+\\int_{e \\setminus f}{\\mathbb e}^x\\left[\\left.\\sum_{t=\\tau_1 + 1}^{\\tau_f } g(y_t)\\right|y_{\\tau_1 } = y\\right]k(x , dy)\\\\ & = { \\mathbb e}^x\\left[\\sum_{t=1}^{\\tau_1 } g(y_t)\\right ] + \\int_{e \\setminus f}{\\mathbb e}^y\\left[\\sum_{t=1}^{\\tau_f } g(y_t)\\right]k(x , dy).\\end{aligned}\\ ] ] integrating against @xmath105 and using stationarity , @xmath272   = { \\mathbb e}^\\pi\\left[\\sum_{t=1}^{\\tau_1 } g(y_t)\\right ]   + \\int_{e \\setminus f}{\\mathbb e}^y\\left[\\sum_{t=1}^{\\tau_f } g(y_t)\\right ] \\pi(dy).\\ ] ] cancelling terms and using the fact that @xmath273 , @xmath274 = \\int_f { \\mathbb e}^y\\left[\\sum_{t=1}^{\\tau_f}g(y_t)\\right ] \\pi(dy ) = \\pi(f){\\mathbb e}^\\rho\\left[\\sum_{t=1}^{\\tau_f}g(y_t)\\right].\\ ] ]",
    "d. aristoff would like to acknowledge enlightening conversations with tony lelivre , petr plech , mathias rousset , gideon simpson , ting wang , and dan zuckerman .",
    "d. aristoff also gratefully acknowledges support from the national science foundation via the award nsf - dms-1522398 ."
  ],
  "abstract_text": [
    "<S> we give a mathematical framework for weighted ensemble ( we ) sampling , a binning and resampling technique for efficiently computing probabilities in molecular dynamics . </S>",
    "<S> we prove that we sampling is unbiased in a very general setting that includes adaptive binning . </S>",
    "<S> we show that when we is used for stationary calculations in tandem with a markov state model ( msm ) , the msm can be used to optimize the allocation of replicas in the bins .    </S>",
    "<S> molecular dynamics , markov chains , stationary distributions , long time dynamics , coarse graining , resampling , weighted ensemble    65c05 , 65c20 , 65c40 , 65y05 , 82c80 </S>"
  ]
}