{
  "article_text": [
    "most algorithms employed to sample from complicated probability distributions such as rejection sampling and importance sampling assume full knowledge of the target density @xcite .",
    "contrary to these approaches markov chain monte carlo ( mcmc ) methods can be used to sample from distributions for which the form of the density function is known , but the function value itself can only be evaluated up to a scalar constant .",
    "mcmc algorithms devise a markov chain on the sample space of a general vector random variable . in typical settings",
    "the probability density function ( pdf ) of the distribution can only be evaluated up to a normalizing constant .",
    "the common metropolis algorithm @xcite starts with an initial state and generates samples of the random variable iteratively . at every step of the procedure a new state",
    "is proposed according to some proposal distribution .",
    "this proposal state is then accepted with a probability determined by the ratio of the pdf values for the new state and the old state . because the accept - reject rule only requires the evaluation of the ratio of the probability densities for the proposed and the old state , it is sufficient to know the target pdf up to a scalar constant .",
    "the sole restriction of the metropolis algorithm is that the proposal density is symmetric and simple enough to sample directly .",
    "one generalization of the metropolis algorithm is the metropolis - hastings algorithm @xcite which can employ non - symmetric proposal densities . to achieve this , the acceptance probability is modified to incorporate a ratio of the proposal density values .",
    "mcmc methods are very general tools in regard to dealing with intractable probabilistic settings .",
    "this generality allows mcmc to be integrated into many practical problems in diverse fields like computational biology @xcite , statistical physics @xcite , random number generation @xcite , artificial intelligence @xcite and many more .",
    "a review for the applications of mcmc can be found in @xcite .",
    "one of these broad applications deals with the model selection problem where one tries to choose a model among many competing models that is more likely to have generated the given probabilistic output data @xcite . in this paper",
    "we investigate a related problem in which the model that generates the given data is fixed , but accepts a random input with an unknown pdf .",
    "this situation arises naturally in the context of complex models which accept random inputs either as the data to be processed or as random model parameters .",
    "the realization of these models in practice can be in various ways such as lengthy and complicated computer routines , a set of involved mathematical equations or any kind of black box evaluation .",
    "nevertheless they can be viewed as a mapping of random variables as illustrated in figure [ fig : sys ] . if @xmath0 is a multi - valued function of multiple variables with @xmath1 and its inverse @xmath2 does not exist or can not be computed analytically then the question arises : how does one choose @xmath3 for @xmath4 to have the desired probability density @xmath5 ?",
    "the answer to this question is not straightforward .",
    "first of all , generally @xmath6 is very complicated and all we have is some kind of routine that evaluates it for a given input .",
    "therefore the unknown density of @xmath3 can be computed through the inverse mapping only in special cases where @xmath6 is known explicitly and @xmath7 with the jacobian of @xmath6 is globally invertible .",
    "the use of standard sampling algorithms including mcmc to sample @xmath3 is for this reason not possible .",
    "additionally more than one input distribution can generate the desired output distribution creating an issue of non - uniqueness .    to address this problem we first review some markov chain and mcmc theory",
    "then we provide a detailed description of the problem at hand and a toy example to demonstrate the concept before proceeding to develop a solution .",
    "finally we conclude our discussion with a numerical example of a stochastic differential equation and demonstrate how our method can be used to sample from the space of solution paths to this equation .",
    "( 0,-1.5)(12,1.5 ) ( 2,0)x ( 10,0)y ( 6,0)m ( x ) , @xmath8 , is a random vector of dimension two while the input @xmath3 is a random vector with three dimensions.,title=\"fig : \" ] ( x ) ( y ) , @xmath8 , is a random vector of dimension two while the input @xmath3 is a random vector with three dimensions.,title=\"fig : \" ] ( y)(0,0)(-1.5,-1.5)(1.5,1.5)[@xmath9,0][@xmath10,90 ] ( m)h@xmath6 ( [ xnodesep=1.9]x)xx ( [ xnodesep=-1.9]y)yy",
    "in this section we present some elementary markov chain and mcmc theory which will be required for later discussion .    a sequence of indexed random variables @xmath11 is called a markov chain if the following property holds for every measurable set @xmath12 @xmath13 @xmath14 is called its transition kernel with the transition density @xmath15 , where @xmath16    [ def : stat_dist ] @xmath17 is called a stationary distribution of the markov chain",
    "if it satisfies @xmath18    [ lem : det_bal ] a sufficient condition for @xmath17 to be a stationary distribution of the markov chain @xmath19 is the detailed balance equation : @xmath20    integrating both sides of equation ( [ eqn : det_bal ] ) and using definition [ def : stat_dist ] , @xmath21    note that lemma [ lem : det_bal ] gives a sufficient condition , and the necessary condition is much looser @xcite .",
    "furthermore under certain conditions the stationary distribution is unique @xcite .    above definitions and lemma [",
    "lem : det_bal ] are sufficient to describe the metropolis - hastings ( and the metropolis algorithm as its special case ) in a formal way .",
    "given a target distribution @xmath17 for the random vector @xmath3 the strategy of the algorithm is to construct a markov chain on the state space of interest , @xmath22 , and choose a transition kernel such that the markov chain has @xmath17 as its stationary distribution .",
    "this is accomplished in two stages . at the first stage",
    "the procedure takes a random step in the state space according to some proposal density @xmath23 which describes the probability of moving from the state , @xmath24 , to the next one , @xmath25 .",
    "most common choice for @xmath26 uses a form of increment on @xmath27 such that @xmath28 .",
    "commonly used densities for the random increment @xmath29 are tractable ones like the uniform and the gaussian density . at the second stage of the algorithm a decision is made whether the chain will advance to @xmath30 as its next state or stay at @xmath27 .",
    "the decision mechanism uses the ratio @xmath31 in the decision rule    @xmath32    which gives the acceptance probability of the proposed move . after evaluating the accept - reject ratio ,",
    "a random number @xmath33 is sampled according to a standard uniform distribution and the move is accepted if @xmath34 . if the proposed state is not accepted the markov chain remains in its previous state .",
    "theorem [ thrm : met - has ] shows that the distribution of the samples taken in this way indeed converges to @xmath17 .",
    "[ thrm : met - has ] the transition kernel of the metropolis - hastings algorithm satisfies the detailed balance condition and @xmath17 is the stationary distribution of the resulting markov chain .",
    "the transition kernel @xmath35 can be written as the sum of two probabilities : the probability of an accepted step to a point @xmath30 in @xmath36 and the probability of a rejection while the point @xmath27 lies in @xmath36 .",
    "@xmath37    hence the transition density is given by @xmath38 where @xmath39 is the point mass at @xmath27 and @xmath40 is the probability that the chain does not leave its current position @xmath27 .",
    "lemma [ lem : det_bal ] gives us a way of checking whether this transition kernel has the desired pdf as its stationary distribution .",
    "if we now check if equation ( [ eqn : det_bal ] ) is satisfied we find for the first summand of the transition density @xmath41 finally for the second summand the requirement is trivially satisfied @xmath42 and this completes the proof .",
    "further discussion of markov chain and mcmc theory is outside the scope of this paper but excellent material on this subject can be found in @xcite and @xcite .",
    "now let us recap the problem described in the introduction .",
    "suppose we are given a general many - to - one , non - isometric map @xmath43 which maps a random vector @xmath3 to another random vector @xmath8 where @xmath44 , @xmath45 and let @xmath5 be the desired probability density of @xmath4 .",
    "given @xmath5 how must @xmath46 be chosen such that the transformed variable @xmath8 has the desired pdf ?    given this setting one might be tempted to construct a markov chain in the space of the input variables to sample @xmath3 while evaluating the accept - reject rule probabilities of the metropolis - hastings algorithm in the space of the random output vector @xmath4 .    as the following toy - example illustrates , this method does not result in a markov chain in the space of input variables with the desired stationary distribution @xmath5 of the output variables .",
    "figure [ fig : toy - example ] describes a discrete state space consisting of three states @xmath47 .",
    "the arrows represent a many - to - one function @xmath48 with @xmath49 and @xmath50 and @xmath51 .",
    "it is of no importance if @xmath52 is discrete or continuous but the range of @xmath6 is discrete for obvious reasons .",
    "r55 mm    ( -0.5,-3)(4,3 ) ( 0,0)(0,0)(4,3)[@xmath53,-90][@xmath54,-25 ] ( 0,-3)(4,-1 ) ( 0,0.5 ) ( 0,0.5)@xmath55 ( 0,2.4 ) ( 0,2.4)@xmath56 ( 0,0.5)(4,0.5 ) ( 0,2.4)(4,2.4 ) ( 1,0)y1 ( 3,0)y2 ( y1)@xmath9 ( y2)@xmath10 ( y1)([offset=0.5]y1 ) ( [ offset=0.5]y1)2 ( y2)([offset=2.4]y2 ) ( [ offset=2.4]y2)2 ( 0.7,-1.7)x1@xmath57 ( 1.8,-2.3)x2@xmath58 ( 3,-1.9)x3@xmath59 ( 3.7,-1)@xmath36    the desired distribution of @xmath60 is @xmath61 and @xmath62 . the results about markov chains and the metropolis - hastings algorithm given in section [ sec : background ] can easily be adopted to general finite state spaces and to this specific example .    now suppose that we are running the metropolis algorithm on @xmath36 with a symmetric proposal distribution @xmath63 . for the current state @xmath64 a new state is proposed according to the rule @xmath65    together with the accept - reject rule of the metropolis algorithm , this results in a markov chain with the transition probabilities @xmath66 for @xmath67 and the transition probability matrix    @xmath68    the left eigenvector of this matrix that corresponds to the eigenvalue @xmath69 gives us the stationary distribution of the chain , which is @xmath70 .",
    "it can be easily seen that this distribution does not provide the desired stationary distribution on the range of @xmath6 .",
    "in fact this distribution corresponds to a function @xmath71 which maps @xmath59 to a different value @xmath72 which has the same probability as @xmath73 .",
    "this behavior can also be observed with the more general metropolis - hastings algorithm by choosing a non - symmetric proposal distribution and applying the corresponding accept - reject rule .",
    "this toy - example illustrates clearly that to address the problem of creating the target probability density @xmath5 we have to take the properties of the mapping @xmath6 into account and modify the metropolis - hastings algorithm accordingly .",
    "the reason that the above example fails to converge to the desired stationary distribution @xmath74 lies within the properties of the general mapping @xmath6 .",
    "first @xmath6 is not one - to - one and hence the probability of a state @xmath75 appearing in the chain on @xmath52 depends on the probability of all the states @xmath76 on the space of inputs for which @xmath77 holds .",
    "additionally for the continuous case , even if @xmath6 was one - to - one it would not necessarily be an isometry so that volumes are distorted under the mapping creating a similar effect on the stationary distribution . in this section we develop a method to overcome the shortcomings of mcmc sampling for the problem described in the previous section .    in this context for the general case we first implement a probing procedure for the mapping @xmath6 by using the output distribution that results when",
    "the input parameters are sampled uniformly and independently .",
    "then we show that a modification of the target density with this uniform output density can be used in the space of parameters for the accept - reject rule in mcmc to achieve the desired density @xmath5 on the range of @xmath6 .",
    "[ thrm : compensation ] let @xmath78 be a uniform random vector on the probability space @xmath79 where @xmath80 is a bounded subset of @xmath22 such that @xmath81 for all @xmath82 with @xmath83 as the probability density function of the cumulative distribution function @xmath84 . and",
    "let @xmath0 be a mapping satisfying the required regularity conditions such that @xmath85 with @xmath86 is the induced sample space by @xmath6 and the associated @xmath87 . then a random variable @xmath44 constructs another random variable @xmath88 with the desired probability density @xmath5 if @xmath3 has the unnormalized probability density    @xmath89    where @xmath90 is the probability density of the transformed random variable @xmath91 .",
    "consider the bounded sample space @xmath92 , @xmath93 \\times [ \\alpha_2 , \\ ; \\beta_2 ] \\times \\dots \\times [ \\alpha_n , \\ ; \\beta_n]$ ] in which we assume @xmath90 is strictly positive .",
    "for the cumulative distribution function of @xmath94 we get    @xmath95    which can be written with the indicator function as    @xmath96    note that the indicator function in equation ( [ eqn : prob_dist_q_ind ] ) can be expressed with the components of the random vector @xmath97 and the function @xmath6 as    @xmath98    where @xmath99 is the unit step function .",
    "the pdf of @xmath94 is given by @xmath100 .",
    "using generalized functions and equation ( [ eqn : indicator_function ] ) we can write this expression as    @xmath101    if we now set the distribution of the input random variable @xmath3 proportional to the ratio of the desired distribution of @xmath4 and the distribution of @xmath94 ,    @xmath102    we have for the cumulative distribution function of @xmath8    @xmath103    finally we have for the output probability density ,    @xmath104    since both are normalized probability densities @xmath105 holds and the distribution of the image of samples on @xmath22 will be equal to the desired distribution on @xmath106 .",
    "theorem [ thrm : compensation ] shows that we can find the distribution of a random variable @xmath3 that gives us the desired density @xmath5 through the mapping @xmath6 provided that we know the uniform input distribution @xmath107 .",
    "this can be accomplished by modifying the metropolis - hastings accept - reject rule in ( [ eqn : accpt - rejct ] ) as    @xmath108    note that theorem [ thrm : compensation ] assumes a bounded support for the uniformly sampled random vector @xmath94 , with @xmath93 \\times [ \\alpha_2 , \\ ; \\beta_2 ] \\times \\dots \\times [ \\alpha_n , \\ ; \\beta_n]$ ] .",
    "this assumption implies that the support of the input vector @xmath3 is equal to or a subset of @xmath80 .",
    "therefore in case @xmath3 has unbounded support , this technique will sample a truncated version of the input random vector .",
    "nevertheless practical difficulties caused by this fact can be overcome with an adjustment of @xmath80 which theoretically can be chosen arbitrarily large .",
    "furthermore theorem [ thrm : compensation ] gives us only the unnormalized pdf which is sufficient to sample @xmath3 with mcmc .",
    "but the above method can be used irrespective of the specific sampling method once this density is normalized .",
    "hence we obtain a general method to control the input of complex systems with prescribed random outputs .    in practical applications one will not always be able to compute @xmath90 analytically . in these situations",
    "@xmath90 will have to be substituted with an approximation @xmath109 .",
    "for this purpose one can use various density estimation schemes available . for large data sets nonparametric schemes like kernel density estimators and nearest neighbour methods",
    "@xcite can be used . for other settings",
    "bayesian schemes like the em algorithm @xcite can be employed for inference .",
    "in this section we demonstrate an example for our algorithm on stochastic differential equations . in this case",
    "the model is given by a differential equation driven by random noise and the input random variable takes the form of the solution to this equation .",
    "consider the one dimensional it stochastic differential equation    @xmath110    where @xmath111 \\to \\mathbb{r}$ ] are measurable functions and @xmath112 is the wiener process .",
    "a numerical treatment of this equation can be done by discretization using the simple euler scheme .",
    "@xmath113    we now set @xmath114 and define the random vectors @xmath115 and @xmath116 with    @xmath117    note that @xmath118 together with @xmath119 completely determines the sample path . hence if we can sample @xmath118 such that it satisfies equation ( [ eqn : dsc_sde ] ) , that means we can generate a solution path to the stochastic differential equation .",
    "the distribution of @xmath118 is unknown but we know that @xmath4 is a gaussian random vector with i.i.d .  zero mean components with variance @xmath120 .",
    "using this fact we can employ the modified mcmc algorithm to sample solution paths .",
    "for this general class of stochastic differential equations we can obtain the pdf of the output vector when the input random variables are sampled uniformly .",
    "first we derive the expression of the joint output distribution for the uniformly sampled input variables .",
    "let @xmath121 be a random vector with i.i.d .",
    "components distributed uniformly in @xmath122 $ ] and @xmath123 another random vector with the joint pdf @xmath90 .",
    "we can express @xmath90 as the product of conditional pdfs as follows .",
    "@xmath124    it can easily be seen from equation ( [ eqn : sde_y ] ) that each of these conditional pdfs are uniform in a range determined by the previous values of @xmath125 . particularly since    @xmath126",
    "we have    @xmath127\\end{aligned}\\ ] ]    where @xmath128 , @xmath129 and @xmath99 is the step function .",
    "now we can write the joint density function .",
    "@xmath130 \\forall i \\in \\{1,2,\\dots , n\\}\\\\      0 & \\text{o.w . }",
    "\\end{cases }    \\label{eqn : sde_uni_joint}\\ ] ]    as discussed in the previous section , the restriction of @xmath131 in @xmath132 $ ] is a practical necessity and does not create any problems in real world applications since @xmath133 can be chosen arbitrarily large , and the points where @xmath90 is zero can be viewed as proposals of impossible states and rejected immediately .    combining equations ( [ eq : mod - accpt - rejct ] ) and ( [ eqn : sde_uni_joint ] ) the whole accept - reject probability of the mcmc algorithm can be written as    @xmath134    with @xmath135 .    as a numerical example for the above procedure",
    "consider the linear stochastic differential equation    @xmath136    where @xmath137 and @xmath138 are scalar constants .",
    "this equation describes the geometric brownian motion @xcite which finds applications in mathematical finance , particularly in the black - scholes model of financial markets @xcite .",
    "this is a good example for demonstration purposes because one can obtain its solution analytically .",
    "a stochastic process satisfying equation ( [ eqn : sde_gbm ] ) will have the form    @xmath139    where @xmath140 .",
    "it s pdf has a lognormal distribution ,    @xmath141    and the autocorrelation of @xmath142 is given by    @xmath143     at t = 0.1 , t= 0.5 and t=1 compared with the empirical pdfs of the simulation data.,width=340 ]     at three different time points compared with simulation data.,width=340 ]    figures [ fig : gbm_pdf ] and [ fig : gbm_corr ] display the results of a simulation with the modified mcmc algorithm .",
    "the scalar constants in equation ( [ eqn : sde_gbm ] ) were chosen as @xmath144 and @xmath145 .",
    "the time axis was divided in one hundred equal length intervals with @xmath146 .",
    "initially @xmath147 samples were generated and the first @xmath148 samples were discarded as the burn - in length . for this setting @xmath133 was chosen to be 2 and a uniform distribution in @xmath149 $ ] was used as the proposal distribution for @xmath118 .",
    "figure [ fig : gbm_pdf ] shows three analytical pdfs at different time points compared with the empirical pdfs obtained from the simulation data and figure [ fig : gbm_corr ] shows the normalized autocorrelation with one time point held fixed and the second one varied between 0 and 1 .",
    "these graphical results verify that the sample paths built using our algorithm converge to the desired stationary distribution and hence satisfy the given stochastic differential equation .",
    "one noteworthy property of numerical solutions using the modified mcmc algorithm is that all points of a sample path get sampled in parallel as opposed to classical iterative methods such as the euler - maruyama scheme @xcite .",
    "these methods usually begin with the initial value @xmath119 , and sample later points of the solution path with an iterative update rule given by the difference equation ( [ eqn : dsc_sde ] ) . for this reason dealing with more complicated settings like stochastic boundary value problems of the form    @xmath150",
    "becomes troublesome because the points of a sample path are not independent of its future values . on the other hand",
    "the incorporation of boundary conditions to the modified mcmc algorithm is straightforward since the points of the proposed sample paths are obtained simultaneously with independent increments .",
    "we have presented a solution to the problem of input variable sampling for complex stochastic models with prescribed output distribution . this approach is based on a modification to the metropolis - hastings algorithm with an additional expression which can be viewed as a probing term for the model of interest .",
    "our algorithm is easy to implement , benefits from the extensive literature on mcmc and hence we believe that it can be adapted to a variety of applications .",
    "we have demonstrated one such application on general stochastic differential equations viewing them from the perspective of stochastic input - output models enabling us to apply our algorithm to obtain solution paths .",
    "although this paper is based on mcmc , the approach taken to tackle the input variable sampling problem does not require any specific sampling method to be used .",
    "the algorithm presented here can be implemented equally well with other sampling methods once the output distribution for uniformly sampled input variables is worked out and therefore offers a fresh approach for dealing with general stochastic models ."
  ],
  "abstract_text": [
    "<S> many random processes can be simulated as the output of a deterministic model accepting random inputs . </S>",
    "<S> such a model usually describes a complex mathematical or physical stochastic system and the randomness is introduced in the input variables of the model . </S>",
    "<S> when the statistics of the output event are known , these input variables have to be chosen in a specific way for the output to have the prescribed statistics . because the probability distribution of the input random variables is not directly known but dictated implicitly by the statistics of the output random variables , this problem is usually intractable for classical sampling methods . based on markov chain monte carlo </S>",
    "<S> we propose a novel method to sample random inputs to such models by introducing a modification to the standard metropolis - hastings algorithm . as an example we consider a system described by a stochastic differential equation ( sde ) and demonstrate how sample paths of a random process satisfying this sde can be generated with our technique .    </S>",
    "<S> models with random input , markov chain monte carlo , sampling methods , stochastic differential equations    65c20 , 65c40 , 65c05 , 62p30 </S>"
  ]
}