{
  "article_text": [
    "nonparametric estimation of unknown densities on partially or totally bounded supports , with or without correlation in its multivariate components , is a recurrent practical problem . because of symmetry , the multivariate classical or symmetric kernels , not depending on any parameter , are not appropriate for these densities .",
    "in fact , these estimators give weights outside the support causing a bias in boundary regions . in order to reduce the boundary problem with multivariate symmetric kernels as gaussian , @xcite and recently @xcite have proposed adaptive full bandwidth matrix selection ; but the bias does not disappear completely . is one of the pioneers who has proposed , in univariate continuous case , some asymmetric kernels ( i.e. beta and gamma ) whose supports coincide with those of the densities to be estimated .",
    "also recently , @xcite investigated several families of these univariate continuous kernels that he called univariate associated kernels ; see also @xcite , @xcite , for univariate discrete situations .",
    "this procedure cancels of course the boundary bias ; however , it creates a quantity in the bias of the estimator which needs reduction ; see , for instance , @xcite , @xcite and @xcite .",
    "several approaches on multivariate kernel estimation have been proposed for various processings .",
    "@xcite used product of kernels for estimating the different nature of both directional and linear components of a random vector . a classical kernel density estimation on the rotation group appropriate for crystallographic texture analysis has been investigated by @xcite .",
    "symmetric kernel smoothers with univariate local bandwidth have been studied by @xcite for semiparametric mixed effect models .",
    "@xcite presented frontier estimation with classical kernel regression on high order moments . in discrete case ,",
    "@xcite provided kernel estimators for binary data while @xcite proposed the product of them with classical continuous one for smoothing regression on both categorical and continuous data . in the same spirit of @xcite ,",
    "@xcite considered some products of different univariate associated kernels in continuous case ; i.e. the bandwidth matrix obtained is diagonal . in the classical kernels case ,",
    "@xcite and @xcite have shown the importance of full bandwidth matrices for certain target densities .",
    "see also @xcite for a support with arbitrary shape .",
    "the main goal of this work is to introduce the multivariate associated kernels with the most general bandwidth matrix . in other words",
    ", the support of the suggested associated kernels coincides to the support of the densities to be estimated ; also , the full bandwidth matrices take into account different correlation structures in the sample .",
    "note that , a full bandwidth matrix significantly improves some complex target densities ( e.g. multimodal ) ; see @xcite . in high dimensions ,",
    "the computational choice of this full bandwidth matrix needs some special techniques .",
    "we can refer to and @xcite for classical ( symmetric ) kernels . for illustrations in the present paper ,",
    "we then focus on a bivariate case as beta kernel with correlation structure introduced by @xcite ; see also @xcite . a motivation to investigate the smoothing of these densities on @xmath0\\times\\left[0 , 1\\right]$ ] comes from a joint distribution of two comparable proportions .",
    "many datasets in @xmath0\\times\\left[0 , 1\\right]$ ] can be found in statistical problems , for example , for comparing two rates .",
    "we shall examine the theoretical bias reduction and practical performances of the full bandwidth selection and two others bandwidth matrix parametrization using least squares or unbiased cross validation ; see , e.g. , @xcite .",
    "the rest of the paper is organized as follows .",
    "section  [ sec : multiasskern ] gives a complete definition of multivariate associated kernels which includes both the product and the classical symmetric ones . a method to construct any multivariate associated kernel from a parametric probability density function ( pdf )",
    "is then provided .",
    "some pointwise properties of the corresponding estimator are investigated , in particular the convergence in the sense of mean integrated squared error ( mise ) and an algorithm of the bias reduction .",
    "section  [ sec : bivbetakern ] provides a particular study of a bivariate beta kernel with a correlation structure introduced by @xcite .",
    "also , some algorithms for the choice of the optimal bandwidth matrix by unbiased cross validation method are presented .",
    "this is followed , in section  [ sec : simulations ] , by simulation studies and a real data analysis of electoral behaviour of a population with regard to a candidate .",
    "especially , the role of forms of bandwidth matrices is explored in details .",
    "section  [ sec : conclusion ] concludes with summary and final remarks , while the proof of a proposition is deferred to the appendix of section  [ sec : appendix ] .",
    "let @xmath1 be independent and identically distributed ( iid ) random vectors with an unknown density function @xmath2 on @xmath3 , a subset of @xmath4 ( @xmath5 ) .",
    "as frequently observed in practice , the subset @xmath3 might be unbounded , partially bounded or totally bounded as : @xmath6^{d_{uw}}\\ ] ] for given reals @xmath7 and @xmath8 with nonnegative values of @xmath9 , @xmath10 and @xmath11 in @xmath12 such that @xmath13 .",
    "a multivariate associated kernel estimator @xmath14 of @xmath2 is simply defined by @xmath15where @xmath16 is a @xmath17 bandwidth matrix ( i.e. symmetric and positive definite ) such that @xmath18 ( the @xmath17 null matrix ) as @xmath19 , and @xmath20 is the so - called associated kernel , parametrized by @xmath21 and @xmath16 , and precisely defined as follows .",
    "[ defkern ] let @xmath22 be the support of the pdf to be estimated , @xmath23 a target vector and @xmath16 a bandwidth matrix .",
    "a parametrized pdf @xmath20 of support @xmath24 is called `` multivariate ( or general ) associated kernel '' if the following conditions are satisfied : @xmath25 where @xmath26 denotes the random vector with pdf @xmath27 and both @xmath28 and @xmath29 tend , respectively , to the null vector @xmath30 and the null matrix @xmath31 as @xmath16 goes to @xmath31 .",
    "[ remark1 ]    a.   the function @xmath20 is not necessary symmetric and is intrinsically linked to @xmath21 and @xmath16 .",
    "b.   the support @xmath32 is not necessary symmetric around of @xmath21 ; it can depend or not on @xmath21 and @xmath16 .",
    "c.   the condition ( [ noyass1 ] ) can be viewed as @xmath33 and it implies that the associated kernel takes into account the support @xmath3 of the density @xmath2 , to be estimated .",
    "d.   if @xmath34 does not contain @xmath3 then this is the well - known problem of boundary bias .",
    "e.   both conditions ( [ noyass2 ] ) and ( [ noyass3 ] ) indicate that the associated kernel is more and more concentrated around of @xmath21 as @xmath16 goes to @xmath31 .",
    "this highlights the peculiarity of associated kernel which can change its shape according to the target position .",
    "f.   the form of orientation of the kernel is controlled by the parametrization of bandwidth matrix @xmath16 ; i.e. a full bandwidth matrix allows any orientation of the kernel and therefore any correlation structure .",
    "the following two examples provide well - known and also interesting particular cases of multivariate associated kernel estimators .",
    "the first can be seen as an interpretation of associated kernels through symmetric kernels .",
    "the second deals on associated kernels without correlation structure .    [ par : exple1 ] ( classical kernels ) the kernel estimator @xmath35 of the density @xmath2 , appropriate for unbounded supports in particular @xmath4 ,",
    "is usually defined by : @xmath36where @xmath21 is a target , @xmath16 a bandwidth matrix and @xmath37 or sometimes @xmath38 for all @xmath39 .",
    "the function @xmath40 is the multivariate kernel assumed to be spherically symmetric and it does not depend on any parameter in particular @xmath21 and @xmath16 .",
    "the kernel function has also mean vector and covariance matrix respectively equal to zero and @xmath41 ; in general , the covariance matrix is the identity matrix : @xmath42 .",
    "this function @xmath40 is here called classical kernel .",
    "the following result connects a classical kernel to its corresponding symmetric or classical ( multivariate ) associated kernel .",
    "[ pro1 ] let @xmath43 be the support of the density to be estimated .",
    "let @xmath40 be a classical kernel with support @xmath44 , mean vector @xmath30 and covariance matrix @xmath41 .",
    "given a target vector @xmath45 and a bandwidth matrix @xmath16 , then the classical kernel induces the so - called classical ( multivariate ) associated kernel : ( i ) @xmath46 on @xmath47 with @xmath48 ( i.e. @xmath49 ) and @xmath50 ; ( ii ) @xmath51 on @xmath52 with @xmath48 ( i.e. @xmath49 ) and @xmath53 .",
    "* we only proof ( i ) because ( ii ) is similar . from ( [ asskern ] ) and ( [ classkern ] ) with @xmath37",
    ", we easily deduce the expression ( [ classcical ] ) . from ( [ classcical ] ) and definition [ defkern ] , for a fixed @xmath54 and for all @xmath55",
    ", there exists @xmath56 such that @xmath57 and therefore @xmath58 .",
    "this implies , from ( [ noyass1 ] ) , that @xmath47 . the last two results are simply derived from calculating the covariance matrix and the mean vector of @xmath59 ( the random vector of pdf @xmath60 ) by making the previous substitution @xmath57.@xmath61 it is known that the choice of classical kernels is not important ; nevertheless , the best classical kernel is the @xcite one in the sense of mise with bounded support @xmath62 .",
    "the most popular is the gaussian kernel with @xmath63 , @xmath42 and therefore @xmath64 ; see @xcite and @xcite .",
    "an interpretation of any classical multivariate associated kernel @xmath65 can be presented as follows : through the symmetry property of the classical kernel , the mean @xmath66 coincides with the mode which is the target @xmath21 ; separately and in contrario to the general case ( [ noyass3 ] ) , the dispersion measure around of the target @xmath21 , @xmath67 which does not here depend on @xmath21 , serves essentially to the smoothing parameters or to the bandwidth matrix .",
    "this is the basic concept of general associated kernels and it is a different approach with respect to the convolution point of view .",
    "note that the bandwidth matrix is similar to the dispersion matrix , which is symmetric and positive definite ; see for instance @xcite . for univariate dispersion parameter",
    ", we can refer to  @xcite and  @xcite for different uses .",
    "[ par : exple2](multiple kernels ) the product kernel estimator introduced by  @xcite can be defined as a product of univariate associated kernel estimators of  @xcite",
    ". we here call it `` multiple associated kernel estimator '' @xmath35 of the density @xmath2 : @xmath68}_{x_{j } , h_{jj}}(x_{ij}),~~ \\forall   x_{j } \\in   \\mathbb{t}^{[j]}_{1 } \\subseteq \\mathbb{r } , \\label{prodkern}\\]]where @xmath69}_{1}$ ] is the support of univariate margin of @xmath2 for @xmath70 , @xmath71}_{1}$ ] , @xmath72 for @xmath73 , and @xmath74 are the univariate bandwidth parameters",
    ". the function @xmath75}$ ] is the @xmath76th univariate associated kernel on the support @xmath77 . in principle , this estimator is more appropriate for bounded or partially bounded distributions without correlation in its components .",
    "a particular multiple associated kernel estimator is obtained by using univariate classical kernels .    in the following proposition ,",
    "we point out that all multiple associated kernels are multivariate associated kernels without correlation structure in the bandwidth matrix .",
    "[ proprod ] let @xmath78}_{1 } = \\mathbb{t}_{d}$ ] be the support of the density @xmath2 to be estimated with @xmath69}_{1 } ( \\subseteq \\mathbb{r})$ ] the supports of univariate margins of @xmath2 .",
    "let @xmath79}_{1}$ ] and @xmath80 with @xmath81 .",
    "let @xmath82}_{x_{j } , h_{jj}}$ ] be a univariate associated kernel ( see definition [ defkern ] for @xmath83 ) with its corresponding random variable @xmath84}_{x_{j } , h_{jj}}$ ] on @xmath85 for all @xmath70 .",
    "then , the multiple associated kernel is also a multivariate associated kernel : @xmath86}_{x_{j } , h_{jj}}(\\cdot)\\end{aligned}\\]]on @xmath87 with @xmath88 and @xmath89 = @xmath90 . in other words , the random variables @xmath84}_{x_{j } , h_{jj}}$ ]",
    "are independent components of the random vector @xmath59 .",
    "* proof . * from ( [ asskern ] ) and ( [ prodkern ] ) , the expression ( [ prodkern1 ] ) is easily deduced .",
    "the remainder results are obtained directly by calculating the mean vector and covariance matrix of @xmath91}_{x_{1 } , h_{11 } } ,   \\ldots , \\mathcal{z}^{[d]}_{x_{d } , h_{dd}})^{\\top } = \\mathcal{z}_{\\mathbf{x } , \\mathbf{h } } $ ] which is the random vector of the pdf ( [ prodkern1]).@xmath61    the multiple associated kernels have been illustrated in bivariate case by @xcite .",
    "for simulation studies , the authors used two independent univariate beta kernels and also two independent univariate gamma kernels .",
    "it is easy to generalize the investigation from two to more independent univariate associated kernels .",
    "if we have an associated kernel , an estimator can be easily deduced as in ( [ asskern ] ) .",
    "otherwise , a construction of associated kernels is possible by using an appropriate pdf .",
    "the pdf used must have at least the same numbers of parameters than the number of components in the couple @xmath92 as parameters of the expected associated kernel .",
    "the rest of this section is devoted to a construction of the multivariate associated kernels and then to some properties of the corresponding estimators .      in order to build a multivariate associated kernel @xmath20",
    ", we have to evaluate the dimensions of @xmath21 and @xmath16 .",
    "we always have @xmath93 components for the target vector @xmath94 which is completely separate from the bandwidth matrix @xmath16 in the classical multivariate associated kernel ; but , in general , @xmath21 is intrinsically linked to @xmath16 .",
    ".numbers @xmath95 of parameters according to the form of bandwidth matrices for general , multiple and classical asociated kernels . [ cols=\"<,^,^,^\",options=\"header \" , ]     finally , tables  [ timehcv ] and [ err ] indicate that the choice of the scott bandwidth matrix using lscv method is a good alternative to the full one in the purpose of preserving a correlation structure in the bandwidth matrix for an associated kernel estimator .",
    "we applied the standard version of the beta - sarmanov estimator ( [ est ] ) on paired rates data set according to the three types of bandwidth matrices in table  [ parameterstable ] .",
    "the dataset of sample size @xmath96 in graph  ( o ) of figure  [ estfull - scottfig ] has been provided by francial g.  @xcite during his last stay in burkina faso .",
    "it represents the popular ratings , for the two first consecutive ballots of the same electoral mandate of five years , of a political figure in different departments .",
    "note that , for both elections , the prominent politician was finally elected in the second round .",
    "we are here interested to the opposite behavior of peoples during first rounds of both elections since the second round is governed by political alliances , which do not constitute a reference for the own popularity of a candidate .",
    "indeed , for many african countries , political elections are generally fought on tribal ethnic origins and partisan interests .",
    "the data displays opposed viewpoints between the results of the first round of the first election ( @xmath97 ) and the first round of the second one ( @xmath98 ) . in fact , the first election saw the candidate program mostly adopted by its clan ( tribe and allied tribes ) and rejected by the others .",
    "a few years later , facing the social discontent , he assumed a new political program which ends to another consultation of the people in a time @xmath98 .",
    "this reversal made him loose the support of his supporters but he received the backing up of formers opponents .",
    "it is thus noticeable that its own popularity is not much different between the first round of both elections ; the first gave an average @xmath99 and the second @xmath100 .",
    "however , there is a significant negative correlation in the dataset : @xmath101 . unlike overall trends @xmath102 , @xmath103 and @xmath104 , the empirical distribution graph  ( o ) of figure  [ estfull - scottfig ] gives more details of the electoral situation department by department",
    "hence , we need a nonparametric smoothing of this joint distribution by using associated kernels .    in order to smooth the joint empirical distribution of these paired data ,",
    "we apply the beta - sarmanov kernel estimator in its standard version ( [ est ] ) .",
    "figure  [ hcvfig ] shows the results of the lscv algorithms a1 , a2 and a3 with the ratings dataset ; see ( [ hcv ] ) and the end of section  [ sssec : standbeta ] .",
    "the computation time of the lscv is in the same trend as in table  [ timehcv ] for @xmath105 . to simplify the presentations in figure  [ hcvfig ] for both the scott and full bandwidth matrices , we only plot @xmath106 for some values of @xmath107 and @xmath108 . in all cases",
    "we observe that there is a global minimum .",
    "the obtained optimal bandwidth matrices are @xmath109 @xmath110 and @xmath111 .",
    "the resulting estimates are displayed in figure  [ estfull - scottfig ] .    from simulation studies of previous section",
    ", the full bandwidth matrix provides the reference smoothing which is appropriated for correlated data ; see graph ( a ) of figure  [ estfull - scottfig ] . in record time",
    ", the scott bandwidth matrix @xmath112 delivers similar smoothing in graph ( b ) of figure  [ estfull - scottfig ] as the full and diagonal ones ( see respectively graphs ( a ) and ( c ) of figure  [ estfull - scottfig ] ) . in conclusion , we found anywhere the shape of a `` carpet flying '' in balance , smoothing thus the joint empirical distribution of the electoral situation of the candidate .",
    "this balance situation makes him to win in the second round of both elections .",
    "we have presented general associated kernels ( with or without correlation structure ) that varying their shape according to the target point along the support . excluding the classical associated kernels , the local adaptability of these associated kernels ( depending on the target point @xmath21 and the bandwidth matrix @xmath16 ) means that they are free of boundary bias but have a slightly bias different .",
    "furthermore , the forms of bandwidth matrices used in the case with correlation structure have both theoretical and practical significances . under the criterion of cross - validation",
    ", we therefore recommend the scott bandwidth matrix which is more workable than the full one .",
    "a method of construction , called _ multivariate mode dispersion _ method , for these kernels are introduced .",
    "also , we have proposed an algorithm of bias - reductions of their corresponding associated kernel estimators .",
    "an extension to discrete multivariate associated kernels is obviously possible .",
    "similarly , a work is in progress on nonparametric multiple regression composed by continuous and discrete univariate associated kernels ( e.g. proposition  [ proprod ] )",
    ".    constructed by the correlation structure of @xcite and by a variant of mode dispersion method , the bivariate beta - sarmanov kernel estimator is completely study with the optimal bandwidth matrix chosen by cross - validation .",
    "this technique can be extended in multivariate case for different type of kernels which are continuous and also discrete .",
    "in fact , from two or more univariate independent pdfs or probability mass functions , the correlation structure of @xcite and a variant of mode dispersion method can always allow to build a multivariate type of kernel with correlation structure ; and , therefore , produced the corresponding multivariate sarmanov kernel . in terms of execution times from using the cross - validation method , we advise to use the scott bandwidth matrix because of its flexibility and efficiency for no very strong correlation in the dataset .",
    "simulation experiments and analysis of a real dataset provide insight into the behavior of the bandwidth matrix for small and moderate sample sizes .",
    "tables  [ timehcv ] and  [ err ] and figure  [ estfull - scottfig ] can be conceptually summarized as follows . as expected",
    ", the full bandwidth matrix is frequently better than the others .",
    "an alternative with correlation structure has been proposed for the cross - validation technique : the scott bandwidth matrix which has a comparable gain in execution times than the diagonal one ; also , it produces better results than the diagonal in most cases .",
    "so , we recommend the scott bandwidth matrix for multivariate use with the cross - validation technique . further research in this direction are in progress , especially on the choice of optimal bandwidth matrix by using bayesian approaches ; see , e.g. , @xcite .",
    "this section is dedicated to the proof of proposition  [ pro3 ] . indeed , using successively ( [ estverskern ] ) and taylor s formula around @xmath113 and then @xmath21 , and",
    "also the invariance under cyclic permutations of the operator @xmath114 , the result ( [ biaisg ] ) is shown by    @xmath115 - f(\\mathbf{x } ) + \\oldstylenums{0}\\left[\\mathbb{e}\\left\\{\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } - \\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)^{\\top}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } - \\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)\\right\\}\\right ] \\\\ & = & f\\left(\\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right ) - f(\\mathbf{x } ) +   \\dfrac{1}{2}\\operatorname{trace}\\left[\\nabla^{2}f\\left(\\mathbb{e } \\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)\\mathbb{e}\\left\\{\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } - \\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)^{\\top}\\right .",
    "\\\\ & & \\left .",
    "\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } - \\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)\\right\\}\\right]+ \\oldstylenums{0}\\left[\\operatorname{trace}\\left(\\mathbb{e}\\left\\{\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } - \\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } - \\mathbb{e}\\left(\\mathcal{z}_{\\theta(x , \\mathbf{h})}\\right)\\right)^{\\top}\\right\\}\\right)\\right ] \\\\ & = & f\\left(\\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right ) - f(\\mathbf{x } ) +   \\dfrac{1}{2}\\operatorname{trace}\\left[\\nabla^{2}f\\left(\\mathbb{e } \\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)\\mbox{cov}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right ] + \\oldstylenums{0}\\left [ \\operatorname{trace}\\left\\{\\mbox{cov}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right\\}\\right]\\\\ & = & f\\left(\\mathbf{x } +   \\mathbf{a}_{\\theta}(\\mathbf{x } , \\mathbf{h})\\right ) - f(\\mathbf{x } ) +   \\dfrac{1}{2}\\operatorname{trace}\\left[\\nabla^{2}f\\left(\\mathbf{x } + \\mathbf{a}_{\\theta}(\\mathbf{x } , \\mathbf{h})\\right)\\mathbf{b}_{\\theta}(\\mathbf{x } , \\mathbf{h})\\right ] + \\oldstylenums{0}\\left [ \\operatorname{trace}\\left\\{\\mathbf{b}_{\\theta}(\\mathbf{x } , \\mathbf{h})\\right\\}\\right]\\\\ & = & \\mathbf{a}^{\\top}_{\\theta}(\\mathbf{x } , \\mathbf{h})\\nabla f\\left(\\mathbf{x}\\right ) + \\dfrac{1}{2}\\operatorname{trace}\\left[\\left\\{\\mathbf{a}_{\\theta}(\\mathbf{x } , \\mathbf{h})\\mathbf{a}^{\\top}_{\\theta}(\\mathbf{x } , \\mathbf{h } ) + \\mathbf{b}_{\\theta}(\\mathbf{x } , \\mathbf{h } ) \\right\\}\\nabla^{2}f\\left(\\mathbf{x}\\right)\\right ] + \\oldstylenums{0}\\left\\{\\operatorname{trace}\\left(\\mathbf{h}^{2}\\right)\\right\\}.\\end{aligned}\\ ] ]    in fact , the rest @xmath116 comes from @xmath117 deduced from proposition  [ pro1 ] of classical associated kernels and @xmath118 & = & \\\\",
    "\\mathbb{e}\\left\\{\\oldstylenums{0}_{p}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } - \\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)^{\\top}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } - \\mathbb{e}\\left(\\mathcal{z}_{\\theta(\\mathbf{x } , \\mathbf{h})}\\right)\\right)\\right\\ } , \\end{aligned}\\ ] ] where @xmath119 is the probability rate of convergence .",
    "concerning the variance ( [ var ] ) one first has @xmath120^{2 } \\\\ & = & \\dfrac{1}{n } \\int_{\\mathbb{s}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } \\cap \\mathbb{t}_{d } } k^{2}_{\\theta(\\mathbf{x } , \\mathbf{h } ) } ( \\mathbf{u})f(\\mathbf{u})d\\bold{u } - \\frac{1}{n } \\left[\\mathbb{e}\\left\\{k_{\\theta(\\mathbf{x } , \\mathbf{h})}\\left(\\mathbf{x}_{1}\\right)\\right\\}\\right]^{2 } \\\\ & = & i_{1 } - i_{2}.\\end{aligned}\\ ] ] from ( [ estverskern ] ) and ( [ biaisg ] ) , one has the following behavior of the second term @xmath121^{2 } \\simeq ( 1/n)f^{2}\\left(\\mathbf{x}\\right ) \\simeq o\\left(1/n\\right)\\ ] ] since @xmath2 is bounded for all @xmath122 . by using taylor s expansion around of @xmath21 ,",
    "the first term @xmath123 becomes @xmath124 with @xmath125d\\bold{u}.\\end{aligned}\\ ] ] a similar argument from ( * ? ? ?",
    "* lemma ) with @xmath2 bounded on @xmath3 shows the existence of @xmath126 and then the condition @xmath127 leads successively to    @xmath128",
    "we sincerely thank francial g. libengu for useful discussions and for the dataset of illustration .",
    "100                          gonzlez - manteiga , w. , lombarda , m.j . , martnez - miranda , m.d . , sperlich , s. , 2013 . kernel smoothers and bootstrapping for semiparametric mixed effects models , _ journal of multivariate analysis _ * 114 * , 288302 .                      kokonendji ,",
    "senga kiss , t. , zocchi , s.s . , 2007 .",
    "discrete triangular distributions and non - parametric estimation for probability mass function , _ journal of nonparametric statistics _ * 19 * , 241254 .",
    "libengu , f.g . , 2013 .",
    "_ mthode non - paramtrique par noyaux associs mixtes et applications_. ph.d .",
    "thesis manuscript ( in french ) to universit de franche - comt , besanon , france & universit de ouagadougou , burkina faso , june 2013 , * lmb no .",
    "14334 * , besanon ."
  ],
  "abstract_text": [
    "<S> multivariate associated kernel estimators , which depend on both target point and bandwidth matrix , are appropriate for partially or totally bounded distributions and generalize the classical ones as gaussian . </S>",
    "<S> previous studies on multivariate associated kernels have been restricted to product of univariate associated kernels , also considered having diagonal bandwidth matrices . </S>",
    "<S> however , it is shown in classical cases that for certain forms of target density such as multimodal , the use of full bandwidth matrices offers the potential for significantly improved density estimation . in this paper , general associated kernel estimators with correlation structure </S>",
    "<S> are introduced . </S>",
    "<S> properties of these estimators are presented ; in particular , the boundary bias is investigated . </S>",
    "<S> then , the generalized bivariate beta kernels are handled with more details . </S>",
    "<S> the associated kernel with a correlation structure is built with a variant of the mode - dispersion method and two families of bandwidth matrices are discussed under the criterion of cross - validation . </S>",
    "<S> several simulation studies are done . in the particular situation of bivariate beta kernels , </S>",
    "<S> it is therefore pointed out the very good performance of associated kernel estimators with correlation structure compared to the diagonal case . finally , an illustration on real dataset of paired rates in a framework of political elections is presented .    </S>",
    "<S> asymmetric kernel , boundary bias , correlation structure , bandwidth matrix , nonparametric estimation , mode - dispersion . : </S>",
    "<S> 62g07(08 ) ; 62h12    * short running title * : multivariate associated kernels </S>"
  ]
}