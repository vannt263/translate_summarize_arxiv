{
  "article_text": [
    "in the current picture of structure formation , inflation ends in reheating , which produces gaussian random field density fluctuations in the radiation , matter , and dark matter . as a gaussian random field",
    ", the density is described completely by its mean and 2-point correlation function ( 2pcf ) , which measures the probability of finding a certain value of the density at one point given the density at another .",
    "however , the subsequent evolution of the density field introduces additional correlations as gravity drives the convergence of overdense regions towards each other .",
    "in particular , a 3-point correlation function ( 3pcf ) is produced by this evolution ( bernardeau et al . 2002 or szapudi 2005 for reviews ) . since the evolution is itself sensitive to the cosmological parameters , measuring the 3pcf of galaxies offers an independent probe of these parameters .",
    "it is typically used to break the degeneracy between galaxy bias ( encoding the fact that galaxies do not trace the matter density field with perfect fidelity ) and the clustering on a given scale ( e.g. @xmath1 ) ( gaztaaga & frieman 1994 ; jing & borner 2004 ; guo et al .",
    "the 3pcf measurements also can probe primordial non - gaussianity ( desjacques & seljak 2010 ) ; while the constraints on this are currently dominated by cmb experiments such as planck , it is expected that the increasing quality and number of galaxy redshift surveys will provide interesting independent information .    since the first measurement by peebles & groth ( 1977 ) , numerous studies have presented 3pcf measurements , summarized in kayo et al .",
    "( 2004 ) , mcbride et al .",
    "( 2011a , b ) , guo et al .",
    "( 2014 ) and references therein . in this work",
    ", we present a new algorithm for measuring the 3pcf of galaxies through its multipole moments .",
    "this decomposition of the 3pcf was first advanced in szapudi ( 2004 ) and to a limited extent ( measurement of the monopole moment ) used in pan & szapudi ( 2005 ) on two - degree - field galaxy redshift survey ( 2dfgrs ) data .",
    "slepian & eisenstein ( 2015 ) ( hereafter se15 ) found this decomposition to be particularly useful for distinguishing linear and non - linear bias as well as isolating a possible relative velocity bias .",
    "current algorithms , such as that used for the mcbride et al .",
    "( 2011 ) measurement ( presented in moore et al . 2001 , gray et al .",
    "2004 , nichol et al .",
    "2006 , and gardner et al .",
    "2007 ) fundamentally scale as the number of possible triangles in a survey . if one wishes to measure the 3pcf out to some scale @xmath2 , there are @xmath3 relevant triangles , where @xmath4 is the number of objects in the survey , @xmath5 is the survey number density and @xmath6 .",
    "the algorithm presented in the series of references above , whose most recent incarnation is developed in march ( 2013 ) , uses multiple mrkd - trees .",
    "here `` mr '' means the kd - tree caches additional information , in this case the number of galaxies within each node of the tree as well as the bounding box of the node .",
    "this algorithm is faster than simply counting all triangles .",
    "it is particularly effective if the galaxies are close to each other , so that there are many triangles whose side lengths fall within a given combination of radial bins .",
    "however , typical galaxy surveys are sparse , particularly those mapping the largest volumes .",
    "for example , the baryon oscillation spectroscopic survey ( boss ) has an average separation of 13 @xmath7 , too large to permit many galaxies to be in the same bin .",
    "this means the algorithm will not be as fast for such large - scale measurements .",
    "the use case tested in march ( 2013 ) is triangles with three sides of @xmath8 mpc each , much smaller than the scales that are well - described by linear perturbation theory and hence most useful for cosmology .",
    "furthermore , even with the speed - ups coming from the multi - tree structure of the algorithm , it is still fundamentally scaling as the number of galaxies in the survey times the square of the number within @xmath2 ( march 2013 , figure 21 ) .    in this paper , we present an algorithm that does better : it scales as the number of galaxies in the survey times the number within @xmath2 , and so by construction is significantly faster than any previous algorithm that is exact in angle . in brief",
    ", we write the opening angle dependence of the triangles about a given vertex in terms of legendre polynomials of @xmath9 , where these are two unit vectors describing two triangle sides .",
    "the dot product seems to require explicitly considering all pairs of galaxies about a given vertex ( i.e. third galaxy ) , but using the spherical harmonic addition theorem , this representation can be factored into a product of spherical harmonics each depending on only one unit vector . therefore from the spherical harmonic expansion of the radially binned density field",
    "one can obtain the multipole moments without ever needing to consider pairs about a given vertex .",
    "this is the central insight of this paper .    in section [ sec :",
    "algorithm ] , we present the algorithm in more detail , and show in section [ sec : proj3pcf ] how this framework goes through to the projected 3pcf .",
    "section [ sec : edgecorrxn ] discusses edge correction , while section [ sec : implementation ] describes our implementation .",
    "section [ sec : covariance ] computes the covariance of this multipole decomposition in the gaussian random field limit , and section [ sec : mock_results ] presents the results of using the algorithm on the lasdamas sdss - ii data release 7 ( sdss - dr7 ) luminous red galaxy mock catalogs .",
    "we conclude in section [ sec : conclusions ] .",
    "in this paper , we parametrize triangle configurations by two side lengths , @xmath10 and @xmath11 , and the angle between them with cosine @xmath12",
    ". we will decompose the 3pcf as a function of these three variables into a sum over legendre polynomials for the angular dependence times radial coefficients encoding the side length dependence , as @xmath13 szapudi ( 2004 ) first advanced this decomposition , and he puts a factor of @xmath14 in front of his analogous expansion coefficients ; we absorb this into @xmath15 .",
    "there are three major advantages to this decomposition .",
    "first , the shape of the 3pcf for fixed side lengths as a function of angle is smooth and slowly varying ( see e.g. bernardeau 2002 , figure 11 ) , without much fine structure .",
    "thus we expect that only a few multipoles will be required to capture the angle dependence .",
    "second , this decomposition provides a natural way to visualize the 3pcf for all triangle configurations ; one can make several panels for different @xmath16 , each with all @xmath10 and @xmath11 and amplitudes indicated by a colorbar , as in se15 .",
    "in contrast to many previous works , this allows immediate appraisal of the information in all triangles and not just a particular set of configurations ( e.g. isosceles , two - to - one , etc . )    third , as we will see , the multipole moments of the 3pcf can be obtained with much greater speed than other decompositions of the 3pcf . however , in contrast to other fast methods , such as tree methods that fix a critical angular scale below which they are approximate ( e.g. zhang & pen 2005 ) or fourier methods that choose a grid with some minimum spacing , we do not sacrifice accuracy to obtain this speed .",
    "our method is exact in angle .",
    "we will bin in side length , but even were speed of no concern this would be necessary to keep the covariance matrix to a reasonable size .",
    "the 3pcf describes the number of triangles of a given configuration whose vertices are the galaxies in a survey . while nine coordinates are required to completely describe any individual triangle connecting three galaxies , the 3pcf averages over both translations and rotations of the triangle configuration .",
    "the presumed losslessness of this averaging corresponds to the two usual cosmological assumptions of isotropy ( rotation - invariance about a given point ) and homogeneity ( translation - invariance ) .",
    "this ultimately reduces the 3pcf to a function of only three variables ; as indicated already , we will use two triangle sides and the angle between them .",
    "we will now show explicitly how to go from nine coordinates to three .",
    "we begin with averaging over rotations .",
    "we will show explicitly that legendre polynomials are an angular basis for the 3pcf after this averaging .",
    "to do so , we first step back and write an estimate ( denoted by a hat ) of the 3pcf for a triangle with sides @xmath17 extending from a vertex whose absolute position within the survey is @xmath18 .",
    "we have @xmath19    we now wish to average over all rotations of the triangle about @xmath18 .",
    "writing a rotation as @xmath20 ( simply a matrix involving the three euler angles ) , we have @xmath21 where subscript `` iso '' abbreviates `` isotropy . ''",
    "noting that @xmath22 , where @xmath23 is a wigner matrix ( e.g. arfken , weber & harris 2013 ( hereafter awh13 ) , equation ( 16.52 ) ) , we find @xmath24 the integral over wigner matrices is simply evaluated by orthogonality ( e.g. brink & satchler 1993 , appendix v ) as @xmath25 , @xmath26 the kronecker delta . using the spherical harmonic addition theorem ( awh13 , equation ( 16.57 ) ) @xmath27 and defining @xmath28 we find @xmath29 in what follows we drop the subscript `` iso '' as we will always be considering the isotropic 3pcf .",
    "we now move to averaging over translations .",
    "recalling that @xmath18 is the vertex of the triangle from which the two sides given by @xmath17 extend , the densities on a particular triangle of points will be @xmath30 . averaging over translations means allowing every point in the survey to serve as the vertex @xmath18 , so we must integrate over @xmath31 .",
    "we thus find that the @xmath32 radial coefficient of the 3pcf is @xmath33 where @xmath34 is the survey volume .",
    "our algorithm will bin radially ( denoted with a bar ) , so we seek @xmath35 with @xmath36 a binning function demanding that we are in the bin given by its second argument . binning averages the radial coefficient over some interval in each side length , and in that sense is not lossless .",
    "it is also necessary for the speed advantage of our algorithm , as will become clear shortly .",
    "we will not compute using equation ( [ eqn : binned_zeta ] ) .",
    "rather , we will bin radially around each possible origin @xmath18 _ before _ averaging over rotations and translations , so it will be useful also to define the binned estimator before translation - averaging as @xmath37 where @xmath38 is the radially binned density field about an origin @xmath39 .",
    "hence in practice we never compute @xmath40 using equation ( [ eqn : binned_zeta ] ) , but rather measure @xmath41 via equation ( [ eqn : binned_zetahat_l ] ) and then compute @xmath42 as the radially binned multipole coefficients of the 3pcf .      a direct way to measure @xmath43 would be to sit on every possible origin and compute the angle between pairs of vectors pointing to all possible sets of two galaxies out to the radius @xmath2 to which one wishes to measure the 3pcf .",
    "this scales as @xmath3 .",
    "as discussed in the introduction , this scaling applies to other algorithms as well ( e.g. the gardner ( 2007 ) and march ( 2013 ) kd - tree approach ) , fundamentally because the number of possible triangles within @xmath2 with one vertex fixed scales as @xmath44 .",
    "however , as is the case for angular power spectra , we can exploit a property of multipole decompositions to enormously accelerate the measurement .",
    "we can use the spherical harmonic addition theorem ( [ eqn : sph_addition_theorem ] ) to decompose the legendre polynomial into factors that depend only on one angular variable each . inserting this into equation ( [ eqn : binned_zetahat_l ] ) , we find @xmath45 this equation immediately shows how to reduce the quadratic scaling in the number density to a linear scaling .",
    "the two angular integrals have now been separated , and each simply asks for a particular expansion coefficient of the density field ( as a function of angle alone ) in spherical harmonics , in a fixed radial bin .",
    "in other words , if we compute for each radial bin @xmath46 @xmath47 we can construct all combinations dictated by @xmath10 and @xmath11 , without ever needing to do an @xmath48 operation .",
    "explicitly , inserting equation ( [ eqn : almsdef ] ) into equation ( [ eqn : zetal_int ] ) , we find @xmath49 this is why radial binning is essential for the speed - up of our algorithm ; we can precompute the @xmath50s in each radial bin . for @xmath51",
    ", we then only need to construct @xmath52 combinations of these coefficients . a schematic about a single possible origin",
    "is shown in figure [ fig : kernel ] .    for a 3pcf measurement , one might use a bin width @xmath53 mpc , and so if one measures out to @xmath54 there will be only @xmath55 distinct bin combinations .",
    "meanwhile , computing the @xmath50s themselves takes only as long as performing the integral ( [ eqn : almsdef ] ) , which should scale as @xmath56 .",
    "we still must integrate over all possible choices of origin as dictated by equation ( [ eqn : translation_avg ] ) . because the galaxies are discrete , this will reduce to a sum with @xmath4 terms .",
    "thus our algorithm will scale as @xmath57 : linear in both the total number of galaxies _ and _ the number within a sphere of radius @xmath2 , and a factor of order @xmath58 faster than the naive counting approach .",
    "our algorithm thus provides a route to the 3pcf that on large scales is no more computationally intensive than calculating the multipole moments ( standardly calculated are monopole and quadrupole ) of the 2-point correlation function ( 2pcf ) .    ) .",
    "the @xmath59 can be combined to yield the multipole moments around this galaxy ( sum over @xmath60 , equation ( [ eqn : zetal_ito_alms ] ) ) and then translation - averaged to yield @xmath15 for the survey . ]    finally , to obtain the spherical harmonic coefficients of the galaxy density as in equation ( [ eqn : almsdef ] ) , one might think a spherical harmonic transform is required .",
    "this scales as @xmath61 , @xmath62 the number of spatial grid cells on the surface of a sphere .",
    "a large number of grid cells is necessary for accuracy even if there are very few galaxies , much as a small @xmath63 is needed when taking a numerical fourier transform to avoid ringing .",
    "however , because only low - order multipoles are needed here ( @xmath64 ) , we can avoid this transform and instead directly evaluate the @xmath65s , which are simply spherical harmonics evaluated at angles given by a galaxy s location with respect to a given choice of origin .",
    "the required @xmath66s can be easily computed using the cartesian expressions for the spherical harmonics ( e.g. awh13 , equation ( 15.139 ) and table 15.4 ) . indeed , about a given origin , the cartesian components @xmath67 and @xmath68 and their powers for each galaxy can be pre - calculated just once and subsequently combined to form all of the required multipoles .",
    "redshift - space distortions ( rsd ) are differences between the true position of a galaxy along the line of sight and its position as inferred from assuming its redshift is purely cosmological .",
    "they arise from peculiar velocities , ultimately generated by the growth of large - scale structure ( hamilton 1998 , for a review ) .",
    "the projected 3pcf is insensitive to these distortions because it is integrated along the line of sight .",
    "below we show how our approach extends to measuring it .",
    "we work in the flat - sky approximation , where there is a single line of sight to all galaxies in the survey . sitting around a given central galaxy and projecting",
    "corresponds to drawing cylindrical shells around that central with bases that are concentric annuli .",
    "all of the galaxies in a given cylinder project down into the cylinder s base annulus .",
    "we thus have a planar problem with circular symmetry .",
    "this permits simplification of our spherical harmonic basis . recall that @xmath69 where here @xmath70 are the angular coordinates of a galaxy in the system where the central is at the origin .",
    "since all the ( projected ) positions are coplanar with the central , the separation along the @xmath71-axis is zero , so @xmath72 . defining @xmath73 we see from equation ( [ eqn : zetal_int ] ) that the multipole moments of the projected",
    ", radially binned 3pcf will simply involve fourier coefficients of the projected , radially binned density field weighted by @xmath74 : @xmath75 above , the integrals over @xmath76 and @xmath77 of equation ( [ eqn : zetal_int ] ) have already been performed using that the projected density field is only non - zero at @xmath78 .    with this in mind",
    ", we observe that if one is solely interested in the projected 3pcf , it is probably optimal simply to use the fourier basis directly .",
    "one parametrizes the projected 3pcf estimator about a given central as @xmath79 and writes the exponential as @xmath80 where @xmath76 and @xmath77 are now angles in the plane in polar coordinates , with @xmath81 . using orthogonality of the plane waves , one",
    "may then extract the expansion coefficients @xmath82 in equation ( [ eqn : fourier_param ] ) as @xmath83 just as in the non - projected case , these integrals can be explicitly evaluated using the cartesian expressions for the exponentials , and precomputing @xmath84 and @xmath85 .",
    "again , one never explicitly considers pairs of galaxies about a given central ; one simply constructs the coefficients @xmath86 for all radial bins , then computes @xmath87 for all desired bin combinations , and finally averages over translations by integrating out @xmath39 .",
    "we should note that chen & szapudi ( 2005 ) advanced a similar scheme to measure the 3pcf of cosmic microwave background ( cmb ) maps , analogous to the projected 3pcf since both are on 2-d manifolds .",
    "however their method evaluates the fourier transform of the ( continuous ) temperature anisotropy map by gridding , whereas here we suggest the ( discrete ) galaxy density field be fourier - transformed using direct evaluation of the cartesian expressions for @xmath84 and @xmath85 .",
    "surveys have jagged and complicated boundaries , and these can produce a spurious contribution to the 3pcf that is the signature of the survey geometry rather than physics the survey hopes to probe .",
    "this spurious contribution must be removed . in fourier space ,",
    "boundaries lead to gibbs phenomenon ringing in the bispectrum , and are challenging to remove .",
    "however , in configuration space , edge correction is fairly straightforward for popular estimators ( see kayo et al .",
    "2004 , appendix , for comparison of several ) .",
    "we focus here on the szapudi & szalay ( 1998 ) estimator , which kayo et al .",
    "( 2004 ) find preferable to the others they consider ; it has now become the standard in the field .",
    "it is @xmath88 with @xmath89 , @xmath90 the data and @xmath91 the random counts .",
    "note that , if one inserted @xmath92 for @xmath93 in section [ sec : algorithm ] , one would need to compute integrals of this fraction against the spherical harmonics , requiring definition of @xmath92 at every point in space .",
    "however , the estimator ( [ eqn : hat_zeta_est ] ) really represents the function @xmath94 averaged over rotations and translations with weights @xmath95 , which in the shot noise limit is just inverse variance weighting ( we include radial binning represented by @xmath96 ) . in short",
    ", @xmath97 thus the estimator ( [ eqn : hat_zeta_est ] ) should be interpreted as demanding the triple count @xmath98 divided by the triple count @xmath99 .",
    "therefore we can insert @xmath4 and @xmath91 separately in turn for @xmath93 in section [ sec : algorithm ] , processing random and data catalogs serially .",
    "the division required can be done as a post - processing step .",
    "we now turn to how this division translates to the legendre basis .",
    "working now in our legendre basis , we have @xmath100 @xmath101 and @xmath102 inserting the multipole expansions ( [ eqn : mp_nr])-([eqn : mp_r ] ) into the estimator ( [ eqn : hat_zeta_est ] ) and multiplying through by @xmath99 we find @xmath103    using a linearization formula for the product of two legendre polynomials ( ferrers ( 1877 ) , adams ( 1878 ) , neumann ( 1878 ) , park & kim ( 2006 ) ; se15 equation ( a11 ) ) we find , with angular arguments suppressed , @xmath104 the wigner 3j - symbol above describes angular momentum coupling ; see e.g. brink & satchler ( 1993 ) or awh13 .",
    "the vector addition of angular momenta means that the upper row must satisfy triangle inequalities , so @xmath105 and at fixed @xmath16 and @xmath106 the sum is finite . using orthogonality , separating out the @xmath107 term , dividing through by @xmath108 , and defining @xmath109",
    ", we obtain @xmath110    for a boundary - free survey the random field would generate only a monopole ( @xmath108 ) , leaving only @xmath111 on the righthand side ; this is the limit where there is no need for edge - correction , but just division by the randoms .",
    "the form of equation ( [ eqn : edgecorrxn_fund ] ) suggests that this problem can be cast as a matrix multiplication , so we define the multipole coupling matrix @xmath112 with elements @xmath113 note that while these matrix elements describe the off - diagonal couplings of different multipoles to each other , they need not be zero along the diagonal .",
    "a given multipole in the data may couple to that same multipole in @xmath114 because the 3j - symbol allows @xmath115 for @xmath116 . but the dominant coupling of a given multipole in the data to the same multipole in @xmath114 is described by @xmath111 in equation ( [ eqn : edgecorrxn_fund ] ) , since the @xmath117 are expected to be much less than unity .",
    "this term translates to the identity matrix @xmath118 .",
    "the edge - correction equation ( [ eqn : edgecorrxn_fund ] ) thus becomes @xmath119 where @xmath120 and analogously for @xmath121 .",
    "the system of equations this represents can then be solved for @xmath121 by matrix inversion .    to explore this matrix for a realistic use case",
    ", we use the lasdamas sdss dr7 real space mock catalogs , using 15 radial bins and a maximum scale of @xmath0 ( further details are given in section [ sec : mock_results ] ) .",
    "we show @xmath122 for a particular bin in @xmath123 in figure [ fig : mkl ] , and the leading order edge correction factor @xmath124 in figure [ fig : f_one ] .",
    "@xmath112 is not symmetric , but @xmath125 is ; this is why the upper off - diagonal , where @xmath126 , exceeds the lower in figure [ fig : mkl ] .",
    "there are two approximations implicit in our approach to solving equation ( [ eqn : matrix_edgecorrxn ] ) .",
    "first , to obtain a given matrix element @xmath122 , formally one requires @xmath117 for all values of @xmath106 .",
    "however , for @xmath127 these factors fall rapidly . for the lasdamas real space mock catalogs for which we present results here , they are @xmath128 by @xmath129 even for the largest - scale radial bin combination ( the values are listed in the caption to figure [ fig : mkl ] ) , so we simply truncate the series there . if one wished one could easily expand our code to measure higher multipoles of the randoms at the cost of slightly more computation time .",
    "however we expect that going to @xmath129 will already render the edge correction error negligible compared to the total error budget .",
    "importantly , the smallness of the @xmath117 for @xmath127 means that the coupling between multipoles @xmath130 and @xmath16 is nearly diagonal .",
    "coupling between multipoles separated by more than one angular momentum step is suppressed as @xmath131 or higher because the 3j - symbol in the coupling matrix elements ( [ eqn : mkl ] ) requires that @xmath132 .",
    "the second approximation relates to the matrix inversion when we solve equation ( [ eqn : matrix_edgecorrxn ] ) .",
    "formally one has an infinite dimensional matrix where at fixed @xmath16 , all @xmath130 enter the correction .",
    "thus this matrix will not be square ( and hence invertible ) unless we go to an infinite number of @xmath16 as well .",
    "however , in practice the matrix is so diagonally - dominant that we believe it is accurate enough simply to invert the sub - matrix given by truncating @xmath16 and @xmath130 at some maximum multipole .",
    "we verify this approximation by constructing @xmath122 using solely the dominant @xmath124 edge - correction factor , letting @xmath130 and @xmath16 go to @xmath133 , inverting , and comparing to the result where both go to @xmath134 . were the matrix purely diagonal",
    ", truncation would not affect the inverse at all . in the limit where only @xmath124 is non - zero ( in reality ,",
    "it does dominate the other edge correction factors ) , the matrix is tridiagonal , and so truncation at @xmath134 affects @xmath135 at order @xmath124 , @xmath136 at order @xmath137 , and @xmath138 at order @xmath139 .      using a simple toy model , we can estimate the edge correction factors @xmath140 to confirm that they really should be small . consider a spherical ball of random galaxies with radius @xmath91 about a given central , and assume this sphere is cut by a planar survey boundary .",
    "orient the @xmath71-axis perpendicular to this boundary , with the central galaxy a distance @xmath71 from it .",
    "the problem now has symmetry about this axis , so we need only compute the @xmath141 spherical harmonic coefficients @xmath65 ; @xmath142 , with @xmath143 . for a galaxy at distance @xmath91 from the central",
    ", there will be some critical angle with cosine @xmath144 such that , for smaller @xmath145 , the galaxy is outside the survey .",
    "we have @xmath146 .",
    "\\end{aligned}\\ ] ] we used the recursion formula @xmath147 $ ] to evaluate the integral and noted that the terms at the lower bound cancel off because they have the same parity .",
    "we now compute the @xmath148 required by equations ( [ eqn : almsdef ] ) and ( [ eqn : zetal_int ] ) and average over @xmath149 ( denoted by angle brackets ) .",
    "we have @xmath150.\\end{aligned}\\ ] ] since each term above has even parity , we can integrate from @xmath151 to @xmath152 , divide by @xmath153 , and then invoke orthogonality , to find that @xmath154 finally , we compute @xmath155 explicitly , to find that @xmath156 @xmath157 , @xmath158 , @xmath159 , @xmath160 , falling to @xmath161 . it should be kept in mind that in a large survey volume such as sdss , many centrals will have spheres around them that do not impinge on a large - scale survey boundary at all , further reducing these factors ; for instance , for the sdss boss dr10 footprint only of order @xmath162 of spheres impinge on a boundary , so our rough estimates should be scaled down by a factor of 5 .",
    "on the other hand , the true survey mask is far more complicated than the simple planar boundary model above , so this model should not be taken too literally .    ) for the lasdamas sdss dr7 real space mock catalogs with 15 radial bins out to @xmath0 .",
    "higher @xmath163 fall off very rapidly .",
    "even the leading order coefficient is small .",
    "this means that one does not need to measure many multipoles of the randoms to obtain a highly accurate edge correction : since the higher @xmath117 fall off so rapidly they contribute very little to the matrix @xmath112 that must be inverted ( equation ( [ eqn : matrix_edgecorrxn ] ) ) .",
    "as we expect , @xmath124 becomes larger at larger scales , as larger scale triangles are more likely to impinge on a survey boundary . ]    ) at each @xmath130 and @xmath16 for the largest combination of radial bins we test here .",
    "this illustrates that all of the couplings are @xmath164 , even for the largest scales we test , which should have the largest correction factors as they are most likely to impinge on a survey boundary ( see figure [ fig : f_one ] ) . while the diagonal appears zero in this plot , it is actually just small , as we discuss in the main text .",
    "the @xmath140 entering the matrix elements @xmath122 for this radial bin combination are @xmath165 , and @xmath166",
    "we next describe our c++ implementation of the ideas in sections [ sec : algorithm ] and [ sec : edgecorrxn ] .",
    "the basic program flow is to loop over each central galaxy . for each",
    ", we find all neighbors within @xmath2  and accumulate the @xmath65 for each of the radial bins . once finished with the neighbor finding , we compute all of the bin cross - powers and add them to our accumulators as a function of bins @xmath10 and @xmath11 and multipole @xmath16 .",
    "all of the accumulations include a user - supplied weight per galaxy .",
    "we accelerate the finding of neighbors by sorting the particles into a grid , so that the search for neighbors need only consider grid cells that include some point closer than @xmath167 .",
    "ideally one wants the grid spacing to be a few times smaller than @xmath167 , so that the inefficiency of doing a cubic search for a spherical region is mild .",
    "one also wants the grid spacing to be large enough to contain at least several particles , so that the overhead of storing and accessing the grid is modest .",
    "these criteria are not hard to satisfy : for the lasdamas mocks , we use a grid spacing of @xmath168 when searching out to @xmath169 ; this typically contains a dozen galaxies ( and somewhat more random points ) . for the sdss - iii baryon oscillation spectroscopic survey , the density is three times higher .",
    "once a neighbor is found , we need to add its contribution to the spherical harmonics .",
    "we do not use an angular binning to compute the spherical harmonics .",
    "rather , as mentioned in section [ sec : algorithm ] , we use the fact that the spherical harmonics can be written as powers of the cartesian coordinates of unit vectors .",
    "in particular , for a unit vector @xmath170 , we can write @xmath171 as a polynomial of terms of the form @xmath172 where @xmath173 . to compute all @xmath65 up to multipole order @xmath174 , we therefore accumulate sums over all neighbors of the cartesian powers @xmath172 with @xmath175 , using the unit vectors of the separation of the neighbor from the central galaxy .",
    "there are @xmath176 such power combinations for each radial bin .",
    "having finished with all neighbors , we convert these powers into the @xmath65 using the appropriate coefficients from the spherical harmonics , then form all of the bin - to - bin cross powers .    for values of @xmath174 of order 10 ,",
    "the computation of the cartesian powers is much faster than doing the spherical harmonic transform of a fine angular grid .",
    "this is particularly true because we use custom assembly code , supplied by marc metchnik as part of the abacus project ( metchnik & pinto , in prep . ) , to accumulate these powers using advanced vector extension ( avx ) instructions . in double precision ,",
    "8 neighbors are computed at once , using two sets of avx registers .",
    "though we do not present the 3pcf measurement here , we also run our algorithm on the sdss - iii boss dr10 data . in the north galactic cap footprint for the cmass sample",
    ", we consider the rrr count of 642,619 random particles .",
    "we count 6.7 billion pairs with @xmath177 , an average of 10,400 neighbors per central , divided into 10 linearly spaced radial bins . using @xmath178",
    ", the code runs in 170 seconds on a 6-core 4.2 ghz i7 - 3930k .",
    "if we use @xmath179 , thereby reducing the problem to the pair finding and a simple accumulation per radial bin , then the code runs in 53 seconds .",
    "loading the particles and sorting them into the grid is a small fraction of that total , so we infer that each pair found and processed at @xmath179 takes about 200 clock cycles .",
    "given @xmath178 , we have 286 powers to track per neighbor , each requiring a separate multiply and add .",
    "hence , we are computing about 3.8 trillion double - precision operations in 120 extra seconds , a rate of 32 double - precision gflops .",
    "this is about 30% of the maximum performance of the cpu ( assuming 4 double precision operations in avx per clock cycle per core ) , a high mark for a practical calculation .",
    "the code is sustaining 22 gflops for the full problem , including the pair finding .",
    "a two - point correlation function code would only need to count half as many pairs , since the particles are indistinguishable in that application , and so at these speeds would take of order @xmath180 seconds .",
    "we therefore find that our computation of the three - point correlation function up to @xmath181 is only about @xmath182 times slower than the equivalent two - point correlation function calculation .",
    "we would expect an explicit counting of triples to be about 3,000 times slower than the two - point pair counting , given the 10,000 neighbors ( divide by a factor of 3 for the number of indistinguishable triples compared to indistinguishable pairs ) . as our method is only six times slower than a two - point measurement , it is a factor of five hundred faster than an explicit triple count for this large - scale example .    in any method that compares the data points to a random set , we have to consider the effect of poisson noise in the randoms .",
    "for example , in the landy - szalay ( 1993 ) estimator for the two - point function , @xmath183 , we will have noise in the data - random @xmath184 and random - random @xmath185 counts that would go to zero in the limit of infinite numbers of random points .",
    "one therefore usually wants to use many more randoms than data ( but note the important optimization presented in padmanabhan et al .",
    "( 2007 ) in which one fits these counts to smooth functions of scale so as to reduce the poisson noise ) .",
    "a common inefficiency , however , is to use the same number of randoms for each of the terms .",
    "this results in spending far too much computational resource on @xmath186 , whose poisson noise will be dwarfed by the @xmath187 noise . for example , if the number of randoms is @xmath60 times the number of data points , then ( assuming uniform galaxy weights ) the variance on @xmath186 will be @xmath188 of that of @xmath189 since the number of @xmath186 pairs is @xmath190 the number of @xmath189 pairs .",
    "in contrast , the variance of @xmath187 will only be reduced to @xmath191 of that of @xmath189 ; the factor of 4 comes from the factor of 2 in the landy - szalay estimator , and the @xmath192 enters because the @xmath189 and @xmath186 pairs have double the variance since each pair is counted twice . meanwhile the work in the two terms is scaling as @xmath193 and @xmath60 , respectively .    a simple way to avoid",
    "this is to compute the @xmath187 and @xmath186 counts with a smaller set of randoms and then repeat this numerous times , averaging over the answers . by choosing the number of randoms in each set",
    ", one can optimize the work .",
    "for example , in the above two - point case , at fixed total work , the number of random catalogs @xmath194 one can use scales as @xmath195 .",
    "the total variance scales as the variance per random catalog divided by @xmath194 , so as @xmath196 .",
    "this is minimized for @xmath197 , i.e. , it is optimal to use random catalogs equal in size to the data set .",
    "a further advantage of this method is that in addition to averaging all of the sets to get the best answer , one can compute the variance to explicitly measure the contribution of the random catalog density relative to one s estimate of the irreducible on - sky variance .    for our three - point algorithm ,",
    "the work scales as @xmath198 , while the poisson variance of @xmath199 for each random catalog scales as @xmath200 for @xmath99 and @xmath201 for @xmath202 and @xmath203 ; the @xmath204 enters due to the @xmath205 in the szapudi - szalay estimator , while the @xmath206 comes from a 6-fold counting symmetry in @xmath207 and @xmath99 compared to a 2-fold one in @xmath203 and @xmath202 .",
    "the total variance is thus @xmath208 . at fixed total work",
    "@xmath194 scales as @xmath209 , and so the total variance scales as @xmath210 .",
    "this is minimized for @xmath211 but with only @xmath212 variation between @xmath213 and @xmath153 .",
    "we implement this strategy in our three - point method by supplying a single list of particles , with the randoms concatenated to the data but with negative weights .",
    "notationally , this is @xmath214 , as in section [ sec : edgecorrxn ] .",
    "we then compute the three - point correlations of this @xmath4 list .",
    "we then re - run repeatedly with new random points @xmath91 .",
    "we avoid the small amount of repeated counting of the @xmath189 pairs and @xmath207 triples by the following trick .",
    "we first run the code with only the data particle list and save a file that contains the cartesian multipoles for each radial bin and each primary particle , in the enumerated order of the particles . when next running with @xmath215 lists , whenever a data particle is the primary ( as marked by its having a non - negative weight ) , we initialize the multipole accumulators with the saved values and then skip any secondary particles that are also from the data list . the resulting sums pass transparently to the rest of the analysis code .",
    "we also run a separate case with only the randoms , so that we can compute the denominator and edge - correction terms in equation ( [ eqn : edgecorrxn_fund ] ) .",
    "this requires much less precision , as the denominator of the estimator is much larger than the numerator for large - scale correlations .",
    "we therefore do this with only a single set of random points .",
    "finally , we have also written a python implementation of the algorithm presented here and tested it on a periodic box with sides of @xmath216 containing @xmath217 galaxies ( roughly the sdss boss number density ) . rather than using gridding ,",
    "this code exploits kd - trees for galaxy finding , using a fast c implementation ( wrapped to python ) in the @xmath218 library within @xmath219 .",
    "we verified the accuracy of this code on a sample of 500 galaxies by comparing with a simple direct - counting algorithm that just counts triplets and then projects onto multipoles .",
    "this provides an important cross check on our spherical harmonics since the simple triple counting never uses spherical harmonics .",
    "we then ran both the multipole python code and the multipole c++ code on a larger , 20,000 galaxy sample to verify the c++ code .",
    "runtime for the python version on a dual core ( 2014 ) macbook air was about @xmath220 minutes ; since the box is periodic , scaling to larger numbers of galaxies is linear .",
    "parameter fitting requires weighting the data points according to how independent they are , with two highly independent points contributing more than two less independent points all else equal .",
    "the covariance matrix describes how independent the measured multipoles at each @xmath123 are . for our algorithm to be useful",
    ", we must show that the covariance matrix can be controlled ; here we compute it with this end in mind .",
    "the general 3pcf covariance has been computed before ( szapudi 2001 ) as a 6-d integral , but it is not straightforward to obtain the covariance of our multipole decomposition from this result . here",
    "we derive the covariance for our multipole decomposition and show that it can be reduced to a sum of 2-d integrals .",
    "this reduction offers a significant improvement in the computation speed possible at a given accuracy .",
    "we begin with some definitions and conventions .",
    "while we wish to compute the covariance matrix of the configuration space 3pcf , we will end up working in fourier space to do the computation because simplifications are available there by appeal to the power spectrum .",
    "we define the fourier transform as @xmath221 with inverse @xmath222 for the earlier stages of our computation we will in fact need to use the discrete fourier transform and its inverse , defined as @xmath223 and @xmath224 where these discrete transforms are over a volume @xmath225 with quantized wavenumbers such that @xmath226 , @xmath227 .",
    "we define the power spectrum as @xmath228 @xmath26 is the kronecker delta , unity when its argument is zero and zero otherwise .",
    "one can check easily that this definition allows one to recover the familiar relation that the correlation function is the fourier transform of the power spectrum .",
    "we will also use the fact that @xmath229    finally , note that one can convert from the discrete to the continous case by replacing @xmath230 with @xmath231 .",
    "we now obtain the covariance of our multipole decomposition of the 3pcf . here",
    "we begin with an estimator for the translation - averaged but not rotation - averaged full 3pcf ; we will project onto multipoles ( which also averages over rotations ) and bin radially later .",
    "@xmath232 for a gaussian random field , @xmath233 .",
    "the covariance is thus @xmath234\\nonumber\\\\ & \\times \\left<\\tilde{\\delta}(\\vec{k})\\tilde{\\delta}(\\vec{q})\\tilde{\\delta}(\\vec{p})\\tilde{\\delta}(\\vec{k}')\\tilde{\\delta}(\\vec{q}')\\tilde{\\delta}(\\vec{p}')\\right>.\\end{aligned}\\ ] ] peforming the integrals over @xmath31 and @xmath235 we have @xmath236\\nonumber\\\\ & \\times\\left<\\tilde{\\delta}(\\vec{k})\\tilde{\\delta}(\\vec{q})\\tilde{\\delta}(\\vec{p})\\tilde{\\delta}(\\vec{k}')\\tilde{\\delta}(\\vec{q}')\\tilde{\\delta}(\\vec{p}')\\right>\\end{aligned}\\ ] ] where @xmath26 is a kronecker delta whose argument is the sum of the subscripted vectors .",
    "we now use wick s theorem to reduce the 6-point expectation value to triple products of 2-point functions ; this is where gaussianity enters .",
    "we need to consider all possible contractions .",
    "@xmath237}\\nonumber\\\\ & \\times\\bigg\\{(qq')(pp')(kk')+(pq')(qp')(kk')+(kq')(qk')(pp')\\nonumber\\\\ & + ( kp')(qk')(pq')+(kq')(pk')(qp')+(kp')(pk')(qq')\\bigg\\ } \\label{eqn : contracted_covar}\\end{aligned}\\ ] ] where parentheses represent contractions of @xmath238 evaluated at the arguments in the parentheses .",
    "using equation ( [ eqn : powerspec_def ] ) , the term in curly brackets above becomes @xmath239.\\end{aligned}\\ ] ] doing the sums over @xmath240 , and @xmath241 in equation ( [ eqn : contracted_covar ] ) we find @xmath242}\\nonumber\\\\ & \\times\\bigg\\ { e^{-i\\left[\\vec{q}\\cdot\\vec{r}_{1}'+\\vec{p}\\cdot\\vec{r}_{2}'\\right]}+e^{-i\\left[\\vec{p}\\cdot\\vec{r}_{1}'+\\vec{q}\\cdot\\vec{r}_{2}'\\right]}+e^{-i\\left[\\vec{k}\\cdot\\vec{r}_{1}'+\\vec{p}\\cdot\\vec{r}_{2}'\\right]}\\nonumber\\\\ & + e^{-i\\left[\\vec{p}\\cdot\\vec{r}_{1}'+\\vec{k}\\cdot\\vec{r}_{2}'\\right]}+e^{-i\\left[\\vec{k}\\cdot\\vec{r}_{1}'+\\vec{q}\\cdot\\vec{r}_{2}'\\right]}+e^{-i\\left[\\vec{q}\\cdot\\vec{r}_{1}'+\\vec{k}\\cdot\\vec{r}_{2}'\\right]}\\bigg\\}. \\label{eqn : sumdone}\\end{aligned}\\ ] ] notice each pair of exponentials in the curly brackets is obviously symmetric under switching @xmath243 . also notice from the first line that equation ( [ eqn : sumdone ] ) is symmetric under @xmath244 if we also flip @xmath245 and @xmath246 . applying this to all of the terms in curly brackets too",
    ", we find @xmath247 if we had originally labeled each exponential in the curly brackets as @xmath248 hence the equation has the desired symmetries .",
    "converting this into an integral we have @xmath249}\\left(\\vec{q}+\\vec{p}+\\vec{k}\\right)e^{-i\\left[\\vec{q}\\cdot\\vec{r}_{1}+\\vec{p}\\cdot\\vec{r}_{2}\\right]}\\bigg\\ { \\cdots\\bigg\\ } , \\label{eqn : fullcovar}\\end{aligned}\\ ] ] where above we have not rewritten the terms in curly brackets from equation ( [ eqn : sumdone ] ) .",
    "we now consider the covariance projected onto multipoles , defining @xmath250 noticing that in equation ( [ eqn : fullcovar ] ) the exponentials contain the only @xmath251 dependence , we first define the projection of one exponential onto one legendre polynomial as @xmath252}p_{l}(\\hat{r}_{1}\\cdot\\hat{r}_{2})d\\omega_{r1}d\\omega_{r2}\\nonumber\\\\ & = ( 2l+1)(-1)^{l}\\mathcal{j}_{l}(k_{1},k_{2})p_{l}(\\hat{k}_{1}\\cdot\\hat{k}_{2 } ) .",
    "\\label{eqn : iproj_def}\\end{aligned}\\ ] ] we will have this factor from projecting the exponential outside the curly brackets in equation ( [ eqn : fullcovar ] ) , and then six analogous factors within the curly brackets from projecting each exponential of @xmath253 onto @xmath254 .    we have defined @xmath255 and will also use @xmath256 . we performed the projection integral by expanding the exponential in spherical harmonics using awh13 equation ( 16.61 ) and expanding the legendre polynomial in spherical harmonics using the spherical harmonic addition theorem ( [ eqn : sph_addition_theorem ] ) ; the integral can then be evaluated by orthogonality .",
    "writing out the projection integrals explicitly using equation ( [ eqn : iproj_def ] ) , we thus have the projected covariance as @xmath257}(\\vec{p}+\\vec{q}+\\vec{k})\\nonumber\\\\ & \\times(2l+1)(2l'+1)(-1)^{l+l'}\\mathcal{j}_{l}(q , p)p_{l}(\\hat{q}\\cdot\\hat{p})\\nonumber\\\\ & \\times\\bigg\\{\\mathcal{j}'_{l'}(q , p)p_{l'}(\\hat{q}\\cdot\\hat{p})+\\mathcal{j}'_{l'}(p , q)p_{l'}(\\hat{p}\\cdot\\hat{q})+\\mathcal{j}'_{l'}(k , p)p_{l'}(\\hat{k}\\cdot\\hat{p})\\nonumber\\\\ & + \\mathcal{j}'_{l'}(p , k)p_{l'}(\\hat{p}\\cdot\\hat{k})+\\mathcal{j}'_{l'}(k , q)p_{l'}(\\hat{k}\\cdot\\hat{q})+\\mathcal{j}'_{l'}(q , k)p_{l'}(\\hat{q}\\cdot\\hat{k})\\bigg\\}. \\label{eqn : proj_covar_qp}\\end{aligned}\\ ] ] note that in equation ( [ eqn : proj_covar_qp ] ) the legendre polynomial dependence is the same for each of the first pair in the curly brackets , the second pair , and the third pair because the dot product is symmetric .",
    "thus we have three possible angular integrals to do , corresponding to these three pairs : @xmath258}(\\vec{k}+\\vec{p}+\\vec{q})\\nonumber\\\\ & i_{{\\rm ang},ll'}^{{\\rm asymm}}=\\int d\\omega_{p}d\\omega_{q}d\\omega_{k}p_{l}(\\hat{q}\\cdot\\hat{p})p_{l'}(\\hat{k}\\cdot\\hat{p})(2\\pi)^{3}\\delta_{d}^{[3]}(\\vec{k}+\\vec{p}+\\vec{q})\\nonumber\\\\ & i_{{\\rm ang},ll'}^{{\\rm asymm}}=\\int d\\omega_{p}d\\omega_{q}d\\omega_{k}p_{l}(\\hat{q}\\cdot\\hat{p})p_{l'}(\\hat{k}\\cdot\\hat{q})(2\\pi)^{3}\\delta_{d}^{[3]}(\\vec{k}+\\vec{p}+\\vec{q } ) .",
    "\\label{eqn : projxn_integrals}\\end{aligned}\\ ] ] note that the second and third integrals above are really the same under @xmath259 .",
    "we term the first integral above the symmetric integral and the second and third asymmetric .",
    "figure [ fig : covar_cycles_diagram ] explains these equations and their symmetries diagrammatically to illustrate the underlying structure of the covariance calculation up to this point .    ) , which in turn derive from the structure of equation ( [ eqn : sumdone ] ) ; one can directly compare the arguments of the exponentials in this latter with the diagram .",
    "the leftmost triangle represents the term @xmath260 outside the curly brackets in equation ( [ eqn : proj_covar_qp ] ) , showing also the radial arguments implicit in the @xmath261 , and the six triangles inside the curly brackets above represent the six terms in the curly brackets .",
    "the legendre polynomials are always evaluated about a particular vertex , as shown in the diagram , and the real - space variables match to fourier - space variables differently in each triangle ( see equation ( [ eqn : sumdone ] ) ) .",
    "one can see from above that each pair of triangles , or pair of terms in curly brackets in equation ( [ eqn : proj_covar_qp ] ) , has switch symmetry @xmath262 .",
    "these are rotation symmetries about the vertex between @xmath263 and @xmath264 in each pair .",
    "one can also see that if we switch @xmath265 and @xmath266 , the leftmost triangle is symmetric",
    ". the topmost pair will also be symmetric under this switch as well , which is why it gives rise to two symmetric projection integrals , but the middle and bottom pairs will not be , which is why they give rise to four asymmetric projection integrals ( see equation ( [ eqn : covar_ito_ints ] ) ) . ]    to evaluate these angular integrals , we write the dirac delta as the fourier transform of unity , @xmath267}(\\vec{k}+\\vec{p}+\\vec{q})=\\int d^3\\vec{r}\\;e^{i\\left[\\vec{k}\\cdot\\vec{r}+\\vec{p}\\cdot\\vec{r}+\\vec{q}\\cdot\\vec{r}\\right]}\\ ] ] expand each exponential in spherical harmonics using awh13 equation ( 16.61 ) , and perform the angular integral over @xmath268 .",
    "defining @xmath269 we obtain @xmath270}(\\vec{k}+\\vec{p}+\\vec{q})=\\nonumber\\\\ & \\left(4\\pi\\right)^{3}\\sum_{l_{1}l_{2}l_{3},m_{1}m_{2}m_{3}}\\mathcal{d}_{l_{1}l_{2}l_{3}}\\mathcal{c}_{l_{1}l_{2}l_{3}}\\mathcal{r}_{l_{1}l_{2}l_{3}}(k , p , q)\\nonumber\\\\ & \\times\\left(\\begin{array}{ccc } l_{1 } & l_{2 } & l_{3}\\\\ 0 & 0 & 0 \\end{array}\\right)\\left(\\begin{array}{ccc } l_{1 } & l_{2 } & l_{3}\\\\ m_{1 } & m_{2 } & m_{3 } \\end{array}\\right)\\nonumber\\\\ & \\times y_{l_{1}m_{1}}^{*}(\\hat{k})y_{l_{2}m_{2}}^{*}(\\hat{p})y_{l_{3}m_{3}}^{*}(\\hat{q } ) .",
    "\\label{eqn : delta_as_ylms}\\end{aligned}\\ ] ] this is equivalent to mehrem ( 2002 ) equation ( 5.1 ) if the 3j - symbols above are translated to clebsch - gordan symbols .",
    "inserting equation ( [ eqn : delta_as_ylms ] ) into equation ( [ eqn : projxn_integrals ] ) and then expanding the legendre polynomials in equation ( [ eqn : projxn_integrals ] ) into spherical harmonics using the spherical harmonic addition theorem ( [ eqn : sph_addition_theorem ] ) , we now simply have integrals over products of three spherical harmonics , which can be done analytically with 3j - symbols .",
    "the result can then be simplified by explicitly evaluating some of the 3j - symbols ( using nist digital library of mathematical functions ( dlmf ) 34.3.1 ) and summing over all of the spin angular momenta ( using nist dlmf 34.3.10 and 34.3.18 ) . for the symmetric",
    "integral we find @xmath271 where we have separated @xmath130 with a semicolon because it is the only argument that does not appear in the legendre polynomials in the integral .",
    "a simple case to check is setting @xmath107 and @xmath272 in equation ( [ eqn : projxn_integrals ] ) .",
    "then @xmath273 so by direct computation @xmath274}(p - q)}{q^2 } \\label{eqn : symm_direct}\\end{aligned}\\ ] ] where we used @xmath275 . in equation ( [ eqn : symm_int ] ) ,",
    "@xmath107 sets @xmath276 and the 3j - symbol s square is @xmath277 . using the orthogonality relation for spherical bessel functions , @xmath278}(p - q)/(2q^2)$ ] ; inserting this in equation ( [ eqn : symm_int ] ) and simplifying yields agreement with the direct computation .    for the asymmetric integral",
    "we find @xmath279 where now @xmath174 is separated by a semicolon because it appeared in two legendre polynomials in the integrand .",
    "note that for @xmath107 , the symmetric and asymmetric integrals of equation ( [ eqn : projxn_integrals ] ) are equal , so equation ( [ eqn : asymm_int ] ) should reduce to equation ( [ eqn : symm_int ] ) in this limit , as can be verified by noting @xmath107 implies @xmath280 .",
    "thus @xmath281    we now interchange the order of integration so that the integrals over @xmath282 and @xmath130 are done first , since they are separable , and the linking integral over @xmath46 implied by @xmath283 is done last .",
    "we also make the sum over @xmath284 explicit and do it after evaluating the @xmath282 and @xmath130 integrals .",
    "finally we define @xmath285 and @xmath286 in terms of these functions , @xmath287+(-1)^{(l+l'+l_{2})/2}\\nonumber\\\\ & \\times\\bigg[f_{ll}(r;r_{1})f_{l'l'}(r;r_{1}')f_{l_{2}ll'}(r;r_{2},r_{2}')\\nonumber\\\\ & + f_{ll}(r;r_{1})f_{l'l'}(r;r_{2}')f_{l_{2}ll'}(r;r_{2},r_{1}')\\nonumber\\\\ & + f_{ll}(r;r_{2})f_{l'l'}(r;r_{1}')f_{l_{2}ll'}(r;r_{1},r_{2}')\\nonumber\\\\ & + f_{ll}(r;r_{2})f_{l'l'}(r;r_{2}')f_{l_{2}ll'}(r;r_{1},r_{1}')\\bigg]\\bigg\\}. \\label{eqn : fullcovar_final}\\end{aligned}\\ ] ] one can see that this is symmetric under switching @xmath288 and @xmath289 , as expected .",
    "we have thus shown how to reduce the covariance of our multipole decomposition to a sum of 2-d integrals .",
    "this is a significant computational benefit : the @xmath290 and @xmath291 can be pre - computed once to give all the terms in the sum above , and then integrated over @xmath292 .",
    "further , since the problem is now 2-d one can simply evaluate the integrals using a grid and avoid appealing to more complicated higher - dimensional integration techniques .    in closing , we note that for @xmath293 ( i.e. @xmath294 ) , @xmath290 and @xmath295 can be computed analytically .",
    "we find @xmath296 using @xmath297 and gradshteyn & ryzhik ( 2007 ) equation ( 6.512.1 ) .",
    "@xmath298 is the hypergeometric function and we assume @xmath299 ; the result for @xmath300 is given by switching @xmath301 .",
    "@xmath295 can be computed using techniques outlined in fabrikant ( 2013 ) and is given by his equation ( 9 ) ; since the expression is rather long we do not reproduce it here .",
    "we mention this since one could imagine scenarios in which high speed was desirable for computing the covariance , such that these approximate forms might suffice . finally ,",
    "to incorporate shot noise in the covariance , one takes @xmath302 , @xmath5 the survey number density .",
    "this will introduce a cross term where one of the @xmath290 or @xmath295 in each pair in equation ( [ eqn : fullcovar_final ] ) no longer involves the power spectrum , and also a term in @xmath303 where both functions in each pair do not .",
    "the required integrals are also analytic : @xmath304}(r - r_1),\\end{aligned}\\ ] ] while @xmath295 is rather longer and given by mehrem ( 2002 ) equation ( 5.14 ) , assuming a much simpler form ( his equation ( 5.15 ) ) if @xmath305 , or @xmath306 .",
    "the above calculation used exact values for @xmath307 and @xmath308 , but we can easily integrate over bins in radius .",
    "we simply integrate the @xmath295 and @xmath290 functions defined above over bins , equivalent to replacing @xmath309 and @xmath310 with their bin - averaged values .",
    "we define @xmath311 and @xmath312 with @xmath313 where @xmath314 is a dummy variable and we recall that @xmath315 is the binning function ensuring @xmath314 is in the bin @xmath316 ( see section [ subsec : binning ] ) .",
    "we display the binned reduced covariance , @xmath317 for fixed @xmath318 and a number of @xmath319 and @xmath320 combinations in figure [ fig : covar_grid ] .",
    "one can see clear features when @xmath321 , especially when @xmath322 as well ( e.g. the 11 , 22 , 33 , and 44 panels ) .",
    "the computation was done in @xmath323 bins but we display with an interpolated color scheme because the underlying radial variables are continuous , in contrast to the multipoles @xmath16 and @xmath106 .",
    "we used the linear - theory matter power spectrum from camb ( lewis 2000 ) and checked convergence of the integrals by varying the endpoints and spacing of the grids in @xmath46 and @xmath130 we used .",
    "cosmology with @xmath324 , and @xmath325 . ] for the spherical bessel functions we used high - order taylor series for small values of the arguments , with the change - over point to the series depending on the order @xmath16 , and cross - checked with direct computation using _",
    "scipy s _ built - in functions . for the @xmath326 ( equation ( [ eqn : jlbar ] ) ) we used analytical results ,",
    "cross - checked with numerical integrations of the @xmath327 .    in figure",
    "[ fig : covar_diag_grid ] , we show the binned covariance when @xmath328 and @xmath329 versus all @xmath16 and @xmath106 , and for a number of choices of @xmath330 and @xmath308 , indicated in the upper left of each panel . notice that the strongest covariance is , as one might expect , when @xmath322 as well , along the diagonal .",
    "we display with no color interpolation because the multipoles are discrete .",
    "we show larger radial bins than the lasdamas mock results contain because these will be relevant for the baryon acoustic oscillation ( bao ) scale analysis planned for future work .",
    "we present the results of running our algorithm on the publicly available lasdamas mock catalogs for the sdss - ii dr7 in both real and redshift space .",
    "we used 15 radial bins with @xmath331 .",
    "we show first the results at each multipole versus the two triangle side lengths @xmath10 and @xmath11 in figure [ fig:3pcf_colorgrid ] .",
    "this shows that the largest amplitude contribution to the 3pcf , especially for triangles well away from the diagonal , is @xmath332 .",
    "this is what we expect from se15 , figure 9 , third row , leftmost panel , showing the perturbation theory results and focusing on the linear bias @xmath333 , which dominates the non - linear bias @xmath334 . in @xmath335",
    ", there is a hint of a large - scale decrement , to be compared with the slight feature close to the diagonal around @xmath336 in se15 figure 9 , second row , leftmost panel .    as in se15 ,",
    "@xmath332 and @xmath337 look similar but with @xmath332 having higher amplitude away from the diagonal . for @xmath338 ,",
    "the panels all begin to look the same , agreeing with our expectation from se15 figure 9 .",
    "this is because these higher multipoles , in particular near the diagonal , are dominated by a small population of squeezed triangles where two sides are equal ( e.g. @xmath10 and @xmath11 ) and the third side nears zero . in the hierarchical ansatz for the 3pcf",
    ", one has @xmath339 , so we expect the amplitude to become very large as any side approaches zero .",
    "also discussed in se15 is another reason for the similarity of the @xmath338 panels : before cyclic summing over vertices of the triangle , the leading order pre - cyclic perturbation theory 3pcf only has structure for @xmath340 . in particular , at leading ( fourth ) order , the 3pcf receives one contribution from the second - order density field , @xmath341 , which is in turn calculated by integrating a kernel @xmath342 against the linear density field ( goroff et al .",
    "1986 ; jain & bertschinger 1994 ; bernardeau et al .",
    "this kernel has only @xmath343 , and @xmath153 terms . if one chooses the second - order density point to be at the origin , the 3pcf therefore has multipole structure only to @xmath332 . in reality",
    "we do not know which point contributes @xmath341 , so we must cyclically sum around the triangle and can not choose @xmath341 at the origin .",
    "this cyclic summing generates additional angular structure , but it just stems from the geometric effect of writing a simple @xmath344 and @xmath153-only multipole expansion with argument e.g. @xmath345 in terms of @xmath346 .",
    "we note that the @xmath343 , and @xmath153 terms that enter pre - cyclically have a physical meaning .",
    "@xmath342 is formed by summing two mode - coupling kernels @xmath347 and @xmath348 ( bernardeau et al .",
    "2002 equations ( 39 ) and ( 156 ) ) .",
    "these in turn come from solving respectively the full continuity equation and the euler equation ( compare bernardeau et al .",
    "2002 equations ( 16 ) and ( 17 ) with their equations ( 37 ) and ( 38 ) ) .",
    "@xmath347 produces all of the @xmath349 and @xmath350 of the @xmath335 terms in @xmath342 .",
    "the @xmath349 contribution is from the product of the velocity divergence and the density , while the @xmath335 contribution is from gradients of the density field parallel to the velocity .",
    "meanwhile , @xmath348 generates the remaining @xmath351 of the @xmath335 term and all of the @xmath332 term in @xmath342 ; these stem from gradients of the velocity divergence parallel to the velocity .",
    "figures [ fig : recon ] and [ fig : ratios ] show that the full 3pcf of the data can be reconstructed well from only a few multipoles .",
    "figure [ fig : recon ] reconstructs the 3pcf from coefficients",
    "@xmath15 , up to and including the @xmath16 indicated in the legend , for a particular triangle configuration with @xmath352 , @xmath353 .",
    "one recovers an accurate shape versus @xmath354 even using only multipoles up to @xmath355 , and that adding in @xmath356 and finally @xmath357 changes the shape very little . in figure",
    "[ fig : ratios ] , we illustrate the same idea for three different triangle configurations : the higher multipoles fall off relative to @xmath358 , meaning they contribute less to reconstructing the full 3pcf .",
    "this plot likely is conservative in that it makes the effect of the higher multipoles appear larger than it is ; the plot shows the ratio of each higher multipole to @xmath358 , but the change in the 3pcf produced by adding in a higher multipole is actually roughly the ratio of the multipole to the sum of _ all _ the lower multipoles . since , in detail , legendre polynomial weights also enter , one might consider an angle - averaged version of this ratio . however since figure [ fig : recon ] effectively already shows the unimportance of the highest multipoles , we have in figure [ fig : ratios ] just chosen to show @xmath359 because it offers more granular information .",
    "indicated in the legend , as described in section [ sec : mock_results ] .",
    "the reconstruction converges even for modest @xmath16 .",
    "the @xmath360 points lie essentially directly under those for @xmath181 . ]",
    "coefficients to @xmath358 for several triangle configurations ( again using the lasdamas real space mocks ) .",
    "the decline of the higher multipoles with @xmath16 indicates that not many multipoles are needed for accurately reconstructing the full 3pcf .",
    "this is especially true for the largest scale triangle we show , which is also the least likely to be altered by non - linear effects .",
    "the relative magnitudes of the higher multipoles here may seem large when recalling from figure [ fig : recon ] that the reconstruction appears well converged by @xmath355 ; but note that a given multipole s contribution to the reconstruction is roughly its ratio to the sum of all the lower multipoles , not just to @xmath358 ; this reduces the importance of the higher multipoles .",
    "finally , the strength of @xmath332 shows the quadratic or u - shaped behavior of the 3pcf traditionally associated with gravitational growth of structure ( see also figure [ fig : recon ] ) .",
    "gravity generates gradients of the density and velocity divergence mostly parallel to the velocity , in turn enhancing roughly collinear structures with @xmath96 near @xmath361 or @xmath362 ( bernardeau et al . 2002 ) . ]",
    "se15 presented a compression scheme for the multipole moments of the 3pcf .",
    "this was designed to avoid the squeezed limit where two galaxies are so nearby that perturbation theory is invalid and also to reduce the dimension of the covariance matrix required for parameter fitting .",
    "this approach integrated each multipole moment over @xmath11 from @xmath363 at each value of @xmath10 .    in the current work",
    "the data is binned coarsely enough in both @xmath10 and @xmath11 that this approach must be adapted slightly .",
    "we simply choose to , for a given bin @xmath10 , sum over all bins with @xmath364 .",
    "@xmath365 is the set of all bins in @xmath11 where @xmath11 is greater than @xmath366 and less than @xmath367 .",
    "one might wish to select a different multiple of @xmath368 in defining @xmath369 .",
    "] this assures that the minimum value of @xmath11 is @xmath370 and that the minimum difference between @xmath10 and @xmath11 is also @xmath370 , meaning by the triangle inequality that @xmath371 .",
    "this avoids the squeezed limit while reducing the dimension of the problem .",
    "mathematically , the compression is defined here as    @xmath372    where bar denotes `` binned '' , superscript `` c '' denotes `` compression '' , and @xmath373 is the @xmath374 binned 3pcf multipole ( see section [ subsec : binning ] ) .",
    "@xmath375 is the volume of bin @xmath11 .",
    "the denominator is for normalization .    in figures [ fig : low_ell_comps ] and [ fig : hi_ell_comps ] we show the results of this compression .",
    "we also compressed the leading ( fourth ) order perturbation theory predictions , calculated as outlined in se15 , and show them for comparison .",
    "the theory requires linear ( @xmath333 ) and non - linear ( @xmath334 ) bias parameters as an input ; we use a least - squares fit with points weighted by the inverse compressed variance . this latter",
    "is computed from the scatter between mocks and ignores noise in the random catalog used for edge correction , which due to the large number of randoms is negligible .",
    "our mocks constitute a volume of order 7 times that used for the theoretical covariance calculation here , so , as explained in figure [ fig : covar_diag_grid ] , we might expect error bars on the compressions of order @xmath376 .",
    "this is indeed what we find .",
    "we offer the caveat that a full , rigorously correct fit of theory to observation would require inversion of the full covariance matrix .",
    "we leave this for future work ; here our goal is simply to indicate that the results of our algorithm roughly agree with perturbation theory predictions .    using the simple procedure above , the results are well - fit with @xmath377 and @xmath378 ; note that to compute the theory predictions we matched the lasdamas cosmology .",
    "there is quoted at @xmath379 ; @xmath380 .",
    "the lasdamas mocks are at @xmath381 , so when normalizing the power spectrum we should use @xmath382 $ ] , with @xmath90 the linear growth factor ( e.g. mo van den bosch & white ( 2010 ) equations ( 4.75 ) , ( 4.76 ) , and ( 3.77 ) ; carroll et al .",
    "( 1992 ) ) .",
    "] there is some deviation noticeable at large scales in @xmath349 ( about @xmath383 ) and @xmath335 ( about @xmath384 ) , with nearly all the other multipoles deviating only within the error bars or at most in a few cases just slightly outside them .",
    "the larger deviations in @xmath349 and @xmath335 are likely because non - linear corrections to the perturbation theory results can not be neglected .",
    "in particular , in @xmath349 we expect non - linear evolution might smooth structure on smaller scales , making the slope of the perturbation theory compression shallower and allowing a better global fit to the @xmath349 mock results .",
    "importantly , the error bars become much larger for @xmath385 as compared to those for @xmath386 .",
    "this suggests when doing a full parameter fit using the covariance matrix , one might not gain much by including these higher multipoles .",
    "one might choose simply to drop these modes to reduce the dimension of the covariance matrix to be inverted .",
    "figures [ fig : low_ell_comps ] and [ fig : hi_ell_comps ] also show that the redshift space results at each multipole appear to be roughly a constant rescaling of the real space results , with a constant that only weakly depends on the multipole . to illustrate this we show the ratio of redshift space to real space results in each radial bin at each multipole ( figure [ fig : redshift_space_rescale ] , left panel ) and the radially - averaged ratio versus multipole ( figure [ fig : redshift_space_rescale ] , right panel ) .",
    "more detailed discussion is in the caption to this figure ; the key point is that for @xmath387 , there is little radial dependence to the rescaling factor and also little multipole dependence .",
    "both dependences are more pronounced for @xmath388 ; we suspect this is because these higher multipoles are dominated , even in the compression , by a small subset of relatively squeezed triangles that are more strongly affected by rsd .",
    "this issue might merit further attention in subsequent work .            ) .",
    "the right panel shows the radial average at each multipole . while there is some radial scale dependence in the left panel , it is modest for all but @xmath388 . thus averaging over the radial dependence does not lose much information for the lower multipoles .",
    "the averages ( right panel ) are similar for all but @xmath388 , and even these differ by less than a factor of 2 from the averages of the lower multipoles . ]      given that we now have compressed data , we must also apply our compression scheme as in the previous section to the binned covariance of section [ subsec : binning ] .",
    "we denote the compressed , binned covariance as @xmath389 , noting that the two superscript `` c ' 's denote that we compress over @xmath11 and @xmath308 , leaving the quantity a function only of @xmath10 and @xmath330 .",
    "it would be computationally intensive to compute the binned covariance using equation ( [ eqn : fullcovar_final ] ) with the @xmath290 and @xmath295 replaced by equations ( [ eqn : flbar_2])-([eqn : jlbar ] ) and then compress , and a faster approach is available .",
    "this is to compress @xmath390 and @xmath391 as necessary first and from them obtain the compressed binned covariance .",
    "@xmath390 need only be compressed at most once ( if its argument is @xmath11 or @xmath308 ) , but @xmath391 may be compressed once or twice depending on if one or both of its arguments have subscript @xmath153 .",
    "we thus define three functions , where `` cc '' again denotes a double compression :    @xmath392    note that in the second line above , the @xmath391 being compressed is a function @xmath10 and @xmath393 , and hence need only be compressed once ",
    "it is not compressed over @xmath10 .",
    "however in the third line above , the @xmath391 being compressed depends on @xmath11 and @xmath308 and so must be compressed twice .",
    "making these replacements as appropriate in equation ( [ eqn : fullcovar_final ] ) yields the compressed , binned covariance .",
    "this shows that the framework of compression can be easily generalized to the covariance .",
    "we have presented a novel algorithm to compute the multipole moments of the 3pcf .",
    "it is especially apt for large cosmological datasets such as sdss and upcoming surveys like euclid , large synoptic survey telescope ( lsst ) , and dark energy spectroscopic instrument ( desi ) , which will have tens of millions to billions of objects ( jain et al . 2015 ) . for these datasets ,",
    "an approach that scales with @xmath394 would be wholly infeasible .",
    "we have shown that our algorithm scales as @xmath395 , handles edge correction easily , and permits computation of the 3pcf of a large dataset quickly even with modest computing resources .",
    "we have also computed the covariance matrix of this decomposition in the gaussian random field limit .",
    "finally , we have developed the compression scheme first presented in se15 and shown its application both to the data and to the covariance matrix .",
    "this compression scheme offers a compelling way to visualize the results of the algorithm that loses little information , in contrast to the plots of the 3pcf or reduced 3pcf versus opening angle @xmath96 for particular triangle configurations that previous literature supplies .",
    "the algorithm presented here is unique in that it fundamentally reduces the scaling of the 3pcf measurement to that of the two - point function , while remaining exact in angle .",
    "this did not have to be the case .",
    "formally , for a complete representation of the 3pcf , one needs an infinite number of multipoles @xmath16 .",
    "however , because the physics generating the 3pcf does not have a great deal of angular structure , in practice a finite , modest number of multipoles suffices .",
    "furthermore , we have shown that in our lasdamas test case , the 3pcf is already well - reconstructed by @xmath355 ( figure [ fig : recon ] ) . since our algorithm fundamentally requires pair - counting , using a fast fourier transform ( fft ) for this step may in some cases offer an additional acceleration ; we present this in slepian & eisenstein 2015c .",
    "finally , one might worry that jagged survey boundaries could easily introduce high multipoles into the measured 3pcf .",
    "but we have shown that the coefficients required for the edge correction , at least for our lasdamas test case , fall off quickly enough that one need only measure a few multipoles of the randoms for an accurate solution ( figures [ fig : f_one ] and [ fig : mkl ] ) .",
    "the 3pcf contains important information on the non - gaussianity of large - scale structure ( lss ) due to growth under gravity and also perhaps that remaining from primordial non - gaussianity . with measurements of only the 2-point function , the amplitude of clustering ( e.g. @xmath1 ) and the linear bias are degenerate",
    "however , the 3pcf is sensitive to a different power of the linear bias than the 2-point function ( cube versus square ) , and so measuring it exposes a raw factor of the bias and helps break this degeneracy . as for primordial non - gaussianity , while the cmb has been the dominant constraint up to now ( see ade et al .",
    "( 2015 ) ) , it is expected that even maximally improved cmb measurements can only enhance the cmb constraint by a factor of a few .",
    "thus lss will become a vital complementary probe .",
    "generically , inflation must couple to ordinary matter so as to produce it during reheating , and this coupling produces some level of non - gaussianity ( desjacques & seljak 2010 , for a recent review ) . thus the 3pcf can be used to probe the dynamics of inflation in principle  and perhaps , soon , in practice .",
    "the 3pcf also contains information on redshift space distortions .",
    "it should be emphasized that in the current work , the multipole moments are averaged over rotations of the triangle configurations , and so we lose any information about anisotropy .",
    "however , our algorithm can easily be adapted to retain the full , unaveraged information ( @xmath65s ) around each possible origin .",
    "this would allow tracing the anisotropy rsd induce .",
    "preliminary calculations indicate that rsd introduce couplings between multipoles @xmath396 which are absent without rsd .",
    "these couplings have selection rules due to the underlying symmetries under rotation about the line of sight and parity flips .",
    "there will also be @xmath60 dependence induced by the preferred direction defined by the line - of - sight .",
    "we therefore expect that the off - diagonal terms in a tensor of spherical harmonic coefficients will have structure that can be used to probe rsd - induced anisotropies .",
    "it is already important that the spherical harmonics , with the introduction of @xmath397 and @xmath60 , offer a natural 5-d basis for redshift - space measurements .",
    "work on these questions from both analytic and numerical perspectives is underway .",
    "we plan to apply our algorithm and analysis approach to sdss dr12 , with the goals of assessing the presence of bao features , measuring the linear and non - linear bias , and constraining the baryon - dark matter relative velocity ( tseliakhovich & hirata 2010 ; yoo , dalal & seljak 2011 ; yoo & seljak 2013 ; se15 ) .",
    "previous literature has found a bao feature in the reduced 3pcf @xmath398 , with @xmath399 the 2pcf ( gaztaaga et al . 2009 ) . that work used only one triangle configuration , @xmath400 and @xmath401 . with the additional",
    "signal - to - noise the large number of galaxies in sdss dr12 offers , as well as our algorithm s ability to consider all triangle configurations quickly , this problem is ripe for revisiting . furthermore , se15 suggests that the multipole decomposition clearly isolates a strong bao feature , especially in the @xmath335 multipole .",
    "this is also a particularly informative multipole for the relative velocity , further discussed in se15 .",
    "that work additionally shows that , in principle , the multipole decomposition can clearly separate the effects of linear and non - linear bias  significant because , as noted above , the 3pcf has traditionally been an important tool for constraining these parameters . finally , the significant speed advantage of our algorithm will permit much finer and much faster calibration of any 3pcf measurements against large cosmological simulations .",
    "such improved calibration should greatly enhance the leverage of the 3pcf as a fundamental probe of large - scale structure .",
    "zs thanks simeon bird , doug finkbeiner , lehman garrison , jr gott iii , robert marsland , philip mocz , cameron mcbride , stephen portillo , david spergel , and yucong zhu for useful discussions .",
    "we thank the anonymous referee for several helpful suggestions as well .",
    "this material is based upon work supported by the national science foundation graduate research fellowship under grant no . dge-1144152 .",
    "= 1.5em = 1 adams j. c. , 1878 , proc .",
    "r. soc . , 27 , 63 = 1.5em = 1 ade p.a.r .",
    "et al . , 2015 ,",
    "preprint ( arxiv:1502.01592 )              = 1.5em = 1 frieman j.a . & gaztaaga e. , 1999 , apj , 521 , l83 - 86 .",
    "= 1.5em = 1 gardner j. p. , connolly a. & mcbride c. , 2007 , in asp conf ser . 376 , astronomical data analysis software and systems xvi , ed",
    ". r. a. shaw , f. hill , & d. j. bell ( san francisco , ca : asp ) , 69    = 1.5em = 1 gaztaaga e. & frieman j.a .",
    ", 1994 , apj , 437 , l13 .",
    "= 1.5em = 1 gaztaaga e. , cabr a. , castander f. , crocce m. & fosalba p. , 2009 , mnras 399 , 2 , 801 - 811 = 1.5em = 1 gradshteyn i.s . &",
    "ryzhik i.m . , 2007 , table of integrals , series , and products , ed .",
    "a. jeffrey & d. zwillinger ( amsterdam : academic press )                        = 1.5em = 1 mehrem r. , 2011 , journal of applied mathematics and computation 217 5360 - 5365 = 1.5em = 1 moore a. w. et al .",
    ", 2001 , in mining the sky , ed . a. j. banday , s. zaroubi , & m. bartelmann ( berlin : springer ) , 71      = 1.5em = 1 nist digital library of mathematical functions ( dlmf ) .",
    "+ http://dlmf.nist.gov/ , release 1.0.10 of 2015 - 08 - 07 .",
    "+ online companion to w. j. olver , d. w. lozier , r. f. boisvert , and c. w. clark , eds .",
    "nist handbook of mathematical functions .",
    "cambridge university press , new york , ny , 2010 .",
    "= 1.5em = 1 nichol r. c. et al .",
    ", 2006 , mnras , 368 , 1507 = 1.5em = 1 padmanabhan , n. , white , m. , & eisenstein , d.j . , 2007 , mnras , 376 , 1702                  = 1.5em = 1 szapudi i. , 2001 , proc .",
    "of `` the onset of nonlinearity in cosmology '' , ed .",
    "fry , j.r .",
    "buchler & h. kandrug , in annals of the new york academy of sciences , vol . 927 .",
    "= 1.5em = 1 szapudi i. , 2004 , apj , 605 , l89    = 1.5em = 1 szapudi i. , 2005 , chapter in `` data analysis in cosmology '' , ed . v.j .",
    "martinez , e. martinez - gonzalez , m.j .",
    "pons - borderia & e. saar , springer - verlag lecture notes in physics .",
    "= 1.5em = 1 tseliakhovich d. & hirata c.m . , 2010 ,",
    "prd 82 , 083520"
  ],
  "abstract_text": [
    "<S> we present an algorithm that computes the multipole coefficients of the galaxy three - point correlation function ( 3pcf ) without explicitly considering triplets of galaxies . rather , centering on each galaxy in the survey , it expands the radially - binned density field in spherical harmonics and combines these to form the multipoles without ever requiring the relative angle between a pair about the central . </S>",
    "<S> this approach scales with number and number density in the same way as the two - point correlation function , allowing runtimes that are comparable , and 500 times faster than a naive triplet count . </S>",
    "<S> it is exact in angle and easily handles edge correction . </S>",
    "<S> we demonstrate the algorithm on the lasdamas sdss - dr7 mock catalogs , computing an edge corrected 3pcf out to @xmath0 in under an hour on modest computing resources . </S>",
    "<S> we expect this algorithm will render it possible to obtain the large - scale 3pcf for upcoming surveys such as euclid , lsst , and desi .    </S>",
    "<S> cosmology : large - scale structure of universe , methods : data analysis , statistical </S>"
  ]
}