{
  "article_text": [
    "we consider a graph where every edge can be sampled .",
    "when sampling an edge , the decision maker obtains a signal that is related to the value of the nodes defining the edge .",
    "the objective of the decision maker is to locate the node with the highest value .",
    "since there is no possibility to sample the value of the nodes directly , the decision maker has to infer which is the best node by considering the differences between the nodes .    as a motivation ,",
    "consider the setup where a user interacts with a webpage . in the webpage ,",
    "several links or ads can be presented , and the response of the user is to click one or none of them .",
    "essentially , in this setup we query the user to compare between the different alternatives .",
    "the response of the user is comparative : a preference of one alternative to the other will be reflected in a higher probability of choosing the alternative .",
    "it is much less likely to obtain direct feedback from a user , asking her to provide an evaluation of the worth of the selected alternative .",
    "in such a setup , not all pairs of alternatives can be directly compared or , even if so , there might be constraints on the number of times a pair of ads can be presented to a user .",
    "for example , in the context of ads it is reasonable to require that ads for similar items will not appear in the same page ( e.g. , two competing brands of luxury cars will not appear on the same page ) . in these contexts ,",
    "a click on a particular link can not be seen as an absolute relevance judgement  ( e.g. , @xcite ) , but rather as a relative preference . moreover , feedback can be noisy and/or inconsistent , hence aggregating the choices into a coherent picture may be a non - trivial task .",
    "finally , in such contexts pairwise comparisons occur more frequently than multiple comparisons , and are also more natural from a cognitive point of view  ( e.g.,@xcite ) .",
    "we model this learning scenario as bandits on graphs where the information that is obtained is differential .",
    "we assume that there is an inherent and unknown value per node , and that the graph describes the allowed ( pairwise ) comparisons .",
    "that is , nodes @xmath1 and @xmath2 are connected by an edge if they can be compared by a single query . in this case",
    ", the query returns a random variable whose distribution depends , in general , on the values of @xmath1 and @xmath2 . for the sake of simplicity ,",
    "we assume that the observation of the edge between nodes @xmath1 and @xmath2 is a random variable that depends only on the _ difference _ between the values of @xmath1 and @xmath2 . since this assumption is restrictive in terms of applicability of the algorithms",
    ", we also consider the more general setup where contextual information is observed before sampling the edges .",
    "this is intended to model a more practical setting where , say , a web system has preliminary access to a set of user profile features .    in this paper ,",
    "our goal is to identify the node with the highest value , a problem that has been studied extensively in the machine learning literature ( e.g. , @xcite ) .",
    "more formally , our objective is to find an approximately optimal node ( i.e. , a node whose value is at most @xmath3 smaller than the highest value ) with a given failure probability @xmath4 as quickly as possible . when contextual information is added , the goal becomes to progressively fasten the time needed for identifying a good node for the given user at hand , as more and more users interact with the system .",
    "* related work .",
    "* there are two common objectives in stochastic bandit problems : minimizing the regret and identifying the `` best '' arm . while both objectives are of interest , regret minimization seems particularly difficult in our setup .",
    "in fact , a recent line of research related to our paper is the _ dueling bandits problem _ of yue et al .",
    "@xcite ( see also @xcite ) . in the dualing bandit",
    "setting , the learner has at its disposal a _",
    "complete _ graph of comparisons between pairs of nodes , and each edge @xmath5 hosts an unknwon preference probability @xmath6 to be interpreted as the probability that node @xmath1 will be preferred over node @xmath2 .",
    "further consistency assumptions ( stochastic transitivity and stochastic triangle inequality ) are added .",
    "the complete graph assumption allows the authors to define a well - founded notion of regret , and analyze a regret minimization algorithm which is further enhanced in @xcite where the consistency assumptions are relaxed .",
    "although at first look our paper seems to deal with the same setup , we highlight here the main differences .",
    "first , the setups are different with respect to the topology handled . in @xcite",
    "the topology is always a complete graph which results in the possibility to directly compare between every two nodes . in our work ( as in real life )",
    "the topology is _ not _ a complete graph , resulting in a framework where a comparison of two nodes requires sampling all the edges between the nodes . in the extreme case of a straight line",
    "we need to sample all the given edges in the graph in order to compare the two nodes that are farthest apart .",
    "second , the objective of minimizing the regret is natural for a complete graph where it amounts to comparing a choice of the best bandit repeatedly with the actual pairs chosen . in a topology other than the complete graph",
    "this notion is less clear since one has to restrict choices to edges that are available .",
    "finally , the algorithms in @xcite are geared towards the elimination of arms that are not optimal with high probability . in our setup",
    "one _ can not _",
    "eliminate such nodes and edges because it is crucial in comparing candidates for optimal nodes .",
    "therefore , the resulting algorithms and analyses are quite different .",
    "on the other hand , constraining to a given set of allowed comparisons leads us to make less general statistical assumptions than @xcite , in that our algorithms are based on the ability to reconstruct the reward difference on adjacent nodes by observing their connecting edge .    from a different perspective , the setup we consider is reminiscent of online learning with partial monitoring @xcite . in the partial monitoring setup ,",
    "one usually does not observe the reward directly , but rather a signal that is related ( probabilistically ) to the unobserved reward .",
    "however , as far we know , the alternatives ( called arms usually ) in the partial monitoring setup are separate and there is no additional structure : when sampling an arm a reward that is related to this arm alone is obtained but not observed .",
    "our work differs in imposing an additional structure , where the signal is derived from the structure of the problem where the signal is always relative to adjacent nodes .",
    "this means that comparing two nodes that are not adjacent requires sampling all the edges on a path between the two nodes .",
    "so that deciding which of two remote nodes has higher value requires a high degree of certainty regarding all the comparisons on the path between them .",
    "another research area which is somewhat related to this paper is learning to rank via comparisons ( a very partial list of references includes  @xcite ) . roughly speaking , in this problem we have a collection of training instances to be associated with a finite set of possible alternatives or classes ( the graph nodes in our setting ) .",
    "every training example is assigned a set of ( possibly noisy or inconsistent ) pairwise ( or groupwise ) preferences between the classes .",
    "the goal is to learn a function that maps a new training example to a total order ( or ranking ) of the classes .",
    "we emphasize that the goal in this paper is different in that we work in the bandit setup with a given structure for the comparisons and , in addition , we are just aiming at identifying the ( approximately ) best class , rather than ranking them all .",
    "* content of the paper . * the rest of the paper is organized as follows .",
    "we start from the formal model in section [ sec : model ] .",
    "we analyze the basic linear setup , where each node is comparable to at most two nodes in section  [ sec : linear - topology ] .",
    "we then move to the tree setup and analyze it in section [ s : tree ] .",
    "the general setup of a network is treated in section [ s : net ] .",
    "some experiments are then presented in section [ s : sims ] to elucidate the theoretical findings in previous sections . in section [",
    "s : extensions ] we discuss the more general setting with contextual information .",
    "we close with some directions for future research .",
    "in this section we describe the classical multi - armed bandit ( mab ) setup , describe the graphical bandit ( gb ) setup , state / recall two concentration bounds for sequences of random variables , and review a few terms from graph theory .      the mab model @xcite is comprised of a set of _ arms _ @xmath7 . when sampling arm @xmath8 , a _ reward _ which is a random variable @xmath9 , is provided .",
    "let @xmath10 $ ] .",
    "the goal in the mab setup is to find the arm with the highest expected reward , denoted by @xmath11 , where we term this arm s reward the _ optimal reward_. an arm whose expected reward is strictly less than @xmath11 is called a _ non - best arm_. an arm @xmath1 is called an @xmath3-optimal arm if its expected reward is at most @xmath3 from the optimal reward , i.e. , @xmath12\\ge r^{*}-\\epsilon$ ] . in some cases ,",
    "the goal in the mab setup is to find an @xmath3-optimal arm",
    ".    a typical algorithm for the mab problem does the following . at each time step @xmath13",
    "it samples an arm @xmath14 and receives a reward @xmath15 .",
    "when making its selection , the algorithm may depend on the history ( i.e. , the actions and rewards ) up to time @xmath16 .",
    "eventually the algorithm must commit to a single arm and select it .",
    "next we define the desired properties of such an algorithm .",
    "( pac - mab ) an algorithm is an @xmath17-probably approximately correct ( or @xmath17-pac ) algorithm for the mab problem with sample complexity @xmath18 , if it terminates and outputs an @xmath3-optimal arm with probability at least @xmath0 , and the number of times it samples arms before termination is bounded by @xmath18 .    in the case of standard mab problems",
    "there is no structure defined over the arms . in the next section we describe the setup of our work where such a structure exists .",
    "suppose that we have an undirected and connected graph @xmath19 with nodes @xmath20 and edges @xmath21 .",
    "the nodes are associated with reward values @xmath22 , respectively , that are unknown to us .",
    "we denote the node with highest value by @xmath23 and , as before , @xmath24 .",
    "define @xmath25 to be the difference between the node with the highest value and the node with the second highest value .",
    "we call @xmath26 the reward _ gap _ , and interpret it as a measure for how easy is to discriminate between the two best nodes in the network . as expected , the gap @xmath26 has a significant influence on the sample complexity bounds ( provided the accuracy parameter @xmath3 is not large ) .",
    "we say that nodes @xmath1 and @xmath2 are _ neighbors _ if there is an edge in @xmath21 connecting them ( and denote the edge random variable by @xmath27 ) .",
    "this edge value is a random variable whose distribution is determined by the nodes it is connecting , i.e. , @xmath5 s statistics are determined by @xmath28 and @xmath29 . in this work , we assume that as a directed edge from @xmath1 to @xmath2 .",
    "it is understood that @xmath30 . ]",
    "@xmath31= r_{j}-r_{i}$ ] . also , for the sake of concreteness , we assume the edge values are bounded in @xmath32 $ ] .    in this model",
    ", we can only sample the graph edges @xmath27 that provide independent realizations of the node differences .",
    "for instance , we may interpret @xmath33 if the feedback we receive says that item @xmath2 is preferred over item @xmath1 , @xmath34 if @xmath1 is preferred over @xmath2 , and @xmath35 if no feedback is received . then the reward difference @xmath36 becomes equal to the difference between the probability of preferring @xmath2 over @xmath1 and the probability of preferring @xmath1 over @xmath2 .",
    "let us denote the realizations of @xmath27 by @xmath37 where the subscript @xmath13 denotes time .",
    "our goal is to find an @xmath3-optimal node , i.e. , a node @xmath1 whose reward satisfies @xmath38 .    whereas neighboring nodes can be directly compared by sampling its connecting edge ,",
    "if the nodes are far apart , a comparison between the two can only be done indirectly , by following a path connecting them .",
    "we denote a _ path _ between node @xmath1 and node @xmath2 by @xmath39 . observe that there can be several paths in @xmath40 connecting @xmath1 to @xmath2 . for a given path @xmath41 from @xmath1 to @xmath2 , we define the _ composed edge _ value @xmath42 by @xmath43 , with @xmath44 . by telescoping ,",
    "the average value of a composed edge @xmath27 only depends on its endpoints , i.e. , @xmath45=\\sum_{(k , l)\\in\\pi_{ij}}\\mathbb{e}\\left[e^{kl}\\right ] = \\sum_{(k , l)\\in\\pi_{ij}}\\left(r_{l}-r_{k}\\right ) = r_{j}-r_{i},\\ ] ] independent of @xmath41 .",
    "similarly , define @xmath37 to be the time-@xmath13 realization of the composed edge random variable @xmath42 when we pull once all the edges along the path @xmath41 joining @xmath1 to @xmath2 .",
    "a schematic illustration of the the gb setup is presented in figure 1 .",
    "the algorithms we present in the next sections hinge on constructing reliable estimates of edge reward differences , and then combining them into a suitable node selection procedure .",
    "this procedure heavily depends on the graph topology . in a",
    "tree - like ( i.e. , acyclic ) structure no inconsistencies can arise due to the noise in the edge estimators .",
    "hence the node selection procedure just aims at identifying the node with the largest reward gap to a given reference node . on the other hand ,",
    "if the graph has cycles , we have to rely on a more robust node elimination procedure , akin to the one investigated in @xcite ( see also the more recent @xcite ) .",
    "in this work we use hoeffding s maximal inequality ( e.g. , @xcite ) .    [",
    "l : hoeff ] [ lem : hoeffding_maximal]let @xmath46 be independent random variables with zero mean satisfying @xmath47 w.p .",
    "1 . let @xmath48 .",
    "then , @xmath49",
    "as a warm - up , we start by considering the gb setup in the case of a linear graph , i.e. , @xmath50 . we call it the _ linear setup_. the algorithm for finding the highest node in the linear setup is presented in algorithm [ alg : algorithm - linear ] .",
    "the algorithm samples all the edges , computes for each edge its empirical mean , and based on these statistics finds the highest edge .",
    "algorithm [ alg : algorithm - linear ] will also serve as a subroutine for the tree - topology discussed in section [ s : tree ] .",
    "the following proposition gives the sample complexity of algorithm [ alg : algorithm - linear ] in the case when the edges are bounded .",
    "[ prop : linear_pac_bounded ] if @xmath51 holds , then algorithm [ alg : algorithm - linear ] operating on a linear graph with reward gap @xmath26 is an @xmath17-pac algorithm when the @xmath52 satisfy @xmath53 if @xmath54 then the sample complexity of each edge is @xmath55hence the sample complexity of the algorithm is @xmath56    let @xmath57 each @xmath58 has zero mean with @xmath59 . hence @xmath60 is a sequence of @xmath61 zero - mean and independent random variables .",
    "set for brevity @xmath62 , and suppose , without lost of generality , that some node @xmath2 has the highest value .",
    "the probability that algorithm [ alg : algorithm - linear ] fails , i.e. , returns a node whose value is @xmath3 below the optimal value is bounded by @xmath63 we can write @xmath64 where in the last inequality we used lemma [ lem : hoeffding_maximal ] . requiring this probability to be bounded by @xmath4 yields the claimed inequality .",
    "the sample sizes @xmath52 in proposition [ prop : linear_pac_bounded ] encode constraints on the number of times the edges @xmath65 can be sampled .",
    "notice that the statement therein implies @xmath66 for all @xmath1 , i.e. , we can not afford in a line graph to undersample any edge .",
    "this is because every edge in a line graph is a _",
    ", hence a poor estimation of any such edge would affect the differential reward estimation throughout the graph . in this respect",
    ", this proposition only allows for a partial tradeoff among these numbers .    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *    as in the proof of proposition [ prop : linear_pac_bounded ] , suppose that @xmath67 for @xmath68 .",
    "the random variable @xmath69 is a gaussian random variable with mean @xmath70 and variance @xmath71 .",
    "now @xmath72 where in the third inequality we use [ lem : bernstein_like ] .",
    "going on similar lines as in proposition [ prop : linear_pac_bounded ] we get@xmath73 the result for the case @xmath74 and @xmath75 is straight forward .    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *",
    "in this section we investigate pac algorithms for finding the best node in a tree . let then @xmath19 be an @xmath76-node tree with diameter @xmath77 and a set of leaves @xmath78 . without loss of generality we can assume that the tree is rooted at node 1 and that all edges are directed downwards to the leaves . algorithm",
    "[ alg : algorithm - tree ] considers all possible paths from the root to the leaves and treats each one of them as a line graph to be processed as in algorithm [ alg : algorithm - linear ] .",
    "we have the following proposition where , for simplicity of presentation , we do no longer differentiate among the sample sizes @xmath79 associated with edges @xmath5 .",
    "[ prop : tree_pac_bounded ] if @xmath80 holds , then algorithm [ alg : algorithm - tree ] operating on a tree graph with reward gap @xmath26 is an @xmath17-pac algorithm when the sample complexity @xmath18 of each edge satisfies @xmath81hence the sample complexity of the algorithm is @xmath82    the probability that algorithm [ alg : algorithm - tree ] returns a node whose average reward is @xmath3 below the optimal one coincides with the probability that there exists a leaf @xmath83 such that algorithm [ alg : algorithm - linear ] operating on the linear graph @xmath84 singles out a node @xmath85 whose average reward is more than @xmath3 from the optimal one within @xmath84 . setting @xmath86 , with @xmath62 , ensures that the above happens with probability at most @xmath87 .",
    "hence each edge is sampled at most @xmath88 times and the claim follows by a standard union bound over @xmath89 .",
    "in this section we deal with the problem of finding the optimal reward in a general connected and undirected graph @xmath19 , being @xmath90 .",
    "we describe a node elimination algorithm that works in phases , sketch an efficient implementation and provide a sample complexity",
    ". the following ancillary definitions will be useful .",
    "we say that a node is a _ local maximum _ in a graph if all its neighboring nodes do not have higher expected reward than the node itself .",
    "the distance between node @xmath1 and node @xmath2 is the length of the shortest path between the two nodes . finally , the diameter @xmath91 of a graph @xmath40 is the largest distance between any pair of nodes .",
    "our suggested algorithm operates in @xmath92 phases . for notational simplicity",
    ", it will be convenient to use subscripts to denote the phase number .",
    "we begin with phase 1 , where the graph @xmath93 is the original graph , i.e. , at the beginning all nodes are participating , and @xmath94 we then find a subgraph of @xmath95 , which we call _ sampled graph _ denoted by @xmath96 , that includes all the edges involved in shortest paths between all nodes in @xmath97 .",
    "we sample each edge in subgraph @xmath96 for @xmath98-times , and compute the corresponding sample averages . based on these averages , we find the local maxima of @xmath96 .",
    "the key observation is that there can be at most @xmath99 maxima .",
    "denote this set of maxima by @xmath100 .",
    "now , define a subgraph , denoted by @xmath101 , whose nodes are @xmath100 .",
    "we repeat the process of getting a sampled graph , denoted by @xmath102 .",
    "we sample the edges of the sampled graph @xmath102 for @xmath103-times and define , based on its maxima , a new subgraph . denote the set of maxima by @xmath104 , and the process continues until only one node is left .",
    "we call this algorithm nne ( _ network node elimination _ ) , which is similar to the action elimination procedure of @xcite ( see also @xcite ) . the algorithm is summarized in algorithm [ alg : network ] .",
    "two points should be made regarding the nne algorithm .",
    "first , as will be observed below , the sequence @xmath105 of diameters is nonincreasing .",
    "second , from the implementation viewpoint , a data - structure maintaining all shortest paths between nodes is crucial , in order to efficiently eliminate nodes while tracking the shortest paths between the surviving nodes of the graph .",
    "in fact , this data structure might just be a collection of @xmath76 breadth - first spanning trees rooted at each node , that encode the shortest path between the root and any other node in the graph .",
    "when node @xmath1 gets eliminated , we first eliminate the spanning tree rooted at @xmath1 , but also prune all the other spanning trees where node @xmath1 occurs as a leaf .",
    "if @xmath1 is a ( non - root ) internal node of another tree , then @xmath1 should not be eliminated from this tree since @xmath1 certainly belongs to the shortest path between another pair of surviving nodes .",
    "note that connectivity is maintained through the process .",
    "the following result gives a pac bound for algorithm [ alg : network ] in the case when the @xmath106 are bounded .",
    "[ lem : network ] suppose that @xmath107 for every @xmath108 .",
    "then algorithm [ alg : network ] operating on a general graph @xmath40 with diameter @xmath77 and reward gap @xmath26 is an @xmath17-pac algorithm with edge sample complexity @xmath109    in each phase we have at most half the nodes of the previous phase , i.e. , @xmath110 .",
    "therefore , the algorithm stops after at most @xmath92 phases . also ,",
    "because we retain shortest path between the surviving nodes , we also have @xmath111 . at each phase ,",
    "similar to the previous sections , we make sure that it is at most @xmath112 the probability of identifying an @xmath113-optimal node .",
    "therefore , it suffices to pull the edges in each sampled graph @xmath114 for @xmath115 times .",
    "hence the overall sample complexity for an @xmath17-pac bound is at most @xmath116 , as claimed .",
    "the last inequality just follows from @xmath110 and @xmath117 for all @xmath1 .",
    "being more general , the bound contained in proposition [ lem : network ] is weaker than the ones in previous sections when specialized to line graphs or trees .",
    "in fact , one is left wondering whether it is always convenient to reduce the identification problem on a general graph @xmath40 to the identification problem on trees by , say , extracting a suitable spanning tree of @xmath40 and then invoking algorithm [ alg : algorithm - tree ] on it .",
    "the answer is actually negative , as the set of simulations reported in the next section show .",
    "in this section we briefly investigate the role of the graph topology in the sample complexity .    in our simple experiment",
    "we compare algorithm [ alg : algorithm - tree ] ( with two types of spanning trees ) to algorithm [ alg : network ] over the  spider web graph `` illustrated in figure [ fig : linear ] ( a ) .",
    "this graph is made up of 15 nodes arranged in 3 concentric circles ( 5 nodes each ) , where the circles are connected so as to resemble a spider web .",
    "node rewards are independently generated from the uniform distribution on [ 0,1 ] , edge rewards are just uniform in [ -1,+1 ] .",
    "the two mentioned spanning trees are the longest diameter spanning tree ( diameter 14 ) and the shortest diameter spanning tree ( diameter 5 ) . as we see from figure [ fig : linear ] ( b ) , the latter tends to outperform the former .",
    "however , both spanning tree - based algorithms are eventually outperformed by nne on this graph .",
    "this is because in later stages nne tends to handle smaller subgraphs , hence it needs only compare subsets of ' ' good nodes \" .    [",
    "cols=\"^,^,^ \" , ]",
    "we now sketch an extension of our framework to the case when the algorithm receives contextual information in the form of feature vectors before sampling the edges .",
    "this is intended to model a more practical setting where , say , a web system has preliminary access to a set of user profile features .",
    "this extension is reminiscent of the so - called _ contextual bandit _ learning setting ( e.g. , @xcite ) , also called _ bandits with covariates _ ( e.g. , @xcite ) .",
    "in such a setting , it is reasonable to assume that different users @xmath118 have different preferences ( i.e. , different best nodes associated with ) , but also that similar users tend to have similar preferences .",
    "a simple learning model that accommodates the above ( and is also amenable to theoretical analysis ) is to assume each node @xmath1 of @xmath40 to host a linear function @xmath119 where , for simplicity , @xmath120 for all @xmath1 and @xmath121 .",
    "the optimal node @xmath122 corresponding to vector @xmath121 is @xmath123 .",
    "our goal is to identify , for the given @xmath121 at hand , an @xmath3-optimal node @xmath2 such that @xmath124 .",
    "again , we do not directly observe node rewards , but only the differential rewards provided by edges .",
    "when we operate on input @xmath121 and pull edge @xmath5 , we receive an independent observation of random variable @xmath125 such that @xmath126 = { \\boldsymbol{u}}_j^{\\top}{\\boldsymbol{x}}- { \\boldsymbol{u}}_i^{\\top}{\\boldsymbol{x}}$ ] .",
    "learning proceeds in a sequence of _ stages _ @xmath127 , each stage being in turn a sequence of time steps corresponding to the edge pulls taking place in that stage . in stage 1",
    "the algorithm gets input @xmath128 , is allowed to pull ( several times ) the graph edges @xmath129 , and is required to output an @xmath3-optimal node for @xmath128 .",
    "let @xmath130 be the sample complexity of this stage . in stage 2 ,",
    "we retain the information gathered in stage 1 , receive a new vector @xmath131 ( possibly close to @xmath128 ) and repeat the same kind of inference , with sample complexity @xmath132 .",
    "the game continues until @xmath133 stages have been completed .    for any given sequence @xmath128 , @xmath131 , @xmath134 , @xmath135 ,",
    "one expects the cumulative sample size @xmath136 to grow _ less than linearly _ in @xmath133 .",
    "in other words , the additional effort the algorithm makes in the identification problem diminishes with time , as more and more users are interacting with the system , especially when these users are similar to each other , or even occur more than once in the sequence @xmath128 , @xmath131 , @xmath134 , @xmath135 .",
    "in fact , we can prove stronger results of the following kind .",
    "notice that the bound does not depend on the number @xmath133 of stages , but only on the dimension of the input space .",
    ", @xmath131 , @xmath134 , @xmath135 are close to each other .",
    "details are omitted due to lack of space . ]    under the above assumptions , if @xmath19 is a connected and undirected graph , with @xmath76 nodes and diameter @xmath77 , and @xmath128 , @xmath131 , @xmath134 , @xmath137 is any sequence of unit - norm feature vectors , then with probability at least @xmath0 a version of the nne algorithm exists which outputs at each stage @xmath138 an @xmath3-optimal node for @xmath118 , and achieves the following cumulative sample size @xmath139 where @xmath140    the algorithm achieving this bound combines linear - regression - like estimators with nne . in particular",
    ", every edge of @xmath40 maintains a linear estimator @xmath141 intended to approximate the difference @xmath142 over both stages and sampling times within each stage . at stage @xmath138 and sampling time @xmath13 within stage @xmath138",
    ", the vector @xmath143 suitably stores all past feature vectors @xmath144 observed so far , along with the corresponding edge reward observations . by using tools from ridge regression in adversarial settings ( see , e.g. , @xcite )",
    ", one can show high - probability approximation results of the form @xmath145 being @xmath146 , and @xmath147 the matrix @xmath148 in stage @xmath138 , nne is able to output an @xmath3-optimal node for input @xmath118 as soon as the rhs of ( [ e : approx ] ) is as small as @xmath149 , for a suitable constant @xmath150 depending on the current graph topology nne is operating on .",
    "then the key observation is that in stage @xmath138 the number of times we sample an edge @xmath5 such that the above is false can not be larger than @xmath151 where @xmath152 is the determinant of the matrix at argument .",
    "this follows from standard inequalities of the form @xmath153 .",
    "this paper falls in the research thread of analyzing online decision problems where the information that is obtained is comparative between arms .",
    "we analyzed a simple setup where the structure of comparisons is provided by a given graph which , unlike previous works on this subject @xcite , lead us focus on the notion of finding an @xmath3-optimal arm with high probability .",
    "we then described an extension to the important contextual setup .",
    "there are several issues that call for further research that we outline below .",
    "first , we only addressed the exploratory bandit problem",
    ". it would be interesting to consider the regret minimization version of the problem . while naively one can think of it as a problem with an arm per edge of the graph",
    ", this may not be a very effective model because the number of arms may go as @xmath154 but the number of parameters grows like @xmath76 . on top of this , definining a meaningful notion of regret may not be trivial ( see the discussion in the introductory section ) .",
    "second , we only considered graphs as opposed to hypergraphs .",
    "considering comparisons of more than two nodes raises interesting modeling issues and well as computational issues .",
    "third , we assumed that all samples are equivalent in the sense that all the pairs we can compare have the same cost .",
    "this is not a realistic assumption in many applications .",
    "an approach akin to budgeted learning @xcite would be interesting here .",
    "fourth , we focused on upper bounds and constructive algorithms . obtaining lower bounds that depend on the network topology would be interesting .",
    "the upper bounds we have provided are certainly loose for the case of a general network . furthermore , more refined upper bounds are likely to exist which take into account the distance on the graph between the good nodes ( e.g. , between the best and the second best ones ) . in any event ,",
    "the algorithms we developed for the network case are certainly not optimal .",
    "there is room for improvement by reusing information better and by adaptively selecting which portions of the network to focus on .",
    "this is especially interesting under smoothness assumptions on the expected rewards .",
    "relevant references in the mab setting to start off with include @xcite .",
    "e. even - dar , s. mannor , y. mansour ( 2006 ) .",
    "action elimination and stopping conditions for the multi - armed bandit and reinforcement learning problems .",
    "_ journal of machine learning research _ ( jmlr ) , * 7 * : 10791105 , mit press          t. joachims , f. radlinski ( 2005 ) . query chains : learning to rank from implicit feedback . _",
    "proceedings of the eleventh acm sigkdd international conference on knowledge discovery in data mining _ ( acm kdd ) , pp ."
  ],
  "abstract_text": [
    "<S> we consider a bandit problem over a graph where the rewards are not directly observed . instead </S>",
    "<S> , the decision maker can compare two nodes and receive ( stochastic ) information pertaining to the difference in their value . </S>",
    "<S> the graph structure describes the set of possible comparisons . consequently , comparing between two nodes that are relatively far requires estimating the difference between every pair of nodes on the path between them . </S>",
    "<S> we analyze this problem from the perspective of sample complexity : how many queries are needed to find an approximately optimal node with probability more than @xmath0 in the pac setup ? </S>",
    "<S> we show that the topology of the graph plays a crucial in defining the sample complexity : graphs with a low diameter have a much better sample complexity . </S>"
  ]
}