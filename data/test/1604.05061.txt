{
  "article_text": [
    "we consider in this review article a series of works  @xcite , completed in collaboration with some colleagues of ours , that all share the following common denominator .",
    "the task to perform is , possibly repeatedly , to approximate numerically the solution to a partial differential equation that has some random character . in most of our works ,",
    "the equation has the simplest possible form : it is scalar - valued , elliptic , linear , non degenerate , in divergence form . typically , and with self - explanatory notations",
    ", it reads as @xmath0 on a domain  @xmath1 , and for a certain right hand side @xmath2 .",
    "the random character of the problem can be encoded in the coefficient  @xmath3 , and/or in the right - hand side  @xmath2 , and/or in the domain  @xmath1 itself .",
    "needless to say , there exist a number of successful approaches to explicitly treat randomness in such partial differential equations .",
    "recent years have witnessed an explosion of the number of methods invented in this extremely lively topic , in particular motivated by the field of _ uncertainty quantification_. stochastic finite elements , spectral methods , sparse tensor products methods , reduced basis techniques , quantization , all methods based one way or another on karhunen - loeve , polynomial chaos , or other types of similar or not economical decompositions of the random functions present in the equation , both as parameters and unknown functions , have been increasingly studied and considerably improved lately .",
    "some accessible general references in the field are the textbooks  @xcite .",
    "review articles on each of the many categories of approaches , such as  @xcite , are also available .",
    "the _ rationale _ behind all these methods is the reduction of the dimension of the problem , considered as a problem in a high - dimensional space consisting of the ambient physical space where the original problem is posed _ augmented _ by the space of approximation for the random dependency .",
    "a simplification of the random dependency follows , and the problem becomes amenable to efficient computational techniques .",
    "we ourselves have used , in  @xcite , and reviewed , in  @xcite , some of these methods ( specifically , reduced basis type methods ) in the context of equations with random parameters .    in the present review article",
    ", we would like to concentrate on a somewhat alternate strategy : _ not attempt to simplify the dependency upon randomness , but embrace the difficulty arising from it_. of course , this may only be achieved in some specific situations , sufficiently general to be of broad interest , but certainly not covering the immense spectrum of applications in the engineering and life sciences , and perhaps not with the same generic character as the above mentioned general purpose methods .",
    "to some extent , the cases we consider must be slightly simpler than , and not as general as , the cases targeted by the above methods . our ambition and our achievements are more modest .",
    "on the other hand , it turns out that the cases we consider arise from a context that brings an additional level of complexity : they originate from multiscale modeling . in that respect , the mix between the presence of randomness , the multiscale feature , and the wish to compute accurately and efficiently lead to an essentially unsolved difficulty ( despite the many efforts of outstanding contributors ) . in multiscale",
    "computational science , a number of techniques exist , and are improved constantly .",
    "but , most of the times , and despite some overly optimistic claims , they do not marry so well with randomness when it comes to practical computations .",
    "conversely , the extremely efficient toolbox available for random problems has essentially no intersection with multiscale science .",
    "well beyond the somewhat limited purpose of this review article , our intention is thus to attract the attention of the community to the state of the art : _ efficiently computing when randomness and many scales are simultaneously present is still an essentially open , considerably challenging , issue_.    [ [ the - two - situations - considered - similarities - and - differences . ] ] the two situations considered : similarities and differences .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we will consider below two prototypical situations .",
    "as we mentioned , we encountered both situations in our research efforts devoted to multiscale science , and more precisely in our endeavor to study and improve computational approaches in materials science : ( i ) the approximation of the homogenized tensor in the context of stochastic numerical homogenization , and ( ii ) the multiscale finite element computation of the solution to an ( harmless ) equation posed on a randomly perforated domain .    in both situations",
    ", randomness originates from geometry .",
    "but , in either situation , geometry is encoded differently in the equation . in ( i ) , it is encoded in the heterogeneities of the coefficient .",
    "in contrast , in ( ii ) it is encoded in the computational domain itself .",
    "the similarity of the two problematics is evident . by penalization",
    ", the second problem may even be viewed as a particular case of the first problem . however , the techniques we employ are different in nature , and have a different purpose .",
    "the former problem ( approximation of the homogenized tensor ) consists in the repeated resolution of an elliptic equation ( the celebrated `` corrector equation '' ) on an as large as possible bounded domain , truncation of the whole space @xmath4 , typically for @xmath5 , or @xmath6 , in practice .",
    "the equation is of the above type   and will be made explicit below , see  .",
    "the purpose of that repeated solution procedure is to compute an expectation ( thus , in practice an empirical mean ) from the solutions obtained for various realizations of the local environment ( mathematically encoded in the coefficient  @xmath3 of  ) .",
    "the reader may think of different microstructures of the material , different inclusions in the medium , etc .",
    "the task of computing an average , that is a single , deterministic output , sounds simple .",
    "in particular , the very process of averaging , performed here in the context of a stationary ergodic problem ( see the details below ) , is essentially of the same nature as the law of large numbers .",
    "this suggests that the random character of the problem progressively vanishes when the number of realizations considered increases .",
    "however , the practical monte carlo approach ( generate random environments and average out an outcome based on the computed solutions ) is plagued by variance issues .",
    "the rate of convergence of the approximation , in terms of the size of the truncated computational domain asymptotically covering the whole ambient space , is universal .",
    "it is dictated by the central limit theorem .",
    "the prefactor appearing in the error estimate is related to the variance of the problem .",
    "efficient computational approaches consist in designing tools to reduce that variance , thus the statistical error in the approximation .",
    "that error largely dominates the bias ( the deterministic part of the error ) , and thus is the critical quantity that governs the overall quality of the numerical approach .",
    "our series of works addresses various techniques to reduce the variance : antithetic variables , control variate , selection approach , the latter being somewhat in the spirit of stratified sampling .",
    "they are imported from several different contexts and are adjusted to the specific context of numerical homogenization .    the latter problem ( multiscale finite element computations on randomly perforated domains ) differs from the former problem in several respects .",
    "as mentioned above , the randomness of the geometry is now encoded not in the coefficients of the equations ( which are constant , for simplicity ) , but in the domain where the equation is posed .",
    "we deal with perforations of that domain that are randomly located .",
    "note however that , as briefly mentioned above , the perforations of the domain can be , in the numerical discretization , treated by penalization , in which case the two situations we consider become closer to one another .",
    "another , more substantial , difference is that this second example is a representative case of modern multiscale techniques .",
    "in contrast with classical techniques which ( i ) aim at computing an equivalent `` homogenized '' medium , and ( ii ) achieve this in the asymptotic limit of vanishing length scales of the oscillations originally present ( this is the case of our former situation ) , modern techniques attack the multiscale problem ( i ) directly and ( ii ) at the actual length scales .",
    "homogenization theory is then seen as a guideline to construct suitable basis functions for the discretization which , in a second stage , are used to expand the numerical solution . now , in the first stage of construction of these basis functions ( the _ ad hoc _ finite elements ) , the geometry of the computational domain matters .",
    "well before being able to average solutions and/or outputs based on solutions , the issue arises to be able to compute efficiently and accurately each and every single solution , in a robust way that does not require regenerating a set of basis functions for each realization of the random environment .",
    "this will be the issue we investigate , and solve using adequate ( crouzeix - raviart type ) boundary conditions for the multiscale finite element basis set and an adequate enrichment ( using bubble functions ) of that basis set .",
    "we wish to emphasize the following fact .",
    "not only the two problems we consider are relevant beyond the context of multiscale computing , and the methods we put in action can be useful elsewhere , but the second problem considered ( robustness of a numerical approach with respect to some wild modifications of the geometry ) is not specific to random modeling and covers the generality of all _ disordered _ geometries , random or deterministic .",
    "not every non periodic problem is indeed random .",
    "techniques literally based upon perfectness of the disorder ( such as the approaches we briefly mentioned at the beginning of this introduction , and also the variance reduction techniques we use ) can be inefficient in the presence of only imperfect , partial disorder . it is indeed true that the random setting often comes with assumptions such as stationarity , etc , that make randomness tractable at the price of somehow _",
    "`` rigidifying the disorder '' _ , if we allow ourselves this abuse of language .",
    "thus the interest of considering other techniques than techniques probabilistic in nature .",
    "other works of ours ( see  @xcite for a review ) proceed further in that direction .    before we get to the heart of the matter , let us expose the problems in slightly more details , and announce the plan of our review .",
    "[ [ an - elliptic - problem - with - random - coefficients . ] ] an elliptic problem with random coefficients .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the first problem we consider ( in section  [ sec : variance ] below ) arises in the numerical approximation of oscillatory / heterogeneous solutions of pdes in the context of classical homogenization .",
    "the specific setting is that of random ergodic homogenization .",
    "the theoretical basis is briefly summarized in subsection  [ ssec : recall ] , both in the deterministic ( periodic ) context and in the random context .",
    "the reader willing to familiarize him or herself with that celebrated theory is referred to the classical textbooks  @xcite , and also to our introductory , computationally oriented lecture notes  @xcite .",
    "the central problem to solve is the corrector problem , which is of the type   and more precisely reads as an elliptic equation with a random parameter  @xmath7 @xmath8 = 0\\ ] ] ( where @xmath9 is a fixed vector ) set on the _ whole _ space @xmath4 .",
    "the precise mathematical formulation is the problem   below . from the solution @xmath10 , an expectation is to be evaluated . in practice",
    ", the equation is set on a large , truncated domain , subset of @xmath4 .",
    "several realizations of @xmath7 are considered , and an empirical mean is employed to approximate the expectation built from the set of  @xmath10 .",
    "this is the essence of the monte carlo approach in this particular context .",
    "details are given below .",
    "making this monte carlo approach efficient requires to reduce the variance .",
    "this is the purpose of our series of works  @xcite , which is overviewed in subsection  [ ssec : variance - reduction ] .",
    "well known variance reduction techniques , adapted to the specific context of homogenization , are described and tested .",
    "notice that our research on such topics has already been partially reviewed in  @xcite where the reader may find more detailed elements of context and some additional comments .",
    "in particular , one will also find in  @xcite a review of some of our works  @xcite dealing with problems that are , in a sense made precise there , only `` weakly random '' .",
    "such problems are small random perturbations of periodic problems , and can be approximated by dedicated methods .",
    "these `` weakly random '' problems and methods have a great interest in their own right .",
    "they are not addressed in the present review .",
    "our target is `` fully random '' problems .",
    "some of these methods will however be briefly mentioned below , for different purposes , namely either constructing auxiliary , surrogate models ( in section  [ sssec : controlvariate ] ) , or deriving selection rules for the draws ( in section  [ sssec : sqs ] ) .",
    "both tools are useful for the reduction of variance in `` fully random '' problems",
    ".    in essence , all variance reduction methods aim at eliminating part of the noise intrinsically present in the draws of the realizations of the random variables at play .",
    "noise can be eliminated in a variety of ways .",
    "one may try and bias the draws , thereby , in again an informal language , `` twisting the arbitrary arm '' of randomness .",
    "this should be made in a very subtle way .",
    "too small a bias in these draws has no effect on the variance .",
    "too large a bias may indeed succeed in reducing the variance but might affect the average and lead to an incorrect numerical result .",
    "alternately , one may first keep the noise as is , leaving the draws unaffected , but try to cancel the noise out in a second stage , subtracting ( in some sense to be made precise ) another simulation to the original one .",
    "the variance reduction techniques we make use of , which we did not invent but borrowed from other contexts and adapted to ours , proceed in either of the above directions .",
    "notice however that the book of possible variance reduction methods is thick .",
    "we have certainly not yet followed all possible tracks .",
    "the first variance reduction technique we employ is relatively elementary .",
    "it is the classical , general purpose technique of _ antithetic variables _ , presented in subsection  [ sssec : antithetic ] .",
    "the efficiency of that technique is substantial , but is also , not unexpectedly , limited in particular because the technique does not exploit much the specifics of the problem considered .",
    "we present in subsection  [ sssec : controlvariate ] the technique of _ control variate _ , which requires a better knowledge of the problem .",
    "a problem simpler to simulate and close to the original problem , in a sense that is made precise below , has to be considered and concurrently solved .",
    "the technique uses that knowledge to get a much better reduction of the variance .",
    "specifically , the auxiliary problem used as control is built upon an approximation method that we developed for the `` weakly random '' problems we were alluding to above . in some sense , this problem is a reduction of the original problem . in subsection  [ sssec :",
    "sqs ] , we expose yet another approach , specifically imported from solid state physics , namely that of _ special quasi - random structures_. it consists in selecting , in the spirit of another well - known technique , _ stratified sampling _ , some configurations of the random environment that are more suitable than generic configurations to compute the empirical averages , so as to again reduce the variance .",
    "similarly to the previous approach of control variate , a reduced model is also useful in the approach .",
    "[ [ an - elliptic - problem - on - a - randomly - perforated - domain . ] ] an elliptic problem on a randomly perforated domain .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our second framework concerns a pde set on a perforated domain .",
    "randomness manifests itself in the problem via the randomness of the location of the perforations ( and , possibly , their size and shape ) .",
    "again , we consider the simplest possible equation : scalar - valued , elliptic , non degenerate , linear and in divergence form .",
    "more precisely , we consider a bounded domain  @xmath11 and a set @xmath12 of perforations within this domain .",
    "the perforations are supposedly small and in extremely large a number .",
    "the parameter  @xmath13 encodes the typical small distance between the perforations .",
    "we denote by  @xmath14 the perforated domain ( see figure  [ fig : perforation ] in section  [ sec : msfem ] ) .",
    "we then consider the following problem : find @xmath15 , solution to @xmath16 where @xmath17 is a given function , assumed sufficiently regular on @xmath1 .",
    "it is important to note that the homogeneous dirichlet boundary condition on @xmath18 ( and hence on the boundary @xmath19 of the perforations ) is a crucial feature of the problem we consider .",
    "the consideration of this particular academic problem stems from our interest in various physically relevant problems , for instance in fluid mechanics , atmospheric modeling , electrostatic devices , etc .",
    "equation   can also be seen as a step toward the resolution of advection - diffusion equations ( see our ongoing work  @xcite for that particular category of equations ) , that of the stokes problem ( see e.g.  @xcite ) , or that of the navier - stokes problem , all on perforated domains . in fluid dynamics applications , homogeneous dirichlet boundary conditions on the perforations",
    "are typical .",
    "we introduce and study a dedicated multiscale finite element method ( msfem ) . the variant of msfem we consider uses _ crouzeix - raviart type _",
    "finite elements  @xcite .",
    "we have introduced this approach in  @xcite on a multiscale elliptic problem ( exactly of the form  ) with a highly oscillatory coefficient ( the coefficient  @xmath3 in  ) , and then extended it in  @xcite to the case of problem  . in the presence of perforations , we indeed have to improve the previously introduced approach by the addition of _ bubble functions _ to the finite element basis set .",
    "both ingredients , crouzeix - raviart type finite elements on the one hand , and addition of bubble functions on the other hand , allow for robustness of the approach , a critical issue when the geometry of the computational domain is random .",
    "it is well known that , for the construction of multiscale finite elements , boundary conditions set on the edges ( or facets in 3d ) of mesh elements for the definition of the basis functions play a critical role for the eventual accuracy and efficiency of the approach .",
    "using crouzeix - raviart type elements ( see  @xcite for their original introduction in the context of classical meaning non - multiscale finite elements ) gives a definite flexibility .",
    "in short , the continuity of the finite element basis set functions across the edges of the mesh is enforced only in a weak sense by requiring that the average of the jump vanishes on each edge .",
    "the nonconforming approximation obtained in this manner proves to be very effective .",
    "the above issue regarding boundary conditions on the mesh elements is all the more crucial when dealing with perforated computational domains , and may be of paramount importance for _ randomly _ perforated computational domains .",
    "the approach is meant to be as insensitive as possible to the possible intersections between element edges and perforations .",
    "the perforations can then be very heterogeneously distributed .",
    "ad hoc _ construction of a mesh that as much as possible avoids intersecting the perforations is indeed prohibitively difficult .",
    "our approach does _ not _ require a mesh of this type .",
    "the second ingredient of our approach is the addition of bubble functions to the finite element space . as illustrated using a simple one - dimensional analysis ( see  @xcite ) , and demonstrated with the extensive set of numerical tests performed in  @xcite , some of which will be reproduced here , bubble functions definitely bring an added value for the overall accuracy of the approach .    in the vast literature devoted to similar types of problems and techniques ,",
    "we refer the reader unfamiliar with the general context to  @xcite for some background on finite element methods in general , to the review article  @xcite and the book  @xcite ( and references therein ) for the general background on msfem , and the works  @xcite specifically addressing problems on perforated domains , either from a theoretical or a numerical standpoint .",
    "our contribution is reviewed in section  [ sec : msfem ] .",
    "that section begins with some generalities about our msfem approach , contained in subsection  [ ssec : presentation2d ] .",
    "in particular , we briefly mention an error estimate that we have established in the case of periodic perforations .",
    "we are unfortunately unable to extend it to the case of random perforations .",
    "it is however useful to illustrate the nice properties of the approach .",
    "subsection  [ ssec : numerical - tests ] is then devoted to some numerical tests that show the announced robustness of the approach in the presence of random perforations .",
    "all the numerical tests we report below have been performed using the finite elements software freefem++  @xcite .",
    "we first recall some basic ingredients of elliptic homogenization theory in the periodic setting .",
    "we consider , in a regular domain @xmath20 in @xmath4 , the problem @xmath21 = f",
    "\\quad \\text{in $ { \\cal d}$ } ,   \\\\ \\noalign{\\vskip 5pt } u^{\\varepsilon}=0 \\quad \\text{on $ \\partial { \\cal d}$ } ,   \\end{array } \\right.\\ ] ] where the matrix @xmath22 is symmetric and @xmath23-periodic .",
    "we manipulate for simplicity _ symmetric _ matrices , but our discussion carries over to non symmetric matrices up to slight modifications .    the corrector problem associated to ( [ eq : pb0-per ] ) reads , for @xmath9 fixed in @xmath4 , @xmath24 it has a unique solution up to the addition of a constant .",
    "then , the homogenized coefficients read @xmath25_{ij } = \\int_q e_i^t a_{\\rm per}(y ) \\left(e_j + \\nabla w_{e_j}(y ) \\right)dy$ ] , where @xmath26 is the unit cube and @xmath27 is the canonical basis of @xmath4 .",
    "the main result of periodic homogenization theory is that , as @xmath13 goes to zero , the solution @xmath28 to ( [ eq : pb0-per ] ) converges to @xmath29 solution to @xmath30 = f \\quad \\text{in $ { \\cal d}$ } ,   \\\\ \\noalign{\\vskip 5pt } u^\\star=0 \\quad \\text{on $ \\partial { \\cal d}$}. \\end{array}\\right.\\ ] ] the convergence holds in @xmath31 , and weakly in @xmath32 .",
    "the correctors @xmath33 , @xmath34 , may then also be used to `` correct '' @xmath29 in order to identify the behavior of @xmath28 in the strong topology @xmath32 .",
    "practically , at the price of only computing @xmath35 periodic problems ( [ eq : cor - per - intro ] ) , the solution to problem ( [ eq : pb0-per ] ) can be efficiently approached for @xmath13 small .",
    "the random setting is , for the simple equation  , a straightforward extension of the periodic setting . skipping all technicalities related to the definition of the probabilistic setting , which we assume discrete stationary and ergodic ( we refer e.g. to  @xcite for all details )",
    ", we now fix @xmath36 a square matrix of size @xmath35 , which is assumed stationary in the sense that @xmath37 ( where  @xmath38 is an ergodic group action ) and which is assumed to enjoy the classical assumptions of uniform ellipticity and boundedness .",
    "then we consider the boundary value problem @xmath39 standard results of stochastic homogenization  @xcite apply and allow to find the homogenized limit of problem ( [ eq : pb0-stoc ] ) .",
    "the solution @xmath40 to ( [ eq : pb0-stoc ] ) converges to the solution to ( [ eq : pb0-star ] ) where the homogenized matrix is now defined as @xmath41_{ij }   =   { \\mathbb{e}}\\left(\\int_q e_i^t a(y,\\cdot ) \\",
    ", \\left ( e_j+\\nabla w_{e_j}(y,\\cdot)\\right ) \\,dy\\right),\\ ] ] where @xmath26 is the unit cube and where , for any @xmath42 , @xmath43 is the solution ( unique up to the addition of a random constant ) to @xmath44 = 0 \\quad \\hbox{\\rm a.s . on $ { \\mathbb{r}}^d$ } ,   \\\\ \\\\",
    "\\nabla w_p \\quad \\mbox{is stationary in the sense of ( \\ref{eq : stationnarite - disc } ) } ,   \\\\ \\\\ { \\displaystyle}{\\mathbb{e}}\\left(\\int_q \\nabla w_p(y,\\cdot)\\,dy\\right ) = 0 .",
    "\\end{array } \\right.\\ ] ] a striking difference between the stochastic setting and the periodic setting can be observed comparing ( [ eq : cor - per - intro ] ) and ( [ eq : correcteur - random ] ) . in the periodic case ,",
    "the corrector problem is posed on a bounded domain ( namely , the periodic cell  @xmath26 ) , since the corrector @xmath43 is periodic . in sharp contrast , the corrector problem ( [ eq : correcteur - random ] ) of the random case is posed on the whole space @xmath4 . in the numerical practice ,",
    "truncations of that problem have to be considered , typically on large domains  @xmath45 ( say , @xmath46 ) and using periodic boundary conditions : @xmath47 = 0 , \\\\ \\\\",
    "w_p^n(\\cdot,\\omega ) \\mbox { is $ q_n$-periodic}. \\end{array } \\right.\\ ] ] the random matrix @xmath48 defined by @xmath49_{ij }   =   \\frac{1}{|q_n| } \\int_{q_n } e_i^t a(y,\\omega ) \\",
    ", \\left ( e_j+\\nabla w_{e_j}^n(y,\\omega)\\right ) \\,dy\\ ] ] converges ( almost surely ) to @xmath50 when @xmath51 ( see e.g.  @xcite ) .",
    "important theoretical questions about the quality and the rate of the convergence in terms of the truncation size arise ( see , in particular , the pioneering works by a.  bourgeat and a.  piatnitski  @xcite and a recent series of works by a.  gloria , f.  otto and their collaborators  @xcite ) .",
    "the error @xmath52 \\big ) + \\big ( { \\mathbb{e}}\\left [ a_n^\\star \\right ] - a_n^\\star(\\omega ) \\big)\\ ] ] is the sum of a systematic error and of a statistical error ( the first and second terms in the above right - hand side , respectively ) .",
    "it is observed , and theoretically demonstrated in some cases , that the statistical error decays with a slower rate with respect to @xmath53 than the systematic error . for large values of @xmath53 ,",
    "the statistical error is therefore dominating the systematic error . in",
    "what follows , we focus on reducing the statistical error , and describe approaches to more efficiently compute @xmath54 $ ] , for a given truncated domain @xmath45 .",
    "the direct approach for numerical random homogenization consists in using empirical means approximating the expectation @xmath55 of the homogenized coefficient computed on a truncated domain of size  @xmath53 .",
    "variance issues are central .",
    "[ [ description - of - the - approach . ] ] description of the approach .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + +    the variance reduction technique known as the technique of _ antithetic variables _ has been adapted to the homogenization context in  @xcite .",
    "it consists in concurrently considering two sets of configurations for the random material instead of only one set .",
    "the two sets of configurations are deduced one from the other ( see figure  [ fig_b12 ] for a simple example ) . fix @xmath56 and consider @xmath57 i.i.d .",
    "copies @xmath58 of @xmath59 .",
    "construct next @xmath57 i.i.d .",
    "_ antithetic _ random fields @xmath60 , @xmath61 , from the @xmath58 .",
    "the map @xmath62 transforms the random field @xmath63 into another , so - called _ antithetic _ , field @xmath64 .",
    "the transformation is performed in such a way that , for each @xmath65 , @xmath64 has the same law as @xmath63 , namely the law of the matrix  @xmath66 .",
    "somewhat vaguely stated , if @xmath66 was obtained in a coin tossing game ( using a fair coin ) , then @xmath64 would be _ head _ each time @xmath63 is _ tail _ and vice versa . then , for each @xmath61 , we solve two corrector problems of the type  .",
    "one is associated to the original @xmath63 , the other one is associated to the antithetic field @xmath64 . using its solution @xmath67",
    ", we define the _ antithetic homogenized matrix _",
    "@xmath68 , the elements of which read , for @xmath69 , @xmath70_{ij } =   \\frac{1}{|q_n| } \\int_{q_n } e_i^t b^m(y,\\omega ) \\ \\left(e_j + \\nabla v_{e_j}^{n ,",
    "m}(y,\\omega ) \\right ) \\ , dy.\\ ] ] next we set , for any @xmath61 , @xmath71 since @xmath63 and @xmath64 are identically distributed , so are @xmath72 and @xmath73 .",
    "thus , @xmath74 is unbiased ( that is , @xmath75 ) .",
    "in addition , it satisfies @xmath76 almost surely , because @xmath64 is ergodic .",
    "the hope ( which is indeed confirmed by theory in simple cases and by numerical observation in all the tests we performed ) is that the new approximation  @xmath74 has a smaller variance than  @xmath72 .",
    "it is indeed the case under appropriate assumptions .     together with its antithetic field @xmath77 for the famous random checkerboard ( reproduced from  @xcite ) .",
    "[ fig_b12],width=336 ]    [ [ foundation - of - the - approach . ] ] foundation of the approach .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + +    some theoretical elements that give a foundation to our approach of variance reduction are collected in  @xcite .",
    "of course , as always in this context , the one - dimensional setting , being explicit , may be entirely analyzed .",
    "two particular higher dimensional cases were also analyzed .",
    "the first one is a `` genuinely '' random setting , the second one is a `` weakly random '' case . in all such cases , under appropriate assumptions ,",
    "the approach is shown to qualitatively reduce the variance .",
    "a quantitative assessment of the reduction is however out of reach .",
    "only numerical tests can provide some information .",
    "[ [ numerical - tests . ] ] numerical tests .",
    "+ + + + + + + + + + + + + + + +    the tests performed concern three different `` input '' random fields @xmath36 in  , some i.i.d . , some correlated , with various correlation lengths .",
    "we have investigated variance reduction on a typical diagonal  @xmath78_{11}$ ] , or off - diagonal  @xmath78_{12}$ ] entry of the approximate homogenized matrix  @xmath79 , as well as on the eigenvalues of the matrix , and the eigenvalues of the associated differential operator  @xmath80 $ ] ( supplied with homogeneous dirichlet boundary conditions on  @xmath81 ) . we show a typical result on figure  [ fig_b12_result ] , for a two - dimensional test case where @xmath82 is given by @xmath83 where @xmath84 , @xmath85 is the identity matrix , and @xmath86 is an i.i.d sequence of random variables such that @xmath87 , with @xmath88 and @xmath89 .",
    "we observe on figure  [ fig_b12_result ] that the confidence interval obtained with our approach is smaller than that obtained with the standard monte carlo ( mc ) approach .",
    "the gain in variance ( at equal computational cost ) is essentially insensitive to the size of the computational domain .",
    "it is here between 6 and 10 . at fixed computational cost ,",
    "the approach improves the accuracy by a factor @xmath90 .",
    "equivalently , for a given accuracy , the computational cost is reduced by a factor @xmath91 .",
    "( with confidence interval ) with respect to @xmath92 ( in red , the classical mc strategy , in green the antithetic variable strategy , for an equal computational cost ; reproduced from  @xcite ) .",
    "[ fig_b12_result],width=336 ]    the approach has been extended in  @xcite to nonlinear convex stochastic homogenization problems .",
    "the highly oscillatory problem , the euler - lagrange equation of which replaces  , is then given by @xmath93 for some appropriate @xmath94 .",
    "we assume that @xmath95 is strictly convex with respect to its third argument , and that , for any @xmath96 , the random field @xmath97 is stationary in the sense of  .",
    "we also assume that @xmath95 satisfies a standard growth condition ( see  @xcite for details ) .",
    "the associated homogenized problem , the euler - lagrange equation of which replaces  , is @xmath98 where , for any @xmath99 , the homogenized energy density @xmath100 is given by @xmath101 where @xmath102 as in the linear case for the corrector problems   and  , we approximate in practice @xmath103 by @xmath104 $ ] for some large @xmath53 , the latter quantity being itself approximated by an empirical mean .",
    "we show in  @xcite that the exact same antithetic variable technique we used in the linear case can be used to compute @xmath104 $ ] ( for any @xmath53 and any @xmath99 ) more efficiently .    to summarize , our numerical results show that the technique may be applied to a large variety of situations and has proved efficient whatever the output considered .",
    "variance is systematically reduced .",
    "we have observed , however , that the rate of reduction is not spectacular .",
    "this has motivated the consideration of other approaches .",
    "the _ control variate approach _ is a variance reduction technique known to be potentially much more efficient than the antithetic variable technique .",
    "it however asks to have beforehand a better information on the random variables simulated . in the context of homogenization",
    ", the work  @xcite presents a first possible investigation of the efficiency of this technique .",
    "as briefly mentioned in the introduction , the approach aims at `` subtracting '' part of the noise , using an auxiliary problem close to the original problem .",
    "we describe how we derive such an auxiliary problem in the next paragraph .",
    "next , we make the setting specific , and present the variance reduction approach .",
    "[ [ a - useful - weakly - random - setting . ] ] a useful `` weakly random '' setting .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one perturbative approach among many other possible ones , described in full details in  @xcite , and addressing the random material as a small perturbation of a periodic material , consists in considering a coefficient of the form @xmath105 where , with evident notation , @xmath22 is a periodic matrix modeling the unperturbed material , and @xmath106 is a periodic matrix modeling the perturbation .",
    "consider then the case @xmath107 where the @xmath108 are , say , independent identically distributed scalar - valued random variables .",
    "one particularly interesting case ( see  @xcite for other cases ) is when the common law of the @xmath108 is assumed to be a bernoulli law of parameter  @xmath109 ( see figure  [ fig : arnaud - bernoumat ] ) .",
    "we now _ formally _ explain how we derive an expansion of the problem in `` powers '' of @xmath109 .",
    "the approach has been recently proven to be rigorous in  @xcite .",
    "5truemm    the basic observation consists in noticing that , in the corrector problem @xmath110 = 0,\\ ] ] the only source of randomness comes from the coefficient @xmath111 .",
    "therefore , in principle , if one knows the law of this coefficient , one knows the law of the corrector function @xmath112 and therefore may compute the homogenized coefficient  @xmath113 , the latter being a ( quite intricate but well defined ) function of this law . when the law of @xmath114 is an expansion in terms of a small coefficient , so is the law of @xmath43 .",
    "consequently @xmath113 can be obtained as an expansion .",
    "heuristically , on the cube  @xmath115^d$ ] and at order 1 in @xmath109 , the probability to get the perfect periodic material ( entirely modeled by the matrix  @xmath22 ) is @xmath116 , while the probability to obtain the unperturbed material on all cells except one ( where the material has matrix @xmath117 ) is @xmath118 .",
    "all other configurations , with more than two cells perturbed , yield contributions of orders higher than or equal to @xmath119 .",
    "this gives the intuition ( confirmed by the mathematical proof ) that the first order correction indeed comes from the difference between the material perfectly periodic except on one cell and the perfect material itself .",
    "the homogenized matrix reads as @xmath120 where @xmath121 is the homogenized matrix for the unperturbed periodic material and @xmath122,\\ ] ] where @xmath123 is the @xmath26-periodic corrector for @xmath22 ( solution to  ) , and @xmath124 solves @xmath125 = 0 \\quad \\text{in $ q_n$ } , \\quad \\text{$w_i^n$ is $ q_n$-periodic}.\\ ] ]    the approach has been extensively tested .",
    "it is observed that , using the perturbative approach , the large @xmath53 limit for cubes of size @xmath53 is already very well approached for small values of @xmath53 .",
    "the computational efficiency of the approach is clear : solving the two periodic problems with coefficients @xmath22 and @xmath126 for a limited size @xmath53 is much less expensive than solving the original , random corrector problem for a much larger size @xmath53 .",
    "when the second order term is needed ( and we will actually use it below ) , configurations with two defects have to be computed .",
    "they all can be seen as a family of pdes , parameterized by the geometrical location of the defects .",
    "reduced basis techniques have been shown to be useful and allow for a definite speed - up in the computation , see  @xcite .",
    "[ [ variance - reduction - in - the - fully - random - setting . ] ] variance reduction in the `` fully random '' setting .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    when the parameter  @xmath109 of the bernoulli law is _ not _ taken small in the definition  - of the coefficient inserted in the equation  , and thus the corrector problem  , the expansion technique we have just described is not correct , and actually we observe experimentally that it is inaccurate .",
    "it can however serve for the construction of a control variate , useful to reduce the variance .",
    "we recall that the field @xmath127 writes as in  . determining the field @xmath82 , given by  , on the truncated domain  @xmath45",
    "amounts to drawing @xmath128 in each cell @xmath129 in  @xmath45 .",
    "this allows to compute the associated ( approximate ) homogenized coefficient @xmath48 from the solution to the corrector problem   ( with @xmath130 ) , see  . in parallel to this task , we _ reconstruct _ from the specific realization of the set of @xmath131 a field that is used as a control variate .",
    "more precisely , we set @xmath132 \\right).\\ ] ] in this formula , @xmath133 where @xmath134 is the deterministic coefficient corresponding to the case of _ one _ defect located at position  @xmath135 in @xmath45 ( it is actually independent of  @xmath135 thanks to the periodic boundary conditions in  ) .",
    "the parameter  @xmath136 is a deterministic parameter , a traditional ingredient of control variate techniques , which is optimized in terms of the estimated variances of the objects at play .",
    "it is crucial to note that the expectation of  @xmath137 is analytically computable . since by construction @xmath138 ,",
    "the technique then consists in approximating the former ( thus the latter ) by an empirical mean . the theoretical study and",
    "the numerical tests in  @xcite show that the variance of @xmath139 is smaller than that of @xmath48 , and hence that the quality of the approximation is improved .    as an illustration",
    ", we use a similar case as in subsection  [ sssec : antithetic ] , which reads as   with @xmath140 . applying the above strategy",
    "provides the results on the left part of figure  [ cv_result ] , where the variance is reduced by a factor close to 6 , that is , comparable to the technique of antithetic variables .",
    "one may next improve on the previous results using a _",
    "second order _ expansion with respect to @xmath109 and including in the control variate the deterministic coefficients corresponding to the case of both one and two defects .",
    "additional parameters playing the role of @xmath136 above are needed , in order to ensure a substantial variance reduction ( see the details in  @xcite ) .",
    "the variance reduction of such a case , of the order of 40 , is represented on the right part of figure  [ cv_result ] .     together with its confidence interval ( computed using @xmath141 i.i.d .",
    "realizations ) . left : we use the classical mc approach ( in blue ) and the control variate approach based on   ( in black ) .",
    "right : we use the classical mc approach ( in blue ) and the second - order control variate approach ( in red ) ( reproduced from  @xcite ) .",
    "[ cv_result],title=\"fig:\",width=278 ]   together with its confidence interval ( computed using @xmath141 i.i.d .",
    "realizations ) . left : we use the classical mc approach ( in blue ) and the control variate approach based on   ( in black ) .",
    "right : we use the classical mc approach ( in blue ) and the second - order control variate approach ( in red ) ( reproduced from  @xcite ) .",
    "[ cv_result],title=\"fig:\",width=278 ]      the variance reduction approach we now overview has been originally introduced by other authors for a slightly different purpose in atomistic solid - state science  @xcite .",
    "it carries the name sqs , abbreviation of _ special quasirandom structures_. the idea there is to sample random atomistic systems by selecting systems of finite size that exhibit all the suitable statistical properties usually only obtained in the asymptotic , bulk limit . for instance , one imposes on each and every finite size sample considered to have the correct volume fraction ( proportion ) of species ( atoms , molecules , ions , etc ) , and/or the correct correlations present in the infinite limit .",
    "to some extent , the approach is actually a particular instance of a general approach , known in many different contexts , and popularized in political sciences because it is at the foundation of many techniques used for opinion polls : _",
    "stratified sampling_. the approach has been adapted to the homogenization context in  @xcite to which we refer the reader for a more detailed presentation .    [",
    "[ mathematical - setting . ] ] mathematical setting .",
    "+ + + + + + + + + + + + + + + + + + + + +    before explicitly formulating the selection mechanism employed in the method , let us motivate it .",
    "consider a formal expansion of the coefficient @xmath66 present in   and   in terms of a small parameter ( even though , as we did in the previous section , we will soon forget about the smallness assumption ) .",
    "assume @xmath66 reads as @xmath142 for some presumably small scalar coefficient @xmath109 , where we assume that @xmath143 and @xmath144 have nice properties .",
    "since @xmath109 is small , @xmath114 is intuitively a perturbation of the matrix - valued field @xmath143 .",
    "at least formally ( and all this has been mathematically justified in our works ) , we may expand all quantities of homogenization theory in powers of the small parameter  @xmath109 .",
    "in particular , the approximations  @xmath145 and @xmath146 of , respectively , the corrector  @xmath147 and the homogenized matrix  @xmath148 on the truncated domain @xmath45 , can be expanded in powers of @xmath109 : @xmath149 inserting the expansion   in the truncated corrector problem  , one easily obtains a hierarchy of equations , the first three of which reading as @xmath150 & \\quad \\text{in } q_n , & \\quad \\text{$u^n_1 $ is $ q_n$-periodic } , \\\\",
    "\\noalign{\\vskip 3pt } - \\hbox{\\rm div}\\,c_0 \\nabla u^n_2 = \\hbox{\\rm div}\\,\\left [ \\chi c_1 \\nabla u^n_1 \\right ] & \\quad \\text{in } q_n , & \\quad \\text{$u^n_2 $ is $ q_n$-periodic}. \\end{array } \\right . \\ ] ] we next deduce from   and   that   holds , with @xmath151    we may now introduce the conditions that we use to select particular configurations of the environment within @xmath45 . for finite fixed @xmath53",
    ", we say that a configuration @xmath152 satisfies the sqs conditions of order up to @xmath135 if , for any @xmath153 , the coefficient @xmath154 in the expansion   exactly matches the corresponding coefficient  @xmath155 of the analogous expansion of the exact homogenized matrix coefficient @xmath148 .",
    "more explicitly , we speak about the sqs condition of    * order 0 if @xmath156 , that is to say , for any @xmath99 , @xmath157.\\ ] ] * order 1 if @xmath158 , that is to say , for any @xmath99 , @xmath159.\\end{gathered}\\ ] ] * order 2 if @xmath160 , that is to say , for any @xmath99 , @xmath161.\\end{gathered}\\ ] ]    it is easily observed that , using such particular configurations that satisfy the sqs conditions of order up to @xmath135 , we have , in the perturbative setting considered here , @xmath162 . taking the expectation over such configurations",
    "therefore formally provides a more accurate approximation of @xmath148 .",
    "of course , the purpose is to apply the approach _ beyond _ the perturbative setting . it can be expected ( and it is indeed observed ) that selecting the configurations using these conditions may reduce the variance .    to make the computation of the right - hand sides of the above conditions practical ( since in theory",
    "they can only be determined using an asymptotic limit , and are therefore as challenging to compute in practice as @xmath50 itself ) , we restrict the generality of our setting .",
    "we assume that , in  , @xmath163 is a deterministic , _ constant _ matrix , @xmath164 is a deterministic , @xmath23-periodic matrix , and that @xmath165 , where @xmath166 are identically distributed , not necessarily independent , bounded random variables . for simplicity",
    ", we also assume here that @xmath167 = 0 $ ] , and refer to  @xcite for more general cases . after a tedious but not complicated calculation , we obtain that the two conditions   rewrite as @xmath168 i_k^\\infty,\\end{aligned}\\ ] ] respectively , where @xmath169 and @xmath170 . in these expressions , @xmath171 and @xmath172",
    "solve @xmath173 = \\hbox{\\rm div}\\,\\left [ \\mathbf{1}_q c_1p\\right ] $ ] in @xmath4 , and @xmath174 = \\hbox{\\rm div}\\,\\left [ \\mathbf{1}_{q } c_1p \\right ] $ ] in @xmath45 with periodic boundary conditions , respectively .",
    "the conditions   are called the sqs  1 and sqs  2 conditions .",
    "on the other hand , in the particular setting chosen , condition   ( sqs  0 , in some sense ) is easily seen to be systematically satisfied when @xmath53 is an integer and the truncated approximation of   that is chosen is the periodic approximation .    [ [ selection - monte - carlo - sampling . ] ] selection monte carlo sampling .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the classical monte carlo sampling consists in successively generating a random configuration  @xmath175 , solving the truncated corrector problem   for that configuration , and computing the empirical mean  @xmath176 as an approximation for  @xmath50 .    in our selection monte carlo sampling",
    ", we systematically test whether the generated configuration satisfies the required sqs conditions , up to a certain tolerance , and reject it if it does not , _ before _ solving the corrector problem   for that configuration and letting it contribute to the empirical mean .    in full generality ,",
    "the cost of monte carlo approaches is usually dominated by the cost of draws , and therefore selection algorithms are targeted to reject as few draws as possible . in sharp contrast ( and this is a very important point which we can not emphasize enough ) , in the present context where boundary value problems are to be solved repeatedly , the cost of draws for the configuration is negligible compared to the cost of the solution procedure for such boundary value problems .",
    "likewise , evaluating the quantities present in   is inexpensive .",
    "therefore , the purpose of the selection mechanism is to limit the number of boundary value problems to be solved , even though this comes at the ( tiny ) price of rejecting many configurations .",
    "we also note that , as for any selection procedure , our selection may introduce a bias ( i.e. a modification of the systematic error in  ) . in practice , we have observed that the gain in variance dominates the bias possibly introduced by the selection approach , and that the approach provides a better approximation of @xmath50 than the standard monte carlo approach .",
    "we have studied the approach theoretically in  @xcite .",
    "we have shown that the estimator provided ( at least in the simplest variant of our approach ) converges to the homogenized coefficient @xmath50 when the truncated domain progressively extends to the whole space .",
    "the efficiency of the approach is also theoretically demonstrated for some particular and simple situations ( such as , again , the one - dimensional setting ) .",
    "a comprehensive experimental study of the approach has been completed .",
    "we include here a typical illustration of the efficiency of the approach .",
    "we again use a similar case as in section  [ sssec : antithetic ] . considering only configurations that exactly satisfy  , we obtain the results shown on the left part of figure  [ fig : sqs_un ] .",
    "it is also possible , among the configurations that exactly satisfy  , to select configurations that satisfy as best as possible the condition  . in practice , we generate 2000 configurations that exactly satisfy   and select among them the 100 configurations for which the difference between the left and the right - hand sides of   is the smallest .",
    "we then obtain the results shown on the right part of figure  [ fig : sqs_un ] .     together with its confidence interval ( computed using @xmath141 i.i.d .",
    "realizations ) as a function of @xmath53 . left : we use the classical mc approach ( in black ) and the sqs approach based on   ( in red ) .",
    "right : we use the classical mc approach ( in black ) and the sqs approach based on   and   ( in blue ) ( reproduced from  @xcite ) .",
    "[ fig : sqs_un],title=\"fig:\",width=278 ]   together with its confidence interval ( computed using @xmath141 i.i.d . realizations ) as a function of @xmath53 . left : we use the classical mc approach ( in black ) and the sqs approach based on   ( in red ) .",
    "right : we use the classical mc approach ( in black ) and the sqs approach based on   and   ( in blue ) ( reproduced from  @xcite ) .",
    "[ fig : sqs_un],title=\"fig:\",width=278 ]    in the case considered here ( for which the contrast in the field @xmath66 is equal to 3 ) , the variance is reduced by a factor 20 when using configurations that exactly satisfy  , and by a factor 300 if   is enforced as well . to compare this variance reduction approach with the two previous ones",
    ", it is however needed to consider a case for which the contrast in @xmath66 is similar . in that case , the variance is reduced by a factor of 9 when using configurations that exactly satisfy  , and by a factor of 60 if   is enforced as well .    in all the test cases we have considered ( see  @xcite for details ) ,",
    "we have observed that the systematic error is kept approximately constant by the approach ( it might even be reduced ) , while the variance is reduced by several orders of magnitude .",
    "such an efficiency is achieved at almost no additional cost with respect to the classical monte carlo algorithm .",
    "we consider the problem   in two dimensions , both for the analysis and for the numerical tests .",
    "we however emphasize that , of course , the approach can be applied to the three dimensional context and that , most likely , the theoretical analysis we review here can also be extended to the three dimensional case .",
    "interestingly , our analysis in  @xcite on a similar problem was performed in both the two and three dimensional settings .",
    "we also assume , for simplicity , that the domain @xmath1 is a polygonal domain .",
    "we define a mesh @xmath177 on @xmath1 , i.e. a decomposition of @xmath1 into polygons each of diameter at most @xmath178 , and denote by @xmath179 the set of all the internal edges of @xmath177 .",
    "note that we mesh @xmath1 and not the perforated domain @xmath180 .",
    "this allows us to use coarse elements ( independently of the fine scale present in the geometry of @xmath180 ) , and leaves us with a lot of flexibility . the mesh does not have to be consistent with the perforations @xmath12 .",
    "some nodes may be in @xmath12 , and likewise some edges may intersect @xmath12 .",
    "see figure  [ fig : perforation ] for a representation of the perforated domain @xmath180 .",
    "contains ( possibly random ) perforations @xmath12 .",
    "the perforated domain is @xmath14 .",
    "the boundary of @xmath180 is the union of @xmath181 ( the part of the boundary of the perforations that is included in @xmath182 ) and of @xmath183 . [",
    "fig : perforation ] ]      to construct our msfem approach , we introduce the space @xmath184 = 0 \\text { for all } e\\in \\mathcal{e}_h , \\quad u=0 \\text { in $ b_{\\varepsilon}$ and on $ \\partial { \\mathcal d}$ } \\end{array } \\right\\}\\ ] ] where  @xmath185 $ ] denotes the jump of  @xmath186 across an edge , and the subspace @xmath187 of @xmath188 .",
    "we define the crouzeix - raviart msfem space @xmath189 as the orthogonal complement of @xmath190 in @xmath188 , where by orthogonality we mean orthogonality for the scalar product @xmath191 .",
    "it is easy to see that we may write @xmath192 where the functions @xmath193 and @xmath194 are respectively defined as follows .",
    "first , for any mesh element @xmath62 that is not a subset of the perforations @xmath12 ( i.e. @xmath195 ) , we define @xmath196 as the solution to @xmath197 with , for each edge @xmath198 of @xmath62 which is an internal edge of @xmath177 , @xmath199 and @xmath200 on @xmath198 for some constant @xmath201 . for any edge @xmath198 of @xmath62 which belongs to @xmath202 , we set @xmath203 on @xmath198 .",
    "second , for any internal edge @xmath204 that is not a subset of the perforations @xmath12 , we denote by @xmath205 and @xmath206 the two triangles sharing this edge , set @xmath207 , and consider @xmath208 solution to @xmath209 with , for each edge @xmath210 which is an internal edge of @xmath177 , @xmath211 and @xmath212 on @xmath213 for some constant @xmath214 and @xmath215 and @xmath216 on @xmath204 for some constant @xmath217 ( with an a priori different constant on the two sides of @xmath204 ) . for any edge @xmath218 , we set @xmath219 on @xmath213 .",
    "although this is not the focus of the present review , which specifically addresses approaches in the presence of randomness , we briefly mention for completeness that the approach we have just introduced enjoys suitable theoretical properties , at least in the periodic setting .",
    "one major reason why we mention this theoretical analysis is that , although there exist many works in the literature dealing with error estimates for msfem type approaches , none of them seems to apply ( to the best of our knowledge ) to problems set on perforated domains . in the periodic",
    "setting ( and unfortunately we do not know how to extend our analysis to the random setting ) , we have established in  @xcite ( in dimension  2 , under technical conditions that are made precise in  @xcite , and using in particular arguments already present in  @xcite ) the following error estimate : @xmath226 for some universal constant  @xmath227 independent from @xmath178 , @xmath13 and @xmath2 , but depending on the geometry of the mesh and other parameters of the problem .",
    "the norm used in the left - hand side of   is the energy norm associated with the form @xmath228 , namely @xmath229 for any @xmath230 .",
    "some important comments are in order .",
    "first of all , the size @xmath13 of the right - hand side of   owes to the fact that , as it is well known theoretically ( see  @xcite ) , the size of the exact solution  @xmath186 ( and thus that of the corresponding approximation  @xmath231 ) is  @xmath13 in @xmath232 norm .",
    "taking this scaling factor into account , the actual rate of convergence for the numerical approach we design is therefore given by @xmath233 .",
    "second of all , if the bubble functions @xmath193 are not included in the discretization space , the estimate   is replaced by @xmath234 and the relative error does not converge to 0 in the limit when @xmath235 and next @xmath236 , which is the relevant limit for our numerical experiments .",
    "this variant without bubbles is considered in our numerical tests for the sake of comparison .",
    "the proof of   is based upon a series of somewhat classical ingredients .",
    "we write @xmath237 where the function @xmath238 is defined as @xmath239 \\ \\phi_e(x),\\ ] ] where the functions @xmath193 and @xmath194 are defined by   and   respectively and @xmath240 is defined as the @xmath241-orthogonal projection of @xmath2 on the space of piecewise constant functions .",
    "the most delicate contribution in the error to estimate is the first one in  .",
    "given the standard finite element interpolation result @xmath242 and the fact that @xmath238 satisfies @xmath243 we expect @xmath244 to be close to the exact solution @xmath186 .",
    "we establish that @xmath245 \\cdot \\nabla \\phi + \\sum_{t\\in \\mathcal{t}_h } \\int_{{\\mathcal d}_{\\varepsilon}\\cap t }   \\left[-\\delta ( { \\varepsilon}^2 w(\\cdot/{\\varepsilon } ) f - v_h ) \\right ] \\phi \\\\ + { \\varepsilon}^2 \\sum_{e \\in \\mathcal{e}_h } \\int_{e \\cap { \\mathcal d}_{\\varepsilon } }   [ [ u - v_h ] ] \\",
    "n \\cdot \\nabla ( w(\\cdot/{\\varepsilon } ) f ) , \\label{eq : decompo_error}\\end{gathered}\\ ] ] where @xmath246 and @xmath247 denotes the periodic corrector associated to the periodic homogenization problem , that is the periodic solution to the problem @xmath248 in @xmath249 , @xmath250 in the perforation @xmath251 ( where @xmath252 is the unit cell ) .",
    "we refer to  @xcite for more background on homogenization theory .",
    "* the first term is small because of a classical homogenization result ( see again  @xcite ) that states that @xmath253 is indeed an accurate approximation of @xmath186 , * the second term is small because , at the leading order term in @xmath13 , the first factor in the integrand is equal to @xmath254 which is small due to  , * the third term is estimated as an integral involving highly oscillatory periodic functions .",
    "we now solve   for some particular settings , comparing our approach with other existing msfem type methods .",
    "our primary focus is the possible intersections of the perforations with the edges of mesh elements .",
    "we address this question in section  [ ssec : num - rob ] , and check there the robustness of our approach with respect to the ( temporarily deterministic , but still variable ) location of the perforations : the fact that the mesh intersects , or does not intersect , the perforations has a very little influence on the ( good ) accuracy of our approach , in contrast to other approaches .",
    "our numerical tests culminate with a couple of test - cases that show the excellent performance of our approach in the presence of randomness .    for the sake of completeness ,",
    "we begin our numerical tests with a comparison ( for a given set of fixed perforations ) with existing numerical msfem type approaches , in both cases when we enrich or not the variational space with bubble functions ( in the case of our crouzeix - raviart msfem approach , the functions @xmath193 defined by  ) .",
    "this is the purpose of subsection  [ ssec : num - comp ] .",
    "we mesh @xmath1 and not the perforated domain @xmath180 .",
    "some nodes may thus be in the perforations @xmath12 , some edges may intersect @xmath12 , etc .",
    "we then face difficulties when using the msfem variant with linear boundary conditions ( a variant that we compare here with our approach ) to directly solve  . indeed , properly defining the msfem basis functions e.g. when edges intersect @xmath12 would not be straightforward .",
    "similar difficulties arise for the oversampling variant .",
    "for this reason , we do not consider  , but the penalized version of that problem as mentioned above .",
    "in contrast , note that the crouzeix - raviart variant we introduce here can be used either on   or on its penalized version .",
    "we solve   on the domain @xmath255 , with the right - hand side  @xmath256 , and we take @xmath12 the set of discs of radius @xmath257 periodically located on the regular grid of period @xmath258 .",
    "the reference solution is computed on a mesh of size @xmath259 .      * the standard q1 finite element method on the coarse mesh of size @xmath178 .",
    "of course , we do not expect that method to perform well for this multiscale problem and we only consider it as a `` normalization '' . * the msfem with linear boundary conditions .",
    "although this method is now a bit outdated , it is still considered as the primary msfem approach , upon which all the other variants are built . * the msfem with oscillatory boundary conditions .",
    "this variant is restricted to the two - dimensional setting .",
    "it uses boundary conditions provided by the solution to the oscillatory ordinary differential equation obtained by taking the trace of the original equation on the edge considered .",
    "the approach performs fairly well on a number of cases , although it may also fail .",
    "* the variant of msfem using oversampling .",
    "this variant is often considered as the `` gold standard '' , although it includes a parameter ( the oversampling ratio ) , the value of which should be carefully chosen .",
    "when this parameter is taken large , the method becomes ( possibly prohibitively ) expensive .",
    "in addition , we consider for each of those approaches , and for our specific crouzeix - raviart type approach , two variants : one with , and the other without a specific enrichment of the basis set elements using bubble functions .",
    "for all approaches but the crouzeix - raviart type approach that we propose , the bubble @xmath260 on the quadrangle @xmath26 is defined as the solution to @xmath261 for our crouzeix - raviart approach , we recall that the bubble @xmath260 is defined by  .    for a given mesh size @xmath178 , the cost for computing the basis functions ( offline stage ) varies from one msfem variant to the other .",
    "however , for a fixed @xmath178 , all methods without ( respectively , with ) bubble functions essentially share the same cost to solve the macroscopic problem on @xmath1 ( online stage ) .",
    "more precisely , for a given cartesian mesh , and when using variants including the bubble functions , there are 1.5 times more degrees of freedom in our crouzeix - raviart approach than in the three alternative msfem approaches mentioned above . since a logarithmic scaling is used for the x - axis in the figures below , this extra cost does not change the qualitative conclusions we draw below .",
    "the numerical results we have obtained in the regime where the meshsize @xmath178 is of the order of , or larger than , the parameter @xmath13 are presented on  figure  [ fig : errors ] .",
    "for all values of the meshsize  @xmath178 , and for both the @xmath241 and the broken @xmath232 norms , a definite superiority of our approach over all other approaches is observed , and the interest of adding bubble functions to the basis set is , for each approach , also evident .",
    "a side remark is the following . on figure  [ fig : errors ] , we observe that , when using bubble functions , the error decreases as @xmath178 increases .",
    "this might seem counterintuitive at first sight .",
    "note however that , when @xmath178 increases , the cost of computing each basis function increases , as we need to solve a local problem ( discretized on a mesh of size @xmath262 controlled by the value of @xmath13 ) on a larger coarse element .",
    "in contrast to traditional fem , increasing @xmath178 does not correspond to reducing the overall computational cost .",
    "for msfem approaches , increasing @xmath178 actually corresponds to decreasing the online cost but increasing the offline cost .",
    "the regime of interest is that of moderate values of @xmath178 , for which the offline stage cost is acceptable .",
    "we only show the right part of figure  [ fig : errors ] ( corresponding to large values of @xmath178 , leading to a prohibitively expensive offline stage ) for the sake of completeness",
    ".    , left , and @xmath232-broken , right ) errors with various approaches in the regimes @xmath263 and @xmath264 : fem  the standard q1 finite elements , no os  msfem with linear boundary conditions , osc  msfem with oscillatory boundary conditions , os  msfem with oversampling ( where the size of the quadrangles used to compute the basis functions is @xmath265 ) , cr  the crouzeix - raviart type msfem approach we propose .",
    "results for all these methods are represented by solid lines .",
    "the dashed lines correspond to the variants of these methods where we enrich the finite element spaces using bubble functions ( reproduced from  @xcite ) .",
    "[ fig : errors],title=\"fig : \" ] , left , and @xmath232-broken , right ) errors with various approaches in the regimes @xmath263 and @xmath264 : fem  the standard q1 finite elements , no os  msfem with linear boundary conditions , osc  msfem with oscillatory boundary conditions , os  msfem with oversampling ( where the size of the quadrangles used to compute the basis functions is @xmath265 ) , cr  the crouzeix - raviart type msfem approach we propose .",
    "results for all these methods are represented by solid lines .",
    "the dashed lines correspond to the variants of these methods where we enrich the finite element spaces using bubble functions ( reproduced from  @xcite ) .",
    "[ fig : errors],title=\"fig : \" ]      in this section , we perform a series of tests with the specific purpose of testing the robustness of the approach with respect to intersections of the mesh and the perforations .",
    "given the flexibility of crouzeix - raviart type finite elements in terms of boundary conditions , we expect our approach to be particularly effective ( and therefore considerably superior to other approaches ) when some edges of the mesh happen to intersect perforations of the domain . the more frequent such intersections , the more important the difference .",
    "we solve   on the domain @xmath255 , with a constant right - hand side  @xmath266 , and we take @xmath12 the set of discs of radius @xmath267 periodically located on the regular grid of period @xmath268 .",
    "we compute the reference solution , and consider 3 variants of msfem : the linear version , the oversampling version and the crouzeix - raviart version .",
    "the last three approaches are implemented in the variant that includes bubble functions in the basis set and applied with a mesh of size @xmath269 .",
    "we perform two sets of numerical experiments .",
    "they are identical except for what concerns the relative position of the mesh with respect to the perforations .",
    "the difference between the two sets of tests is that , from one set of tests to the other one , the perforations are shifted by @xmath270 in the directions @xmath271 and @xmath272 . in our test  1 , no edge intersects any perforation , while , on our test  2 , many edges actually intersect perforations ( see figure  [ fig : decalage - test1 ] ) .",
    "to some extent , the situation of test 1 is the best case scenario ( where as few edges as possible intersect the perforations ) and the other situation is the worst case scenario .",
    "the numerical solutions are shown on figure  [ fig : decalage - test1 ] .",
    "the numerical errors , computed both in @xmath241 and @xmath232-broken norms , are correspondingly displayed on tables  [ table : test1 ] and  [ table : test2 ] , respectively .",
    "more than the actual values obtained for each case , this is the trend of difference between table  [ table : test1 ] and table  [ table : test2 ] that is the practically important feature .",
    "a comparison between the two tables indeed show that , qualitatively and in either of the norms used for measuring the error , the linear version and the oversampling version of msfem are both much more sensitive to edges intersecting perforations than the crouzeix - raviart version of msfem .",
    "in particular , the gain of our approach with respect to the linear version of msfem is much higher in our test 2 ( which is , from the geometrical viewpoint , the worst case scenario ) than in test 1 .",
    "this confirms the intuition of a better flexibility of our approach .",
    "this also allows for expecting a much better behavior of that approach for non - periodic multiscale perforated problems for which it is extremely difficult , practically , to avoid repeated intersections of perforations with mesh edges .",
    "this is confirmed by the numerical experiments we perform in the next paragraph .",
    "we have tested several examples of randomly distributed perforations , two of them being shown on figure  [ fig : ex - non - per ] . for each of them , the domain @xmath273 is meshed using quadrangles of size @xmath178 , with @xmath274 .",
    "the reference solution is again computed on a mesh of size @xmath259 .     according to the uniform distribution .",
    "left : the perforations are 100 rectangles , the width and height of which are uniformly distributed between 0.02 and 0.05 .",
    "right : the perforations are 60 rectangles , the width ( resp .",
    "the height ) of which is uniformly distributed between 0.02 and 0.04 ( resp .",
    "0.02 and 0.4 ) ( reproduced from  @xcite ) .",
    "[ fig : ex - non - per],title=\"fig : \" ]   according to the uniform distribution . left : the perforations are 100 rectangles ,",
    "the width and height of which are uniformly distributed between 0.02 and 0.05 .",
    "right : the perforations are 60 rectangles , the width ( resp .",
    "the height ) of which is uniformly distributed between 0.02 and 0.04 ( resp .",
    "0.02 and 0.4 ) ( reproduced from  @xcite ) .",
    "[ fig : ex - non - per],title=\"fig : \" ]    errors are shown on figure  [ fig : errors - non - per3 ] ( resp .",
    "figure  [ fig : errors - non - per5 ] ) for the test - case shown on the left ( resp .",
    "right ) part of figure  [ fig : ex - non - per ] .",
    "our approach provides results at least as accurate as , and often more accurate than the msfem approach with oversampling on quadrangles of size @xmath265 .    , left , and @xmath232-broken , right ) errors with the same approaches as on figure  [ fig : errors ] for the test - case shown on the left part of figure  [ fig : ex - non - per ] ( reproduced from  @xcite ) .",
    "[ fig : errors - non - per3],title=\"fig : \" ] , left , and @xmath232-broken , right ) errors with the same approaches as on figure  [ fig : errors ] for the test - case shown on the left part of figure  [ fig : ex - non - per ] ( reproduced from  @xcite ) .",
    "[ fig : errors - non - per3],title=\"fig : \" ]    , left , and @xmath232-broken , right ) errors with the same approaches as on figure  [ fig : errors ] for the test - case shown on the right part of figure  [ fig : ex - non - per ] ( reproduced from  @xcite ) .",
    "[ fig : errors - non - per5],title=\"fig : \" ] , left , and @xmath232-broken , right ) errors with the same approaches as on figure  [ fig : errors ] for the test - case shown on the right part of figure  [ fig : ex - non - per ] ( reproduced from  @xcite ) .",
    "[ fig : errors - non - per5],title=\"fig : \" ]    * acknowledgements : * the work of the two authors is partially supported by eoard under grant fa8655 - 13 - 1 - 3061 and by onr under grant n00014 - 15 - 1 - 2777 .",
    "the authors would like to thank their many friends and collaborators on the issues presented here , in particular x. blanc ( paris 7 ) , p .-",
    "l .  lions ( collge de france ) , a.  lozinski ( besanon ) and w.  minvielle .      ,",
    "_ introduction to numerical stochastic homogenization and the related computational challenges : some recent developments _ , in _ multiscale modeling and analysis for materials simulation _ , w. bao and q. du eds . ,",
    "lecture notes series , institute for mathematical sciences ( national university of singapore ) , vol .",
    "22 , 2011 , pp .  197 - 272 .          , _ mixed multiscale methods for heterogeneous elliptic problems _ , in _ numerical analysis of multiscale problems _ , i.g .",
    "graham , t.y .",
    "hou , o. lakkis and r. scheichl eds . ,",
    "lecture notes in computational science and engineering , vol .",
    "83 , springer , 2011 , pp .",
    "243 - 283 .      ,",
    "_ variance reduction in stochastic homogenization : the technique of antithetic variables _ , in _ numerical analysis of multiscale computations _ , b.  engquist , o.  runborg and r.  tsai eds . ,",
    "lecture notes in computational science and engineering , vol .",
    "82 , springer , 2012 , pp .  47 - 70 .    , _ variance reduction in stochastic homogenization using antithetic variables _ , markov processes and related fields 18 ( 2012 ) 31 - 66 ( preliminary version available at http://cermics.enpc.fr/@xmath275legoll/hdr/fl24.pdf ) .              , _ a reduced basis approach for variational problems with stochastic parameters : application to heat conduction with variable robin coefficient _ , comput . methods appl .",
    "mech . eng .",
    "198(41 - 44 ) ( 2009 ) 3187 - 3206 .        , _",
    "approximation numrique dune classe de problmes en homognisation stochastique [ numerical approximation of a class of problems in stochastic homogenization ] _ , c. r. acad .",
    "srie i 348 ( 2010 ) 99 - 103 .                          , _ some numerical approaches for `` weakly '' random homogenization _ , springer lecture notes in computational science and engineering , g. kreiss et al .",
    "( eds . ) , numerical mathematics and advanced applications 2009 , pp .  29 - 45 .        , _ msfem  la crouzeix - raviart for highly oscillatory elliptic problems _ , in * partial differential equations : theory , control and approximation , in honor of the scientific heritage of jacques - louis lions * , ph.g .",
    "ciarlet , t. li and y.  maday eds . ,",
    "springer , 2014 , pp .  265 - 294 .                          , _ nonconforming multiscale finite element method for stokes flows in heterogeneous media .",
    "part i : methodologies and numerical experiments _ , siam multiscale modeling & simulation 13(4 ) ( 2015 ) 1146 - 1172 ."
  ],
  "abstract_text": [
    "<S> we overview a series of recent works addressing numerical simulations of partial differential equations in the presence of some elements of randomness . </S>",
    "<S> the specific equations manipulated are linear elliptic , and arise in the context of multiscale problems , but the purpose is more general . on a set of prototypical situations , we investigate two critical issues present in many settings : variance reduction techniques to obtain sufficiently accurate results at a limited computational cost when solving pdes with random coefficients , and finite element techniques that are sufficiently flexible to carry over to geometries with random fluctuations </S>",
    "<S> . some elements of theoretical analysis and numerical analysis are briefly mentioned . </S>",
    "<S> numerical experiments , although simple , provide convincing evidence of the efficiency of the approaches . </S>"
  ]
}