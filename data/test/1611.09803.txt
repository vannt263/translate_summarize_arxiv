{
  "article_text": [
    "the leading optical flow algorithms to date , with few exceptions , are not end - to - end deep learning . while some of them employ deep matching scores for estimating the best match in image i for every location in image i , almost all methods employ multiple steps that do not involve learning . with the current affinity toward end - to - end deep learning solutions ,",
    "the existence of large training datasets , and many concurrent contributions in the field of deep optical flow and related fields , one may wonder why this is the case .    out of the four steps of modern optical flow pipelines : matching , filtering , interpolation and variational refinement , we focus on the third . in this step ,",
    "a sparse list of matches is transformed into dense optical flow maps .",
    "it is one of the most crucial steps and without the availability of the epicflow method  @xcite , which currently dominates this step , a large number of sparse matching techniques would not have been competitive enough to gain attention .",
    "epicflow is extremely effective and is built on top of solid computer vision foundations .",
    "however , despite using sophisticated heuristics for improved runtime , it is still rather slow and as a non - learning method , it is bounded in the performance it can deliver .",
    "replacing epicflow by a deep learning method is harder than it seems at first glance .",
    "feedforward neural networks excel in analyzing image information , but neuroscience tells us that in biological networks , lateral and top - down feedback loops are involved in solving cases where the information is missing or corrupted at random locations .",
    "artificial feedback networks are slower than feedforward networks , harder to train , and have not proven themselves in the practice of computer vision .",
    "we note that feedback networks with a predefined number of feedback iterations can be unrolled into deep feedforward networks with one major caveat  while in most feedforward networks , the supervision flows from the top down , in feedback networks , the supervision occurs at each iteration . to resolve this",
    ", we equip our network with supervision at every layer .    inspired by neuroscience",
    ", we also suggest a loss involving lateral dependencies . here , too , we replace the process of lateral feedback during run - time with additional supervision during training . in this way",
    ", the feedforward network learns how to mimic a network with lateral feedback loops by utilizing the training labels .    taken together ,",
    "our contributions are : ( a ) we propose , for the first time , to the best of our knowledge , a neural network based sparse - to - dense interpolation for optical flow .",
    "our network performs better than the current state of the art , it is robust and can be adjusted to different matching algorithms and serve as the new default interpolation method in optical flow pipelines .",
    "( b ) we introduce a new lateral dependency loss , embedding the correlations between neighbors into the learning process .",
    "( c ) we define a novel architecture involving detour networks in each layer of the network .",
    "the new architecture provides a substantial increase in performance .",
    "( d ) we solidify the importance of motion boundaries in learning dense interpolation for optical flow .",
    "[ [ interpolation - in - the - visual - cortex . ] ] interpolation in the visual cortex . + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the visual system often receives a noisy and missing input .",
    "however it is known to robustly denoise and fill - in the gaps in the input image .",
    "this phenomenon termed - perceptual filling - in  @xcite , was reported to occur for occlusions  @xcite , illusory contours and surfaces  @xcite , in the `` blind spot''@xcite and in visual scotomas  @xcite .",
    "different features in the visual stimulus are filled in , including brightness@xcite , color@xcite , texture and motion@xcite .",
    "the neurophysiological mechanism underlying perceptual filling - in is still under debate .",
    "however many have found evidence for the existence of a neuronal filling - in mechanism  @xcite . in this mechanism , neurons that are retinotopically mapped to visible or salient parts of an image ( such as the edges ) are activated first .",
    "this initial activation is followed by a later spread to neurons that are mapped to the missing parts , resulting in a complete representation of the image @xcite .",
    "this activation spread is mediated by both lateral connections within areas in the cortex as well as top down connections  @xcite .",
    "it was also shown to be very sensitive to edges in the image , usually originating in edges and stops when encountered with edges  @xcite .",
    "finally , neuronal filling - in was found to take place in multiple areas in the visual cortex hierarchy , from v1 and v2  @xcite via v4  @xcite and in higher areas  @xcite .",
    "we designed our interpolation network to incorporate three concepts inspired by neuronal filling - in : the interactions between neighbor neurons , multi - layer supervision and the importance of edges .",
    "neighbor neurons interactions can be modeled by recurrent connections within a layer , such as the model suggested by liang and hu  @xcite .",
    "while the anatomic resemblance of such models to the cortex is appealing , in reality , they are unfolded to a feedforward network with shared weights . we , therefore , preferred to utilize the loss to force the interaction between neighbor neurons while using more simple , strictly feedforward networks , which were shown to perform extremely well for vision tasks while excelling in training time and simplicity .",
    "[ [ interpolation - for - optical - flow . ] ] interpolation for optical flow .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    most current optical flow approaches are based on a four phase pipeline .",
    "the first phase matches pixels between the images in the image pair , based on nearest neighbor fields or feature matching techniques ( hand engineered or learned )  @xcite .",
    "the second phase filters matches with low confidence producing a noisy and missing flow map@xcite .",
    "the missing pixels usually undergo large displacements , a significant shift in appearance , or are occluded in one of the images .",
    "therefore , a third phase is needed to interpolate the missing parts and reduce the noise .",
    "a fourth and final phase applies refinement to the interpolated dense map from phase 3 .",
    "the best and most used algorithm for optical flow interpolation ( the third phase ) is currently epicflow  @xcite .",
    "epicflow computes the flow of each pixel using a weighted sum of the pixel s local environment .",
    "locality is defined by a geodesic distance function based on the image edges that correspond to the motion boundaries .",
    "this edges aware approach yields good interpolation results for occluded pixels and large displacement .",
    "epicflow excels in interpolation .",
    "however it is less robust to noisy matches , especially in the vicinity of large missing regions , as displayed in their figure 8 .",
    "this sensitivity to noise is increased by the fact that the noise produced by each matching algorithm displays slightly different patterns . to overcome these difficulties ,",
    "a trained algorithm like ours that learns the noise patterns is more suitable .",
    "we suggest a new interpolation method based on a deep convolutional neural network .",
    "the method is applied in a feedforward manner and leads to an improvement in both accuracy and speed over the epicflow method .    finally , it is noteworthy that some of the new optical flow methods do not rely on the aforementioned pipeline @xcite .",
    "one interesting example is presented by dosovitskiy et al .",
    "@xcite in their flownet model .",
    "they present an end to end convolutional neural network for optical flow that outputs a dense flow map .",
    "while their method does not reach the state of the art performance , it runs in real - time and demonstrates the power of feedforward deep learning in optical flow estimation .",
    "the optical flow dense interpolation problem is defined in the following way : given a sparse and noisy set of matches between pixels @xmath0 , we want to approximate the dense flow field @xmath1 between a source image @xmath2 and a target image @xmath3 . to solve this problem",
    ", we use a fully convolutional network with no pooling .",
    "the main branch of the network consists of ten layers each applying a 7x7 convolution filter followed by an elu  @xcite non - linearity ( fig .",
    "[ fig : net_arch ] ) .",
    "we use zero - padding to maintain the same image dimensions at each layer of the network .",
    "the input to our algorithm is a set of sparse and noisy matches @xmath4 .",
    "these matches can be produced by any third party matching algorithm . in our experiments",
    ", we used several of the leading matching algorithms : flowfields ( ff )  @xcite , cpm - flow ( cpm )  @xcite , discreteflow ( df )  @xcite , and finally deepmatching ( dm )  @xcite . from the matches",
    ", we produce a sparse flow map of size @xmath5 where @xmath6 and @xmath7 are the height and width of the image pair .",
    "each pixel is initialized with the displacement to its match in the x and y axis . missing pixels",
    "are filled with zeros . apart from the sparse flow map , we add two additional matrices as guiding inputs to the networks : a binary mask of the missing pixels , and the edges map ( fig . [",
    "fig : net_arch ] ) .",
    "we create a binary mask of all the missing pixels to indicate their position to the network ( since zero can be a valid displacement value ) .",
    "it was shown by others  @xcite to enhance performance in deep neural networks for inpainting .",
    "the last input to the network is an edges map of one of the images in the image pair for which the flow is computed .",
    "the contours of an image was shown to be a key feature in image processing in the early visual cortex  @xcite .",
    "epicflow  @xcite already showed the benefit of the image edges as motion boundaries for optical flow estimation . in our work , we show evidence that a learning system also benefits from receiving the edges as input ( see fig .  [",
    "fig : edges ] ) .",
    "we used an off - the - shelf edges detector - the `` structured edges detector '' ( sed )  @xcite - the same one used by epicflow .",
    "all the inputs are stacked together and downsampled by 8 to form an @xmath8 matrix .",
    "rather then a simple stacking , we also considered different ways of introducing the edges map into the network . among others ,",
    "we have tried feeding the edges to all layers in the deep network , feeding the map to a different network and combining its output with the main branch in a deeper layer as well as constructing different networks to deal with pixels around the edges and far from the edges .",
    "however , we found that the simplest approach used here produced the best results .",
    "to optimize the network results , we used the epe ( end point error ) loss function , which is one of the standard error measures for optical flow .",
    "it is defined as the euclidean distance between two flow pixels : @xmath9 [ eq : epe ] the loss for an image pair was the average epe over pixels : @xmath10 [ eq : epe_loss]where @xmath11 is the network prediction , @xmath12 is the ground truth flow map and n is the number of pixels in the flow map .",
    "this standard loss by itself does not yield good enough results ( see sec .",
    "[ sec : exp_loss_var ] ) . we , therefore , resort to cortical neuronal filling - in processes in our search for better losses .",
    "neuronal filling - in is characterized by spatial spread of activation .",
    "there is evidence that the activation spread is mediated by both lateral and top - down connections . to imitate the lateral dependency between neighbors in the network ,",
    "we define a new lateral dependency loss .",
    "this loss pushes the distance between neighboring pixels to be similar to the distance in the ground truth flow .",
    "it is defined in the following way : @xmath13 [ eq : lateral_lass ] the proposed loss term directly includes the local spatial dependencies within the training process similar to what happens in the early stages of the visual cortex  @xcite .",
    "top - down connections are tricky to implement in artificial neural networks .",
    "we , therefore , use the loss function , which is the main feedback to the network , to imitate top - down connections .",
    "also inspired by the evidence that neuronal filling - in takes place in many layers in the visual system hierarchy  @xcite , we used detour networks connecting each and every layer directly to the loss function .    during training , the loss function served as top down information pushing each layer to perform interpolation in the best possible manner .",
    "the detour networks were kept simple : aside from the main branch of the network , each of the layer s activations was transformed into a 2 channels flow map using a single convolution layer with linear activations ( no nonlinearity , see fig .",
    "[ fig : net_arch ] ) .",
    "each of the flow maps produced by the detour networks was compared to the ground truth flow map using the epe and ld losses .",
    "the final network loss was the weighted sum of all the losses : @xmath14 where @xmath15 , @xmath16 and @xmath17 are the weight , epe loss and ld loss of layer l. we found that weights of 0.5 for each of the middle layers and 1 for the last yielded the best results . for inference ,",
    "we use only the last detour layer output - the one connected to the last layer of the network s main branch .",
    "our approach has some similarities to the one used in the inception model introduced by szegedi et al .",
    "@xcite , which employs auxiliary networks with independent losses during training .",
    "they found it to provide regularization and combat the vanishing gradients problem .",
    "however , in their network , the first auxiliary network was added in the tenth layer . we found that adding a detour network for each layer gave the best results .",
    "szegedi et al.s auxiliary networks were also built of several layers and performed some computation within them .",
    "we found that the simplest linear convolution was the best architecture .",
    "additional layers or non - linearities did not improve the performance of the network .        taken together , our network was equipped with mechanisms with which it could imitate interpolation in the visual cortex .",
    "interestingly , not only did it learn to perform interpolation of regular motion , it also performed strikingly similar to the visual cortex when presented with an illusion .",
    "figure [ fig : kanizsa ] shows the interpolation applied by different variants of our network and epicflow on a given kanizsa like motion pattern .",
    "the network never saw such a pattern in training time .",
    "when masking parts of the image , our network interpolates the motion pattern from the background and the interior . the propagation from the background stops in the borders of the imaginary square contour ( marked by a dashed line ) much like our visual perception .",
    "importantly , only the real edges , not those of the imaginary contour , were fed to the network .",
    "other networks that were not equipped with all the tools we presented as well as epicflow performed different levels of a simpler interpolation .",
    "our fully convolution with zero padding and no pooling network produces an output in the same size of the input .",
    "we , therefore , upsample the output by a factor of 8 using bi - linear interpolation . like others before us  @xcite , we found that using the variational energy minimization post - processing used in epicflow  @xcite slightly improved our final prediction ( 0.25px . gain in mean epe ) .",
    "we employ the same parameters as epicflow , as appears in their section 4 .",
    "we report the results of our network on the sintel  @xcite , kitti 2012  @xcite and kitti 2015  @xcite datasets .",
    "we also show the effectiveness of different features in the network : the lateral dependency loss , the multi - layer loss and the edges input",
    ".      * preprocessing . * as described in section [ sec : net_arch ] , the network receives a 4 channel input composed of 2 sparse flow channels given as the output of a matching algorithm , a binary mask and the edges map . to reduce training time",
    ", we downsample all the inputs by 8 ( some matching algorithms output a downsampled version by default  @xcite ) . to reduce the number of missing pixels in training time we apply bidirectional averaging ( see supplementary ) .",
    "we apply flipping as our only data augmentation method .",
    "other transformations such as scaling , shearing , rotating and zooming did not improve the network performance , probably due to the interpolations that accompany them and drastically change the flow map .",
    "* datasets . *",
    "we evaluated our network on the three main optical flow benchmarks : mpi sintel @xcite is a collection of several scenes taken from a graphical animation movie .",
    "each scene consists of several consecutive frames for which a dense ground truth flow map is given ( a total of 1041 training image pairs ) .",
    "the scenes are diverse and include battle scenes with challenging large displacements .",
    "kitti 2012 @xcite is composed of real world images taken from a moving vehicle ( 194 training images ) . and kitti 2015 ,",
    "@xcite is similar to the kitti 2012 dataset but with more challenging scenes ( 200 training images ) .",
    "since convolutional networks demand a large set of training data , we use the same approach used by dosovitskiy et al .  @xcite . for initial pre - training ,",
    "we use the flying chairs dataset that they introduced .",
    "this is a relatively large synthetic dataset ( 22,875 image pairs ) composed of chair objects flying over different backgrounds .",
    "we train on all the dataset and use a sub - sample of the sintel dataset as validation . due to time constraints",
    ", we could not apply all matching algorithms to the big flying chairs dataset .",
    "we , therefore , used only flowfields  @xcite for this initial training on flying chairs .",
    "additional fine tuning was applied using the training sets of specific benchmarks and for the specific matching algorithm , see supplementary . in all presented experiments to follow , we pre - train the networks on flying chairs and fine tune on sintel using the flowfields matching algorithm - unless stated otherwise .",
    "all the analysis , results , and visualizations are done without the variational post - processing except for the benchmark results .",
    "* optimization .",
    "* we use adam  @xcite with standard parameters ( @xmath18 , @xmath19 ) .",
    "a learning rate of @xmath20 for the pre - training and @xmath21 for the fine tuning is used .      .comparing losses for the sintel final pass validation set , trained on the output of flowfields .",
    "[ cols=\"<,^\",options=\"header \" , ]     we found that the training process results declined when the average number of missing pixels in the training flow maps was too high .",
    "some of the matching algorithms , in particular deepmatching , did produce sparse maps like these . to tackle this problem",
    ", we calculate the flow map bidirectionally ( from @xmath2 to @xmath3 and from @xmath3 to @xmath2 ) using the matching algorithm .",
    "we invert the second flow map and average the two maps .",
    "this simple step solves the sparseness problem for all of the matching algorithms we used .",
    "this procedure added to the computation time of our method .",
    "however most matching algorithms already compute bidirectional maps for consistency check and false matches filtering purposes and so we did not need to apply them twice .",
    "importantly , we found that the bidirectional averaging is critical mostly for training the network and specifically for deepmatching outputs .",
    "training on flowfields non averaged maps , for instance , gives comparable results to training with the averaged maps .",
    "interestingly , applying epicflow on the bidirectional average of the deepmatching algorithm output also slightly improved their results ( table [ tab : bidi_avg ] ) . for consistency reasons ,",
    "we choose to present in this paper the results gained using the bidirectional averaged maps for training and evaluation .",
    "however , for all matching algorithms using only the original , non averaged map , in evaluation time yields results similar to those presented ( table [ tab : bidi_avg ] ) .",
    "the analysis in this section was performed without the variational post processing for both our method and epicflow .",
    "the validation sets for both kitti2012 and kitti2015 datasets were the last 20% of the pairs in each .",
    "for the sintel dataset , due to the temporal dependencies within scenes which are a pitfall for over - fitting , we define 4 whole scenes including 167 image pairs as a validation set rather than a random sample .",
    "we use the same validation set in the pre - training and sintel fine tuning phases .",
    "early stopping served as our only regularization method .",
    "the number of steps before performing the stop was 5000,1000 and 400 for training on the flying chairs , sintel and kitti datasets respectively .",
    "we use 4 rounds of early stopping in which we divide the learning rate by two starting with a learning rate of @xmath20 for the pre - training and @xmath21 for the fine tuning .",
    "after 4 rounds , we choose the weights that yielded the best performance on the validation set throughout the training .",
    "to further investigate our performance compared to epicflow , we looked at the epe over all noisy pixels ( pixels with @xmath22 ) and missing pixels from all the flow maps in the sintel validation set . to make a fair comparison for this analysis",
    ", we performed our prediction without bidirectional averaging so the number of noisy and missing pixels in the input to our network and epicflow was identical .",
    "we found that our performance were better than epicflow s in both of these areas , but it was significantly better only for the missing pixels ( @xmath23 difference between epic epe and our epe : @xmath24 , @xmath25 pixels ; paired t - test p=0.42 , @xmath26 for noisy and missing pixels respectively , n=167 ) .",
    "this emphasize our superiority over epicflow , especially in large missing regions , as was demonstrated in figure 5 of the main text .",
    "the supplemental figures presented here show further examples on top of the ones presented in the figures in the main text .",
    "figure [ fig : layers_supp ] shows the progression of the prediction process in the network as appears in the output of the different detour layers , similar to figure 3a in the main text .",
    "notice here also how the network first performs a simple interpolation and then refines the predictions in the deeper layers .",
    "figure [ fig : edges_supp ] presents the predictions of networks with and without the edges input , similar to figure 4a in the main text .",
    "the progression of the predictions in the different layers in those network is presented in figure [ fig : edges_layerssupp ] .",
    "these two figures illustrate how the edges input function in the network - acting as a stopper for spread of activation .",
    "notice how the bottom `` simple interpolation '' layers performs similarly in both networks .",
    "however , starting from layer 4 , the refinement process is very different .",
    "the network that receives the edges as input utilizes them to act as motion boundaries .",
    "finally , figures [ fig : epic_supp ] , [ fig : epic_kitti2012_supp ] and [ fig : epic_kitti2015_supp ] shows additional examples to the ones presented in figure 5 in the main text , for the comparison between the performance of our method and epicflow on the sintel , kitti 2012 and kitti 2015 validation sets ."
  ],
  "abstract_text": [
    "<S> sparse - to - dense interpolation for optical flow is a fundamental phase in the pipeline of most of the leading optical flow estimation algorithms . </S>",
    "<S> the current state - of - the - art method for interpolation , epicflow , is a local average method based on an edge aware geodesic distance . </S>",
    "<S> we propose a new data - driven sparse - to - dense interpolation algorithm based on a fully convolutional network . </S>",
    "<S> we draw inspiration from the filling - in process in the visual cortex and introduce lateral dependencies between neurons and multi - layer supervision into our learning process . </S>",
    "<S> we also show the importance of the image contour to the learning process . </S>",
    "<S> our method is robust and outperforms epicflow on competitive optical flow benchmarks with several underlying matching algorithms . </S>",
    "<S> this leads to state - of - the - art performance on the sintel and kitti 2012 benchmarks . </S>"
  ]
}