{
  "article_text": [
    "the problem of constructing fast algorithms for multivariate approximation of scattered data points has recently interested many researchers , who work in various areas of applied mathematics and scientific computing such as interpolation , approximation theory , neural networks , computer aided geometric design ( cagd ) and machine learning , to name a few .",
    "so we often need to have numerical algorithms , which allow us to efficiently deal with a large number of points , not only in one or two dimensions but also in higher dimensions , as it usually occurs in several applications ( see , e.g. , @xcite and references therein ) .",
    "though there exist several numerical algorithms and alternative techniques for bivariate interpolation to scattered data , the problem of efficiently approximating many thousands or millions of three dimensional data does not seem to be much considered in the literature , with the exception of a few cases such as in @xcite ; a comparison of radial basis function ( rbf ) methods in the 3d setting can be found in @xcite .",
    "since mesh - based methods require some sort of an underlying computational mesh , i.e. any triangulation of the domain , their construction is a rather difficult task , already in two dimensions , where the mesh generation turns out usually to be one of the most time consuming part .",
    "for this reason , in the following we focus on a _ meshfree _ or _ meshless _ approximation .",
    "more precisely , here we consider the partition of unity method , which involves the use of rbfs as local approximants and of locally supported weight functions ( see @xcite ) .",
    "further details on the origin of the partition of unity method can be found in @xcite .",
    "moreover , some other examples of local approaches involving modified shepard s methods and different searching procedures can be found in @xcite .",
    "starting from the previous work @xcite , where an efficient algorithm with a new cell - based searching procedure is presented for bivariate interpolation of large scattered data sets , in this paper we directly extend it to trivariate case , obtaining in this way a new fast algorithm for interpolation , which can briefly be summarized in three stages as follows :    1 .",
    "partition the domain into a suitable number of cubes ; 2 .",
    "consider an optimized cube - partition searching procedure establishing the minimal number of cubes to be examined , in order to localize the subset of nodes belonging to each subdomain ; 3 .",
    "apply the partition of unity method combined with local rbfs .",
    "in particular , the algorithm is characterized by the construction of a _ cube - partition searching procedure _",
    ", whose origin comes from the repeated use of a _ quicksort _ routine with respect to different directions , which enables us to pass from unordered to ordered data structures .",
    "moreover , this technique is strictly related to the construction of a partition of the domain in cubes and depends on the size of its subdomains , thus producing a nearest neighbor searching procedure , which is particularly efficient in local interpolation methods .",
    "numerical experiments show efficiency and accuracy of the cube algorithm .    the paper is organized as follows . in section [ pum ]",
    "we recall some theoretical results , giving a general description of the partition of unity method , which makes use of rbfs as local approximants . in section [ pum_alg ] ,",
    "we present in detail the cube - partition algorithm for trivariate interpolation , which is efficiently implemented and optimized by using a nearest neighbor searching procedure",
    ". computational complexity and storage requirements of the interpolation algorithm are analyzed as well . in section [ num_res ] ,",
    "we show numerical results concerning efficiency and accuracy of the partition of unity algorithm .",
    "finally , section [ concl ] deals with conclusions and future work .",
    "let @xmath0 be a set of distinct data points or nodes , arbitrarily distributed in a domain @xmath1 , @xmath2 , with an associated set @xmath3 of data values or function values , which are obtained by sampling some ( unknown ) function @xmath4 at the nodes , i.e. , @xmath5 , @xmath6 .",
    "the basic idea of the partition of unity interpolation is to start with a partition of the open and bounded domain @xmath1 into @xmath7 subdomains @xmath8 such that @xmath9 with some mild overlap among the subdomains .",
    "associated with these subdomains we choose a partition of unity , i.e. a family of compactly supported , non - negative , continuous functions @xmath10 with @xmath11 such that @xmath12 for each subdomain @xmath8 we consider a local approximant @xmath13 and form then the global approximant @xmath14 here @xmath15 defines a rbf interpolant of the form @xmath16 where @xmath17 represents a radial basis function , @xmath18 denotes the euclidean norm , and @xmath19 indicates the number of data points in @xmath8 .",
    "furthermore , @xmath13 satisfies the interpolation conditions @xmath20 note that if the local approximants satisfy the interpolation conditions , then the global approximant also interpolates at this node , i.e. @xmath21    solving the @xmath22-th interpolation problem leads to a system of linear equations of the form @xmath23 \\left [ \\begin{array}{c } c_1\\\\ c_2\\\\ \\vdots\\\\ c_{\\bar{n}_j } \\end{array } \\right ] = \\left [ \\begin{array}{c } f_1\\\\ f_2\\\\ \\vdots\\\\ f_{\\bar{n}_j } \\end{array } \\right ] ,    \\end{aligned}\\ ] ] or simply @xmath24 in particular , the interpolation problem is well - posed , i.e. , a solution to the problem exists and is unique , if and only if the matrix @xmath25 is nonsingular .",
    "a sufficient condition to have nonsingularity is that the corresponding matrix is positive definite .",
    "in fact , if the matrix @xmath25 is positive definite , then all its eigenvalues are positive and therefore @xmath25 is nonsingular ( see , e.g. , @xcite ) .",
    "though the theory of rbfs is here considered , for brevity we do not report basic definitions and theorems , referring to @xcite for a more detailed analysis .",
    "then , we give the following definition ( see @xcite ) .",
    "let @xmath1 be a bounded set .",
    "let @xmath26 be an open and bounded covering of @xmath27 .",
    "this means that all @xmath8 are open and bounded and that @xmath9 .",
    "set @xmath28 .",
    "we call a family of nonnegative functions @xmath29 with @xmath30 a @xmath31-stable partition of unity with respect to the covering @xmath26 if    1 .   @xmath32 ; 2 .",
    "@xmath33 on @xmath27 ; 3 .   for every @xmath34 with @xmath35",
    "there exists a constant @xmath36 such that @xmath37 for all @xmath38 .    in agreement with the statements in @xcite",
    ", we require additional regularity assumptions on the _ covering _ @xmath26 .",
    "[ defpr ] suppose that @xmath39 is bounded and @xmath40 are given .",
    "an open and bounded covering @xmath26 is called regular for @xmath41 if the following properties are satisfied :    * for each @xmath42 , the number of subdomains @xmath8 with @xmath43 is bounded by a global constant @xmath44 ; * each subdomain @xmath8 satisfies an interior cone condition ; * the local fill distances @xmath45 , where @xmath46 , are uniformly bounded by the global fill distance @xmath47 , i.e. @xmath48    property ( a ) is required to ensure that the sum in is actually a sum over at most @xmath44 summands . since @xmath44 is independent of @xmath49 , unlike @xmath7 , which should be proportional to @xmath49 , this is essential to avoid losing convergence orders .",
    "it is crucial for an efficient evaluation of the global interpolant that only a constant number of local approximants has to be evaluated . in such way",
    ", it should be possible to locate those @xmath44 indices in constant time .",
    "properties ( b ) and ( c ) are important for employing the estimates on rbf interpolants ( see @xcite ) .    moreover , we are able to formulate the following theorem , which yields the polynomial precision and controls the growth of error estimates , denoting by @xmath50 the set of polynomials of degree at most @xmath51 ( see , e.g. , @xcite ) .",
    "[ tp ] suppose that @xmath1 is compact and satisfies an interior cone condition with angle @xmath52 and radius @xmath53 .",
    "let @xmath54 be fixed and there exist constants @xmath55 depending only on @xmath56 such that @xmath57 .",
    "then , for all @xmath58 and all @xmath42 , there exist functions @xmath59",
    ", @xmath60 , such that    1 .   @xmath61 ,   @xmath62 ; 2 .   @xmath63 ; 3 .",
    "@xmath64 provided that @xmath65 .",
    "therefore , after defining the space @xmath66 of all functions @xmath67 whose derivatives of order @xmath68 satisfy @xmath69 for @xmath70 , we consider the following convergence result ( see , e.g. , @xcite ) .",
    "let @xmath39 be open and bounded and suppose that @xmath71 @xmath72 .",
    "let @xmath73 be a strictly conditionally positive definite function of order @xmath74 .",
    "let @xmath26 be a regular covering for @xmath75 and let @xmath29 be @xmath31-stable for @xmath26 .",
    "then the error between @xmath76 , where @xmath77 is the native space of @xmath78 , and its partition of unity interpolant ( [ pui ] ) can be bounded by @xmath79 for all @xmath42 and all @xmath80 .    comparing this convergence result with the global error estimates ( see e.g. @xcite ) , we note that the partition of unity preserves the local approximation order for the global fit .",
    "this means that we can efficiently compute large rbf interpolants by solving small rbf interpolation problems ( in parallel as well ) and then glue them together with the global partition of unity @xmath29 . in other words ,",
    "the partition of unity approach is a simple and effective technique to decompose a large problem into many small problems while at the same time ensuring that the accuracy obtained for the local fits is carried over to the global one .",
    "in particular , the partition of unity method can be thought as a shepard s type interpolation with higher - order data , since local approximations @xmath13 instead of data values @xmath81 are used .",
    "finally , we remark that , among several weight functions @xmath82 in , a possible choice is given by shepard s weight @xmath83 where @xmath84 is the inverse of the euclidean norm @xmath85 .",
    "it constitutes a partition of unity as in .",
    "in this section we propose a new algorithm for trivariate interpolation of large scattered data sets lying on the domain @xmath86 ^ 3 \\subset { \\mathbb{r}}^3 $ ] .",
    "this algorithm , which is based on the partition of unity method for constructing a global interpolant by blending rbfs as local approximants and using locally supported weight functions , is efficiently implemented and optimized by connecting the interpolation method with an effective cube - partition searching procedure .",
    "more precisely , the considered approach is characterized by the construction of a _ cube - based structure _ , which partitions the domain @xmath27 in cubes and strictly depends on the dimension of its subdomains .",
    "this technique is a direct extension in three - dimensional case of the square - partition searching procedure presented in @xcite for bivariate interpolation , which we briefly recall in subsection [ review ] .",
    "note that the paper @xcite follows preceding works , where efficient searching procedures based on the partition of the domain in strips or spherical zones are considered ( see @xcite ) .",
    "the construction of the 2d searching procedure described in @xcite is obtained by making a partition of the bivariate domain in square cells .",
    "they are achieved generating two orthogonal families of parallel strips ( see figure [ double - strips ] ) .",
    "this approach is combinated with the repeated use of a _ quicksort _ routine with respect to different directions . at first",
    ", we make a sorting along the @xmath87-axis on all the points , constructing then a first family of strips parallel to the @xmath88-axis .",
    "afterwards , we order the points contained in each strip with respect to the @xmath88-axis direction , and finally we build the second family of strips parallel to the @xmath87-axis .",
    "the outcome is a square - based structure , which allows us to pass from unordered to ordered data structures .",
    "following this idea , we can suitably split up the original data set in ordered and well - organized data subsets .",
    "more precisely , we may act as follows :    1 .",
    "organize all the data by means of a _",
    "quicksort@xmath89 procedure _ applied along the @xmath87-axis ( the subscript denotes the sorting direction ) ; 2 .",
    "consider a first family of @xmath90 strips , parallel to the @xmath88-axis and order the points of each strip by using a _",
    "quicksort@xmath91 procedure _ ; 3 .",
    "create a second family of @xmath90 strips , parallel to the @xmath87-axis , which orthogonally intersect the first strip family , thus producing a partition of the bivariate domain in square cells ( see figure [ cell - struct ] ) .",
    "note that a specific square cell @xmath31 is denoted by a double index notation in square brackets , i.e. @xmath92 $ ] .    in order to obtain an efficient searching technique in the localization of points",
    ", we connect the interpolation method with the square - based partition structure , exploiting the data structure and the domain partition previously considered .",
    "this result is obtained assuming that the square side is equal to the subdomain radius .",
    "though this choice might seem to be trivial , in practice such an imposition means that the search of the nearby points , an essential aspect of local methods as the partition of unity method , is limited at most to nine squares : the square on which the considered point lies , and the eight neighbouring squares ( see figures [ double - strips][cell - struct ] ) .",
    "the combination between square cell and subdomain sizes constitutes an _ optimal _ choice , since it allows us to search the closest points only considering a very small number of them , i.e. taking those points belonging to one of the nine square cells and _ a priori _ ignoring all the other ones .",
    "finally , for all those points belonging to the first and last square cells , namely the ones located on or close to the boundary of the domain , we reduce the total number of square cells to be examined .              as in the 2d case ,",
    "the basic idea in constructing the 3d searching procedure comes from the repeated use of a _ quicksort _ routine with respect to ( three ) different directions , i.e. along the @xmath93-axis , the @xmath87-axis and the @xmath88-axis , enabling us to pass from unordered to ordered data structures .",
    "this process is strictly related to the construction of a partition of the domain , here the unit cube , in smaller cubes .",
    "they are obtained generating three orthogonal families of parallelepipeds , while at the same time the original data set is suitably split up in ordered and well - organized data subsets .",
    "more precisely , in order to obtain the cube - based structure and then the resulting searching procedure , we may act as follows :    1 .",
    "organize all the data by means of a _",
    "quicksort@xmath94 procedure _ applied along the @xmath93-axis ; 2 .",
    "consider a first family of @xmath90 parallelepipeds , parallel to the @xmath95-plane , and order the points of each parallelepiped by using a _",
    "quicksort@xmath91 procedure _ ; 3 .",
    "create a second family of @xmath90 parallelepipeds , parallel to the @xmath96-plane , which orthogonally intesect the first family , and order the points of each parallelepiped by using a _",
    "quicksort@xmath89 procedure _ ; 4 .",
    "construct a third family of @xmath90 parallelepipeds , parallel to the @xmath97-plane , which orthogonally intesect the two previous families , thus producing a partition of @xmath27 in cubes ( see figure [ cube_1 ] ) .",
    "now , exploiting the data structure and the domain partition , we construct an efficient searching technique to be used in the localization of points , effectively connecting the partition of unity scheme with the cube - partition structure .",
    "this result is got assuming that the cube side @xmath98 is equal to the subdomain radius @xmath99 , i.e. taking @xmath100 . from this assumption",
    "it follows that the search of the nearby points is limited at most to twenty - seven ( @xmath101 ) cubes : the cube on which the considered point lies , and the twenty - six neighboring cubes ( see figure [ cube_2 ] ) . from now on , to locate a specific cube @xmath31 , we define a triple index notation using square brackets , i.e. @xmath102 $ ] , @xmath103 .",
    "we note that the combination between cube and subdomain sizes provides an _ optimal _ choice , since it allows us to search the closest points only considering a very small number of them ( that is only those points belonging to one of the twenty - seven cubes ) and _ a priori _ ignoring all the other points of @xmath27 . obviously , then",
    ", for all those points belonging to cubes close to the boundary of @xmath27 , it will be required a reduction of the total number of cubes to be examined .",
    "further details on this searching procedure are contained in subsection [ cube - algor ] , where we give a detailed description of the proposed algorithm .",
    "input : @xmath49 , number of data ; @xmath104 , set of data points ; @xmath105 , set of data values ; @xmath7 , number of subdomains ; @xmath106 , set of subdomain points ( centres ) ; @xmath51 , number of evaluation points ; @xmath107 , set of evaluation points .",
    "output : @xmath108 , set of approximated values .",
    "stage 1 . the set @xmath109 of nodes and the set @xmath110 of evaluation points",
    "are ordered with respect to a common direction ( e.g. the @xmath93-axis ) , by applying a _",
    "quicksort@xmath94 procedure_. stage 2 . for each subdomain point @xmath111 , @xmath112 ,",
    "a local spherical subdomain is constructed , whose spherical radius depends on the subdomain number @xmath7 , i.e. @xmath113{d}}.   \\end{aligned}\\ ] ] although other choices @xmath99 are possible , this value is suitably chosen , supposing to have a nearly uniform node distribution and assuming that the ratio @xmath114 .",
    "a triple structure of intersecting parallelepipeds is constructed as follows :    1 .   a first family of @xmath90 parallelepipeds , parallel to the @xmath95-plane ,",
    "is considered taking @xmath115 and a _",
    "quicksort@xmath91 procedure _ is applied to order the nodes belonging to each parallelepiped ; 2 .   a second family of @xmath90 parallelepipeds , parallel to the @xmath96-plane , is constructed and a _ quicksort@xmath89 procedure _",
    "is used to order the nodes belonging to each of the resulting parallelepipeds ; 3 .",
    "a third family of @xmath90 parallelepipeds , parallel to the @xmath97-plane , is considered .",
    "note that each of the three families of parallelepipeds are ordered and numbered from 1 to @xmath90 ; the choice in ( [ q_par ] ) follows directly from the side length of the domain , i.e. the unit cube , and the subdomain radius @xmath99 .",
    "the unit cube is partitioned by a cube - based structure consisting of @xmath116 cubes , whose side length is @xmath100 .",
    "then , the sets @xmath109 , @xmath117 and @xmath110 are partitioned by the cube structure into @xmath116 subsets @xmath118 , @xmath119 and @xmath120 , @xmath121 , where @xmath122 , @xmath123 and @xmath124 are the number of points in the @xmath31-th cube .",
    "this stage can be summarized in algorithm [ alg1 ] .",
    "partition and count the number of points @xmath125 ( nodes ) @xmath126 ( subdomain points ) @xmath127 ( evaluation points ) ; @xmath128    stage 5 .",
    "in order to identify the cubes to be examined in the searching procedure , we adopt the following rule which is composed of three steps :    1 .",
    "the cube side @xmath98 is chosen equal to the subdomain radius @xmath99 , i.e. @xmath100 , and the ratio between these quantities is denoted by @xmath129 ; 2 .   the value @xmath130 provides the number @xmath131 of cubes to be examined for each point by the rule @xmath132 , which obviously here gives @xmath133 . in practice",
    ", this means that the search of the nearby points is limited at most to twenty - seven cubes : the cube on which the considered point lies , and the twenty - six neighboring cubes ; 3 .   for each cube @xmath102 $ ] , @xmath103 , a cube - partition searching procedure is considered , examining the points from the cube @xmath134 $ ] to the cube @xmath135 $ ] . for the points of the first and last cubes ( those close to the boundary of the unit cube ) , we reduce the total number of cubes to be examined , setting @xmath136 and/or @xmath137 and/or @xmath138 ( when @xmath139 and/or @xmath140 and/or @xmath141 ) and @xmath142 and/or @xmath143 and/or @xmath144 ( when @xmath145 and/or @xmath146 and/or @xmath147 ) .",
    "then , after defining which and how many cubes are to be examined , the cube - partition searching procedure ( see algorithm [ alg2 ] ) is applied :    * for each subdomain point of @xmath119 , @xmath121 , to determine all nodes belonging to a subdomain . the number of nodes of the subdomain centred at @xmath148 is counted and stored in @xmath19 , @xmath149 ; * for each evaluation point of @xmath120 , @xmath121 , in order to find all those belonging to a subdomain of centre @xmath111 and radius @xmath99 .",
    "the number of subdomains containing the @xmath150-th evaluation point is counted and stored in @xmath151 , @xmath152 .",
    "set @xmath153 = [ u - i^*,v - i^*,w - i^*]$ ] @xmath154 = [ u + i^*,v + i^*,w + i^*]$ ] set @xmath155 and/or @xmath156 and/or @xmath157 set @xmath158 and/or @xmath159 and/or @xmath160 set @xmath161 set @xmath162 @xmath163 @xmath164    set @xmath165 set @xmath166 @xmath167 @xmath168    stage 6 .",
    "a local interpolant @xmath13 , @xmath169 , is found for each subdomain point .",
    "a local approximant @xmath170 and a weight function @xmath171 , @xmath149 , is found for each evaluation point .",
    "stage 8 . applying the global interpolant ( [ pui ] )",
    ", one can find approximated values computed at any evaluation point @xmath172 .",
    "the algorithm is based on the construction of a cube - partition searching procedure .",
    "it enables us to efficiently determine all points belonging to each subdomain @xmath8 , @xmath149 , so that we can compute local rbf interpolants to be used in the partition of unity scheme . assuming that the covering @xmath26 is regular and local and the set @xmath109 of data points is quasi - uniform , we analyze the complexity of this code .",
    "the cube - partition algorithm involves the use of the standard _ quicksort _ routine , which requires on average a time complexity @xmath173 , where @xmath174 is the number of points to be sorted .",
    "specifically , we have a distribution phase consisting of building the data structure , in which the computational cost has order : @xmath175 for the sorting of all @xmath49 nodes and @xmath176 for the sorting of all @xmath51 evaluation points in ` stage 1 ` . then , ` in stage 3 ` the _ quicksort _ routine is repeatedly used with respect to different directions considering a reduced number of points ( see subsections [ cube - proc][cube - algor ] ) . since the number of centres in each subdomain @xmath8 is bounded by a constant ( see definition [ defpr ] ) , we need @xmath177 space and time for each subdomain to solve the local rbf interpolation problems .",
    "in fact , in order to obtain the local rbf interpolants , we have to solve @xmath7 linear systems of ( relatively ) small sizes , i.e. @xmath178 , with @xmath179 , thus requiring a constant running time @xmath180 , @xmath149 , for each subdomain ( see ` stage 6 ` ) .",
    "then , in ` stage 5 , 7 ` and ` 8 ` we also need a cost of @xmath181 , @xmath149 , @xmath182 , for the @xmath31-th evaluation point of @xmath110 ; in other words , we have a constant time to get the value of the global fit .",
    "finally , the algorithm requires @xmath183 , @xmath184 and @xmath185 storage requirements for the data , and @xmath19 , @xmath186 , locations for the coefficients of each local rbf interpolant .",
    "in this section we present a few numerical tests to show performance of the cube - partition algorithm , numerically analyzing efficiency and accuracy of the local interpolation scheme on some sets of scattered data .",
    "the code is implemented in c / c++ language , while numerical results are carried out on a intel core i7 - 4500u 1.8 ghz processor . in the experiments we consider a node distribution containing @xmath187 , @xmath188 , uniformly random halton nodes generated by using the matlab program ` haltonseq.m ` ( see @xcite ) .",
    "the cube - partition algorithm is run considering @xmath189 , @xmath188 , subdomain points and @xmath190 evaluation ( or grid ) points , which are contained in the unit cube @xmath86 ^ 3 $ ] . here ,",
    "for the global interpolant ( [ pui ] ) we use shepard s weight ( [ sh_w ] ) .",
    "the performance of the interpolation algorithm is verified taking the data values by the following two trivariate franke s test functions ( see , e.g. , @xcite ) @xmath191   \\nonumber \\\\ & + & \\frac{3}{4 } \\exp\\left[-\\frac{(9x+1)^2}{49}-\\frac{9y+1}{10}-\\frac{9z+1}{10}\\right ] \\nonumber \\\\ & + & \\frac{1}{2 } \\exp\\left[-\\frac{(9x-7)^2+(9y-3)^2+(9z-5)^2}{4}\\right ] \\nonumber \\\\ & -&\\frac{1}{5 } \\exp\\left[-(9x-4)^2-(9y-7)^2-(9z-5)^2\\right],\\nonumber \\\\ \\nonumber \\\\ f_2(x , y , z)&=&\\frac{\\left(1.25+\\cos(5.4y)\\right)\\cos(6z)}{6 + 6\\left(3x-1\\right)^2 } , \\nonumber\\end{aligned}\\ ] ] and using gaussian @xmath192 ( g ) , mat@xmath193rn @xmath194 ( m4 ) and wendland @xmath194 ( w4 ) as local rbf interpolants @xmath195 where @xmath196 are the _ shape parameters _ , @xmath197 is the euclidean distance , and @xmath198 denotes the truncated power function .",
    "note that gaussian @xmath192 and mat@xmath193rn @xmath194 are globally supported basis functions , whereas wendland @xmath194 is a compactly supported one ( see @xcite ) .",
    "some information about the execution of the interpolation algorithm described in section [ pum_alg ] are reported in table [ time ] , namely the number @xmath116 of partitions in cubes of the domain and the cpu times ( in seconds ) obtained by running the cube - partition algorithm . moreover , since we are interested in pointing out the effectiveness of the proposed algorithm , in table [ time ] we also show cpu times obtained by using the same interpolation method , but without partitioning the domain @xmath27 in cubes and , accordingly , without considering the corresponding searching procedure .",
    "this analysis emphasizes that the use of a cube structure gives a considerable saving of time , mainly when the number of points to be handled becomes quite a lot large .        ' '' ''",
    "@xmath49 & @xmath7 & @xmath116 & * @xmath199 * & @xmath200 +    ' '' ''    @xmath201 & @xmath202 & @xmath203 & @xmath204 & @xmath205 +    ' '' ''    @xmath206 & @xmath207 & @xmath208 & @xmath209 & @xmath210 +    ' '' ''    @xmath211 & @xmath212 & @xmath213 & @xmath214 & @xmath215 +    analyzing the performance of the algorithm , we observe that the cube - partition searching procedure turns out to be powerful and efficient , because cpu times reported in table [ time ] are mainly due to solution of @xmath7 linear systems having matrices with a relatively large number of entries , usually more than a hundred .    now , in order to investigate accuracy of the method , we compute the root mean square error ( rmse ) , whose formula is @xmath216 analyzing its behavior by varying the values of the shape parameters for gaussian , mat@xmath193rn and wendland functions ( see figure [ shape_f1 ] ) .",
    "these graphs allow us to find the optimal values of @xmath217 , @xmath218 and @xmath219 , i.e. those values for which we obtain the smallest rmses ( see tables [ tab_errors][tab_errors_bis ] ) . note that each evaluation is carried out by choosing equispaced values of the shape parameters , taking @xmath220 $ ] and @xmath221 $ ] . analyzing error tables and graphs",
    ", we can see that mat@xmath193rn and wendland functions have a greater stability than rbf gaussian , but the latter gives us a greater accuracy although its interpolation matrices might be subject to ill - conditioning problems for small values of @xmath217 .",
    "this behavior is what we expect from theoretical standpoint , but here it is validated by numerical tests .",
    "moreover , we remark that several numerical experiments ( not reported here for shortness ) have been carried out using other test functions and the results show a uniform behavior .",
    "@xmath222    -1.2 cm        g  @xmath223     +        m4 ",
    "@xmath222    -1.2 cm        m4  @xmath223     +        w4 ",
    "@xmath222    -1.2 cm        w4 ",
    "@xmath223        ' '' ''    @xmath49 & rmse & @xmath224 & rmse & @xmath225 & rmse & @xmath226 +    ' '' ''    @xmath227 & @xmath228 & @xmath229 & @xmath230 & @xmath231 & @xmath232 & @xmath233 +    ' '' ''    @xmath211 & @xmath234 & @xmath235 & @xmath236 & @xmath229 & @xmath237 & @xmath233 +        ' '' ''    @xmath49 & rmse & @xmath224 & rmse & @xmath225 & rmse & @xmath226 +    ' '' ''    @xmath227 & @xmath238 & @xmath239 & @xmath240 & @xmath241 & @xmath242 & @xmath243 +    ' '' ''    @xmath211 & @xmath244 & @xmath235 & @xmath245 & @xmath241 & @xmath246 & @xmath247 +    finally , to show that the cpu times in table [ time ] essentially depend on the size of interpolation matrices , we repeat numerical tests fixing a maximum number ( i.e. , @xmath248 , @xmath112 ) of nodes for each subdomain , namely only considering the @xmath249 nodes closest to the subdomain centres . in fact , for example , taking @xmath250 ( and also @xmath249 not fixed ) and denoting by @xmath251 the corresponding execution times , we get a significant reduction of times , since @xmath252 and @xmath253 for @xmath254 , @xmath255 and @xmath256 for @xmath257 , while @xmath258 and @xmath259 for @xmath260 ( see table [ time ] for a comparison ) .",
    "nevertheless , this reduction expressed in terms of cpu times is paid , in general , only with a slight loss of accuracy , since the behavior of rmses is similar to that shown in figure [ shape_f1 ] .    in conclusion , in table [ tab_comp_1 ] we also report the rmses obtained by applying the cube - partition algorithm on sets of grid points .        ' '' ''    & @xmath222 & @xmath223 & @xmath222 & @xmath223 +    ' '' ''    g & @xmath261 & @xmath262 & @xmath263 & @xmath264 + @xmath224 & @xmath265 & @xmath266 & @xmath267 & @xmath229 +    ' '' ''",
    "m4 & @xmath268 & @xmath269 & @xmath270 & @xmath271 + @xmath225 & @xmath272 & @xmath273 & @xmath274 & @xmath275 +    ' '' ''    w4 & @xmath276 & @xmath277 & @xmath278 & @xmath279 + @xmath226 & @xmath280 & @xmath281 & @xmath282 & @xmath283 +",
    "in this paper we propose a new local interpolation algorithm for trivariate interpolation of scattered data points .",
    "it is based on the construction of a partition of the domain in cubes , enabling us to optimally implement a cube - partition searching procedure in order to efficiently detect the nodes belonging to each subdomain of the partition of unity method .",
    "this technique works well and quickly also when the amount of data to be interpolated is very large .",
    "moreover , the proposed algorithm is flexible , since different choices of local interpolants are allowable , and completely automatic .",
    "as regards research and future work we are interested in refining the cube algorithm adopting suitable data structures like kd - trees and range trees , connecting these data structures with the special partition of the domain in cubes .",
    "moreover , we are going to extend the proposed algorithm to higher dimensions . then , even though the choice of low - order basis functions such as mat@xmath193rn and wendland functions gives a good trade - off between stability and accuracy , we are still considering the need of dealing with the ill - conditioning problem of high - order basis functions . on the one hand , we might consider suitable preconditioning techniques for rbf interpolation matrices as already done in @xcite for rbf collocation matrices ; on the other hand , one could study alternative stategies to have a stable evaluation of interpolants via hilbert - schmidt svd as in @xcite , or new stable bases as in @xcite .",
    "r. cavoretto , a. de rossi , m. donatelli , and s. serra - capizzano , _ spectral analysis and preconditioning techniques for radial basis function collocation matrices _ , numer .",
    "linear algebra appl . , 19 ( 2012 ) , pp .",
    "3152 .",
    "m.  a. iyer , l.  t. watson , and m.w .",
    "berry , _ sheppack : a fortran 95 package for interpolation using the modified shepard algorithm _ , in proceedings of the annual southeast conference ,",
    "r. menezes et al .",
    ", eds . , acm , new york , 2006 , pp . 476481 .",
    "w.  i. thacker , j. zhang , l.  t. watson , j.  b. birch , m.  a. iyer , and m.  w. berry , _ algorithm 905 : sheppack : modified shepard algorithm for interpolation of scattered multivariate data _ , acm trans . math .",
    "software , 37 ( 2010 ) , art .",
    "34 , pp . 120 .",
    "h. wendland , _ fast evaluation of radial basis functions : methods based on partition of unity _ , in approximation theory x : wavelets , splines , and applications , c.  k. chui , l.  l. schumaker , j. st@xmath286ckler , eds .",
    ", vanderbilt univ . press ,",
    "nashville , tn , 2002 , pp ."
  ],
  "abstract_text": [
    "<S> in this paper we propose a fast algorithm for trivariate interpolation , which is based on the partition of unity method for constructing a global interpolant by blending local radial basis function interpolants and using locally supported weight functions . </S>",
    "<S> the partition of unity algorithm is efficiently implemented and optimized by connecting the method with an effective cube - partition searching procedure . </S>",
    "<S> more precisely , we construct a cube structure , which partitions the domain and strictly depends on the size of its subdomains , so that the new searching procedure and , accordingly , the resulting algorithm enable us to efficiently deal with a large number of nodes . complexity analysis and numerical experiments </S>",
    "<S> show high efficiency and accuracy of the proposed interpolation algorithm .    </S>",
    "<S> meshless approximation , fast algorithms , partition of unity methods , radial basis functions , scattered data .    65d05 , 65d15 , 65d17 . </S>"
  ]
}