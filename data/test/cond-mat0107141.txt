{
  "article_text": [
    "the storage and retrieval properties , as well as the dynamics , of large attractor neural networks have been studied over some time and numerous results are now available .",
    "the presence of an exponentially large number of unwanted spin - glass - like states in fully connected networks may limit severely the storage capacity , the information content and the performance , in particular the retrieval quality of previously stored patterns which act as attractors in the dynamics of the network .",
    "also , the size of the corresponding basins of attraction may be considerably reduced .",
    "other tasks , as the categorization or generalization ability of a network , are also impaired due to the presence of such states and , except for a low storage ratio , that is for a reduced level of stochastic noise , a performing network is very likely to be trapped in one of those states preventing the occurence of finite overlaps with the patterns of interest .",
    "the study of the equilibrium behavior of the hopfield model with binary neurons and extremely low _ symmetric _ connectivity @xmath3 suggested that @xcite , except for zero storage ratio @xmath4 or in the absence of synaptic noise @xmath5 , the properties of the model may be quite different from those of the extremely diluted network with asymmetric synapses , which has a trivial dynamics @xcite .",
    "in particular , the equations for the order parameters are equivalent to those of the sherrington and kirkpatrick ( sk ) spin - glass ( sg ) model @xcite .",
    "it has been shown , nevertheless , that strong symmetric dilution of synapses in the hopfield model @xcite may considerably reduce the stability of spin - glass states . indeed , in the limit @xmath6 , the retrieval states are globally stable in their whole domain of existence of the @xmath7 phase diagram , thus leaving only locally stable sg states @xcite , in contrast to the situation in the fully connected hopfield model @xcite .",
    "it has also been shown that already a gradual dilution reduces the stability of the sg states in the region where they compete with the retrieval states and that the storage capacity of the network is increased @xcite .",
    "these are important results on the performance of a network which also suggest that the basins of attraction of the memory ( retrieval ) states should be increased in symmetrically diluted networks .",
    "networks of q - ising neurons in various architectures have been studied over some time , in particular , fully connected , layered feed - forward and extremely dilute networks with asymmetric connectivity @xmath8 $ ] .",
    "they are of interest for possible hardware applications and an eventual biological modeling , because of the increased flexibility of the states of the network to account for complex neural behavior .",
    "it has been suggested that an attractor neural network model with multi - state neurons may describe the short term memorization performance of the @xmath9 region of the hyppocampus in both the brain of primates and in the human brain , and results of numerical simulations for the selective performance of a network with asymmetric synapses and small connectivity ( @xmath10 ) are now available @xcite .",
    "however , complete phase diagrams that give a global picture of the performance of a network and a physical explanation of why biological networks seem to prefer a low connectivity are still missing .",
    "attractor network models with a hebbian type of learning rule may also serve to account for long - term memory in the brain @xcite .    both the parallel dynamics and the equilibrium properties of extremely diluted networks with symmetric connectivity between multi - state q - ising neurons",
    "have been studied in recent works @xcite .",
    "the symmetry of the synaptic connections allows for a detailed balance assumption in the dynamics and enables one to perform full analytic calculations of the equilibrium properties of a network .",
    "this is particularly convenient in the search for phase diagrams .",
    "so far , there are no results , to our knowledge , concerning the memorization performance of symmetrically diluted q - ising networks with small but finite connectivity and low - activity patterns , which characterize a biological network .",
    "the purpose of the present work is to consider the retrieval performance of an attractor neural network modeled on some of the features of a biological network .",
    "we study here the equilibrium behavior of a symmetrically diluted hopfield model with finite connectivity and low - activity units in q - ising states .",
    "multi - state networks are known to have complex properties and our main aim here is to find out how that behavior is changed by a finite dilution of the synapses and the low activity of the embedded patterns .",
    "we consider explicitly a @xmath0 , @xmath1 and a continuous @xmath2-state network .",
    "the outline of the paper is the following . in sec .",
    "ii we present the model and show how the hamiltonian becomes the sum of an effective hopfield - model hamiltonian and that of a sherrington - kirkpatrick - like spin - glass model . the replica - symmetric mean - field theory for the model and the relevant order parameters are derived in sec .",
    "iii and explicit expressions are presented in the appendix .",
    "the results for the phase diagrams and the retrieval performance are discussed in sec .",
    "iv , and our conclusions with a summary of the results can be found in sec . v.",
    "attractor neural networks are dynamical systems . consider a network of @xmath11 neurons , @xmath12 . at the time step @xmath13",
    ", the state of neuron @xmath14 is described by the variable @xmath15 , that can be in any one of the @xmath16 ising states @xmath17 in the interval [ -1,1 ] , for @xmath18 . a macroscopic set of @xmath19 independent and identically distributed random patterns @xmath20 , with @xmath21",
    ", is embedded in the network by means of a hebbian - like learning rule , specified below . here , @xmath22 is the storage ratio per connected site and @xmath3 is the connectivity of the network",
    ". every bit of each pattern can be in any one of @xmath16 equally spaced states , also in the interval [ -1,1 ] , which are assumed to have zero mean and variance @xmath23 this is a measure of the size of the patterns , describing their mean activity , that accounts for bits that either are turned off or depressed .",
    "the first task to be performed by the network is to attain a finite storage ratio @xmath4 and this ratio can be optimized for patterns of a given size by means of an appropriate tuning of the states of the network , discussed below .",
    "the second aim is to reach a sufficiently small hamming distance @xmath24 between the network state @xmath25 and a given pattern @xmath26 , as a measure of the retrieval performance of the network .",
    "this depends on both the overlap @xmath27 and the dynamical activity of the network , @xmath28 .",
    "we consider next the dynamics of the partially connected model . for a given configuration @xmath29 of the network ,",
    "the local field acting on neuron @xmath14 is given by @xmath30 where @xmath31 is the synaptic coupling between neurons @xmath14 and @xmath32 .",
    "we assume that the synapses of the network are symmetrically diluted being left with a _ finite _",
    "connectivity @xmath3 ( the fraction of connected neurons ) which , eventually , may become vanishingly small .",
    "specifically , the synapses are of the hebbian - like form , @xmath33 for our non - sparse network , in which @xmath34 . here",
    ", @xmath35 is a set of independent identically distributed random variables , such that @xmath36 with probability @xmath3 and zero with probability @xmath37 , while @xmath38 .",
    "thus , the symmetric dilution introduces an additional randomness both into the dynamics of the network , which becomes non - trivial even in the extremely diluted case due to feedback loops @xcite , as well as in the thermodynamics .",
    "we are interested , in the following , in the case of a large connected network , in which @xmath39 is very large .",
    "the state of each neuron is updated asynchronously according to a glauber ( single spin - flip ) dynamics @xcite in which the transition probabilities are given by @xmath40 }      { \\sum_{l=1}^q\\exp[\\beta\\epsilon_j(\\sigma_l|h_j(\\{s_i(t)\\}))]}\\ ; , \\label{7}\\ ] ] where @xmath41 is the inverse synaptic noise ( temperature ) and the single site energy , @xmath42 , is given by @xmath43 here , @xmath44 is a tuning parameter favoring local states of small dynamical activity . in the absence of stochastic noise",
    ", the deterministic evolution of the system follows the updating rule @xmath45 where @xmath46 is the non - decreasing step function , for finite @xmath16 , @xmath47 \\label{10}\\ ] ] with @xmath48 and @xmath49 , in which @xmath50 , if @xmath51 , and zero otherwise .",
    "clearly , @xmath44 is a threshold parameter since the state of neuron @xmath32 assumes the value @xmath52 given by eq .",
    "( [ 1 ] ) if the local field @xmath53 is bound by @xmath54 .",
    "the width of the intermediate states with constant @xmath52 for @xmath55 ( that is , excluding the limiting values of @xmath56 ) , is given by @xmath57 .",
    "thus , the width of the zero state for the three - state network studied below is @xmath58 . in the limit @xmath59 ,",
    "the input - output function becomes the piecewise linear function @xmath60 where @xmath61 means the minimum between @xmath62 and @xmath63 .",
    "the slope of the linear part , @xmath64 , is the gain parameter of the continuous network .",
    "both , the locally stable states of the dynamics , as well as the globally stable states that characterize the equilibrium thermodynamic properties of the diluted network , that follow from the above dynamics , are described by the hamiltonian @xmath65 where the first sum is over all distinct pairs of neurons @xmath66 .",
    "eventually , a field - dependent term , @xmath67 , may be added to generate the overlap with a specific pattern , and this will be implicitly assumed below .",
    "we adapt next the procedure of viana and bray @xcite for diluted spin glasses in order to deal with the random dilution . in distinction to their case , which is that of a strongly interacting spin glass , we have here a diluted network with randomness in the patterns and weak interactions between units .",
    "the latter allows for an exact truncation to the relevant order in @xmath68 that is sufficient for the mean - field calculation of the following section .",
    "consider the disorder dependent part of the hamiltonian in the exponentiated form @xmath69 given a fixed set @xmath70 of patterns embedded in the network , we first have to build up a finite connectivity between units .",
    "that is to say , we have to find a network such that the mean of @xmath71 is precisely @xmath3 and , to this end , we have to perform first an average over these random variables .",
    "the average over the random patterns , that is necessary to evaluate the performance of the network , comes at a later stage .",
    "the configurational average over the set @xmath72 of the @xmath73 times replicated function @xmath74 becomes @xmath75 where @xmath76 denotes the value of @xmath77 for @xmath36 .",
    "we are interested in dense networks , that is , @xmath78 and large @xmath39 , letting eventually @xmath79 after the thermodynamic limit . for finite @xmath80 , the weak @xmath81 may be used to expand the logarithm to next - to - leading order in @xmath76 . using the law of large numbers to deal with @xmath82",
    "we obtain @xmath83 in which the effective coupling @xmath84 is given by @xmath85 the first term is the hebbian synapsis of the fully connected network with multi - state patterns of activity @xmath86 and @xmath87 is a gaussian random variable with zero mean and a pattern - independent variance @xmath88 ; the brackets on the right - hand side of eq.(15 ) denote an average over this random variable .",
    "this generalizes an earlier result by sompolinsky @xcite showing that dilution appears as a synaptic noise .",
    "thus , the symmetric dilution introduces an effective hamiltonian , in the large @xmath39 limit , @xmath89 where the first term is a sum of a hopfield - model hamiltonian and a kind of sk - model term .",
    "this is used in the following section to derive the mean - field theory for the model .",
    "we consider now the mean - field theory for finite @xmath4 and for any connectivity @xmath78 .",
    "the averaged free energy per connected site is given by @xmath90 with the averages first over the gaussian noise in the synaptic interactions and then over the pattern distribution .",
    "the effective partition function is then given by @xmath91 and this is used in the replica method to perform the random averages by means of @xmath92 the essential point is then the calculation of the averaged replicated partition function .",
    "assuming , as usual , that a finite number of patterns @xmath93 is condensed , with finite overlaps with the state of the network , we perform the random noise average and sum over the uncondensed patterns to obtain @xmath94\\ }          \\right\\rangle_{\\{\\xi^{\\mu}_i\\}}\\ , . \\label{21}\\end{aligned}\\ ] ] where , the sum over @xmath95 counts the configurations for all possible replicas @xmath4 .",
    "the dilution appears only in the first factor and @xmath96 is the average over the uncondensed patterns .    for both , the calculation of the function @xmath97 and the linearization of the quadratic form in the dilution term",
    ", we introduce the replica matrix elements @xmath98 of the sg order parameter and @xmath99 which is the dynamical activity @xmath100 of the network .",
    "the latter is one only in the case of binary units and , in general , @xmath101 . in the thermodynamic limit @xmath102",
    ", we obtain @xcite @xmath103 where @xmath104 is the matrix of elements @xmath105 and @xmath106 .",
    "introducing as usual the overlap parameter @xmath107 associated to the correlation between the overlaps of the patterns that do not condense , we restrict ourselves to replica symmetry , in which @xmath108 the free - energy per connected site , in the thermodynamic @xmath102 limit , then follows as @xmath109\\nonumber\\\\ & + & \\alpha(1-c)(\\frac{\\chi^2}{4\\beta}+\\frac{q\\chi}{2 } ) -\\frac{1}{\\beta}\\left\\langle \\int{\\cal d}z\\,\\ln\\sum_{\\{s\\}}\\exp(\\beta{\\cal h}_{eff})\\right\\rangle_{\\{\\xi^{\\nu}\\}}\\ ; , \\label{27}\\end{aligned}\\ ] ] where @xmath110 is a gaussian measure , and @xmath111 , given by @xmath112 , is the susceptibility of the network .",
    "the new , site independent effective hamiltonian @xmath113 , is given by @xmath114 in terms of which the thermal averages are defined as @xmath115 note , incidentally , that the explicit term in @xmath116 in the free energy comes from the variance of the gaussian random noise due to the dilution .    the order parameters that describe the performance of the network are given by the saddle - point equations @xmath117 @xmath118 and the susceptibility becomes @xmath119 in which @xmath120 , for a given gaussian noise @xmath121 is given by eq.(32 ) . noting that the effective hamiltonian @xmath113 is formally the same as either that of the fully connected or the extremely diluted network , with a different stochastic gaussian noise and different effective threshold @xmath122 , for each connectivity @xmath3 , our equations for @xmath123 , @xmath124 and @xmath125 will be formally similar to the equations for both these networks , and explicit expressions are given in the appendix .",
    "the parameter @xmath126 follows from the algebraic saddle - point equation @xmath127 and @xmath128 is the effective width of the intermediate states .",
    "eventually , depending on the state of the network specified by the dynamical activity @xmath100 and the sg order parameter @xmath124 , @xmath129 may become negative , favoring an order with large absolute values for @xmath130 .",
    "whenever this is the case the network acts , at zero temperature , as a binary network with zero threshold , as will be seen below .",
    "the combination @xmath131 , in which the second term is the gaussian noise due to the macroscopic number of uncondensed patterns , can be viewed as an effective random field that will influence the network performance through a competition with the effective threshold @xmath129 .",
    "having performed the thermodynamic limit , one may now allow _ any _ value for the connectivity within @xmath132 , including the limit @xmath6 .",
    "it can easily be seen that one recovers for @xmath133 both the mean - field free energy for the fully connected network when @xmath134 @xcite and that for the extremely dilute case , when @xmath79 @xcite . in this limit , @xmath135 and @xmath136 , whereas for @xmath134 we have , @xmath137 and @xmath138 , also in agreement with the known results .",
    "these relations are valid for any temperature parameter @xmath139 .",
    "thus , we have the complete form for the replica - symmetric free energy for arbitrary connectivity .    note , incidentally , that @xmath135 not only in the above limit but also for @xmath140 , in the @xmath141 limit , for any connectivity @xmath3 , ( that is , for any architecture ) and for all @xmath16 , and this is based on @xmath142 in that limit . otherwise , the susceptibility remains finite , even at zero temperature , since @xmath143 , when @xmath144 , while at finite temperature we have , in general , @xmath145 .",
    "the limit of stability of the replica - symmetric solution comes from the study of quadratic fluctuations of the free - energy in the vicinity of the symmetric saddle - point . following the de almeida and thouless ( at ) analysis @xcite",
    ", we obtain @xmath146 ^ 2      \\right\\rangle_{\\{\\xi^{\\nu}\\ } }          \\leq 1\\ , , \\label{35}\\ ] ] as the stability condition for the replica - symmetric solution .",
    "this equation is to be solved together with the saddle - point equations for the order parameters .",
    "the formal results obtained so far are valid for any finite number of condensed patterns with finite overlaps with the state of the network .",
    "we are mainly interested in this work in the retrieval performance with a single condensed pattern , and this will be discussed in the following section .",
    "for the retrieval of a single condensed pattern , say @xmath147 , we have @xmath148 , and omit the index @xmath149 from now on . we consider separately the results for @xmath0 , @xmath1 and @xmath2 that follow by solving the saddle - point equations and",
    "restrict ourselves to the simplest case of uniformly distributed patterns .",
    "in the @xmath0 case , the patterns take the values @xmath150 with probability @xmath151 and @xmath152 with probability @xmath153 , in which @xmath154 in the case of uniformly distributed patterns .",
    "the effective transfer function @xmath155 that follows from the average in eq.(32 ) is given by @xmath156 which becomes @xmath157 in the zero temperature limit . clearly , when @xmath158 , the network acts as a binary network at @xmath159 .",
    "in the cases of the fully connected @xcite or the extreme symmetrically diluted network @xcite , explicit closed form expressions that signal the appearance of either a retrieval or a spin - glass phase , at zero temperature , have been obtained in the @xmath160 limit when @xmath161 .",
    "these are particularly useful to understand the low - threshold behavior of the phase diagrams . in the present case , of a network with finite and less than complete connectivity , closed form expressions for the onset of the ordered phases",
    "can not be obtained and one has to resort fully to numerical solutions .    nevertheless , the zero - temperature behavior of the thermodynamic transition can easily be analyzed as in previous works , to demonstrate that the retrieval state corresponds to the most stable phase , despite the presence of a spin - glass and a paramagnetic phase ( which is a frozen zero - spin state ) .",
    "indeed , the physical free energy , @xmath162 at zero temperature becomes @xmath163 since the susceptibility vanishes in the @xmath164 limit when @xmath159 for any of the three phases , and at the same time @xmath165 , the retrieval free energy is the minimum whenever @xmath166 .",
    "note that the susceptibility of the paramagnetic phase , @xmath167 also vanishes in the zero temperature limit for finite @xmath4 and @xmath122 converging to @xmath44 , ensuring a minimum retrieval free energy for small @xmath4 .",
    "although much emphasis is often made on the thermodynamic transition to globally stable retrieval states , which have the lowest free energy , it is worth keeping in mind that neural networks are dynamical systems with accessible _ locally _ stable retrieval states , in particular in the presence of some amount of noise . as far as the performance of the network is concerned , these are the most interesting states and they usually appear for higher values of @xmath4 @xcite .",
    "we are interested here in the characteristic features of the phase diagrams and the specific performance of the network . to see the effects of a gradual change in the connectivity , we show in fig .",
    "1 the @xmath168 phase diagrams for @xmath159 . the full lines represent the phase boundaries where the locally stable retrieval states appear at the critical storage ratio @xmath169 , whereas the long - dashed lines indicate the thermodynamic transitions to the globally stable retrieval phase .",
    "the sg phase appears to the left of the short - dashed lines representing the boundary to the paramagnetic state . to distinguish in what follows the transitions involving locally stable states from the thermodynamic transitions , we refer to the former simply as retrieval transitions .",
    "as long as the connectivity remains finite , all the transitions are discontinuous and , as usual in connected networks , the sg state is globally stable only above the thermodynamic transition @xcite .",
    "consider first the case of the fully connected network , with @xmath134 , which has been redone and completed here for the purpose of comparison .",
    "there are two retrieval regions , i and ii for small @xmath4 , separated by a sharp phase boundary , and this is the case both below and above the thermodynamic transition .",
    "the first is a region of non - optimal performance characterized by a moderately large hamming distance which decreases with increasing @xmath44 , whereas in region ii the hamming distance is small , dropping discontinuously at the phase boundary between the two regions with optimal network performance along the dotted line .",
    "the situation should change with decreasing connectivity , even at zero temperature . due to the synaptic noise produced by the dilution , given by the variance @xmath88",
    ", one now expects an end to the discontinuous transition between the retrieval regions i and ii at a @xmath3-dependent critical point for finite @xmath4 , below @xmath169 .",
    "this starts to appear for @xmath170 , with @xmath171 and @xmath172 , as shown in the inset of the figure for the retrieval transition .",
    "a critical point also appears at the thermodynamic transition and in fig .",
    "1 we show the results for @xmath173 and @xmath174 . there can be now a continuous transition with increasing @xmath44 induced by stochastic noise between the non - optimal and optimal performance retrieval states above the critical point suggesting the presence of increasingly larger regions of continuous changes .",
    "the interesting point is that this is a feature that already starts to appear for finite and _ intermediate _ connectivity , between that of the fully connected network and the @xmath6 limit .    to understand the role of the threshold one may use as a guide the case of vanishing stochastic noise , with @xmath164 .",
    "when @xmath44 is small , the state of a unit will be essentially @xmath175 , with an overlap @xmath176 in region i for uniformly distributed three - state patterns @xmath177 , that take the values @xmath178 , @xmath152 and @xmath179 . since @xmath180 , the hamming distance in this region will be @xmath181 . on the other hand ,",
    "as @xmath44 becomes larger , the state @xmath182 becomes increasingly important and , despite the fact that @xmath183 also yields an overlap @xmath184 , the sg order parameter @xmath124 is now reduced to the activity @xmath185 .",
    "thus , the resulting hamming distance @xmath186 will be vanishingly small .",
    "note that these results do not depend on the connectivity and they are , therefore , independent of the architecture of the network .",
    "this also follows from the zero - temperature saddle - point equations as can easily be checked with the appendix . in the case of a finite non - zero stochastic noise , instead , the performance of the network becomes explicitly dependent on the connectivity , but the overall qualitative dependence on @xmath44 below the critical phase boundaries is expected to follow that at @xmath140 .",
    "the critical storage capacity now increases with decreasing connectivity and the presence of two comparable maxima for @xmath169 is only a feature of intermediate @xmath3 .",
    "indeed , as the synapses are further diluted a single maximum is left , albeit with a shift to higher values of @xmath44 . finally , it is also worth noting that , in the @xmath6 limit , the retrieval state is the globally stable phase everywhere below the critical @xmath169 line and to the left of the globally stable paramagnetic phase , despite the relatively large stochastic noise due to the presence of spin - glass states in most of this region .",
    "the zero - temperature results presented so far are not stable to replica - symmetry breaking perturbations but it is expected that most of the features described here will be present at already a small but finite temperature above the at line , shown as dash - dotted in fig .",
    "2 , for @xmath187 .",
    "the full lines again represent the transitions to the locally stable retrieval states and the thermodynamic transitions are not shown .",
    "note that , even for small connectivity , there is only a low synaptic - noise region in which the network is not stable to replica - symmetry breaking perturbations . for a larger @xmath188",
    "we expect a similar behavior for the transition to the locally stable retrieval state with decreasing connectivity as that found before for the fully connected network , but still quite different from the behavior for lower @xmath44 @xcite .      in the case of @xmath1",
    "the phase diagrams are more involved .",
    "the patterns are assumed to take the values @xmath150 with probability @xmath189 and @xmath190 with probability @xmath191 , in which @xmath192 , where @xmath193 for uniformly distributed patterns .",
    "we consider in the following the zero - temperature behavior of the network and begin with the fully connected case as a guide .",
    "we recover precisely the retrieval phase boundaries found before @xcite .",
    "similar results with exclusively sharp phase boundaries , between now enlarged ordered regions , are found for somewhat lower connectivity , as shown in fig .",
    "3(a ) for @xmath173 . for low @xmath4 ,",
    "we find three different ordered retrieval ferromagnetic phases @xmath194 , @xmath195 and @xmath196 , in a previous notation @xcite and characterized below , separated by discontinuous phase boundaries and in which @xmath197 for uniformly distributed patterns .",
    "as @xmath4 increases , these phases disappear discontinuously at the critical phase boundaries @xmath169 into the @xmath198 phase .",
    "the three phases correspond to possible locally stable states which become globally stable at the thermodynamic transition for lower @xmath4 , not shown in the figure for simplicity .",
    "which of the locally stable states is actually reached in the dynamic evolution of the network will depend , as usual , on their basins of attraction and the choice of the initial state .",
    "one may consider four regimes in the @xmath199 limit .",
    "first , when @xmath44 is small , that is within the phase @xmath194 , mainly the high activity states are favored with @xmath200 with an overemphasized overlap @xmath201 ; the spin - glass order parameter and the hamming distance become @xmath180 and @xmath202 , respectively . for larger and intermediate @xmath44",
    ", there should be a phase , called @xmath195 , characterized by states of the network that follow essentially the patterns , with @xmath203 and an overlap given by @xmath204 , the spin - glass order parameter @xmath205 and a vanishing hamming distance . between the small and the intermediate @xmath44 regimes",
    "there could be a coexistence region of the phase @xmath194 with the phase @xmath195 where the states of the network start to recognize the full structure of the patterns .",
    "finally , there should be a phase characteristic of the large @xmath44 regime in which mainly the intermediate states with @xmath206 are activated leading to a performance with @xmath207 , @xmath208 and again @xmath202 .",
    "this is the phase @xmath196 , which should have an overlap with the phase @xmath195 at intermediate @xmath44 .",
    "these expectations have been confirmed by means of the solutions to the saddle - point equations in the @xmath199 limit and some of the results can be found in earlier work @xcite .",
    "the four regimes are given by @xmath209 , @xmath210 , @xmath211 and @xmath212 .",
    "they do not depend on the connectivity and are therefore independent of the architecture of the network , in accordance with earlier results either on the fully connected or the extreme symmetrically dilute network @xcite .    on the other hand",
    ", we confirm the symmetry of the limiting @xmath169 for @xmath213 and for @xmath214 , in accordance with earlier results @xcite .",
    "we also find that the optimal performance line appears within the @xmath195 phase and that the network has a relatively high performance with a small hamming distance in that phase , with an overlap at the critical phase boundary that is @xmath215 of that at @xmath140 .",
    "when the connectivity is reduced to @xmath216 , the distinction between the phases @xmath194 and @xmath195 starts to disappear , as shown by the enlarged gap in fig .",
    "3(b ) , allowing for a continuous change into the high performance phase for intermediate @xmath4 . note that there is still a discontinuous phase boundary between the phases @xmath194 and @xmath196 and that the presence of this phase boundary is important in order to inhibit the transition to the low performance phase @xmath196 .",
    "furthermore , we still find four regimes for low @xmath4 and that the three main retrieval phases , @xmath194 , @xmath195 and @xmath196 , end discontinuously at the critical phase boundary @xmath169 .",
    "the optimal performance line is still purely within the @xmath195 phase , as in the previous case , and the network has a high performance up to @xmath169 , with an overlap close to one on the phase boundary , for @xmath44 around @xmath217 .    as the connectivity is further decreased to @xmath218",
    "we find the phase diagram shown in fig .",
    "3(c ) with the three main retrieval phases that disappear discontinuously at @xmath169 and the four low-@xmath4 regimes discussed above .",
    "the distinction between the phases @xmath194 and @xmath195 disappears now at lower @xmath4 and the optimal network performance in the central phase @xmath195 can be reached continuously within a considerable range of @xmath4 from the @xmath194 phase . as in the previous cases ,",
    "there is a coexistence region between the phases @xmath194 and @xmath195 , now only for small @xmath4 .",
    "moreover , there is no need now for a specific choice of threshold parameter @xmath44 in order to access most of the high performance domain of the network .",
    "incidentally , note that the continuous retrieval phase boundary for the common phase @xmath194 and @xmath195 is similar to that found for the fully connected network with pattern activity @xmath219 @xcite .",
    "we have no further insight , at present , of this feature .    finally , in order to check the overall simplification of the phase diagrams that appears with decreasing connectivity , we also present results for @xmath220 that are shown in fig .",
    "the phase boundaries are still lines of discontinuous transitions and the distinction between the four regimes is restricted to even lower values of @xmath4 .",
    "there is now a considerably larger region of continuous changeover from the phase @xmath194 to the phase @xmath195 , with access to optimal performance , without the need of a fine adjustment in @xmath44 .      in the case of",
    "@xmath2 we again consider uniformly distributed patterns between @xmath178 and @xmath149 , implying that @xmath221 , and restrict the results to the zero temperature case .",
    "the discontinuous transitions to the ordered phase are shown in full lines in the @xmath222 phase diagram for decreasing connectivity in fig .",
    "4 , where we omit again the thermodynamic transitions and the long - dashed lines indicate now the onset of the binary - network behavior .",
    "note that the disappearance of the ordered phase takes place at @xmath223 for any finite connectivity , as in the case of the fully connected network and in networks of different architecture , like the extremely asymmetric diluted and the @xmath16-ising layered network @xcite . in the case of the extremely diluted networks ,",
    "the retrieval phase boundaries have a reentrance for @xmath224 @xcite .",
    "this seems to be a feature of the @xmath6 limit , as one can see from our further results for the connectivity dependence of the maximum storage capacity @xmath225 and the corresponding @xmath226 , both shown in fig .",
    "5 .    as in the case of both the",
    "fully connected and the symmetrical extremely diluted network , and in contrast with the @xmath0 state network , we find that even at zero temperature most of the retrieval regions for different @xmath3 are stable to replica - symmetry - breaking perturbations , that is for @xmath44 above the at lines .",
    "this includes the maximum storage capacity and it follows from a positive replicon eigenvalue for this case obtained from eq.(38 ) , @xmath227 where @xmath125 is the susceptibility for the continuous network presented in the appendix .",
    "the at line is given by @xmath228 and , again , in both the @xmath134 and the @xmath6 limit , in which @xmath135 , this result coincides with that for the fully connected and the symmetrical extremely diluted network @xcite .",
    "we derived in this work the replica symmetric mean - field theory for @xmath16-ising attractor networks with low - activity patterns and arbitrary symmetric dilution of the synaptic connections .",
    "we extended earlier studies on the retrieval behavior and thermodynamic properties of either fully connected or symmetrical extremely diluted @xmath16-ising neural networks with low activity patterns , in order to study the effects of a gradual dilution of the synaptic connections guided by the motivation that neurons in biological networks of associative memory are neither fully connected nor very sparsely linked to other neurons .",
    "we are mainly interested in the nature of the phase transitions to locally stable retrieval states and in the role that synaptic dilution has in either reducing or destroying sharp transitions motivated by the plasticity of biological networks . in the context of the networks studied here , we focus mainly on the dependence of the retrieval properties on the threshold or",
    "gain parameter @xmath44 for decreasing connectivity @xmath3 and ask to which extent can a network go from a given locally stable retrieval state to a nearby high - performance state without crossing phase boundaries of discontinuous transitions .    in order to answer that question , one has to look for appropriate phase diagrams that were obtained here in replica - symmetric mean - field theory .",
    "since deviations from that theory are very small and appear only in a small region near @xmath159 , we may still draw relevant conclusions from those diagrams .",
    "the explicit phase diagrams obtained in this work apply to uniformly distributed patterns and to networks with arbitrary symmetric dilution .",
    "the behavior of both the fully connected and the extremely diluted network are recovered when @xmath134 and @xmath6 , respectively , in that our general saddle - point equations become identical to those for either case that have been obtained before @xcite .",
    "we find that common features of the @xmath199 limiting behavior in either fully connected or symmetrical extremely diluted networks also appear for arbitrary finite connectivity @xmath3 .",
    "this confirms the expectations of earlier works that pointed out the architecture independent nature of some properties @xcite . among these",
    "is the particular @xmath188 where the thermodynamic transition ends in the @xmath0 state network and where the optimal performance takes place for low @xmath4 , both for @xmath159 .",
    "the common limiting @xmath5 in the @xmath229 phase diagram for varying @xmath3 is a further property of this kind , as well as the four distinct domains in the @xmath1 state network and the @xmath188 limiting threshold for the @xmath2 network at @xmath140 .    the main dependence of the behavior of the network on the connectivity arises for finite @xmath4 .",
    "for both odd and even @xmath16 , we find that a common feature that appears with an increase in the dilution of the synaptic connections is to suppress selected sharp phase boundaries of discontinuous transitions that make the optimal performance domain readily accessible to a wide region of low - threshold locally stable retrieval states . note that , on the other hand , the sharp boundary for the @xmath1 state network between the low performance phases @xmath194 and @xmath196 survives synaptic dilution , at least to quite an extent .",
    "these features of the network for small but finite connectivity appear long before the extremely diluted limit and they should be of considerable interest .    concentrating , for simplicity , on the @xmath0 state network we also found that the boundaries between thermodynamic transitions are suppressed by an increase of the synaptic dilution , and expect a similar behavior for the @xmath1 state network .",
    "the results of our work may be used to infer the behavior of other networks . since the fully connected network is strongly sensitive to pattern activity",
    ", one may consider other than uniformly distributed patterns @xcite .",
    "there are , essentially , two kinds of phase diagrams in that case about which we can make definite predictions .",
    "one is the type of phase diagram for patterns of relatively large activity that has mostly a decreasing phase boundary with increasing @xmath44 and an optimal performance line that appears only at small @xmath44 .",
    "the other type , that appears for medium or small pattern activity , has an optimal performance only at intermediate @xmath44 , like the cases shown in fig . 3 , and both types appear for @xmath0 and @xmath1 , while only the first type seems to appear for @xmath2 .",
    "we expect that the main effect of a finite synaptic dilution on the first type of phase diagram is simply to shift the retrieval phase boundaries upwards towards a larger @xmath169 . in the second type of phase diagrams ,",
    "however , we expect also a disappearance of the discontinuous phase boundary between the @xmath194 and @xmath195 phases , in essentially the same way we found in the present work , allowing for a smooth changeover from states of non - optimal to those of optimal performance",
    ".    the main result of this work , that partially connected multi - state hebbian networks can attain near - optimal performance without a fine tuning of neuron activity may be a simplified statistical mechanics explanation of why biological memory networks seem to prefer low - activity patterns between partially connected neurons .",
    "of course , biological networks have asymmetric synaptic connections which may lead through a dynamic evolution to different stationary states , the search of which is certainly an interesting issue that deserves a separate investigation , currently in progress .",
    "the study of the effects of symmetric synaptic dilution may be extended to other problems that deal with associative memory , like the categorization problem as a classification task in @xmath16-ising networks @xcite .",
    "this has been done recently for @xmath230 @xcite and there is work in progress for general @xmath16 @xcite .    *",
    "acknowledgments *    we thank d. boll and g. m. shim for clarifying a point on a previous version of the manuscript .",
    "this work was financially supported in part by cnpq ( conselho nacional de desenvolvimento cientfico e tecnolgico ) brazil .",
    "we present here , for completeness , the explicit expressions for the saddle - point equations obtained for the symmetrically diluted network with arbitrary connectivity @xmath3 and uniformly distributed patterns , for @xmath0 , @xmath1 and @xmath2 .    for @xmath0 taking patterns",
    "@xmath150 with probability @xmath151 and @xmath152 with probability @xmath153 we have @xmath231 @xmath232\\ , , \\label{a.2}\\ ] ] @xmath233\\ , , \\label{a.3}\\ ] ] with @xmath234 given by eq.(39 ) .",
    "these equations reduce to the equations for the extreme symmetrically diluted network , as well as for the fully connected network , in the @xmath6 limit and @xmath134 , respectively .",
    "the same applies for the cases of @xmath1 and @xmath2 , presented below .    in the zero - temperature limit ( @xmath144 )",
    ", the integrations over the gaussian variable @xmath121 can be done explicitly . in the @xmath0 case",
    "we obtain , for @xmath235 , @xmath236\\ , , \\label{a.4}\\ ] ] @xmath237\\ , , \\label{a.5}\\ ] ] @xmath238\\ , , \\label{a.6}\\ ] ] with the relation between @xmath126 , @xmath124 and @xmath125 given by eq.(36 ) .    for the @xmath1 state model with states and",
    "uniformly distributed patterns that take the values @xmath178 , @xmath239 , @xmath240 and @xmath179 , @xmath193 and we obtain @xmath241\\ , , \\label{a.7}\\ ] ] @xmath242\\ , , \\label{a.8}\\ ] ] @xmath243\\ , .",
    "\\label{a.9}\\ ] ] where @xmath244 in the zero - temperature limit @xmath245\\ , , \\label{a.11}\\ ] ] and the above equations yield , for positive @xmath122 , @xmath246\\nonumber\\\\       & + & \\frac{1}{10}\\left[{\\rm erf}(\\frac{m+4\\tilde\\theta }       { 3\\sqrt{2\\alpha rc } } )                                    + { \\rm erf}(\\frac{m-4\\tilde\\theta}{3\\sqrt{2\\alpha rc } } )       + { \\rm erf}(\\frac{m}{3\\sqrt{2\\alpha rc}})\\right]\\ , , \\label{a.12}\\end{aligned}\\ ] ] @xmath247\\ , , \\label{a.13}\\ ] ] @xmath248\\ , .",
    "\\label{a.14}\\end{aligned}\\ ] ] finally , in the zero - temperature limit for @xmath2 and uniformly distributed patterns between @xmath178 and @xmath149 , implying @xmath221 , we obtain for @xmath235 , @xmath249\\ , , \\label{a.11}\\ ] ] @xmath250\\ , , \\label{a.12}\\end{aligned}\\ ] ] @xmath251 where @xmath252 and this integrations can be performed directly .",
    "watkin and d. sherrington , europhys . lett .",
    "* 14 * , 791 ( 1991 ) .",
    "b. derrida , e. gardner and a. zippelius , europhys .",
    "lett . * 4 * , 167 ( 1987 ) .",
    "d. sherrington and s. kirkpatrick , phys .",
    "lett . * 35 * , 1792 ( 1975 ) .",
    "hopfield , proc .",
    "usa * 79 * , 2554 ( 1982 ) .",
    "j. hertz , a. krogh and r. palmer , _ introduction to the theory of neural computation _",
    "( reading , ma .",
    "addison - wesley , 1991 ) .",
    "a. canning and j .- p .",
    "naef , j. phys .",
    "i * 2 * , 1791 ( 1992 ) .",
    "amit , h. gutfreund and h. sompolinsky , ann .",
    "( ny ) * 173 * , 30 ( 1987 ) .",
    "yedidia , j. phys .",
    "a * 22 * , 2265 ( 1989 ) .",
    "h. rieger , j. phys .",
    "a * 23 * , l1273 ( 1990 ) . c. meunier , d. hansel and a. verga , j. stat",
    ". phys . * 55 * , 859 ( 1989 ) .",
    "d. boll , p. dupont and b. vinck , j. phys .",
    "a. * 25 * , 2859 ( 1992 ) .",
    "d. boll , b. vinck and v.a .",
    "zagrebnov , j. stat . phys . * 70 * , 1099 , ( 1993 ) .",
    "d. boll , g.m .",
    "shim , b. vinck and v.a .",
    "zagrebnov , j. stat . phys . * 74 * , 565 ( 1994 ) .",
    "d. boll , g.m .",
    "shim and b. vinck , j. stat . phys .",
    "* 74 * , 583 ( 1994 ) .",
    "d. boll , h. rieger and g.m .",
    "shim , j. phys .",
    "a * 27 * , 3411 ( 1994 )",
    "rolls , a. treves , d. foster and c. perez - vicente , neural networks * 10 * , 1559 ( 1995 ) .",
    "arbib , editor ( m.i.t . press , 1995 ) .",
    "d. boll , g. jongen and g.m .",
    "shim , j. stat . phys . * 96 * , 861 ( 1999 ) .",
    "d. boll , d. m. carlucci and g.m .",
    "shim , j. phys .",
    "a * 33 * , 6481 ( 2000 ) .",
    "l. viana and a.j .",
    "bray , j. phys .",
    "c * 18 * , 3037 ( 1985 ) .",
    "h. sompolinsky , phys . rev . * 34 * , 2571 ( 1986 ) . m.a .",
    "p. idiart and a. theumann , j. phys .",
    "a * 25 * , 779 ( 1992 ) .",
    "j.r . almeida and d. thouless ,",
    "a * 11 * , 983 ( 1978 ) .",
    "r. erichsen jr . , w.k .",
    "theumann and d.r.c .",
    "dominguez , phys rev .",
    "e * 60 * , 7321 ( 1999 ) .",
    "p.r . krebs and w.k .",
    "theumann , phys .",
    "e * 60 * , 4580 ( 1999 ) .",
    "r. erichsen jr . and w.k .",
    "theumann , unpublished .",
    "+    * figure captions * + fig .",
    "phase diagram @xmath168 for the @xmath0 state network with uniformly distributed patterns and connectivity @xmath3 as shown , at @xmath159 .",
    "the full and the long - dashed lines represent the retrieval and the thermodynamic transition , respectively . the latter ends on the right at the ( dotted ) optimal performance line and the spin - glass phase appears at the left of the paramagnetic phase boundary indicated by the short - dashed lines .",
    "the two retrieval regions i and ii are discussed in the text and the inset corresponds to @xmath253 where the distinction betweeen these phases starts to disappear .",
    "stable phase diagram to the right of the de almeida - thouless ( dot - dashed ) line in the @xmath229 plane for the @xmath0 state network with uniformly distributed patterns , @xmath187 and connectivity @xmath3 as shown .",
    "the full lines represent the retrieval transition .",
    "phase diagram @xmath168 for the @xmath1 state network with uniformly distributed patterns and connectivity ( a)@xmath173 , ( b)@xmath254 , ( c)@xmath218 and ( d)@xmath220 , at @xmath159 .",
    "the full lines represent retrieval transitions and the optimal performance is indicated in dotted lines .",
    "the central region is the best performance phase @xmath195 and there is a low-@xmath4 coexistence region between phases @xmath194 and @xmath195 .",
    "phase diagram @xmath168 for the @xmath2 state network with uniformly distributed patterns and connectivity @xmath3 as shown , at @xmath159 .",
    "the full lines represent retrieval transitions , the optimal performance is indicated in dotted lines and the onset of the binary network is shown by long - dashed lines .",
    "the phases are stable to the right of the de almeida - thouless line ( dot - dashed ) . fig . 5 : connectivity dependence for the maximum storage capacity @xmath225 and the corresponding @xmath226 in the @xmath2 state network with uniformly distributed patterns at @xmath159 ."
  ],
  "abstract_text": [
    "<S> the retrieval behavior and thermodynamic properties of symmetrically diluted q - ising neural networks are derived and studied in replica - symmetric mean - field theory generalizing earlier works on either the fully connected or the symmetrical extremely diluted network . </S>",
    "<S> capacity - gain parameter phase diagrams are obtained for the @xmath0 , @xmath1 and @xmath2 state networks with uniformly distributed patterns of low activity in order to search for the effects of a gradual dilution of the synapses . </S>",
    "<S> it is shown that enlarged regions of continuous changeover into a region of optimal performance are obtained for finite stochastic noise and small but finite connectivity . </S>",
    "<S> the de almeida - thouless lines of stability are obtained for arbitrary connectivity , and the resulting phase diagrams are used to draw conclusions on the behavior of symmetrically diluted networks with other pattern distributions of either high or low activity .    </S>",
    "<S> epsf    [ sec : level1 ] </S>"
  ]
}