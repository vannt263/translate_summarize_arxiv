{
  "article_text": [
    "electronic structure calculations based on first principles use a very successful combination of _ density functional theory _ ( dft )",
    "@xcite and _ pseudopotential theory _ @xcite .",
    "dft reduces the original multi - electron shrdinger equation into an effective one - electron kohn - sham equation , where all non - classical electronic interactions are replaced by a functional of the charge density .",
    "the pseudopotential theory further simplifies the problem by replacing the true atomic potential with an effective `` pseudopotential '' that is smoother but takes into account the effect of core electrons . combining pseudopotential with dft",
    "greatly reduces the number of one - electron wave - functions to be computed .",
    "however , even with these simplifications , solving the final kohn - sham equation can still be computationally challenging , especially when the systems being studied are complex or contain thousands of atoms .",
    "several approaches have been employed in solving the kohn - sham equations .",
    "they can be classified in two major groups : basis - free or basis - dependent approaches , according to whether they use an explicit basis set for electronic orbitals or not . among the basis - dependent approaches ,",
    "plane - wave methods are frequently used in applications of dft to periodic systems @xcite , whereas localized basis sets are very popular in quantum - chemistry applications @xcite .",
    "special basis sets , which do not make use of pseudopotentials , have also been designed for all - electron dft calculations .",
    "these basis sets include localized atomic orbitals , linearized augmented plane waves , muffin - tin orbitals , and projector - augmented waves .",
    "a survey of advantages and disadvantages of these explicit - basis methods can be found in @xcite .",
    "real - space methods are basis - free , and they have gained ground in recent years @xcite due in great part to their simplicity .",
    "one advantage of real - space methods is that they are quite easy to implement in parallel environment .",
    "a second advantage is that , in contrast with the plane - wave approach , they do not impose artificial periodicity in non - periodic systems .",
    "third , the application of potentials onto electron wave - functions is performed directly in real space .",
    "although the hamiltonian matrices with a real - space approach are typically larger than with plane waves , the hamiltonians are highly sparse and never stored or computed explicitly . only matrix - vector products that represent the application of the hamiltonians on wave - functions need to be computed .",
    "this article focusses on effective techniques to handle the most computationally expensive part of dft calculations , namely the self - consistent - field ( scf ) iteration .",
    "we present details of a recently developed nonlinear chebyshev - filtered subspace iteration ( chefsi ) method .",
    "the sequential version of chefsi is first proposed in @xcite .",
    "the parallel chefsi is implemented in our own dft package called parsec ( pseudopotential algorithm for real - space electronic calculations ) @xcite .",
    "although chefsi is described in the framework of real - space dft , the subspace filtering method can be employed to other self - consistent field iterations .",
    "this method takes advantage of the fact that intermediate scf iterations do not require accurate eigenvalues and eigenvectors of the kohn - sham equation .",
    "the standard scf iteration framework is used in chefsi , and a self - consistent solution is sought , which means that chefsi has the same accuracy as other standard dft approaches .",
    "one can view chefsi as a technique to directly tackle the original nonlinear kohn - sham eigenvalue problems by a form of nonlinear subspace iteration , without emphasizing the intermediate linearized kohn - sham eigenvalue problems .",
    "in fact , within chefsi , explicit eigenvectors are computed only at the first scf iteration , in order to provide a suitable initial subspace .",
    "after the first scf step , the explicit computation of eigenvectors at each scf iteration is replaced by a single subspace filtering step .",
    "the method reaches self - consistency within a number of scf iterations that is close to that of eigenvector - based approaches .",
    "however , since eigenvectors are not explicitly computed after the first step , a significant gain in execution time results when compared with methods based on explicit diagonalization . when compared with calculations based on efficient eigenvalue packages such as arpack @xcite and trlan @xcite , a tenfold or higher speed - up is usually observed .",
    "chefsi enabled us to perform a class of highly challenging dft calculations , including clusters with over ten thousand atoms , which were not feasible before .",
    "this article begins with a summary of scf for dft calculations in section [ eigp ] .",
    "details about the parallel implementation are included in section [ ppp ] .",
    "the chebyshev subspace filtering algorithm is presented in section [ main - alg ] , and the block chebyshev - davidson algorithm for the initial diagonalization is discussed in section [ chdav ] .",
    "the block chebyshev - davidson method @xcite improves considerably the efficiency of the diagonalization at the first scf iteration , compared with the thick - restart lanczos ( trlan ) method @xcite which was used in @xcite .",
    "the paper ends with numerical results in section [ numer ] , and a few concluding remarks .",
    "within dft , the multi - electron schrdinger equation is simplified as the following kohn - sham equation : @xmath0      \\psi_i(r ) = e_i \\psi_i(r),\\ ] ] where @xmath1 is a wave function , @xmath2 is a kohn - sham eigenvalue , @xmath3 is the planck constant , and @xmath4 is the electron mass . in practice",
    "we use atomic units , thus @xmath5 .",
    "the _ total potential _",
    "@xmath6 , also referred to as the _ effective potential _",
    ", includes three terms , @xmath7 where @xmath8 is the ionic potential , @xmath9 is the hartree potential , and @xmath10 is the exchange - correlation potential .",
    "the hartree and exchange - correlation potentials depend on the _ charge density _ @xmath11 , which is defined as @xmath12 here @xmath13 is the number of occupied states , which is equal to half the number of valence electrons in the system .",
    "the factor of two comes from spin multiplicity .",
    "equation ( [ density ] ) can be easily extended to situations where the highest occupied states have fractional occupancy or when there is an imbalance in the number of electrons for each spin component .",
    "the most computationally expensive step of dft is in solving the kohn - sham equation [ kseq ] .",
    "since @xmath6 depends on the charge density @xmath11 , which in turn depends on the wavefunctions @xmath14 , this equation can be viewed as a _ nonlinear eigenvalue problem_. the scf iteration is a general technique used to solve this nonlinear eigenvalue problem .",
    "it starts with an initial guess of the charge density , then obtains the initial @xmath6 and solves [ kseq ] for @xmath1 s to update @xmath11 and @xmath6 .",
    "then [ kseq ] is solved again for the new @xmath1 s and the process is iterated until @xmath6 ( and also the wave functions ) becomes stationary .",
    "in general , most of the computational effort involved in dft is spent solving equation [ kseq ] .",
    "for this reason , it is the goal of any dft code to lessen the burden of solving [ kseq ] in the scf iteration .",
    "one possible avenue to achieve this is to use better diagonalization routines .",
    "however this approach is limited as most diagonalization software has now reached maturation . at the other extreme , one can attempt to avoid diagonalization altogether , and this leads to the body of work represented by linear - scaling or order - n methods ( see e.g. @xcite ) .",
    "this approach however has other limitations .",
    "in particular , the approximations involved rely heavily on some decay properties of the density matrix in certain function bases",
    ". in particular , they will be difficult to implement in real - space discretizations .",
    "our approach lies somewhere between these extremes .",
    "we take advantage of the fact that accurate eigenvectors are unnecessary at each scf iteration , since hamiltonians are only approximate in the intermediate scf steps , and we exploit the nonlinear nature of the problem .",
    "the main point of our algorithm , developed in @xcite , is that once we have a good starting point for the hamiltonian , it suffices to filter each basis vector at each iteration . in the intermediate scf steps ,",
    "these vectors are no longer eigenvectors but together they represent a good basis of the desired invariant subspace .",
    "the parallel implementation of the idea will be discussed in section [ main - alg ] .",
    "the next section summarizes parallel implementation issues in parsec .",
    "parsec uses pseudopotential real - space implementation of dft .",
    "the motivation and original ideas behind the method go back to the early 1990s @xcite . within parsec , an uniform cartesian grid in real - space",
    "is placed on the region of interest , and the kohn - sham equation is discretized by a high order finite - difference method @xcite on this grid .",
    "wavefunctions are expressed as functions of grid positions . outside a specified sphere boundary that encloses the physical system ,",
    "wavefunctions are set to zero for non - periodic systems .",
    "in addition to the advantages mentioned in the introduction , another advantage of the real - space approach is that periodic boundary conditions are also reasonably simple to implement @xcite .    the latest version of parsec is written in fortran 95 .",
    "parsec has now evolved into a mature , massively parallel package , which includes most of the functionality of comparable dft codes @xcite .",
    "the reader is referred to @xcite for details and the rationale of the parallel implementation .",
    "the following is a brief summary of the most important points .",
    "the parallel mode of parsec uses the standard message passing interface ( mpi ) library for communication .",
    "parallelization is achieved by partitioning the physical domain which can have various shapes depending on boundary conditions and symmetry operations .",
    "figure [ ddm ] illustrates four cube - shaped neighboring sub - domains . for a generic , confined system without symmetry ,",
    "the physical domain is a sphere which contains all atoms plus some additional space ( due to delocalization of electron charge ) . in recent years",
    ", parsec has been enhanced to take advantage of physical symmetry .",
    "if the system is invariant upon certain symmetry operations , the physical domain is replaced with an irreducible wedge constructed according to those operations .",
    "for example , if the system has mirror symmetry on the @xmath15 plane , the irreducible wedge covers only one hemisphere , either above or below the mirror plane . for periodic systems , the physical domain is the periodic cell , or an irreducible wedge of it if symmetry operations are present . in any circumstance ,",
    "the physical domain is partitioned in compact regions , each assigned to one processor only .",
    "good load balance is ensured by enforcing that the compact regions have approximately the same number of grid points .",
    "once the physical domain is partitioned , the physical problem is mapped onto the processors in a data - parallel way : each processor is in charge of a block of rows of the hamiltonian corresponding to the block of grid points assigned to it . the eigenvector and potential vector arrays are row - wise distributed in the same fashion .",
    "the program only requires an index function @xmath16 which returns the number of the processor in which the grid point @xmath17 resides .    because the hamiltonian matrix is never stored , we need an explicit reordering scheme which renumbers rows consecutively from one processor to the next one . for this purpose",
    "we use a list of pointers that gives for each processor , the row with which it starts .",
    "since finite difference discretizetion is used , when performing an operation such as a matrix - vector product , communication will be required between nearest neighbor processors . for communication",
    "we use two index arrays , one to count how many and which rows are needed from neighbors , the other to count the number of local rows needed by neighbors .    with this design of decomposition and mapping , the data required by the program can be completely distributed .",
    "being able to distribute the memory requirement is quite important in solving large problems on standard supercomputers .",
    "parallelizing subspace methods for the linearized eigenvalue problems ( obtained from a finite difference discretization of eqn . [ kseq ] ) becomes quite straightforward with the above mentioned decomposition and mapping .",
    "note that the subspace basis vectors contain approximations to eigenvectors , therefore the rows of the basis vectors are distributed in the same way as the rows of the hamiltonian .",
    "all matrix - matrix products , matrix - vector products , and vector updates ( e.g. , linear combinations of vectors ) , can be executed in parallel .",
    "reduction operations , e.g. , computing inner products and making the result available in each processor , are efficiently handled by the mpi reduction function mpi_allreduce ( ) .",
    "the main idea of chefsi is to start with a good initial subspace @xmath18 corresponding to occupied states of the initial hamiltonian .",
    "this initial @xmath18 is usually obtained by a diagonalization step .",
    "no diagonalizations are necessary after the first scf step . instead , the subspace from the previous iteration is filtered by a low degree-@xmath19 chebyshev polynomial , @xmath20 , constructed for the current hamiltonian @xmath21 .",
    "the polynomial differs at each scf step since @xmath21 changes .",
    "the goal of the filter is to make the subspace spanned by @xmath22 approximate the eigensubspace corresponding to the occupied states of the final @xmath21 . at the intermediate scf steps , the basis need not be an accurate eigenbasis since the intermediate hamiltonians are not exact .",
    "the filtering is designed so that the resulting sequence of subspaces will progressively approximate the desired eigensubspace of the final hamiltonian when self - consistency is reached .",
    "our approach exploits the well - known fast growth property outside the @xmath23 $ ] interval of the chebyshev polynomial , this allows us to use low degree chebyshev polynomials to achieve sufficient filtering . at each scf step ,",
    "only two parameters are required to construct an effective chebyshev filter , namely , a lower bound and an upper bound of the higher portion of the spectrum of the current hamiltonian @xmath21 in which we want @xmath20 to be small .",
    "we propose simple but efficient ways to obtain these bounds , very little additional cost is required for the bound estimates .    after self - consistency",
    "is reached , the chebyshev filtered subspace includes the eigensubspace corresponding to occupied states .",
    "explicit eigenvectors can be readily obtained by a _ rayleigh - ritz refinement _",
    "@xcite ( also called _ subspace rotation _ ) step .",
    "we refer to @xcite for more algorithmic details and a literature survey concerning application of chebyshev polynomials in dft calculations .",
    "the main structure of the chefsi method is given in algorithm [ chefsi ] .",
    "it is quite similar to that of the standard scf iteration discussed in section ii .",
    "one major difference is that the inner iteration for diagonalization at _ step 2 _ is now performed only at the first scf step .",
    "thereafter , diagonalization is replaced by a single chebyshev - filtered subspace step , denoted as * chefs * in algorithm [ chefsi ] .",
    "chefsi for scf calculation : [ chefsi ] +    ' '' ''    1 .   start from an initial guess of @xmath11 , get  @xmath24 .",
    "2 .   solve  @xmath25        \\psi_i(r ) = e_i \\psi_i(r ) $ ]   for @xmath26 .",
    "3 .   compute new charge density  @xmath27 .",
    "4 .   solve for new hartree potential  @xmath9 from  @xmath28 .",
    "5 .   update  @xmath10 ; get new  @xmath29 with + a potential - mixing step .",
    "if  @xmath30 , * stop*. 7 .",
    "@xmath31 ( update @xmath21 implicitly ) ; apply the following + chebyshev - filtered subspace ( * chefs * ) method to get @xmath32 approximate wavefunctions : 1 .",
    "compute  @xmath33 upper bound of the spectrum of @xmath21 + set @xmath34 the largest ritz value from previous iteration .",
    "2 .   perform chebyshev filtering to the matrix @xmath35 , whose column - vectors + are the @xmath32 discretized wavefunctions of @xmath36 : + @xmath37 3 .",
    "ortho - normalize the basis @xmath38 by iterated gram - schmidt .",
    "4 .   perform the rayleigh - ritz ( rotation ) step : a.   compute @xmath39 ; b.   compute the eigendecomposition of @xmath40 :  @xmath41 , + where @xmath42 contains non - increasingly ordered eigenvalues of @xmath40 , + and @xmath43 contains the corresponding eigenvectors ; c.   rotate the basis as @xmath44 ;  return @xmath38 and @xmath42 .",
    "goto step 3 .    ' '' ''    the upper bound at _ step 7.1 _ in algorithm [ chefsi ] can be obtained by using an upper - bound - estimator presented in @xcite .",
    "the chebyshev - filter step in _ step 7.2 _ calls a subroutine which applies the chebyshev filter to each of the columns of @xmath38",
    ". if @xmath19 is the degree of the polynomial , this operation amounts to computing the sequence of blocks @xmath45 , @xmath46 as follows : @xmath47 starting with @xmath48 , @xmath49 .",
    "the returned filtered block is @xmath50 .",
    "the scalars @xmath51 and @xmath52 are defined by @xmath53 and @xmath54 . for simplicity we presented here an unscaled version of the filtering process . to prevent the @xmath45 blocks from overflowing it is safer to scale them at each iteration .",
    "the scaling operation is inexpensive as it uses only values of the chebyshev polynomial at the approximate smallest eigenvalue of the hamiltonian .",
    "the reader is referred to @xcite for details . for discussion of scaling related to chebyshev filtering",
    ", we refer interested readers to @xcite or a more detailed technical report @xcite .",
    "the parallel implementation of algorithms [ chefsi ] is straightforward with the parallel paradigm discussed in section [ ppp ] .",
    "we only mention that the matrix - vector products related to filtering , computing upper bounds , and rayleigh - ritz refinement , can easily be executed in parallel .",
    "the re - orthogonalization at _ step 7.3 _  of algorithm [ chefsi ] uses a parallel version of the iterated gram - schmidt dgks method @xcite , which scales better than the standard modified gram - schmidt algorithm .",
    "the estimated complexity of the algorithm is similar to that of the sequential chefsi method in @xcite . for parallel computation",
    "it suffices to estimate the complexity on a single processor .",
    "assume that @xmath55 processors are used , i.e. , each processor shares @xmath56 rows of the full hamiltonian .",
    "the estimated cost of a chefs step on each processor with respect to the dimension of the hamiltonian denoted by @xmath57 , and the number of computed states @xmath32 , is as follows :    * the chebyshev filtering in _ step 7.2 _ costs @xmath58 flops .",
    "the discretized hamiltonian is sparse and each matrix - vector product on one processor costs @xmath59 flops .",
    "_ step 7.2 _ requires @xmath60 matrix - vector products , at a total cost of @xmath61 where the degree @xmath19 of the polynomial is small ( typically between 8 and 20 ) .",
    "* the ortho - normalization in _ step 7.3 _ costs @xmath62 flops .",
    "there are additional communication costs because of the global reductions . * the eigen - decomposition at _ step 7.4 _ costs @xmath63 flops .",
    "* the final basis refinement step ( @xmath64 ) costs @xmath62 .",
    "if a standard iterative diagonalization method is used to solve the eigenproblem [ kseq ] at each scf step , then it also requires ( i ) the orthonormalization of a ( typically larger ) basis ; ( ii ) the eigen - decomposition of the projected rayleigh - quotient matrix ; and ( iii ) the basis refinement ( rotation ) .",
    "these operations need to be performed several times within this single diagonalization . but",
    "chefs performs each of these operations only once per scf step .",
    "therefore , although chefs scales in a similar way to standard diagonalization - based methods , the scaling constant is much smaller . for large problems",
    ", chefs can achieve a tenfold or more speedup per scf step , over using the well - known efficient eigenvalue packages such as arpack @xcite and trlan @xcite .",
    "the total speedup can be more significant since self - consistency requires several scf iteration steps .    to summarize",
    ", a standard scf method would have an outer scf loop  the usual nonlinear scf loop , and an inner diagonalization loop , which iterates until eigenvectors are within specified accuracy .",
    "algorithm  [ chefsi ] simplifies this by merging the inner - outer loops into a single outer loop , which can be considered as a _ nonlinear subspace iteration algorithm_. the inner diagonalization loop is reduced into a single chebyshev subspace filtering step .",
    "within chefsi , the most expensive scf step is the first one , as it involves a diagonalization in order to compute a good initial subspace to be used for latter filtering . in principle",
    ", any effective eigenvalue algorithms can be used .",
    "parsec originally had three diagonalization methods : diagla , which is a preconditioned davidson method @xcite ; the symmetric eigensolver in arpack @xcite ; and the thick - restart lanczos algorithm called trlan @xcite . for systems of moderate sizes ,",
    "diagla works well , and then becomes less competitive relative to arpack or trlan for larger systems when a large number of eigenvalues are required .",
    "trlan is about twice as fast as the symmetric eigensolver in arpack , because of its reduced need for re - orthogonalization . in @xcite , trlan was used for the diagonalization at the first scf step .    for very large systems",
    ", memory can become a severe constraint .",
    "one has to use eigenvalue algorithms with restart since out - of - core operations can be too slow .",
    "however , even with standard restart methods such as arpack and trlan , the memory demand can still surpass the capacity of some supercomputers .",
    "for example , the @xmath65 cluster by trlan or arpack would require more memory than the largest memory allowed for a job at the minnesota supercomputing institute in 2006 .",
    "hence it is important to develop a diagonalization method that is less memory demanding but whose efficiency is comparable to arpack and trlan . the chebyshev - davidson method @xcite is developed with these two goals in mind .",
    "it is generally accepted that for the implicit filtering in arpack and trlan to work efficiently , one needs to use a subspace with dimension about twice the number of wanted eigenvalues .",
    "this leads to a relatively large demand in memory when the number of wanted eigenvalues is large .",
    "the block chebyshev - davidson method discussed in @xcite introduced an _ inner - outer restart _ technique .",
    "the _ outer restart _ corresponds to a standard restart in which the subspace is truncated to a smaller dimension when the specified maximum subspace dimension is reached .",
    "the _ inner restart _ corresponds to a standard restart restricted to an active subspace , it is performed when the active subspace dimension exceeds a given integer @xmath66 which is much smaller than the specified maximum subspace dimension . with _",
    "inner - outer restart _ , the subspace used in chebyshev - davidson is about half the dimension of the subspace required by arpack or trlan .",
    "we adapted the proposed chebyshev filters into a davidson - type eigenvalue algorithm .",
    "although no ritz values are available from previous scf steps to be used as lower bounds , the rayleigh - ritz refinement step within a davidson - type method can easily provide a suitable lower bound at each iteration .",
    "the upper bound is again estimated by the upper - bound - estimator in @xcite , and it is computed only once .",
    "these two bounds are sufficient for constructing a filter at each chebyshev - davidson iteration .",
    "the constructed filter magnifies the wanted lower end of the spectrum and dampens the unwanted higher end , therefore the filtered block of vectors have strong components in the wanted eigensubspace , which results in an efficiency that is comparable to that of arpack or trlan .",
    "the main structure of this chebyshev - davidson method is sketched in algorithm [ bcd ] , we refer interested readers to @xcite for algorithmic details .",
    "structure outline of the block chebyshev - davidson method [ bcd ] +    ' '' ''    = 4.6 mm    1 .",
    "compute  @xmath67 using the upper - bound - estimator in @xcite ;   set  @xmath68 as the median of the + eigenvalues of the tri - diagonal matrix from the upper - bound - estimator .",
    "+ make the given initial size-@xmath69 block @xmath70 orthonormal , set @xmath71 $ ] .",
    "@xmath72= { { \\tt chebyshev\\_filter } } ( v_1 ,   m , { b_{low } ,   b_{up } } ) $ ] .",
    "3 .   augment the basis @xmath18 by @xmath73 :   @xmath74 $ ] , make @xmath18 orthonormal .",
    "inner - restart if active subspace dimension exceeds a given integer  @xmath66 .",
    "rayleigh - ritz refinement :   update matrix @xmath4 s.t .",
    "@xmath75 ; + do eigendecomposition of @xmath4 :   @xmath76 ;   updated basis @xmath18 :   @xmath77 . 6 .",
    "compute residual vectors , determine convergence ; + perform deflation if some eigenpairs converge . 7",
    "if all wanted eigenpairs converged , stop ;  else , adapt @xmath78 , + set   @xmath79 @xmath80 _ the first @xmath69 non - converged ritz vectors _ in @xmath18 @xmath81 $ ] . 8 .   outer - restart",
    "if size of  @xmath18 exceeds maximum subspace dimension .",
    "9 .   continue from step 2 .    ' '' ''    the first step diagonalization by the block chebyshev - davidson method , together with the chebyshev - filtered subspace ( chefs ) method , enabled us to perform scf calculations for a class of large systems , including the silicon cluster @xmath65 for which over 19000 eigenvectors of a hamiltonian with dimension around 3 million were to be computed .",
    "these systems are practically infeasible with the other three eigensolvers ( arpack , trlan and diagla ) in parsec , using the current supercomputer resources available to us at the minnesota supercomputing institute ( msi ) .",
    "parsec has been applied to study a wide range of material systems ( e.g. @xcite ) .",
    "the focus of this section is on large systems where relatively few numerical results exist because of the infeasibility of eigenvector - based methods .",
    "we mention that @xcite contains very interesting studies on clusters containing up to 1100 silicon atoms , using the well - known efficient plane - wave dft package vasp @xcite ; however , it is stated in @xcite that a cluster with 1201 silicon atoms is `` too computationally intensive '' . as a comparison , parsec using chefsi , together with the currently developed symmetric operations of real - space pseudopotential methods @xcite",
    ", can now routinely solve silicon clusters with several thousand atoms .",
    "the hardware used for the computations is the sgi altix cluster at msi , it consists of 256 intel itanium processors at cpu rates of 1.6 ghz , sharing 512 gb of memory ( but a single job is allowed to request at most 250 gb memory ) .",
    "the goal of the computations is not to study the parallel scalability of parsec , but rather to use parsec to do scf calculation for large systems that were not studied before .",
    "therefore we do not use different processor numbers to solve the same problem .",
    "scalability is studied in @xcite for the preconditioned davidson method . here",
    "we mention that the scalability of chefs is better than eigenvector - based methods because of the reduced reorthogonalizations .    [ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]     the first example in table [ si - fe ] is a relatively small silicon cluster @xmath82 , which is used to compare the performance of chefsi with two eigenvector - based methods .",
    "all methods use the same symmetry operations @xcite in parsec .    for larger clusters @xmath83 and @xmath84 , diagla became too slow to be practical .",
    "however , we could still apply trlan for the first step diagonalization for comparison , but we did not iterate until self - consistency was reached since that would cost a significant amount of our cpu quota .",
    "note that with the problem size increasing , chebyshev - davidson compares more favorably over trlan .",
    "this is because we employed an additional trick in chebyshev - davidson , which corresponds to allowing the last few eigenvectors not to converge to the required accuracy .",
    "the number of the non fully converged eigenvectors is bounded above by @xmath66 , which is the maximum dimension of the active subspace .",
    "typically @xmath85 for hamiltonian size over a million where several thousand eigenvectors are to be computed .",
    "the implementation of this trick is rather straightforward since it corresponds to applying the chefs method to the subspace spanned by the last few vectors in the basis that have not converged to required accuracy .    for even larger clusters @xmath86 and",
    "@xmath65 , it became impractical to apply trlan for the first step diagonalization because of too large memory requirements .",
    "for these large systems , using an eigenvector - based method for each scf step is clearly not feasible .",
    "we note that the cost for the first step diagonalization by chebyshev - davidson is still rather high , it took close to 50% of the total cpu . in comparison",
    ", the chefs method saves a significant amount of cpu for scf calculations over diagonalization - based methods , even if very efficient eigenvalue algorithms are used .",
    "once the dft problem , eq .",
    "( [ kseq ] ) , is solved , we have access to several physical quantities . one of them is the ionization potential ( ip ) of the nanocrystal , defined as the energy required to remove one electron from the system .",
    "numerically , we use a @xmath87 method : perform two separate calculations , one for the neutral cluster and another for the ionized one , and observe the variation in total energy between these calculations .",
    "figure [ si10k ] shows the ip of several clusters , ranging from the smallest possible ( @xmath88 ) to @xmath65 . for comparison",
    ", we also show the eigenvalue of the highest occupied kohn - sham orbital , @xmath89 .",
    "a known fact of dft - lda is that the negative of the @xmath89 energy is lower than the ip in clusters @xcite , which is confirmed in figure [ si10k ] .",
    "in addition , the figure shows that the ip and @xmath90 approach each other in the limit of extremely large clusters .    figure [ si10k ] also shows the electron affinity ( ea ) of the various clusters .",
    "the ea is defined as the energy released by the system when one electron is added to it .",
    "again , we calculate it by performing scf calculations for the neutral and the ionized systems ( negatively charged instead of positively charged now ) . in parsec",
    ", this sequence of scf calculations can be done very easily by reusing previous information : the initial diagonalization in the second scf calculation is waived if we reuse eigenvectors and eigenvalues from a previous calculation as initial guesses for the chebfsi method .",
    "figure [ si10k ] shows that , as the cluster grows in size , the ea approaches the negative of the lowest - unoccupied eigenvalue energy .",
    "a power - law analysis in figure [ si10k ] indicates that both the ionization potential and the electron affinity approach their bulk values according to a power - law decay @xmath91 with exponent close to 1 . the numerical fits are :    @xmath92    @xmath93    with @xmath94 4.50 ev , @xmath95 3.87 ev , @xmath96 1.16 , @xmath97 1.09 , @xmath98 3.21 ev , @xmath99 3.13 ev . these values for @xmath100 and @xmath101 assume a cluster diameter @xmath42 given in nanometers . the difference between ionization potential and electron affinity is the electronic gap of the nanocrystal .",
    "as expected , the value of the gap extrapolated to bulk , @xmath102 0.63 ev , is very close to the energy gap predicted in various dft calculations for silicon , which range from 0.6 ev to 0.7 ev @xcite . owing to the slow power - law decay , the gap at the largest crystal studied is still 0.7 ev larger than the extrapolated value .",
    "other properties of large silicon clusters are also expected to be similar to the ones of bulk silicon , which is equivalent to a nanocrystal of `` infinite size '' .",
    "figure [ si9k - dos ] shows that the density of states already assumes a bulk - like profile in clusters with around ten thousand atoms .",
    "the presence of hydrogen atoms on the surface is responsible for subtle features in the dos at around -8 ev and -3 ev . because of the discreteness of eigenvalues in clusters , the dos is calculated by adding up normalized gaussian distributions located at each calculated energy eigenvalue . in figure",
    "[ si9k - dos ] , we used gaussian functions with dispersion of 0.05 ev .",
    "more details are discussed in @xcite .",
    "we also applied parsec to some large iron clusters .",
    "extensive analysis of the magnetic properties of iron clusters based on the methodology presented here and in previous work@xcite , has provided decisive evidence for surface effects in the magnetic moment of these systems @xcite , confirming earlier experimental data . table",
    "[ si - fe ] also contains three clusters with more than 300 iron atoms .",
    "these metallic systems are well - known to be very difficult for dft calculations , because of the `` charge sloshing '' @xcite . the lda approximation used to get exchange - correlation potential @xmath10",
    "is also known not to work well for iron atoms . however , parsec was able to reach self - consistency for these large metallic clusters within reasonable time length .",
    "it took more than 100 scf steps to reach self - consistency , which is generally considered too high for scf calculations , but we observed ( from calculations performed on smaller iron clusters ) that eigenvector - based methods also required a similar number of scf steps to converge , thus the slow convergence is associated with the difficulty of dft for metallic systems . without chefs , and under the same hardware conditions as listed in table",
    "[ si - fe ] , over 100 scf steps using eigenvector - based methods would have required months to complete for each of these clusters .",
    "we developed and implemented the parallel chefsi method for dft scf calculations . within chefsi",
    ", only the first scf step requires a true diagonalization , and we perform this step by the block chebyshev - davidson method . no diagonalization is required after the first step ; instead , chebyshev filters are adaptively constructed to filter the subspace from previous scf steps so that the filtered subspace progressively approximates the eigensubspace corresponding to occupied states of the final hamiltonian .",
    "the method can be viewed as a nonlinear subspace iteration method which combines the scf iteration and diagonalization , with the diagonalization simplified into a single step chebyshev subspace filtering .",
    "additional tests not reported here , have also shown that the subspace filtering method is robust with respect to the initial subspace .",
    "besides self - consistency , it can be used together with molecular dynamics or structural optimization , provided that atoms move by a small amount . even after atomic displacements of a fraction of the bohr radius , the chefsi method was able to bring the initial subspace to the subspace of self - consistent kohn - sham eigenvectors for the current position of atoms , with no substantial increase in the number of self - consistent cycles needed .",
    "chefsi significantly accelerates the scf calculations , and this enabled us to perform a class of large dft calculations that were not feasible before by eigenvector - based methods .",
    "as an example of physical applications , we discuss the energetics of silicon clusters containing up to several thousand atoms .",
    "we thank the staff members at the minnesota supercomputing institute , especially gabe turner , for the technical support .",
    "there were several occasions where our large jobs required that the technical support staff change certain default system settings to suit our needs .",
    "the calculations would not have been possible without the computer resource and the excellent technical support at msi .",
    "this work was supported by the msi , by the national science foundation under grants itr-0551195 , itr-0428774 , dmr-013095 and dmr-0551195 and by the u.s .",
    "department of energy under grants de - fg02 - 03er25585 , de - fg02 - 89er45391 , and de - fg02 - 03er15491 .",
    "r.  b. lehoucq , d.  c. sorensen , and c.  yang , _ arpack users guide : solution of large scale eigenvalue problems by implicitly restarted arnoldi methods _",
    "( siam , philadelphia , 1998 ) .",
    "available at link : http//www.caam.rice.edu / software / arpack/ [ http//www.caam.rice.edu / software / arpack/ ] ."
  ],
  "abstract_text": [
    "<S> solving the kohn - sham eigenvalue problem constitutes the most computationally expensive part in self - consistent _ density functional theory _ ( dft ) calculations . in a previous paper </S>",
    "<S> , we have proposed a nonlinear chebyshev - filtered subspace iteration method , which avoids computing explicit eigenvectors except at the first scf iteration . </S>",
    "<S> the method may be viewed as an approach to solve the original nonlinear kohn - sham equation by a nonlinear subspace iteration technique , without emphasizing the intermediate linearized kohn - sham eigenvalue problems . </S>",
    "<S> it reaches self - consistency within a similar number of scf iterations as eigensolver - based approaches . </S>",
    "<S> however , replacing the standard diagonalization at each scf iteration by a chebyshev subspace filtering step results in a significant speedup over methods based on standard dagonalization . here , we discuss an approach for implementing this method in multi - processor , parallel environment . </S>",
    "<S> numerical results are presented to show that the method enables to perform a class of highly challenging dft calculations that were not feasible before . </S>"
  ]
}