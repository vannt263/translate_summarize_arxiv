{
  "article_text": [
    "the exponential growth in the volume of astronomical data being generated from ever larger format imaging detectors continues to drive up the data handling costs of both large and small telescope projects .",
    "the cost of archiving the images is only one part of the problem .",
    "a typical observational work flow involves a long cascade of temporary and permanent copies of the data replicated from observatory to data processing facility to deep storage site to science archive center to virtual observatory portal to multiple end users . each science image provided as input to a pipeline",
    "will produce several output images as a result of processing operations such as resampling onto a standard grid , co - adding , mosaicking , and any analysis steps specific to the science program .",
    "the problem is one of throughput  not just storage  of the total system data flow .",
    "network transmission costs also rival or exceed the cost of storage media and can be breathtakingly large for spacecraft or remote mountaintops .",
    "often there is an upper limit to the network bandwidth at any price .",
    "making effective use of the available image compression technologies is an important component in dealing with these data handling costs .",
    "lossy data compression techniques , which do not exactly preserve each image pixel value but do still preserve the required scientific information content of the image , are already used by many projects . to cite just a few examples , the kepler space telescope project @xcite uses a lossy image quantization method to reduce the data volume to fit within the limited bandwidth from its heliocentric orbit , the gong helioseismology project @xcite relies on lossy compression to transmit images from its telescopes deployed at six locations worldwide , and the noao high - performance pipeline @xcite includes a final quantization step from an internal floating - point representation to the final integer archive data products to achieve greater image compression .    in a previous contribution (",
    "* hereafter , paper i ) , we demonstrated that the maximum possible lossless compression ratio for integer format astronomical images is determined by the amount of noise in the background pixels ( i.e. , the `` sky '' ) in the image .",
    "the noise in astronomical images often has 2 main components : poissonian - distributed photon noise and gaussian distributed `` read - out '' noise .",
    "if each pixel is represented by bitpix bits ( usually 16 or 32 bits ) and if , on average , @xmath0 of those bits are filled with uncompressible , randomly fluctuating noise , then the maximum theoretical compression ratio for that image is given by bitpix / @xmath0 .",
    "in practice , no compression algorithm is 100% efficient , so the actual maximum compression ratio , @xmath1 , is given by @xmath2 where @xmath3 is an empirical measure of the efficiency ( or overhead ) of the algorithm in units of bits per pixel .",
    "we compared several lossless compression algorithms and found that the rice algorithm @xcite , which has a small @xmath3 value of about 1.2 bits per pixel , provided the best combination of speed and compression efficiency .",
    "the relationship between noise and entropy in images is discussed more fully in the appendix of paper i , based on the seminal work by @xcite , where we showed that the `` equivalent '' number of noise bits per pixel in an image can be calculated from the rms noise ( @xmath4 ) of the pixels in background regions of the image such that @xmath5 which , when combined with equation 1 , gives @xmath6    in this current article we extend the previous analysis of integer images to study compression techniques for astronomical images in floating - point format . in the cases we are mainly concerned with here , these images originally had integer pixel values , but",
    "were converted into 32-bit ieee floating - point format during the calibration processing ( e.g. , bias subtraction , flat - fielding , absolute flux calibration , etc . ) .",
    "equation [ eq : ratio2 ] applies to floating point images as well as integer images , however typical floating - point astronomical images contain so much noise that it is impossible to achieve significant amounts of compression with lossless algorithms ( often less than a factor of 2 ) .",
    "one explanation for this excess noise is that a 32-bit ieee floating - point number can express 7 decimal places of precision but this usually far exceeds the inherent precision of individual image pixel values . as a result many of the least significant bits in the mantissa of the floating - point pixel values",
    "are effectively filled with quasi - random noise which is inherently uncompressible .",
    "while there are counter - examples of floating - point fits arrays that have very little noise and can be losslessly compressed effectively ( e.g. , generated by theoretical simulations ) , these are not typical of the types of floating - point images commonly found in large astronomical data archives and are not the subject of this article .",
    "there are many published articles on lossless floating - point data compression schemes ( see * ? ? ? * and reference therein as recent examples ) but it is beyond the scope here to summarize them in detail .",
    "the main point is that ultimately all of these lossless compression techniques face the same shannon entropy limit , and the only way to achieve greater compression of noisy floating - point images is to use techniques that discard some of the noise .",
    "these methods are technically `` lossy '' because they do not exactly preserve the pixel values , however , if only noise is discarded , then the compression can still be considered lossless from a scientific standpoint because all the useful information is retained .    in the remainder of this article",
    "we describe a lossy compression technique for floating - point astronomical images that provides an optimal combination of speed , compression ratio , and preservation of information content .",
    "it is faster and achieves much higher compression than generic lossless file compression algorithms like gzip @xcite , yet it produces no significant loss of information in the image when used appropriately . in ",
    "[ s : methods ] we describe in detail the quantization and compression techniques that have been implemented in our publicly available _ fpack _ and _ funpack _ image compression utility programs . then in  [",
    "s : tests ] we describe the results of several experiments that demonstrate that astronomical floating - point images can be compressed by up to a factor of 10 without significant loss of astrometric or photometric precision .",
    "finally ,  [ s : discussion ] summarizes the results and gives recommendations for achieving the best compression of astronomical images .",
    "the most common lossy compression technique for floating - point images is to preprocess the pixel values by quantizing them into a smaller set of discrete values prior to applying a lossless compression algorithm . in the simplest case ,",
    "the values are rounded into a grid of equally spaced floating - point levels .",
    "this reduces the number of different bit patterns in the image pixels ( i.e. , reduces the entropy in the image ) and improves the efficiency of file compression programs like gzip which accumulate a dictionary of the most common bit patterns in the file and represent them using a shorter code in the compressed file .",
    "@xcite applied an analogous technique to integer images . in order to accommodate compression algorithms , like rice , that only operate on integer arrays , the quantized floating - point values",
    "are usually represented by scaled integers so that the image pixel values are approximated by @xmath7 note that this integer scaling technique was the only way to represent floating - point images in the fits data format @xcite before support for the ieee floating - point format was officially added in 1990 .    as an aside , there are many articles in the literature ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) that advocate using a square root scaling function , in part because the poissonian shot noise scales by this same factor . what is usually not stated in these studies",
    "is that practically the same increase in compression that is obtained after applying a square root scaling function can be obtained by linearly scaling _ all _ the pixels in the image by the same factor as is applied to the background pixels during the square root scaling .",
    "since the compression ratio is determined mainly by the noise in the background areas of the image ( from equation [ eq : ratio2 ] ) , the amount of scaling that is applied to the relatively infrequent bright pixels usually makes little difference to the overall compression ratio of the image . in experiments on simulated astronomical images , @xcite found that using square - root scaling only produced significantly better compression than linear scaling when more than 10% of the image pixels are affected by isolated bright objects or cosmic rays .",
    "@xcite developed the technique that forms the basis of the fits tiled - image compression format that is used here along with a few new refinements .",
    "each row of the image ( or in principle , any other rectangular `` tile '' in the image ) is compressed separately to provide fast random access to individual sections of an image without having to uncompress the entire image . in the case of floating - point images ,",
    "the pixel values are converted to integers with a scale factor that , by default , is proportional to the measured amount of noise in that tile .",
    "the noise in each tile of the image is calculated using a robust algorithm that was originally developed to autonomously measure the signal - to - noise in spectroscopic data @xcite .",
    "in particular , we use their third order `` median absolute difference '' ( mad ) formula to compute the standard deviation of the pixel values : @xmath8 where @xmath9 is the vector index of the pixel within each row of the image , and @xmath10 is the value of the @xmath11 pixel . the median value is computed over all the pixels in each row of the image . in the limiting case where the pixel values have a gaussian distribution , this formula converges to same value as the standard deviation of the pixels .",
    "note that this formula is not affected by linear intensity gradients across the image ( which are canceled out by the first and third terms ) , and the use of the median makes the result insensitive to the presence of outlying large pixel values .",
    "for example , if one randomly sets 5% of the pixels in an image with otherwise gaussian - distributed noise to very large values to simulate the effects of cosmic rays , then the mad noise estimate only increases by about 20% .",
    "once the noise level has been calculated , the floating - point pixels are quantized into scaled integers where the quantized levels are spaced at some user - specified fraction , q , of the noise , so that the spacing is given by @xmath12 .",
    "normalizing the quantization spacing to @xmath4 is a convenient way to produce similar quality compressed images regardless of the intrinsic noise level in the image .",
    "the scaled integers are then compressed using the default rice algorithm , or one of the other optional compression algorithms .",
    "finally , the compressed stream of bytes is stored in a fits binary table structure as defined in the fits tiled image compression convention @xcite .",
    "since the noise @xmath4 in the array of quantized integers is simply equal to q , the expected image compression ratio , from equation [ eq : ratio2 ] , is given by @xmath13 for example , quantizing a 32-bit floating - point image using q values of 1 or 4 will produce compression ratios of about 10 or 6.4 , respectively , when using the rice algorithm that has @xmath14 .",
    "if the same image is stored in 64-bit double precision format it will compress by twice this amount ( i.e. , the compressed files will have the same size ) .",
    "in most cases , the compression ratio does not depend very much on the distribution of objects or structures within the image itself .",
    "note that this formula tends to break down for q values much less than 1 because many compression algorithms become less effective on very low entropy images and because the size of the fits file header , which remains uncompressed , becomes relatively more significant .",
    "one important caveat with the use of this quantizing method is that if the noise level in the image is significantly overestimated for some reason ( for our purposes it is generally sufficient if it is accurate to within about a factor of 2 ) , then the image may be inadvertently quantized more coarsely than expected for a given q value , thus possibly causing a loss of information in the compressed image .",
    "circumstances where the mad algorithm could overestimate the noise include the following :    * if a large fraction of the pixels in an image tile are covered by bright objects and have values ( and noise ) which is many times greater than in the fainter pixels , then the mad noise estimate will be representative of those bright pixels and not that of the fainter `` background '' pixels .",
    "this may cause the fainter pixels to be more coarsely quantized than would be desired . *",
    "if a significant amount of the pixel - to - pixel variation in the image is real and not due to noise , ( e.g. , if there are large pixel - to - pixel variations in the detector sensitivity , or if the observed object contains significant structure on a pixel size scale ) , then the noise level may be overestimated . *",
    "if the noise in an image is anti - correlated between adjacent pixels ( e.g. , after certain types of image convolutions ) then the noise will be overestimated .",
    "note , however , that equation [ eq : noise3 ] is a function only of the values in every other pixel in each row of the image , so the anti - correlation scale length must extend over at least 2 pixels to affect the mad noise estimate .",
    "our _ fpack _ compression program ( see  [ s : fpackfunpack ] ) offers several options for dealing with this issue .",
    "one simple method is to just compress the image using a larger q value to compensate for the possible mad noise overestimate , although this can negatively affect the overall compression ratio of the image .",
    "another option in cases where only a small fraction of the rows in an image might be affected is to compress the entire image as a single tile , rather than using the default row - by - row tiling pattern , so that the mad noise estimate then more accurately reflects the noise in the background regions of the image as a whole . finally , _",
    "users do not need to rely on the mad noise estimate at all , and instead can directly specify the desired spacing between the quantization levels .",
    "this latter option is especially appropriate for projects that generate large amounts of relatively homogeneous images because it ensures that all the images will be compressed using the same quantization factor .",
    "this method has the added advantage that it will improve the compression speed because it is not necessary to compute the mad noise value in this case .",
    "the effects of linear quantization are naturally greater in the fainter areas of an image than for the brighter pixels where the poissonian uncertainty of the photon counts can be much larger than the quantized spacing .",
    "measurement of the local `` sky '' background around the image of a star or galaxy can be especially vulnerable to the effects of quantization , in part because it is usually necessary to identify and correct for pixels that are affected by other objects or by defects in the detector .",
    "the issue of detecting small amplitude signals in a quantized system is a well - studied problem in engineering and communications fields where the phenomenon is known as `` stochastic resonance '' .",
    "the somewhat counter - intuitive solution for improving the signal - to - noise of measurements of quantized data is to add a moderate amount of noise into the system .",
    "when applied to images , this technique is commonly called `` dithering '' .",
    "@xcite devote 2 chapters of their book to the theory and practice of dithering and recommend using a clever `` subtractive dithering '' technique , first proposed by @xcite .",
    "this technique overcomes the drawback of having to add noise to the , with a value uniformly distributed between 0 and 1 during the scaling process , @xmath15 where @xmath16 is the original floating - point value and @xmath17 is the the quantized integer value .",
    "the interesting trick that distinguishes subtractive dithering from ordinary dithering methods is that exactly the _ same _ random dither value is subtracted when converting back to the quantized float value : @xmath18 the net effect of this subtractive dithering operation is to shift the entire grid of linearly spaced intensity levels up or down by a random amount on a pixel by pixel basis .",
    "it should be noted that the dithered values are uniformly distributed between the quantized levels in this implementation .",
    "one possible future enhancement may be to use a triangular or gaussian dither @xcite which may more closely replicate the actual distribution of pixel values in the image .    in order to use this subtractive dithering method",
    "it is necessary to define a specific pseudo random number generator ( prng ) algorithm for use by both the compressor and the uncompressor so that the same predictable sequence of random numbers is used in both cases .",
    "we adopted the prng algorithm described by @xcite which has been shown to produce statistically independent random numbers uniformly distributed between 0 and 1 .",
    "however , for pragmatic reasons we do not compute a unique random number for every single image pixel because ( a ) it would add significant computational overhead relative to the very efficient rice compression algorithm , and ( b ) true randomness is not required for this purpose since even crude dithering patterns would still help to mitigate the measurement biases in quantized images . our compromise solution is to calculate a look - up - table of 10000 random numbers using the above mentioned prng , and then repeatedly recycle through this lut when calculating the amount of dither for each pixel in the image . as a precaution against introducing regular cyclical noise patterns into the image ,",
    "a pseudo random starting offset is computed each time when recycling through the lut .",
    "finally , 1 out of a possible 10000 initial seed values for the entire dithering process is computed based on the system clock time ( or optionally the checksum of the first row of pixel values in the image ) to ensure that the same dithering pattern is not repeated in every image .",
    "this initial seed value is stored in the header of the compressed image for reuse when uncompressing the image .      while quantization reduces the entropy in the representation of the pixel values ( thus improving the image compression ratio ) , any quantization operation ,",
    "even with subtractive dithering , modifies the pixel values and thus inherently increases the rms noise in the pixel - to - pixel variations in the image by an amount given by : @xmath19 where the total variance @xmath20 in the quantized image is the sum of the variance @xmath21 in the original image plus the quantization noise variance , and where @xmath22 is the intensity spacing between the quantized levels .",
    "the factor 1/12 comes from the variance of a uniform random distribution with unit width ( * ? ? ?",
    "* also see the appendix to paper i ) .",
    "substituting @xmath23 , the fractional increase in the noise caused by quantizing the image can be expressed as @xmath24 figure 1 shows how the fractional noise ratio ( from equation [ eq : fractionalnoise ] ) and the compression ratio ( from equation [ eq : ratio3 ] ) of an image containing gaussian - distributed noise both depend on q. to foreshadow the results of the experiments that will be described in ",
    "[ s : tests ] , this figure shows that q values in the range of 4 to 1 provide a good combination of high compression ratio with relatively little added noise .",
    "it should be cautioned that if a floating - point image is repeatedly compressed and uncompressed , then the cumulative quantization noise will be given by @xmath25 where n is the number of compression and uncompression cycles .",
    "( this assumes that the dithering is re - randomized during each cycle , which is always the case in our implementation of the subtractive dithering algorithm ) .",
    "the amplitude of this effect depends strongly on the q value . to put this in practical terms ,",
    "an image can be compressed and uncompressed at least 16 times using q @xmath26 4 before the noise would increase to the same level equivalent to compressing the image once with q = 1 .",
    "but if the image is compressed multiple times using q = 1 , the noise would increase to scientifically unacceptable levels after just a few cycles .",
    "ideally , an image should only be compressed once , and then all the subsequent data analysis should be performed directly on the tile - compressed fits file .",
    "if the software can not read the compressed format directly , then it should operate on an uncompressed version of the original compressed file , which then should not be recompressed .      in order to make the image quantization and compression techniques that are described in the previous sections more widely available to the astronomical community",
    ", we have developed a pair of general purpose utility programs , called _ fpack _ and _ funpack _",
    "@xcite , which can be used to compress and uncompress any fits image in integer or floating - point format .",
    "these utilities rely on the underlying cfitsio library @xcite to perform the quantization and compression operations .",
    "the _ fpack _ and _ funpack _ utility programs were used in the experiments that are described in the following sections to quantize and compress the images .",
    "further information about _ fpack _ and _ funpack _ is available from the heasarc web site at http://heasarc.gsfc.nasa.gov/fitsio/fpack .",
    "in this section we present the results of experiments designed to show how the measurements of objects in an image are affected as the image is quantized by varying degrees .",
    "in particular , we will verify that the noise in the image increases as a function of q by the amount predicted by equation [ eq : fractionalnoise ] , and more significantly , that the statistical errors on the magnitude and position measurements of faint objects in an image , which are limited mainly by the background noise , also increase by a similar factor .",
    "these results will provide general guidelines for achieving the greatest amount of image compression while still preserving the required level of scientific precision in the image .",
    "section [ s : setup ] describes the method of constructing the simulated ccd images that are used in the first 2 experiments .",
    "the first experiment , in  [ s : exp1 ] , examines how quantization affects the uncertainties of measurements of single star images , and the second experiment , in ",
    "[ s : exp2 ] , examines the case where many quantized images are added together to detect sources far below the detection threshold of a single image .",
    "finally , the third experiment , in  [ s : exp3 ] , is performed on a set of actual astronomical images to verify the results obtained from the synthetic images .      in order to determine how quantization affects the precision of measurements of objects in an image",
    ", we generated a large sample of realistic ccd star images with known input positions and magnitudes .",
    "this allows us to precisely calculate the errors on the measured positions and magnitudes in the quantized images .",
    "all the stars have circular gaussian profiles with @xmath27 and fwhm = 2.35 pixels .",
    "this is typical of the spatial resolution commonly found in astronomical ccd images and is adequate to avoid the difficulties when analyzing spatially undersampled images .",
    "the central location of the star images , relative to the pixel grid , was varied so as to average out any subtle biases in the subsequent star detection and measurement steps that might depend on the exact position .",
    "the total integrated flux in the stars covered a range of 10 magnitudes ( a factor of 10000 in intensity ) in 0.5 magnitude increments .",
    "finally , the sky background was simulated by adding 1000 counts to each pixel .",
    "poissonian - distributed shot noise and gaussian distributed `` read - out '' noise was then added to each of these star images to simulate real ccd images .",
    "the shot noise in each pixel was randomly calculated using a @xmath4 equal to the square root of that pixel value ( which implicitly assumes that the `` gain '' of the simulated ccd has been set to 1 electron per analog - to - digital readout count ) , and the readout noise was calculated using @xmath4 = 10 .",
    "the read - out noise in these images is relatively small compared to the shot noise in the sky background , which is usually the case for real astronomical ccd images that have a moderately bright background level .",
    "the total noise in the background areas of these images has @xmath28 .",
    "different starting random seed values were used so that the actual noise distribution varies in every image .    the widely used sextractor source extraction program @xcite was employed to objectively detect and measure the position and magnitude of the stars in these simulated , noisy ccd images .",
    "sextractor calculated the positions ( given by the x_image and y_image output parameters ) from the flux - weighted centroid of all the pixels in each star image above an empirically determined flux detection threshold .",
    "the total magnitude of each star ( given by the mag_aper parameter ) was measured within a 7-pixel diameter aperture ( i.e. , out to 3.5 @xmath4 of the gaussian profile ) around the centroid position .",
    "we calculated the actual errors on these measurements from the differences between the known input position and the input flux ( corrected for the 0.3% of the flux that falls outside the 3.5@xmath4 aperture ) of each star in the synthetic image . for reference ,",
    "the faintest stars that sextractor could reliably detect in these images contained about 1000 net counts , which is coincidentally equal to the mean sky counts in each pixel .",
    "we arbitrarily set the zero point of the instrumental magnitude scale , @xmath29 so that these faintest detected stars have a magnitude of 20.0 .",
    "we repeated the sextractor measurements of the simulated ccd images after quantizing and compressing each image with _",
    "fpack _ using q values ranging from 8 to 0.25 , both with and without the subtractive dithering option .",
    "since the sextractor program can not directly read images in the compressed fits format , it was necessary to convert them back into the standard fits image format using _ funpack _ ( but the pixel values remain quantized , of course ) . in the case where dithering was not applied , we also selected the option to compress the entire image as a single large tile so that all the pixels are quantized into the same fixed grid of intensity values .",
    "if we had used the default row - by - row tiling option instead , it effectively would have introduced some dithering of the quantized levels between adjacent rows , and the results would be intermediate between the dithered and non - dithered cases presented below .",
    "figure 2 shows the dramatic effect that subtractive dithering has on the histogram of the pixel values in a q = 1 quantized image ; the dithered image histogram is nearly identical to the that of the original image , whereas the non - dithered histogram clearly shows the coarse intensity binning . without dithering ,",
    "the image breaks up into discrete `` bands '' of constant intensity which makes it more difficult to detect faint features in the image .",
    "this effect is shown in figure 3 , ( using an even more coarsely quantized q = 0.5 image to enhance the effect ) , where the majority of the background pixels all have the same ( medium gray ) intensity value .      in this first experiment",
    ", we examine how the uncertainties of the photometric and astrometric measurements of individual stars depend on the q quantization factor . to measure this effect , we computed the standard deviation of the magnitude and position errors ( i.e. , the value computed by sextractor minus the known input magnitude or position value ) for 6250 simulated star images at each 0.5 magnitude increment .",
    "figure 4 shows how the magnitude uncertainties decrease as the brightness of the star increases ( towards the right ) .",
    "the lower , thicker line in the figure was derived from the original , unquantized images and shows that the statistical uncertainty on the magnitudes decreases from @xmath30 for the faintest detectable stars ( with m = 20 ) , to @xmath31 for stars that are 3 magnitudes brighter .",
    "the line has a slope close to 1.0 ( in log - log coordinates ) as expected in the limiting case where the noise is dominated by the sky , and hence the signal - to - noise ratio of the measurement increases in direct proportion to the signal .",
    "the other 3 lines in figure 4 were derived from the same images after they were first quantized and compressed with successively coarser q values of 1.0 , 0.5 , and 0.25 , when also applying the subtractive dithering option .",
    "the vertical displacement of these lines shows that the measurement errors are systematically larger in the quantized images as compared to the measurements in the original image .",
    "this increase is relatively small for q @xmath26 1 , but increases rapidly for coarser quantization values .",
    "figure 5 shows a similar plot of the standard deviation of the stellar centroid measurements , in units of pixels , as a function of the magnitude of the star and the q quantization factor . in the original unquantized images , the positional uncertainty decreases from @xmath32 pixels for the m = 20 stars , to @xmath33 pixels for the stars that are 3 magnitudes brighter",
    "the positional measurement uncertainties are larger in the quantized image by about the same factor as the increase in the magnitude uncertainties shown in figure 4 .    in order to better quantify the effects shown in these 2 figures , table 1",
    "summarizes how the noise and the measurement uncertainties increase as the images are quantized more coarsely .",
    "the measured percentage increase in the mad noise level in the quantized images is given in column 2 and agrees exactly with the predicted value from equation [ eq : fractionalnoise ] .",
    "more strikingly , the magnitude and position uncertainties for the faintest stars also increase by about the same factor as the noise , as shown in columns 3 and 4 .",
    "this means that equation [ eq : fractionalnoise ] also provides a good estimate of how much the measurement uncertainties of the faintest objects in an image , which are limited by the background noise , will increase when the image is quantized .",
    "finally , columns 5 and 6 in table 1 give the corresponding increase in measurement uncertainties for stars that are 5 magnitudes , or a factor of 100 , brighter than the image detection threshold .",
    "as expected , these brighter objects are relatively less affected by quantization because the inherent poissonian noise in the brighter pixels is larger than the spacing between the quantized levels . also , the small formal statistical errors on the magnitudes and positions of the brighter stars ( which are less than 0.001 of a magnitude or pixel , respectively , in this case ) are often insignificant compared to the systematic errors in the absolute calibration of the measurements .",
    "cccccc 4 & 0.26% & 0.31% & 0.18% & 0.10% & 0.20% + 2 & 1.04% & 1.1% & 0.93% & 0.25% & 0.83% + 1 & 4.08% & 5.6% & 4.1% & 1.7% &",
    "3.4% + 0.5 & 15.5% & 19% & 15% & 5.8% & 12% +    for comparison , figures 6 and 7 show that if the quantized pixels are not dithered then the measurement errors are larger than in the dithered case shown previously in figures 4 and 5 .",
    "it is striking that while dithering provides a modest increase in the accuracy of the centroid measurements , it greatly improves the magnitude measurements .",
    "further investigation has shown that the larger magnitude errors are almost entirely caused by a dramatic increase in the errors in the sextractor background estimate around each star if the quantized image is not dithered .",
    "sextractor assumes that the best estimate of the true background level is given by the peak in the histogram of the pixel values ( i.e. , the mode ) and it uses the following empirically derived formula @xmath34 to correct for the slight skewness in the pixel distribution ( i.e. , an excess of brighter pixels ) that is commonly seen due to contamination by other objects in the image .",
    "this formula generally works well if the pixel values have a continuous distribution , as demonstrated in our tests on the dithered star images , however , it behaves poorly if the pixels are quantized because then the median value is also quantized .",
    "the amplitude of the error in the background estimate depends on how closely one of the quantized levels happens to match the true background level . in the worst case , where the true value lies half way between 2 of the quantized levels ( and assuming that the mean value lies very close to the true background level , which is usually the case in our images ) , then the error is equal to 1.25 times the intensity spacing between adjacent quantized levels . on average , the rms error in the background estimate introduced by this effect will be @xmath35 times the quantized spacing .",
    "it is ironic that equation [ eq : mode ] is intended to provide a more accurate background estimate than simply using the median value alone , but it actually increases the errors by a factor of 2.5 if the image is significantly quantized .",
    "it should be emphasized that while this particular problem applies specifically to the way sextractor estimates the background intensity , it is likely that similar problems would arise with other astronomical data analysis packages unless they are specifically designed to deal with quantized data . another way to view",
    "this problem is that many algorithms are not well behaved if the noise is under - sampled .",
    "dithering helps to eliminate this problem because it preserves the natural distribution of the pixel values , as shown in figure 2 .    as a final test",
    ", it is important to establish that there are no subtle systematic zero - point biases in the measured magnitudes in the quantized images .",
    "this is demonstrated in figure 8 , which plots the mean magnitude residual ( true magnitude minus measured magnitude ) for the 6250 simulated star images within each 0.5 magnitude bin after quantizing the images with a range of different q values .",
    "the upper panel shows the mean residuals in the subtractively dithered images , and the lower panel shows the residuals in the non - dithered quantized images .",
    "the thicker line in both panels was derived from the original unquantized images and shows that there is a small intrisic negative bias ( -0.02 mag ) in the sextractor magnitudes of the faintest stars .",
    "the cause of this small measurement bias , which is less than 1/10th the statistical error on a single magnitude measurement , is unknown , but it might be due to the algorithms that sextractor uses to measure the fainter stars , or perhaps due to the particular set of sextractor configuration parameters that we used in these tests .",
    "the important point here is that a very similar pattern of residuals is seen ( in the upper panel ) in the coarsely quantized and dithered images , which shows that there are no significant additional magnitude biases in these quantized images . for @xmath36 , the mean",
    "residuals match those in the unquantized images so closely that the points lie within the thickness of the line in the figure .",
    "if dithering is not applied , however , then significant biases in the magnitude residuals may be present in the quantized images , as shown in the lower panel of figure 8 .",
    "this effect is entirely due to the systematic errors caused by the use of the median function in estimating the background intensity level , as previously discussed .",
    "the second experiment investigates how well faint simulated gaussian stars ( as described in ",
    "[ s : setup ] ) that are below the detection threshold of a single image can be measured after co - adding 250 similar images together .",
    "to first order , one would expect that this experiment should detect stars that are about @xmath37 magnitudes fainter than in the single images . for comparison , we also generated quantized co - added images by quantizing each of the 250 individual images ( using a range of q values , with and without subtractive dithering ) before co - adding them .",
    "the magnitude and position of the stars in each of these co - added images were then measured with the sextractor program , just as in the first experiment .",
    "figure 9 shows the results of the photometric measurements in the co - added images .",
    "other than the fact that the lines in the plots exhibit more statistical scatter , since they were derived from a sample of only 250 star measurements in each 0.5 magnitude bin instead of 6250 , these results are very similar to the results from the single images shown in figure 4 , after allowing for the expected shift of the horizontal axis by 3 magnitudes .",
    "this similarity confirms that the photometric measurements in the co - added images have the same dependence on q as in the individual images .",
    "in particular , it confirms that information about faint stars that are well below the detection threshold in a single image is still preserved in the quantized images and can be detected after co - adding many quantized images together .",
    "we also confirmed that the astrometric precision in the co - added images shows the same dependence on q as the measurements in the single images .",
    "a plot of the positional uncertainty as a function of magnitude ( not shown here ) is almost identical to figure 5 , except for the 3 magnitude shift of the horizontal axis .",
    "finally , figure 10 shows the magnitude uncertainties when the quantized images are not subtractively dithered before co - adding them . unlike the case for single images (",
    "as compared in figures 4 and 6 ) , dithering has little effect on the precision of the photometry in the co - added image .",
    "this is because the co - adding process effectively introduces its own form of pixel dithering if the quantized levels in the different images are randomly offset with respect to each other .",
    "thus , there is little added benefit by also dithering the pixel values within each image .",
    "@xcite demonstrate an even more extreme case where accurate photometry and astrometry could be performed on a co - added sum of 1024 images , each quantized with q = 1/16 = 0.0625 without any dithering .      in the third and final experiment we performed tests on a set of real astronomical ccd images to confirm the previous results derived from synthetic images .",
    "we used a sequence of 20 similar ccd images taken with the 2.5-m isaac newton telescope at la palma that show a random distribution of faint stars and galaxies ( figure 11 ) .",
    "all the exposures were for 600 seconds through a v - band filter with the same pointing on the sky ( @xmath38 ) .",
    "these images are publicly available through the virtual observatory portal at http://portal-nvo.noao.edu .",
    "we performed 2 tests to measure the effects of quantization on these images . in the first test we coarsely quantized one of the images using q = 1 ( with subtractive dithering ) , by compressing it with _ fpack _ and then uncompressing it again with _ funpack_. as predicted by equation [ eq : ratio3 ] , _ fpack _ achieved a compression ratio of about 10 , which is equivalent to 3.2 bits per pixel in the compressed image . also as expected from equation [ eq : fractionalnoise ] , the measured background noise level increased by 4.1% , from @xmath4 = 22.79 in the original image to @xmath4 = 23.73 in the quantized image .",
    "we then compared the sextractor magnitude measurements in the original image to those derived from the quantized image .",
    "since we do not know the true magnitudes of the stars in this image ( unlike in the experiments on the synthetic stars ) , we can only compare the measurements of the stars in the 2 images , both of which have measurement uncertainties .",
    "the top panel of figure 12 shows the difference between the 2 magnitude measurements for each star as a function of the magnitude of the star , and the middle panel shows the corresponding _ relative _ errors ( the magnitude difference divided by the statistical error on that magnitude as calculated by sextractor ) .",
    "the larger points in these panels show the mean difference averaged over 0.5 mag bins , which demonstrate that there is no significant systematic bias between the 2 sets of magnitudes measurements .",
    "the rms value of all the relative errors in the middle panel is @xmath39 .",
    "this is slightly larger than the factor of @xmath40 that one would expect simply from the added quantization noise and may be due to other residual sources of noise in the sextractor calculations .",
    "the fact that this is much less than the approximately @xmath41 dispersion that one would expect when comparing the magnitudes derived from 2 identical ccd images of the same stars , confirms that quantizing the image with q = 1 has not introduced statistically significant differences in the magnitude measurements .",
    "finally , the lower panel plots the ratio of the magnitude errors in the quantized and original images which shows that the statistical errors of the faintest stars are on average about 4% greater in the q = 1 quantized image , as expected .    for the second test we created 2 new images by co - adding the 20 original ccd images and by coadding the q = 1 quantized version of each of the images and then repeated the same tests as described above .",
    "the results , shown in figure 13 , are similar to those in figure 12 except that the faintest detected stars are now @xmath42 mag fainter , as a result of co - adding the 20 images .",
    "the rms value of the relative errors shown in the middle panel is @xmath43 in this case , which again demonstrates that quantizing the images with q = 1 has not produced any significant photometric errors , even in objects that are fainter than the detection threshold in a single image .",
    "the main purpose of this work has been to find a more effective compression method for floating - point astronomical images than is provided by the lossless methods that are commonly used ( such as gzip ) .",
    "these floating - point images typically do not compress well with lossless algorithms because a large fraction of the bits in each pixel value representation contain no significant information and are effectively filled with uncompressible noise .",
    "we have adopted the method of eliminating some of this noise by quantizing the pixel values into a set of discrete , linearly spaced intensity levels , which are represented by scaled integer values .",
    "the scaled integers can then be efficiently compressed using the very fast rice algorithm . in order to make these compression techniques more widely available ,",
    "we have produced a pair of utility programs called _ fpack _ and _ funpack _ that can be used to compress any fits format image .    for convenience ,",
    "we define a quantization parameter , q , which is equal to the measured rms noise in background regions of the image divided by the spacing between the quantized intensity levels .",
    "given a particular q value when quantizing and compressing an image , one can calculate from fundamental principles the expected image compression ratio , as given by equation [ eq : ratio3 ] .",
    "coarser quantization ( i.e. , smaller q values ) gives greater image compression , but at the same time it increases the rms pixel - to - pixel noise by an amount given by equation [ eq : fractionalnoise ] which also tends to degrade the precision of the magnitude and position measurements of the objects in the image .",
    "our series of experiments on simulated and on real astronomical ccd images demonstrate that the noise equation [ eq : fractionalnoise ] also gives a good estimate of the increase in measurement uncertainties for objects near the detection threshold in a quantized image ( which are noise limited ) . for many practical applications , q values between 1 and 4 provide a good combination of high compression and low increased noise :",
    "q = 1 gives a compression ratio of about 10 while increasing the noise and the measurement uncertainties by about 4% , and q = 4 gives a compression ratio of 6 with a negligible 0.26% increase in the noise and measurement uncertainties . in `` quick - look '' types of applications , where high scientific accuracy is not of primary importance , even greater",
    "compression can be obtained by using q values less than 1 .",
    "one necessary requirement for achieving these results , at least when using the sextractor program to perform the measurements , is that the pixel values must be dithered to be able to accurately measure the background intensity level around each object .",
    "the algorithm that sextractor uses to estimate the background relies on the median of the pixels values , which is not a reliable statistic if the values are quantized .",
    "since other astronomical image analysis software may have similar issues dealing with quantized images , it would be prudent to always dither the pixel values during the quantization process to avoid possible complications later on , especially since dithering introduces no significant undesirable side effects .",
    "several other recent studies have reached similar conclusions about the benefits quantizing astronomical images to reduce the amount of noise and improve the compression ratio .",
    "@xcite performed photometric and astrometric measurements on stars in simulated ccd images ( using a slightly different methodology than used here ) and concluded that no significant errors were introduced if the image is quantized ( without dithering ) with q @xmath44 .",
    "@xcite found that using q = 1 , along with square - root scaling does not induce any significant bias in weak - lensing shape measurements of galaxies ( i.e. , the second statistical moment of the image ) in simulated images from future space - based imaging missions .",
    "@xcite describe how the kepler mission is performing on - board quantization of the images with q values as low as 1.15 to obtain the necessary amount of compression of the downlinked telemetry while still preserving the required high precision in the differential photometry measurements of stars . while we recognize that applying any sort of lossy compression scheme to scientific data tends to go against the inclination of scientists and data archive professionals , hopefully",
    "the results of the experiments performed here and in the other cited references will help to alleviate these concerns .",
    "while we believe our test results should be applicable to a wide range of floating - point astronomical images , we strongly encourage users to perform their own tests to verify that this compression technique is appropriate for their own data .",
    "users can easier create a quantized and dithered version of any floating - point fits image by compressing it with _ fpack _ and then uncompressing it with _",
    "funpack_. this image can then then be processed just like the original image to see if there are any significant differences in the results .",
    "nieto - santisteban , m. a. , fixsen , d. j. , offenberg , j. d. , hanisch , r. j. & stockman , h. s. 1999 , in asp conf .",
    "172 , astronomical data analysis software and systems viii , eds .",
    "d. m. mehringer , r. l. plante , & d. a. roberts ( san francisco : asp ) , 487          pence , w. d. , white , r. l. , greenfield , p. , & tody , d. 2000 , in asp conf .",
    "216 , astronomical data analysis software and systems ix , eds .",
    "n. manset , c. veillet , & d. crabtree ( san francisco : asp ) , 551          seaman , r. , pence , w. d. , white , r. , dickinson , m. , valdes , f. , & zarate , n. 2007 , in asp conf .",
    "376 , astronomical data analysis software and systems xvi , eds .",
    "r. a. shaw , r. hill , & d. j. bell ( san francisco : asp ) , 483"
  ],
  "abstract_text": [
    "<S> we describe a compression method for floating - point astronomical images that gives compression ratios of 6  10 while still preserving the scientifically important information in the image . </S>",
    "<S> the pixel values are first preprocessed by quantizing them into scaled integer intensity levels , which removes some of the uncompressible noise in the image . </S>",
    "<S> the integers are then losslessly compressed using the fast and efficient rice algorithm and stored in a portable fits format file . </S>",
    "<S> quantizing an image more coarsely gives greater image compression , but it also increases the noise and degrades the precision of the photometric and astrometric measurements in the quantized image . </S>",
    "<S> dithering the pixel values during the quantization process can greatly improve the precision of measurements in the images . </S>",
    "<S> this is especially important if the analysis algorithm relies on the mode or the median which would be similarly quantized if the pixel values are not dithered . </S>",
    "<S> we perform a series of experiments on both synthetic and real astronomical ccd images to quantitatively demonstrate that the magnitudes and positions of stars in the quantized images can be measured with the predicted amount of precision . in order to encourage wider use of these image compression methods , </S>",
    "<S> we have made available a pair of general - purpose image compression programs , called fpack and funpack , which can be used to compress any fits format image . </S>"
  ]
}