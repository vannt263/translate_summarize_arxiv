{
  "article_text": [
    "with decoding of the human genome and other eukaryotic organisms molecular biology has entered into a new era .",
    "high - throughput technologies , such as genomic microarrays can be used to measure the expression levels of essentially all the genes within an entire genome scale simultaneously in a single experiment and can provide information on gene functions and transcriptional networks @xcite .",
    "the major challenge in microarray data analysis is due to their size , where the number of genes or variables ( @xmath0 ) far exceeds the number of samples or observations ( @xmath1 ) , commonly known as the `` large @xmath0 , small @xmath1 '' problem .",
    "this takes it difficult or even impossible to apply class prediction methods ( e.g. , logistic regression , discriminant analysis ) to the microarray data .",
    "class prediction is a crucial aspect of microarray studies and plays important role in the biological interpretation and clinical application of microarray data @xcite . for the last few years",
    ", microarray - based class prediction has been a major topic in applied statistics @xcite . in a class prediction study ,",
    "the task is to induce a class predictor ( classifier ) using available learning samples ( i.e. , gene expression profiles ) from different diagnostic classes . given the learning samples representing different classes , first the classifier is learned and then the classifier is used to predict the class membership ( i.e. , diagnostic class ) of unseen samples @xcite .    generally , the performance of a classifier depends on three factors : the sample size , number of variables , and classifier complexity @xcite .",
    "it was shown that for the fixed sample size , the prediction error of a designed classifier decreases and then increases as the number of variables grows .",
    "this paradox is referred to as the peaking phenomenon @xcite . moreover , some well known classifiers are even inapplicable in the setting of high - dimensional data . for example , the pooled within - class sample covariance in linear discriminant analysis ( lda ) is singular if number of variables exceeds the number of samples .",
    "similarly , in logistic regression the hessian matrix will not have full rank and statistical packages will fail to produce reliable regression estimates @xcite .",
    "therefore , the number of samples must be larger than the number of variables for good prediction performance and appropriate use of classifiers .",
    "this naturally calls for the reduction of the ratio of sample size to dimensionality .",
    "there are two major ways to handle high - dimensional microarray data in the class prediction framework .",
    "the first approach is to eliminate redundant or irrelevant genes ( a.k.a .",
    "feature selection ) .",
    "the idea is to find genes with maximal discrimination performance and induce a classifier using those genes only @xcite .",
    "the most commonly used procedures of feature selection are based on simple statistical tests ( e.g. , fold change , @xmath2-test , anova , etc . ) , which are calculated for all genes individually , and genes with the best scores are selected for classifier construction @xcite .",
    "the advantages of this approach are its simplicity , low computational cost , and interpretability .",
    "an alternative approach to overcome the problem of high - dimensionality is application of dimension reduction techniques ( a.k.a .",
    "feature extraction ) .",
    "generally , the aim of dimension reduction procedures is to summarize the original @xmath0-dimensional gene space in a form of a lower @xmath3-dimensional gene components space ( @xmath4 ) that account for most of the variation in the original data @xcite",
    ". most commonly used methods for feature extraction with microarray gene expression data are principal component analysis ( pca ) @xcite , partial least squares ( pls ) @xcite , and sliced inverse regression ( sir ) @xcite .",
    "although statistical analysis dealing with microarray data has been one of the most investigated areas in the last decade , there are only a few papers addressing the development and experimental validation of new methods and techniques for microarray dimension reduction .",
    "as @xcite claimed , the high - dimensional data analysis will be one of the most important research topics in statistics in the nearest future . here",
    ", we fill this gap by proposing a latent variable approach for handling high - dimensional microarray data and show its promising potential for class prediction .",
    "the conceptual framework on latent variable modeling originates from psychometrics , starting at the beginning of the 20th century @xcite .",
    "utility of these models in biomedical research has only quite recently been recognized @xcite . by latent variable model we mean any statistical model that relates a set of observed variables to set of latent variables @xcite .",
    "a latent variable is a variable that is not directly observable but does have a measurable impact on observable variables .",
    "latent variables describe features that underlie the data . for example , a child s intelligence ( i.e. , latent variable ) is typically assessed by measuring their answers to solving problems or items ( i.e. , observed variables ) on intelligence test .",
    "the more items we ask of the child and the wider the breadth of items is included in the assessment , the more our understanding of that child s intellectual ability will be accurate .",
    "the rasch model ( rm ) , originally proposed by @xcite , is the simplest latent variable model .",
    "the idea behind the rm is that the probability of getting an item correct is a function of a latent trait or ability .",
    "for example , a child with higher intellectual ability would be more likely to correctly respond to a given item on an intelligence test . in psychological applications ,",
    "data are usually given in a matrix , with rows being participants and columns being responses to a set of items .",
    "microarray gene expression data can be represented in a similar way : columns are used to represent genes and rows are used to represent expression levels in biological samples .",
    "the rm can therefore be used to explain the observed gene expression patterns over different samples .",
    "we assume that gene expression levels vary under the influence of @xmath3 latent gene factors .",
    "the idea behind our approach is to partition @xmath0 genes into @xmath3 functional subgroups and that covariations between genes with similar expression ( i.e. , genes in the same partition ) could be described with a single gene factor .",
    "the factors in the model are latent , unobserved variables that account for the covariation among genes .",
    "it is assumed that genes with similar expression patterns might share biological function or might be under common regulatory control @xcite .",
    "moreover , it is particularly interesting to model a large set of genes as functions of fewer gene factors , because biologist believe the changes of mrna levels are due to some regulatory factors @xcite .",
    "specifically , regulatory factors are proteins that bind certain dna elements to regulate gene transcription to mrna .",
    "therefore , the gene factors obtained from latent modeling of gene expression could be interpreted as latent measurements of common regulatory factors of related genes . the number of gene factors is considered to be a meta - parameter and must be estimated or directly supplied based on researcher s prior knowledge .",
    "rm can then be used to estimate the magnitude of gene factors .",
    "class prediction using standard prediction methods can then be carried out in the reduced space by using constructed gene factors as predictor variables .",
    "the main objective of this paper is to evaluate the potential of rm - based dimensionality reduction with microarray gene expression data and investigate its prediction accuracy in the context of class prediction using lda . to validate the proposed approach we apply a parallel pca - based dimension reduction .",
    "we propose a framework for dimension reduction and class prediction with application to gene expression data as illustrated in figure  [ fig : figure1 ] .",
    "our procedure consists of two basic steps : the first step is dimension reduction , in which data are reduced from high @xmath0-dimensional gene space to a lower @xmath3-dimensional gene factor space ; the second step is class prediction , in which response classes are predicted using a class prediction method on the extracted gene factors .",
    "we apply our algorithms to two publicly available microarray data sets which have been considered before by several authors .",
    "the leukemia data set @xcite contains @xmath5 tissue samples with @xmath6 genes : @xmath7 samples of acute lymphoblastic leukemia ( all ) and @xmath8 samples of acute myeloid leukemia ( aml ) .",
    "the prostate data set @xcite contains @xmath9 tissue samples with @xmath10 genes : @xmath11 prostate tumor samples and @xmath12 non - tumor prostate samples .",
    "both data sets are from affymetrix high - density oligonucleotide microarrays and are publicly available @xcite .    for both data sets ,",
    "the pre - processing steps are applied as follows @xcite : ( a ) thresholding , floor of @xmath13 and ceiling of @xmath14 ; ( b ) filtering , exclusion of genes with @xmath15 and @xmath16 , where @xmath17 and @xmath18 refer to the maximum and minimum intensities for a particular gene across all samples ; and ( c ) @xmath19 transformation and standardization to zero mean and unit variance .",
    "the data were then summarized by a matrix @xmath20 , where @xmath21 denotes the expression level for gene @xmath22 in sample @xmath23 . the data for each sample consist of a gene expression profile @xmath24 and a class label @xmath25 .",
    "after data preprocessing the dimension of the matrix @xmath26 was @xmath27 and @xmath28 for leukemia and prostate data set , respectively .",
    "although the procedure described here can handle a large number ( thousands ) of genes , the number of genes may still be too large for practical use .",
    "the model assessment procedure is very cpu - expensive and therefore time - consuming process , because it requires fitting the data many times due to cross - validation and re - randomization .",
    "furthermore , a considerable percentage of the genes do not show differential expression across groups and only a subset of genes is of interest .",
    "we used two different methods for feature selection in this study .",
    "first we performed an unsupervised random subset selection , consisting of @xmath29 ( @xmath30 ) genes from the set of all genes , as described by @xcite .",
    "we selected @xmath29 genes with @xmath31 from both experimental data sets .",
    "as the supervised alternative , we applied welch s",
    "@xmath2-test @xcite to embed the class information in feature selection process and thus improved prediction accuracy .",
    "@xmath2-test provides the measure of the statistical significance of changes in gene expression between classes .",
    "@xmath2-test defines the statistic @xmath2 by @xmath32 where @xmath33 , @xmath34 , and @xmath35 are the mean , sample variance , and sample size of the class @xmath36 ( @xmath37 ) for each gene , respectively .",
    "feature selection was carried out based on absolute value of the @xmath2-statistic and the top @xmath29 genes with @xmath31 were used for further processing .      here",
    "we describe the core of feature extraction based on the rms and then briefly outline the pca method , which we used as a benchmark .      in this subsection",
    "we first give a short overview of the rm theory in its original form , and then present its application to gene expression data .",
    "the rm is a simple latent factor model , primarily used for analyzing data from assessments to measure psychological constructs such as personality traits , abilities , and attitudes @xcite .",
    "assume that we have @xmath38 persons and @xmath39 items .",
    "let @xmath40 be the response of person @xmath23 to the item @xmath22 , where the @xmath40 is ` 1 ' if person @xmath23 answered item @xmath22 correctly and ` 0 ' otherwise .",
    "in the rm , the probability of the outcome @xmath41 is given by @xmath42 for @xmath43 and @xmath44 .",
    "@xmath45 is the person parameter that denotes the latent factor of the @xmath23th person that is measured by the item @xmath22 and @xmath46 is the item parameter , which denotes the difficulty of the item @xmath22 .",
    "difficulty of the item describes the region of the latent trait distribution where the probability of producing a specific response changes from low to high .",
    "probability of the response is monotonous in both person and item parameters . figure  [ fig : figure2 ] plots the rasch probabilities as a function of the value of the latent factor ( @xmath47 ) for three different items .",
    "it can be seen that for a given item , persons with larger @xmath47 value tend to have greater probability of expressing high scores on the latent factor , and for a given person , the response probabilities are different for items with different @xmath48 values .    , @xmath49 , and @xmath50 , respectively .",
    "]    the final step of the rm - based modeling is to derive latent scores from the item responses .",
    "latent score is the total score of person @xmath23 over @xmath39 items .",
    "the most common approach to calculate latent scores is to use the expectation of the posterior distribution of @xmath45 given @xmath51 with parameter estimates plugged in @xcite .",
    "details on the calculation can be found in @xcite .",
    "[ [ application - of - rasch - model - to - gene - expression - data ] ] application of rasch model to gene expression data + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in terminology of rm , we denote each gene as an `` item '' and each sample as a `` person '' . the expression level @xmath21 of gene @xmath22 in sample @xmath23 is the response of a given sample to a given gene .",
    "our main assumption is , that one - dimensional latent model may not hold for the complete set of @xmath29 genes selected in the gene filtering step ( see subsection  [ subsec : feature_selection ] ) .",
    "based on the assumption that expressional similarity implies functional similarity of the genes ( and vice versa ) , we assume that genes with similar expression patterns determine one latent factor @xcite .    to identify coexpressed genes we used @xmath52-means clustering @xcite to partition @xmath29 genes into @xmath3 partitions ( @xmath53 ) based on their gene expression profiles over @xmath1 samples .",
    "@xmath3-means clustering is a simple and widely used partitioning algorithm .",
    "its helpfulness in discovering groups of coexpressed genes has been demonstrated @xcite .",
    "the optimal number of @xmath3 is estimated following the procedure described in subsection  [ subsec : model_selection ] .",
    "to apply the rm to the gene expression data , we need to discretize the gene expression data matrix @xmath26 into binary form .",
    "we use the median as a cut - off point for discretization .",
    "the intensity of every gene expression value is compared with the median gene expression data of the @xmath26 and assigned a ` @xmath54 ' if it is above and ` @xmath55 ' otherwise .",
    "note that gene partitioning is done before discretization step .",
    "we fit a rm for genes in each of the @xmath3 partitions respectively and calculate gene factor scores .",
    "specifically , we construct @xmath3 latent gene factors on which each gene in the @xmath52 partition is located .",
    "the measure for each sample for each gene factor is then estimated . to fit the rm for genes in the @xmath52th partition ,",
    "let @xmath23 be the sample index , and @xmath22 be the gene index , for @xmath56 , and @xmath57 , and let @xmath58 be the latent gene factor for the @xmath23th sample which is determined by the genes in the @xmath52th partition , and @xmath46 be the gene specific parameter for the @xmath22th gene .",
    "class prediction is then carried out in the reduced space by using the gene factors .",
    "pca is the most commonly used technique for dimension reduction in microarray data analysis @xcite . the main idea behind",
    "the pca is to reduce the dimensionality of a data set , while retaining as much as possible the variation in the original variables @xcite .",
    "this is achieved by transforming the @xmath29 original variables @xmath59 $ ] to a new set of @xmath3 predictor variables @xmath60 $ ] , which are linear combinations of the original variables .",
    "more formally , pca sequentially maximizes the variance of a linear combination of the original variables , @xmath61 subject to the constraint @xmath62 , for all @xmath63 , where @xmath64 is covariance matrix of the original data .",
    "the orthogonal constraint ensures that the linear combinations are uncorrelated .",
    "linear combinations @xmath65 are known as the principal components .",
    "these linear combinations represent the selection of a new coordinate system obtained by rotating the original system .",
    "the new axes represent the directions with maximum variability and are ordered in terms of the amount of variation of the original data they account for . the first principal component accounts for as much of the variability in the original data as possible , and each succeeding component accounts for as much of the remaining variability as possible .",
    "computations of the weighting vectors @xmath66 involves the calculation of the eigenvalue decomposition of a data covariance matrix @xmath67 , @xmath68 where @xmath69 is the @xmath23th eigenvalue in the descending order for @xmath70 and @xmath71 is the corresponding eigenvector .",
    "the eigenvalue @xmath69 measures the variance of the @xmath23th principal component and the eigenvector @xmath71 provides the loadings for the linear transformation .",
    "the number of components @xmath3 is specified on the basis of researcher s prior knowledge or determined using dedicated procedures ( e.g. , kaiser - guttman rule , cattell s scree test , etc . ) .",
    "class prediction using standard methods can then be carried out in the reduced space by using the constructed principal components .",
    "after dimension reduction , the high dimension of @xmath29 is now reduced to a lower dimension .",
    "the original data matrix is approximated by matrix of gene factors ( @xmath72 , where @xmath73 ) , constructed by rms or pca , as described in the previous section . to avoid confusion ,",
    "we use the term `` factor '' to refer to both latent factor obtained from rm analysis and principal component derived from pca .",
    "once the @xmath3 gene factors are constructed we consider prediction of the response classes .    to describe the class prediction problem formally ,",
    "let we have a learning set @xmath74 consisting of samples whose class is known and a test set @xmath75 consisting of samples whose class has to be predicted",
    ". denote the data matrix corresponding to @xmath74 as the learning data matrix @xmath76 , and the data matrix corresponding to @xmath75 as the test data matrix @xmath77 .",
    "the vector containing the classes of the samples from @xmath74 is denoted as @xmath78 .",
    "the goal is to build a rule implementing the information from @xmath76 and @xmath78 in order to predict the class @xmath36 of the @xmath23th sample from the test set given the gene expression profile @xmath79 : @xmath80    because our focus here is on dimension reduction , we fixed the class prediction step with lda , although other methodologies can be used @xcite .",
    "a short description of the lda method is given in the following @xcite .",
    "suppose we have @xmath3 predictor variables .",
    "the random vector @xmath81 is assumed to a multivariate normal distribution within class @xmath82 ( in our procedure @xmath83 ) with mean @xmath84 and covariance matrix @xmath85 . in lda",
    ", @xmath85 is assumed to be the same for all classes : for all @xmath36 , @xmath86 . using estimates @xmath87 and @xmath88 in place of @xmath84 and @xmath89 , the discriminant rule assign the @xmath23th new observation @xmath79 to the class @xmath90    lda has been well studied and widely used for class prediction problems .",
    "lda relies on a hypothesis of multinormality , and assumes that the classes have the same covariance matrix .",
    "although these hypotheses are rarely satisfied with real data sets , lda generally gives good results .",
    "studies have demonstrated favorable prediction performances of lda models when compared with more complicated and computationally intensive algorithms such as neural networks and tree method @xcite .",
    "for the details of the calculation we refer the reader to @xcite .",
    "the number of gene factors @xmath3 is a meta - parameter in the procedure .",
    "we estimate @xmath3 on the learning set @xmath74 using leave - one - out cross - validation ( loocv ) .",
    "loocv has been shown to give an almost unbiased estimator of the prediction error @xcite , and therefore provide a sensible criterion for our purposes . in a nutshell ,",
    "a subset of @xmath29 genes is selected ( @xmath30 ) from @xmath74 , and one of the samples is left - out .",
    "the feature extraction models are fitted to all but the left - out sample ( see subsection  [ subsec : feature_extraction ] ) .",
    "the fitted models are then used to predict the class of the left - out sample ( see subsection  [ subsec : class_prediction ] ) .",
    "this is repeated for all samples in the learning data set @xmath91 with @xmath3 taking successively different values .",
    "the mean error rate ( _ mer _ ) over the @xmath91 runs is computed for each value of @xmath3 by @xmath92 where @xmath93 is the predicted response class and @xmath25 is the observed response class .",
    "@xmath38 is the indicator function ( @xmath94 if @xmath95 is true , @xmath96 otherwise ) . the value of @xmath3 minimizing the _ mer _ is selected and denoted as @xmath97 .",
    "we select @xmath98 in our experiments .      to assess the performance of the rm- and pca - based dimension reduction methods in the framework of class prediction we perform a re - randomization study .",
    "this evaluation approach was first used by @xcite .",
    "the reader may refer to the review of @xcite on this subject .",
    "the procedure consists of the six steps as follows .    1 .   for each data set , create @xmath99 random partitions into learning data set @xmath74 with @xmath91 samples and a test set @xmath75 with @xmath100 samples ( @xmath101 ) .",
    "denote @xmath76 as the learning data matrix of size @xmath102 , and @xmath77 as the test data matrix of size @xmath103 .",
    "2 .   select a subset of @xmath29 genes from the set of all genes @xmath0 from matrix @xmath76 using one of the gene selection methods , resulting in @xmath104 matrix of size @xmath105 and @xmath106 matrix of size @xmath107 ( see subsection  [ subsec : feature_selection ] ) .",
    "3 .   use the learning data matrix @xmath104 to determine the number of latent factors @xmath97 , by loocv ( see subsection  [ subsec : model_selection ] ) .",
    "perform dimension reduction using rm- or pca - based dimension reduction ( see subsection  [ subsec : feature_extraction ] ) .",
    "let @xmath108 denote the matrix containing the factor loadings of size @xmath109 .",
    "compute the matrix @xmath110 of gene factors for the learning data set ( @xmath111 ) , and the matrix @xmath112 of gene factors for the test data set ( @xmath113 )",
    ". refers to component loadings , and matrix @xmath114 to gene components when pca is performed . ]",
    "fit the class prediction model to the learning gene factors @xmath110 .",
    "predict the classes of samples in the test set using the fitted classifier and the test gene factors , @xmath112 ( see subsection  [ subsec : class_prediction ] ) .",
    "repeat all above steps @xmath115 times with re - randomization of the whole data set .",
    "the mean error rate ( @xmath116 ) for each method is given by @xmath117 where @xmath93 is the predicted response class and @xmath25 is the observed response class .",
    "@xmath38 is the indicator function ( @xmath94 if @xmath95 is true , @xmath96 otherwise ) .",
    "although the @xmath116 is the most widely used metric for measuring the performance of the prediction systems , it considers all mispredictions as equally damaging @xcite .",
    "it has been demonstrated @xcite that , when the prior class probabilities are different , this measure is not appropriate because it does not consider misprediction cost , is strongly biased to favor the majority class , and is sensitive to class skewness . to overcome these problems the performance evaluation",
    "was also carried out via receiver operator characteristic ( roc ) analysis .",
    "for comprehensive introduction to roc analysis we refer the reader to @xcite .",
    "the roc analysis was performed by plotting true positive rate ( sensitivity ) versus the false positive rate ( 1@xmath118specificity ) at various threshold values , and the resulting curve was integrated to give an area under the curve ( _ auc _ ) value .",
    "_ auc _ is a measure of the discriminative power of the classes using the given features and classifier , and varies from @xmath119 for non - distinguishable classes to @xmath120 for perfectly distinguishable classes @xcite .",
    "the _ auc _ can be interpreted as the probability that two random samples from the two classes will be predicted correctly , and is invariant to changes in class proportions ( unlike _ mer _ ) .",
    "an @xmath121 is generally considered acceptable , @xmath122 as good , and @xmath123 as excellent prediction performance .",
    "all computations were carried out in the @xmath124 software environment for statistical computing and graphics @xcite .",
    "@xmath3-means clustering was performed using generic ` kmeans ` function .",
    "binarization of continuous gene expression values was performed by ` binarize ` function in the ` minet ` package .",
    "the function ` generate.split ` of the ` wilcoxcv ` package was used to generate random splitting into learning and test data sets .",
    "rm analysis was performed using ` ltm ` package .",
    "pca was conducted using generic ` prcomp ` function .",
    "lda was carried out using ` lda ` function in the ` mass ` package .",
    "roc analysis was performed using the ` caret ` package .",
    "the procedures described here can be reproduced using the @xmath124 scripts available from http://www2.arnes.si/~akastr1/rasch/",
    "we illustrate the interest of rm - based dimension reduction by considering applications for the class prediction of microarray data .",
    "we compare the results from our procedure with the performance of the pca - based approach .",
    "we will consider in turn the leukemia and prostate data sets , as described previously in subsection  [ subsec : data_sets ]      after data preprocessing , we applied the proposed performance evaluation procedure on the leukemia data set .",
    "first , we consider @xmath31 randomly selected genes and used @xmath99 random subsets .",
    "we randomly split each subset of genes into two data sets : a learning set with @xmath125 samples and a test set with @xmath126 samples .",
    "we used loocv procedure on the learning set to determine the number of gene factors ( components in the case of pca ) , and the test set for evaluating prediction performances . in total",
    ", @xmath127 class predictions were calculated using each of the dimension reduction method based on @xmath13 randomization trials .",
    "table  [ tab : table1 ] gives the estimated mean error rates ( _ mer _ ) , average values of the estimated meta - parameters ( @xmath97 ) , corresponding standard deviations , and areas under the roc curves ( _ auc _ ) with the considering methods , for different number of variables .",
    "a roc curve analysis is depicted in figure  [ fig : figure3](a ) .",
    "it can be seen from table  [ tab : table1 ] that _ mer _ decreases with the increase of the size of gene subsets @xmath29 .",
    "inversely , the _ auc _ increases when more predictor genes are included in model building . at any of the subsets size ,",
    "the _ _ mer__s of pca - based class prediction are lower that that of rm - based procedure .",
    "_ auc _ scores suggest acceptable prediction performance for rm - based dimension reduction model and excellent performance for the pca - based model .",
    ".prediction performances of the rm- and pca - based prediction models using random gene selection on the leukemia data set with @xmath128 split of samples over @xmath13 randomization trials .",
    "[ cols=\">,^,^,^,^,^,^,^ \" , ]     legend : rm - lda  rm - based class prediction ; pca - lda  pca - based class prediction ; @xmath29  number of selected genes ; _ mer _  mean error rate ; @xmath97  estimated number of gene factors ( components ) ; _ auc _  area under the roc curve .",
    "in this paper we explored the possibility of rms to solve the course of dimensionality problem arising in the context of microarray gene expression data , and evaluated its performance in class prediction framework using lda .",
    "to our knowledge , this is the first extensive validation study addressing rms for microarray data analysis . in terms of using rm - based dimension reduction of microarray data",
    ", the evaluated approach appears to be as effective as widely used pca - based dimension reduction .",
    "theoretically rms can handle a large number of genes .",
    "however , as many other multivariate methods it is challenged by large computational time and danger of over - fitting . therefore , we have used unsupervised random selection of small subset of genes and supervised welch s @xmath2-test gene selection procedure . applying random selection and using the _ mer _ and _ auc _ scores as class prediction performances , overall average values of @xmath129 ( @xmath130 ) and @xmath131 ( @xmath132 ) have been reached for leukemia and prostate data sets , respectively .",
    "we demonstrated that simple @xmath2-test improve the prediction performance significantly .",
    "considering supervised gene selection procedure , overall average values of @xmath133 ( @xmath134 ) and @xmath135 ( @xmath136 ) have been reached for leukemia and prostate data sets , respectively .",
    "the patterns of performance measures between rm- and pca - based procedures were similar , although the results suggested that rms benefit more from preliminary gene selection .",
    "compared to other studies aimed at class prediction , such as ones by @xcite , @xcite , or @xcite , our performance values are comparable .",
    "slightly better prediction performances in the case of leukemia data set confirm the fact that the biological separation between the two classes is more pronounced in leukemia data set @xcite .",
    "we have developed our approach for discretized microarray data because rm scaling assumes a binary response of a gene expression level . although our results indicate that the loss of information due to discretization step in our procedure is minimal , it is still the issue , if it is reasonable to consider gene expression discretely .",
    "referring to the work of @xcite , who demonstrated the effectiveness of the gibbs sampling to the biclustering of discretized microarray data , we argue that discretization may improve the robustness and generalizability of the prediction algorithm with regard to the high noise level in the microarray data .",
    "following @xcite the discretization of continuous gene expression levels is preferred for three reasons : ( i ) gene transcription occurs in one of a small number of states ( low  high , off  low ",
    "high , low  medium  high , off  low  medium  high , etc . ) ; ( ii ) the mechanisms of cellular regulatory networks can be reasonably approximated by primarily qualitative statements describing the relationships between states of genes ; ( iii ) discretization , as a general rule , introduces a measure of robustness against error .",
    "it is a worthwhile future project to study the performance of our method on different levels of dicretization , using polytomous latent variable models ( e.g. , partial credit model ) that could model more than two states of gene expression .",
    "the major dilemma coupled with class prediction studies is the measurement of the performance of the classifier .",
    "the classifier can not be evaluated accurately when sample size is very low .",
    "moreover , feature selection and feature extraction steps should be an integral part of the classifier , and as such they must be a part of the evaluation procedure that is used to estimate the prediction performance @xcite .",
    "@xcite reported several studies published in high impact factor journals where this issue is overlooked , and biased prediction performances are reported . to address these issues we applied loocv scheme to estimate the appropriate number of gene factors and re - randomization experimental design to stabilize performance measures .",
    "it seems that loocv is appropriate , but a more sophisticated design ( e.g. , subsampling , bootstrap sampling , @xmath137 estimator , etc . ) to determine the number of gene factors could improve the prediction performance of the rm - based approach .",
    "the vast amounts of gene expression data generated in the last decade have significantly reshaped statistical thinking and data analysis .",
    "the approach presented here can be also applied to many other problems in computational biology ( e.g. , single nucleotide polymorphism ( snp ) array data analysis ) and could be generalized to the other fields of sciences and humanities ( e.g. , health studies , risk management , financial engineering , etc . ) . hence",
    ", innovative statistical methods like the one presented in this paper are of great relevance .",
    "we have proposed a rm - based dimension reduction approach for the class prediction on microarray gene expression data .",
    "our method is designed to address the course of dimensionality and overcome the problem of `` large @xmath0 , small @xmath1 '' so common in microarray data analysis .",
    "experimental results showed that our procedure appears to be as effective as widely used pca - based dimension reduction method .",
    "we demonstrated that binarization of continuous gene expression levels does not affect prediction performance of the classifier .",
    "we showed that appropriate gene selection is crucial before dimension reduction is performed .",
    "we restricted our approach to the binary prediction problem , but the methodology can be extended to cover multiclass prediction .",
    "the application of our method to other prediction problems ( e.g. , regression , survival analysis ) is straightforward .",
    "we are currently working on extending this work on other latent variable models ( e.g. , partial credit model , rasch - andrich model , etc . ) .",
    "the first author was supported by junior research fellowship granted by slovenian research agency .",
    "00 alter , o. , brown , p. o. , & botstein , d. ( 2000 ) . singular value decomposition for genome - wide expression data processing and modeling .",
    "_ proc natl acad sci unit states am _ , _",
    "97_(18 ) , 1010110106 .",
    "antoniadis , a. , lambert - lacroix , s. , & leblanc , f. ( 2003 ) .",
    "effective dimension reduction methods for tumor classification using gene expression data .",
    "_ bioinformatics _ , _ 19_(5 ) , 563570 .",
    "asyali , m. h. , colak , d. , demirkaya , o. , & inan , m. s. ( 2006 ) .",
    "gene expression profile classification : a review .",
    "_ curr bioinformatics _ , _",
    "1_(1 ) , 5573 .",
    "bellazzi , r. , & zupan , b. ( 2008 ) .",
    "predictive data mining in clinical medicine : current issues and guidelines .",
    "_ int j med informat _ , _",
    "77_(2 ) , 8197 .",
    "boulesteix , a .-",
    "pls dimension reduction for classification with microarray data .",
    "_ stat appl genet mol biol _ ,",
    "_ 3_(1 ) . retrieved from doi:10.2202/1544 - 6115.1075 boulesteix ,",
    "l . , & strimmer , k. ( 2007 ) .",
    "partial least squares : a versatile tool for the analysis of high - dimensional genomic data . _ brief bioinform _ , _",
    "8_(1 ) , 3244 .",
    "boulesteix , a .-",
    "l . , strobl , c. , augustin , t. , & daumer , m. ( 2008 ) .",
    "evaluating microarray - based classifiers : an overview .",
    "_ canc informat _ ,",
    "_ 6 _ , 7797 . retrieved from http://www.la-press.com/evaluating-microarray-based-classifiers-an-overview-a577 bura , e. , & pfeiffer , r. m. ( 2003 ) .",
    "graphical methods for class prediction using dimension reduction techniques on dna microarray data . _ bioinformatics _ , _",
    "19_(10 ) , 12521258 .",
    "chen , j. j. ( 2007 ) .",
    "key aspects of analyzing microarray gene - expression data . _ pharmacogenomics _ , _",
    "8_(5 ) , 473482 .",
    "chiaromonte , f. , & martinelli , j. ( 2002 ) .",
    "dimension reduction strategies for analyzing global gene expression data with a response .",
    "_ math biosci _ , _",
    "176_(1 ) , 123144 . cordero , f. , botta , m. , & calogero , r. a. ( 2007 ) .",
    "microarray data analysis and mining approaches .",
    "_ brief funct genomic proteomic _ , _",
    "6_(4 ) , 265281 .",
    "dai , j. j. , lieu , l. , & rocke , d. ( 2006 ) .",
    "dimension reduction for classification with gene expression microarray data .",
    "_ stat appl genet mol biol _ , _ 5_(1 ) . retrieved from doi:10.2202/1544 - 6115.1147 de boeck , p. , & wilson , m. ( eds . ) .",
    "_ explanatory item response models : a generalized linear and nonlinear approach_. new york , ny : springer .",
    "de smet , f. , moreau , y. , engelen , k. , timmerman , d. , vergote , i. , & de moor , b. ( 2004 ) .",
    "balancing false positives and false negatives for the detection of differential expression in malignancies . _",
    "br j canc _ , _",
    "91_(6 ) , 11601165 . dettling , m. ( 2004 ) .",
    "bagboosting for tumor classification with gene expression data .",
    "_ bioinformatics _ , _",
    "20_(18 ) , 3583 - 3593 . do , j. h. , & choi , d. k. ( 2008 ) . clustering approaches to identifying gene expression patterns from dna microarray data .",
    "_ mol cells _ , _",
    "25_(2 ) , 279288 .",
    "dudoit , s. , fridlyand , j. , & speed , t. p. ( 2002 ) .",
    "comparison of discrimination methods for the classification of tumors using gene expression data .",
    "_ j am stat assoc _ , _",
    "97_(457 ) , 7787 .",
    "dupuy , a. , & simon , r. m. ( 2007 ) .",
    "critical review of published microarray studies for cancer outcome and guidelines on statistical analysis and reporting .",
    "_ j natl cancer inst _ , _",
    "99_(2 ) , 147157 . fan , j. , & li , r. ( 2006 ) .",
    "statistical challenges with high dimensionality : feature selection in knowledge discovery . in m. sanz - sol , j. soria , j. l. varona , & j. verdera ( eds . ) , _ proceedings of the international congress of mathematicians _",
    "( pp . 595622 ) .",
    "madrid : european mathematical society publishing house .",
    "fawcett , t. ( 2006 ) .",
    "an introduction to roc analysis . _ pattern recogn lett _ , _",
    "27_(8 ) , 861874 .",
    "fischer , g. h. , & molenaar , i. w. ( eds . ) .",
    "( 1995 ) . _",
    "rasch models : foundations , recent developments , and applications_. berlin : springer .",
    "gan , g. , ma , c. , & wu , j. ( 2007 ) .",
    "_ data clustering : theory , algorithms , and applications_. philadelphia , pa : society for industrial and applied mathematics .",
    "golub , t. r. , slonim , d. k. , tamayo , p. , huard , c. , gaasenbeek , m. , mesirov , j. p. , et al .",
    "molecular classification of cancer : class discovery and class prediction by gene expression monitoring . _ science _ , _",
    "286_(5439 ) , 531537 .",
    "hartemink , a. j. ( 2001 ) .",
    "_ principled computational methods for the validation and discovery of genetic regulatory networks_. unpublished doctoral dissertation , massachusetts institute of technology , boston .",
    "hastie , t. , tibshirani , r. , & friedman , j. h. ( 2001 ) . _",
    "the elements of statistical learning_. new york , ny : springer .",
    "holter , n. s. , mitra , m. , maritan , a. , cieplak , m. , banavar , j. r. , & fedoroff , n. v. ( 2000 ) .",
    "fundamental patterns underlying gene expression profiles : simplicity from complexity . _",
    "proc natl acad sci unit states am _ , _",
    "97_(15 ) , 84098414 .",
    "huang , j. , & ling , c. x. ( 2005 ) .",
    "using auc and accuracy in evaluating learning algorithms .",
    "_ ieee trans knowl data eng _ , _",
    "17_(3 ) , 299310 .",
    "hughes , g. ( 1968 ) . on the mean accuracy of statistical pattern recognizers .",
    "_ ieee trans inform theor _ , _",
    "14_(1 ) , 5563 . jain , a. k. , duin , r. p. w. , & mao , j. ( 2000 ) .",
    "statistical pattern recognition : a review .",
    "_ ieee trans pattern anal mach intell _ , _",
    "22_(1 ) , 437 .",
    "jeffery , i. b. , higgins , d. g. , & culhane , a. c. ( 2006 ) .",
    "comparison and evaluation of methods for generating differentially expressed gene lists from microarray data .",
    "_ bmc bioinformatics _ , _ 7 _ , 359 . retrieved from doi:10.1186/1471 - 2105 - 7 - 359 larraaga , p. , calvo , b. , santana , r. , bielza , c. , galdiano , j. , inza , i. , et al .",
    "machine learning in bioinformatics . _",
    "brief bioinform _ , _",
    "7_(1 ) , 86112 .",
    "li , h. , & hong , f. ( 2001 ) .",
    "cluster - rasch models for microarray gene expression data .",
    "_ genome biol _ , _",
    "2_(8 ) . retrieved from doi:10.1186/gb-2001 - 2 - 8-research0031 nguyen , d. v. , & rocke , d. m. ( 2002 ) .",
    "tumor classification by partial least squares using microarray gene expression data .",
    "_ bioinformatics _ , _",
    "18_(1 ) , 3950 .",
    "nguyen , d. v. , & rocke , d. m. ( 2004 ) . on partial least squares dimension reduction for microarray - based classification : a simulation study .",
    "comput stat data anal _ , _",
    "46_(3 ) , 407425 .",
    "orlando , d. a. , lin , c. y. , bernard , a. , wang , j. y. , socolar , j. e. , iversen , e. s. , et al .",
    "global control of cell - cycle transcription by coupled cdk and network oscillators .",
    "_ nature _ , _",
    "453_(7197 ) , 944947 .",
    "r development core team ( 2008 ) .",
    "_ r : a language and environment for statistical computing_. vienna : r foundation for statistical computing .",
    "available from http://www.r-project.org rabe - hesketh , s. , & skrondal , a. ( 2008 ) .",
    "classical latent variable models for medical research . _",
    "stat meth med res _ , _",
    "17_(1 ) , 532 .",
    "rasch , g. ( 1966 ) .",
    "an item analysis which takes individual differences into account . _",
    "br j math stat psychol _ , _",
    "19_(1 ) , 4957 .",
    "raudys ,  .",
    "measures of data and classifier complexity and the training sample size . in m. basu , & t. k. ho ( eds . ) , _ data complexity in pattern recognition _",
    "london : springer .",
    "richards , a. l. , holmans , p. , odonovan , m. c. , owen , m. j. , & jones , l. ( 2008 ) . a comparison of four clustering methods for brain expression microarray data . _ bmc bioinformatics _ , _ 9 _ , 490 .",
    "retrieved from doi:10.1186/1471 - 2105 - 9 - 490 ripley , b. d. ( 1996 ) .",
    "_ pattern recognition and neural networks_. cambridge : cambridge university press .",
    "sheng , q. , moreau , y. , & de moor , b. ( 2003 ) .",
    "biclustering microarray data by gibbs sampling .",
    "_ bioinformatics _ , _ 19_(suppl .",
    "2 ) , 196205 . simon , r. ( 2003 ) .",
    "diagnostic and prognostic prediction using gene expression profiles in high - dimensional microarray data .",
    "_ br j canc _ , _",
    "89_(9 ) , 15991604 .",
    "singh , d. , febbo , p. g. , ross , k. , jackson , d. g. , manola , j. , ladd , c. , et al .",
    "gene expression correlates of clinical prostate cancer behavior .",
    "_ canc cell _ , _",
    "1_(2 ) , 203 - 209 .",
    "slawski , m. , daumer , m. , & boulesteix , a .-",
    "cma - a comprehensive bioconductor package for supervised classification with high dimensional data .",
    "_ bmc bioinformatics _ , _",
    "9_(1 ) , 439 . retrieved from doi:10.1186/1471 - 2105 - 9 - 439 tibshirani , r. , hastie , t. , narasimhan , b. , & chu , g. ( 2002 ) .",
    "diagnosis of multiple cancer types by shrunken centroids of gene expression .",
    "_ proc natl acad sci unit states am _ , _",
    "99_(10 ) , 65676572 . zhang , c. , fu , h. , jiang , y. , & yu , t. ( 2007 ) .",
    "high - dimensional pseudo - logistic regression and classification with applications to gene expression data .",
    "_ comput stat data anal _ , _ 52_(1 ) ,"
  ],
  "abstract_text": [
    "<S> class prediction is an important application of microarray gene expression data analysis . </S>",
    "<S> the high - dimensionality of microarray data , where number of genes ( variables ) is very large compared to the number of samples ( observations ) , makes the application of many prediction techniques ( e.g. , logistic regression , discriminant analysis ) difficult . </S>",
    "<S> an efficient way to solve this problem is by using dimension reduction statistical techniques . </S>",
    "<S> increasingly used in psychology - related applications , rasch model ( rm ) provides an appealing framework for handling high - dimensional microarray data . in this paper </S>",
    "<S> , we study the potential of rm - based modeling in dimensionality reduction with binarized microarray gene expression data and investigate its prediction accuracy in the context of class prediction using linear discriminant analysis . </S>",
    "<S> two different publicly available microarray data sets are used to illustrate a general framework of the approach . </S>",
    "<S> performance of the proposed method is assessed by re - randomization scheme using principal component analysis ( pca ) as a benchmark method . </S>",
    "<S> our results show that rm - based dimension reduction is as effective as pca - based dimension reduction . </S>",
    "<S> the method is general and can be applied to the other high - dimensional data problems .    </S>",
    "<S> high - dimensional data , feature extraction , gene expression , class prediction , rasch model 02.70.rr , 07.05.kf , 02.50.sk , 87.18.vf , 87.80.st </S>"
  ]
}