{
  "article_text": [
    "a standard problem in contemporary galaxy dynamics is the interpretation of kinematic observations of galaxies in terms of their orbital structure as well as their dark and luminous matter distribution .",
    "there are several methods one can employ for this problem .",
    "first , moment - based methods find solutions of the jeans equations ( or higher - order velocity moments of the collisionless boltzmann equation ) that best fit the observed moments , such as density and velocity dispersion .",
    "secondly , distribution - function - based methods directly fit the distribution function to the data , which can be more general than mere moments , e.g.  the line - of - sight velocities of many individual objects .",
    "both techniques are usually restricted to spherical or , under certain simplifying assumptions , axisymmetric systems ( though for different reasons ) . however , distribution - function models are technically much more challenging ( since an integral equation has to be solved instead of differential equations ) and hence much less used than the moment - based approach . in both cases , astrophysically unjustified assumptions , such as velocity isotropy ,",
    "are often made in order to make the problem tractable .",
    "thirdly , schwarzschild s ( @xcite , @xcite ) orbit - based method constructs a dynamical model by first integrating many orbits over many orbital times in an assumed gravitational potential , whereby recording their properties in an orbit library , and then superposing them such that a best fit to the data is obtained .",
    "this is a powerful method , since it comes , in principle , without restrictions on the symmetry , and one may even obtain the distribution function @xcite .",
    "however , in practice most applications are restricted to axisymmetry , since there are several technical subtleties to overcome when applying the method to potentials with a complex phase - space structure , the typical situation for triaxial or barred systems ( though this is not impossible and has been done , e.g. * ? ? ?",
    "fourthly , in 1996 , @xcite ( hereafter st96 ) introduced the ` made - to - measure @xmath0-body method ' , which slowly adapts a @xmath0-body model to fit the data .",
    "the first application of this method came as late as 2004 , when @xcite used it to construct a dynamical model for the milky way s barred bulge and inner disk .",
    "more recently , @xcite ( @xcite , hereafter dl07 ) refined the method to incorporate observational errors ; this has since been applied for modelling elliptical galaxies to asses their dark - matter content @xcite .",
    "the made - to - measure ( hereafter ` m2 m ' ) method is as powerful as schwarzschild s orbit - based method , and in fact is closely related .",
    "whereas in schwarzschild s approach orbits are first separately integrated and then superimposed , these two steps are merged in the m2 m method : trajectories are integrated and their weights adapted at the same time . as a consequence there is no need for an orbit library and all the technical difficulties associated with it .",
    "however , with the m2 m method as proposed by st96 & dl07 some problems remain , as i shall discuss , in particular the appropriate time scale for adapting the particle weights of the @xmath0-body model .",
    "finally , @xcite introduced a variation of the m2 m technique ( though the authors did not make this association ) , which they dubbed the ` iterative method ' .",
    "their method starts from a near - equilibrium dynamical model ( constructed by any other method ) , which is alternately relaxed under self - gravity ( to evolve towards equilibrium ) and adapted to prescribed properties . in practice",
    ", this method too employs the @xmath0-body approach and , like the traditional m2 m technique , suffers from the time - scale problem .",
    "another application of all the aforementioned techniques is the generation of @xmath0-body initial conditions representing a galaxy or galaxy component ( though moment - based models additionally require the incorrect assumption of a gaussian velocity distribution and should not be used for this purpose ) .",
    "however as mentioned above , distribution - function models , which are the most commonly employed technique for generating @xmath0-body galaxy models , are restricted to spherical ( or , under simplifying assumptions , axial ) symmetry , which seriously limits their realism .",
    "since the m2 m technique works directly with @xmath0-body data , it offers a simple and natural way to generate @xmath0-body initial conditions with prescribed properties ( st96 ) , in particular non - spherical shape and non - isotropic velocity structure .",
    "as we shall see , however , this requires some modification to the traditional m2 m technique .    in this paper ,",
    "i revisit the m2 m method and propose several modifications aimed at improving it , in particular in view of its application for tailoring @xmath0-body initial conditions .",
    "i present the traditional st96 & dl07 version of m2 m in section [ sec : trad ] and my modifications to the method in  [ sec : novel ] , while  [ sec : ics ] presents some tests of tailoring non - spherical and/or velocity - anisotropic @xmath0-body models .",
    "finally  [ sec : disc ] discusses the results and concludes .",
    "in this section , the m2 m method as laid out by dl07 ( which in turn was based on st96 ) is outlined , though with slightly different notation and conventions .",
    "the fitting of the @xmath0-body model to the data is expressed as maximisation problem : the @xmath0-body model shall maximise the _ merit function _",
    "@xmath1 here , @xmath2 is the _ constraint function _ , which measures the goodness of fit of the @xmath0-body model to some target .",
    "there are many possible choices for @xmath2 , but for now let us follow dl07 and consider a @xmath3-like measure of the deviation of moments of the @xmath0-body model from target values @xmath4 here , @xmath5 are some _ moments _ of the model defined via the _ kernel _ @xmath6 and the particle weights @xmath7 , while @xmath8 are the _ targets _ for those moments and represent the observed data for an example ] with uncertainties @xmath9 .",
    "simply minimising @xmath2 is not a well defined procedure for two reasons : first , there is no point in reducing @xmath2 well below the expectation value even if this were possible ( this would amount to ` fitting the noise ' ) ; second , minimising @xmath2 may not be uniquely constraining the @xmath0-body model : there are , for instance , many possible equilibrium models with the same density .",
    "thus , in order to yield a well - defined problem , one has to _ regularise _ the merit function by a penalty functional @xmath10 times a lagrange multiplier @xmath11 , which controls the amount of regularisation .",
    "the penalty function is traditionally taken to be the pseudo - entropy @xmath12 with @xmath13 the normalised weights and @xmath14 a pre - determined set of normalised weights , the so - called priors .",
    "for general priors , @xmath10 defined in this way is the @xcite information distance ( also known as ` k - l divergence ' ) of the model corresponding to @xmath15 from the actual @xmath0-body model , i.e.  @xmath10 penalises against deviations of the normalised weights from the priors . only for",
    "@xmath16 , where @xmath17 denotes the value of the equilibrium distribution function corresponding to @xmath18 , does @xmath10 reduce to the true entropy of the @xmath0-body model ( plus a constant ; this corrects statements made by st96 & dl07 ) .",
    "the idea of the m2 m method is now to adjust the weights slowly such that @xmath19 is maximised .",
    "the standard method is to evolve the weights according to @xmath20 with some _ rate of change _ @xmath21 and the _ _ velocity of change _ _ the ` force of change ' , which is an inaccurate analogy since it is proportional to the first time derivative of the dependent variable .",
    "below i introduce a method which indeed uses the second time derivate , for which the expression ` force of change ' is much more appropriate . ]",
    "@xmath22 for the particular choice ( [ eq : c ] ) of the constraint function , this gives @xmath23 for sufficiently small @xmath21 , integrating ( [ eq : dotw ] ) will increase @xmath19 and eventually result in a @xmath0-body model for which @xmath19 is maximal and the @xmath24 no longer change .",
    "this method is similar to ( and was in fact inspired by ) @xcite - @xcite iteration , though with a much reduced step size .",
    "unfortunately , it is not as simple as that , because the merit function , being a function of the randomly sampled particle trajectories , is itself a random variable and fluctuates even with fixed weights . in order to suppress these fluctuations ,",
    "traditional m2 m replaces the model moments @xmath25 in ( [ eq : c ] ) with their time - averaged values @xmath26 , which are obtained by integrating the differential equation @xmath27 starting with ; st96 & dl07 give @xmath28 which results from integrating ( [ eq : mom : ave ] ) from @xmath29 , a practical impossibility . ]",
    "@xmath30 at @xmath31 . if fitting to observed data with finite uncertainties @xmath9 , this method has the virtue that the model uncertainties due to @xmath0-body shot noise ( which have been ignored in the definition of the constraint function ) are much reduced .",
    "a problem with this time - averaging is that the computation of the derivatives required for the velocity of change ( [ eq : foc ] ) is no longer straightforward .",
    "in fact , @xmath32 is simply the time - averaged kernel  the quantity which in schwarzschild s method is stored in the orbit library . in traditional m2 m , one simply replaces @xmath25 with @xmath26 directly in equation ( [ eq : foc : trad ] ) .",
    "even though , this means that weight adaption is not strictly along the gradient of the merit function , it appears that the method still converges in practice , though it is not completely obvious that it always does ( dl07 introduce the time - averaging only after they argue for convergence ) , in particular for other forms of the constraint function than simple @xmath3 expressions on model moments .",
    "in this section i criticise the traditional m2 m method and propose alternatives and/or modifications , which ultimately cumulate in a novel method .",
    "an important issue is the appropriate choice for the adjustment rate @xmath21 .",
    "the velocity of change ( [ eq : foc ] ) varies on the orbital time scale of the @xmath33th trajectory , because different parts of the orbit contribute differently to the merit function .",
    "clearly , the weight adaption should happen adiabatically , i.e.  @xmath34 with @xmath35 the natural ( orbital ) frequency of trajectory @xmath33 .",
    "unfortunately , the orbital frequencies of the @xmath0 trajectories may easily vary by many orders of magnitude , such that meeting this condition for all of them becomes a serious problem . in traditional m2 m",
    "this is not really solved : using a very low adaption rate @xmath21 ensures that the weights for all but the outermost trajectories are adapted adiabatically .",
    "one may think that using individual adjustment rates @xmath36 would solve the problem .",
    "however , this is not the case : the method no longer converges ( it does initially , but eventually convergence stalls well before reaching the optimum ) , presumably because such an alteration changes the direction of adjustment away from the gradient of @xmath19 .",
    "instead , i turn the tables and achieve @xmath37 by integrating each trajectory on its own dynamical time scale . to this end , i introduce the dimensionless time @xmath38 with @xmath39 the orbital period , such that with respect to this new dimensionless time each trajectory has natural frequency @xmath40 .",
    "the equations of motion for the @xmath0-body system expressed in @xmath41 are @xmath42 where a prime denotes derivative w.r.t .",
    "conversely , the m2 m equation remains : @xmath43 such that now @xmath21 is a dimensionless rate per orbit for _ each _ particle . in practice ,",
    "a rough estimate for the orbital period , e.g.  based on the epicycle approximation , is sufficient for @xmath44 .      with the traditional m2 m formulation , conservation of the total weight",
    "is not guaranteed , as the maximum of @xmath19 may occur at @xmath45 .",
    "this problem has not been discussed by st96 & dl07 , and i assume that it is dealt with by simply re - normalising the weights after each step .    while this may be a viable method , i propose a somewhat different approach which incorporates the total - weight constraint into the adjustment step .",
    "i start by observing that the unconstrained maximum of the modified merit function @xmath46 maximises @xmath47 subject to the constraint @xmath48 ( e.g. * ? ? ?",
    "thus , the total - weight constraint can be incorporated by replacing @xmath19 with @xmath49 in equation ( [ eq : foc ] ) .",
    "note that since @xmath49 depends on the constraints only through the @xmath50 , the @xmath0-body system must still be re - normalised after each adaption step , but the step hardly carries the system away from normalisation .",
    "alternatively , the total weight of the @xmath0-body system may be allowed to float freely and be constrained only by the data via the constraint function .      as discussed in the last paragraph of  [ sec : trad ] the traditional time - averaging procedure interferes with the computation of the gradient of the merit function . moreover , as i shall discuss in the next subsection , the time - averaging is particularly undesirable when using the m2 m method for tailoring @xmath0-body initial conditions .",
    "these considerations lead me to consider a different time - averaging approach : instead of averaging the moments , i consider suppressing fluctuations in the merit function by averaging @xmath49 ( or @xmath19 ) itself and its derivatives . in analogy to the moment - averaging equation  ( [ eq : mom : ave ] ) , this would yield @xmath51 with the dimensionless averaging rate @xmath52 . combining this with the weight - adjustment equation ( [ eq : dotw : mod ] ) results in a second - order differential equation for @xmath53 : @xmath54",
    "thus , @xmath55 acts like a force for the @xmath56 .",
    "i now take this analogy even further and replace it with the gradient of @xmath49 w.r.t .  the dependent variable @xmath56 : @xmath57 ( where i have substituted @xmath58 for @xmath59 ) , corresponding to @xmath60 for @xmath61 , equation ( [ eq : ddphi : new ] ) is equivalent to the familiar equation of motion under the influence of the ` potential ' @xmath62 .",
    "thus , if the time - dependence of @xmath49 were solely due to temporal changes in the weights , then the energy - like quantity @xmath63 is conserved .",
    "the frictional term proportional to @xmath52 in equation ( [ eq : ddphi : new ] ) in fact ensures that @xmath64 is not conserved but decreases , thus ultimately leading to the maximum of @xmath49 , as desired .",
    "thus , unlike the situation for traditionally m2 m , where the time - averaging of model moments may interfere with the convergence ( see the discussion in the last paragraph of  [ sec : trad ] ) , the time - averaging in my approach provides the damping term required for convergence .",
    "as already mentioned in the introduction , the m2 m technique offers a natural and powerful way to generate @xmath0-body initial conditions with prescribed properties .",
    "there is , however , a fundamental difference compared to employing m2 m for fitting data : the target values @xmath8 now represent these prescribed properties and , unlike observed data , have no natural uncertainties .",
    "a common practice with model fits without known uncertainties is to simply set @xmath65 ( alternatively , setting @xmath66 alters @xmath2 to measure the relative error and yields st96 s original method ) .",
    "however , this is rather unsatisfactory here , as the value obtained for @xmath2 then no longer provides insight about the goodness of fit .",
    "moreover , unlike most parametric model fits , a @xmath0-body model , being a monte - carlo representation , does have its own natural uncertainties .",
    "this suggests that the @xmath9 should be set to the uncertainties expected from shot noise in the @xmath0-body model itself .",
    "if this is done , @xmath2 retains its interpretability : a good fit corresponds to @xmath2 equalling to the number of constraints .",
    "while this sounds natural and straightforward , it introduces some subtle problems .",
    "one problem with traditional m2 m is that the time - averaging of the model moments intentionally reduces the shot noise , which invalidates the interpretability of @xmath2 .    with the alternative time - averaging of the merit function itself ( see  [ sec : novel : adjust ] ) ,",
    "this is no longer the case , but the shot noise in the @xmath0-body model causes temporal variations of @xmath49 additional to those induced by changing the weights .",
    "this means that equation ( [ eq : ddphi : new ] ) corresponds to following a frictional trajectory ( in @xmath0-dimensional @xmath67-space ) in a temporally fluctuating potential .",
    "the fluctuations are of the same order as the optimal value for @xmath2 and prevent the algorithm to converge in the sense that @xmath68 . however , the examples in  4 suggest that this is not a serious problem",
    ".      the adjustment of the weights in the m2 m technique may lead to a wide range of weights ( or for @xmath69 to a wide range of @xmath70 ) .",
    "this potentially reduces the effective resolution of the @xmath0-body model substantially and is particularly undesirable if the @xmath9 represent the uncertainties expected for a @xmath0-body system with weights following the priors .",
    "a wide range in @xmath70 ( corresponding to unequal masses for a flat prior ) is also undesirable with @xmath0-body initial conditions .",
    "therefore , it is useful to re - sample the @xmath0-body model from time to time during and after the adjustment process .",
    "this is easily done by drawing phase - space points for the new model from the original set @xmath71 with probability proportional to the relative normalised weight @xmath72 and subsequently setting the weights to @xmath15 if the total weight is constraint to unity and @xmath73 otherwise .    in this process",
    ", some trajectories of the original set will not be re - sampled , others get copied exactly once , yet others several times . in this latter case ,",
    "i make the first copy a straight clone of the original phase - space point , but for any additional copies , i first randomise position and velocity as far as the underlying symmetry allows ( for spherical symmetry , for instance , rotate them by a random angle about a random axis ) , and secondly add a small random velocity component .",
    "this added velocity component prevents multiple trajectories to be on identical orbits , and allows the model to explore phase - space regions of high weights .",
    "in order for the m2 m method to still maximise the same merit function , one has to alter the definition of the pseudo - entropy to @xmath74 with @xmath75 the product of the factors @xmath76 from each re - sampling so far . in this way , the contributions to @xmath10 from each trajectory are on average the same before and after re - sampling .",
    "however , the actual value for @xmath10 may increase ( in particular if a trajectory with @xmath77 happens to be re - sampled ) .      the description of my m2 m method , is completed by giving some technical details .",
    "the m2 m adjustment step is taken to be @xmath78 , which appears to be sufficiently short . between these ,",
    "the trajectories are integrated using individual adaptive time steps ( which are required despite the fact that every trajectory is integrated on its own orbital time ) .",
    "while this could be implemented with any type of method , i use the traditional @xmath0-body block - step scheme with a kick - drift - kick leap - frog and a time step @xmath79 with @xmath80 . in this way , trajectories are automatically synchronised at m2 m adjustment steps and the simultaneous computation of gravitational forces for many positions allows some optimisation .",
    "the m2 m equations are also integrated using a kick - drift - kick leap - frog  note that equation ( [ eq : foc : alt ] ) can be integrated exactly at fixed @xmath24 . in practice , @xmath21 is grown slowly over @xmath81 to its final value , but also limited to @xmath82 at any time .",
    "the @xmath0-body model is re - sampled whenever the ratio between maximum and minimum @xmath83 exceeds a certain threshold ( 4 in the runs of  [ sec : ics ] ) and a minimum interval has elapsed since the last re - sampling ( @xmath84 in  [ sec : ics ] ) .",
    "the phase - space coordinates for the @xmath85th re - sampled trajectory are set to those of the @xmath33th original trajectory where @xmath86\\ ] ] with @xmath87 the mean relative normalised weight and @xmath88 the cumulative relative normalised weight of the original model .",
    "trajectories with @xmath89 generate at most one copy , while those with @xmath90 get copied once or more .",
    "the random component added to the velocities of extra copies is drawn from a normal distribution with standard deviation @xmath91 times the local escape velocity ( but avoiding generation of unbound trajectories ) . in the case of a flat prior @xmath92 , which i used in  [ sec : ics ] , these relations simplify somewhat ( in particular @xmath93 ) .",
    "the m2 m method is ideally suited for distributed - memory parallelisation , since the gravitational potential is fixed ( no interactions between trajectories ) and the evaluation of the merit function and its derivatives require only minimal communications .",
    "i implemented my method using the message - passing interface ( ) and found the resulting code to be super - scaling : doubling the number of processors at fixed problem size reduces the execution time to less then half .",
    "this is presumably a result of the increase in total cache , reducing the total sum of computation times , which out - weighs the small communication overhead .",
    "almost all published @xmath0-body simulations featuring individual galaxies use initially spherical dark - matter haloes with isotropic velocity distributions .",
    "this is because for these settings distribution - function models , on which @xmath0-body initial conditions are usually based , are relatively simple to obtain .",
    "however , there is no physical justification for these simplifications and triaxial dark haloes with anisotropic velocity distributions are certainly more realistic .",
    "here , i apply my novel m2 m method to tailor such @xmath0-body initial conditions .",
    "let us first consider the problem of designing a triaxial equilibrium with prescribed shape and density profile , but without constraining its velocity structure .",
    "the aim is to construct a triaxial truncated @xcite model , which has density @xmath94^{-6 }    \\mathrm{sech}\\frac{q}{r_{\\mathrm{t}}},\\ ] ] with scale radius @xmath95 , truncation radius @xmath96 , and ` elliptical radius ' @xmath97 with @xmath98 . for this model , the radius at which @xmath99 , often referred to as the scale radius for dark - matter haloes , equals @xmath100 .",
    "i choose @xmath101 and axis ratios @xmath102 and @xmath103",
    ".    a convenient way to constrain the full three - dimensional density distribution of the model is by means of an expansion in bi - orthonormal potential - density basis functions @xmath104 and @xmath105 .",
    "these satisfy the poisson equation as well as the bi - orthonormality and completeness conditions @xmath106 where @xmath107 . in this study ,",
    "i use @xcite s ( @xcite ) basis set , whose lowest - order functions satisfy @xmath108 with scale radius @xmath109 , and a free parameter @xmath110 , which controls the density profile .",
    "the expansion coefficients @xmath111 are moments of the model and of the form ( [ eq : y ] ) , such that the resulting constraint function @xmath112 is of the form ( [ eq : c ] ) .",
    "note that the calculation of the derivative @xmath113 is equivalent to computing the gravitational potential due to the coefficients @xmath114 at the position @xmath115 .",
    "this has the benefit that the functionality of an existing basis - function based @xmath0-body force solver ( dubbed  self - consistent field code  by * ? ? ?",
    "* ) can be readily utilised .",
    "i use @xmath116 and @xmath117 for the parameters of the expansion and include terms up to @xmath118 and @xmath119 . since the model is forced to have triaxial symmetry already by the assumed underlying gravitational potential ( see below ) , one does not need to constrain this symmetry .",
    "this considerably reduces the number of terms in equation ( [ eq : c : rho ] ) , since coefficients with odd @xmath120 or @xmath121 can be ignored ( they vanish for triaxial symmetry ) as well as those with @xmath122 ( since @xmath123 ) , which leaves just 588 independent constraints for @xmath124 particles .    in order to prepare for the m2 m adjustment , i sample @xmath124 positions from the target density model and evaluate the resulting @xmath125",
    "this is repeated many times to obtain the target values @xmath126 and the expected errors @xmath127 from ensemble averaging .",
    "next , also the velocities are sampled from the equivalent spherical ( and velocity - isotropic ) distribution - function model and scaled in each dimension such that the tensor virial theorem is satisfied ( whereby correcting for unbound particles ) .",
    "lastly , to achieve phase - mixing the resulting trajectories are integrated for several orbital times in the potential of the target model computed from the expansion @xmath128 i hoped this procedure already results in a model close to the target , but this was not the case at all : the resulting value for the constraint function ( [ eq : c : rho ] ) is @xmath129 .",
    "finally , i run the m2 m scheme of equations ( [ eq : dotw ] ) and ( [ eq : foc : alt ] ) with @xmath130 , @xmath131 , and various values for @xmath11 , whereby integrating the trajectories in the target potential ( [ eq : pot ] ) . fig .",
    "[ fig : m2m : triaxial ] shows the time evolution of @xmath132 and the rms value of @xmath133 for an adjustment run with @xmath134 . after a quick reduction of the error ( as measured by @xmath135 ) , convergence becomes somewhat slower .",
    "@xmath135 fluctuates with amplitude similar to its good - fit value of 588 , as the discussion in  [ sec : novel : ics ] suggested , and does not reach this value .    in order to independently assess whether the adjustment successfully produced a stable @xmath0-body model with the desired properties ,",
    "i run it for 200 time units , @xmath136 , and @xmath137 , the total halo mass . ]",
    "( corresponding to @xmath138 dynamical times at the scale radius ) under self - gravity , whereby monitoring shape and density profile .",
    "this latter is done by first estimating the density at each particle using a kernel - estimator from its 32 nearest neighbours and then binning particles in density ( with 5000 per bin ) to estimate the rms radius and axis ratios ( from the eigenvalues of the moment - of - inertia tensor ) of density shells . as evident from fig .",
    "[ fig : rho : triaxial ] , the @xmath0-body model matches the target very well , except for too little flattening in the outermost regions .",
    "it appears thus , that the failure of convergence of @xmath135 close to its good - fit value is caused by the model being too round at very large radii ( well outside the virial radius of a cdm halo ) .",
    "the model appears stable : there is no significant change over 200 time units .",
    "next i consider the problem of generating a spherical halo model with specified velocity anisotropy .",
    "i use the spherical version of the model ( [ eq : rho : halo ] ) and aim to constrain binney s anisotropy parameter @xmath139 to have radial profile @xmath140 this corresponds to isotropy ( @xmath141 ) in the very centre , and a slowly increasing radial anisotropy ( for @xmath142 ) , reaching @xmath143 at @xmath144 , which describes simulated dark - matter haloes remarkably well @xcite .",
    "if one wants to retain the traditional m2 m approach of constraining model moments , one must constrain the moments @xmath145 , @xmath146 , and @xmath147 to values obtained from solving the jeans equation .",
    "however , this latter step requires spherical symmetry and hence can not be generalised to non - spherical systems .",
    "instead , i directly constrain the anisotropy via @xmath148 where @xmath149 indexes radial bins with rms radius @xmath150 and measured anisotropy @xmath151 where the sums are over all particles in the @xmath149th radial bin . since @xmath152 is not a moment of the model , but a function ( ratio ) of moments , it is not of the form ( [ eq : y ] ) .",
    "however , the derivatives @xmath153 , needed for @xmath154 , can still be easily computed .",
    "the uncertainties @xmath9 could be estimated from the @xmath0-body model , but since such an estimate depends on the @xmath24 and hence adds to @xmath154 , this would complicate matters unnecessarily .",
    "instead , i simply assume ( with @xmath155 the number of particles in the bin ) @xmath156 which is the standard deviation expected for a multivariate normal velocity distribution .",
    "the minimum occurs for @xmath157 and corresponds to equation  ( [ eq : sigma : beta ] ) , while the maximum ( arising at vanishing @xmath158 or @xmath159 ) is only a factor @xmath160 larger . ] with anisotropy @xmath161 .",
    "[ fig : m2m : aniso ] shows the time evolution of the various quantities for an m2 m run with @xmath124 , @xmath118 in @xmath135 ( only terms with @xmath162 are considered ) and 100 radial bins for @xmath163 with @xmath164 , i.e. increasing radial anisotropy .",
    "the values for the constraint functions converged to their best - fit values relatively quickly and after @xmath165 hardly any improvement is made .",
    "this is different from the situation for the triaxial halo model in the previous sub - section , which took much longer to reduce @xmath135 and required much smaller @xmath11 .",
    "the reason for this difference is not clear , but possibly it is because the solution space for spherical models with anisotropic velocities is larger than that for triaxial models with the assumed axis ratios .",
    "the resulting radial profiles for @xmath166 and @xmath161 for the @xmath0-body model provide an excellent match to the target values both just after the m2 m adjustment and after running the model in isolation ( under self - gravity ) for 200 time units , as demonstrated in fig .",
    "[ fig : rho : aniso ] .      finally , i want to generate a triaxial halo with the same triaxial density distribution as in  [ sec : ics : triaxial ] but with the velocity anisotropy profile given by equation ( [ eq : beta : model ] ) with @xmath164 , though with @xmath167 replaced with the elliptical radius @xmath168 defined in equation ( [ eq : ell : rad ] ) .",
    "to this end , i take the @xmath0-body models generated in ",
    "[ sec : ics : triaxial ] as starting point for the m2 m adjustment .",
    "just as in the previous sub - section , the constraint function now consists of two terms , constraining the density and velocity anisotropy , respectively . figs .",
    "[ fig : m2m : triaxial : aniso ] and [ fig : rho : triaxial : aniso ] show , respectively , the m2 m adjustment and the comparison of the final model with the target .",
    "evidently , the model matches the target excellently , even the shape in the outermost parts , which was too round in  [ sec : ics : triaxial ] .",
    "the basic idea of the made - to - measure ( m2 m ) method is to adjust the @xmath0-body weights until the model satisfies some constraints , expressed as maximisation of a merit function .",
    "this is achieved by changing the weights slowly in the uphill direction of the merit function .",
    "while any m2 m algorithm must follow this basic recipe , there is significant freedom in the details of how this is done .",
    "the purpose of this study was to improve these details compared to the original method as proposed by @xcite and slightly further developed by @xcite .",
    "a significant problem of this original method originates from the fact that the natural time scale for the adjustment ( and moment - averaging ) is some small multiple of the orbital time .",
    "since the latter varies substantially between orbits and , in particular , has no finite upper limit , any finite value for the adjustment time results in too slow or too fast an adjustment for most orbits .",
    "i solved this problem by introducing a dimensionless time variable , which effects to integrating each trajectory for the same number of orbital times .",
    "this is similar to schwarzschild s method , where usually each orbit considered is integrated for a fixed amount of orbital times .",
    "in fact , the number of orbital time scales in schwarzschild s method is of the same order ( @xmath169 , depending on details , such as orbital symmetries ) as with my m2 m technique , indicating that for typical orbits this number is required to gather sufficient information .",
    "note that the iterative method of @xcite , mentioned in the introduction , suffers from the same basic problem : evolving the model over some ( short ) time scale will bring the inner parts , where the dynamical time is short , much closer to equilibrim than the outer parts . in order to gather sufficient information about the dynamics in the outer parts",
    ", one would need to integrate orbits ( or evolve the model ) over a considerably longer time than is often practical .",
    "another issue with the original m2 m method is that the averaging of the model moments , required to suppress @xmath0-body shot noise , interferes with the adjustment process , though apparently this did not lead to practical problems so far .",
    "however , if the m2 m method is used to tailor @xmath0-body initial conditions , the uncertainties entering the constraints are not observational errors but those due to shot noise in the @xmath0-body model itself . in this case , time - averaging the model moments reduces this shot noise and renders the interpretation of the @xmath3-like constraint meaningless .",
    "i have overcome both these problems by introducing a novel adjustment algorithm which effects to time - averaging the merit function instead of the model moments and corresponds to following an orbit in @xmath0-dimensional weight space with the merit function representing the potential . a damping term , which emerges from the averaging , guarantees that the maximum of the merit function will be reached .",
    "i also propose to ( optionally ) modify the merit function such that it automatically meets the total - mass conservation constraint .",
    "finally , i propose to re - sample the @xmath0-body model from time to time during the m2 m adjustment process to ( 1 ) avoid a loss of resolution because of unequal weights , and ( 2 ) to allow the model to explore phase - space in regions of high weights .",
    "this latter is achieved by adding a small random velocity to extra copies of trajectories , effecting to probe another orbit close to a highly weighted one .",
    "certainly , one can think of further improvements to the m2 m method .",
    "one issue is an automatic adaption of the parameters @xmath21 and @xmath52 to achieve optimal convergence ( a technique to adapt @xmath11 such that the constraint function obtains a certain numerical value was already proposed by st96 ) .",
    "the priors for the weights can be used to allow the @xmath0-body model to have different mass resolution in different phase - space regions , which is a common technique ( e.g. * ? ? ?",
    "* ) for increasing the resolution in , say , the inner parts of models for dark - matter haloes .",
    "a significant speed - up may be achieved by starting with a relatively low number of particles and increasing @xmath0 ( essentially like re - sampling ) only later after the merit function is close to maximal .",
    "finally , one would like to adapt not only the weights of the @xmath0-body model , but also the underlying mass distribution generating the gravitational potential , for instance when interpreting kinematic data in terms of the underlying ( dark- ) matter distribution .",
    "unfortunately , changes in the orbits induced by changes of the gravitational potential are not straightforward to anticipate and hence to take into account in the adjustment process . in a spherical setting one",
    "may , for instance , re - scale the phase - space coordinates of every particle such that the eccentricity , inclination , and mean radius is preserved when the gravitational potential is changed . unfortunately , however , something similar can no longer be done in the general , i.e.  triaxial , case .",
    "thus , it seems that this is a really hard problem and that one is forced to ` jump ' from one mass model to the next whereby starting from the best - fit @xmath0-body model of a ` nearby ' potential . in this case",
    ", convergence may be fast , i.e.  only a few ten orbital times , leading to significant speed - up .",
    "as the practical examples of the previous section demonstrated , my novel m2 m algorithm is a powerful tool to construct @xmath0-body models with specified properties .",
    "one may use the method to explore possible stellar - dynamical equilibrium solutions and their properties .",
    "for instance , the triaxial models of  [ sec : ics : triaxial ] exhibit a significant radial velocity anisotropy ( fig .",
    "[ fig : rho : triaxial ] bottom panel ) , even though the initial conditions fed to the m2 m adjustment procedure were created from a velocity isotropic model and the velocity structure was not constrained .",
    "this strongly suggests that radial velocity anisotropy is an inevitable property of ( non - rotating ) triaxial equilibrium models .",
    "this can be qualitatively understood from the inevitable prevalence of box orbits , which are the only orbital family supporting a triaxial shape , but a more quantitative understanding would be desirable ."
  ],
  "abstract_text": [
    "<S> the made - to - measure @xmath0-body method @xcite slowly adapts the particle weights of an @xmath0-body model , whilst integrating the trajectories in an assumed static potential , until some constraints are satisfied , such as optimal fits to observational data . </S>",
    "<S> i propose a novel technique for this adaption procedure , which overcomes several limitations and shortcomings of the original method . </S>",
    "<S> the capability of the new technique is demonstrated by generating realistic @xmath0-body equilibrium models for dark - matter haloes with prescribed density profile , triaxial shape , and slowly outwardly growing radial velocity anisotropy .    </S>",
    "<S> [ firstpage ]    stellar dynamics  </S>",
    "<S> methods : @xmath0-body simulations  galaxies : kinematics and dynamics  galaxies : structure  galaxies : haloes </S>"
  ]
}