{
  "article_text": [
    "two important database operations are sorting and joins .",
    "these operations have three primary hardware - related costs : disk access , cpu operation and main memory access .",
    "the growth of main memory in current computers implies that main memory databases become more popular . for main memory databases ,",
    "the bottleneck moves from disk to main memory and the cost for disk access is not an issue anymore .",
    "further , the growing cpu - memory gap implies that cpu costs represent an increasingly small portion of the total time .",
    "this has been borne out by several studies of dbms  @xcite .",
    "the impact of the cpu - memory gap was popularized by the paper of wulf and mckee  @xcite on the _ memory wall_.    the diminishing role of the cpu in the total running time is partially accounted for by increasing cpu speeds and greater on - chip functional parallelism . in part , it is also accounted for because most cpus today implement non - blocking caches and hardware prefetch in order to overlap cpu execution with memory access  @xcite . hence , memory access becomes the bottleneck .",
    "therefore , we follow the example of previous researchers  @xcite in concentrating on main memory as the bottleneck .    at the heart of this memory bottleneck",
    "lies the _ record retrieval problem _ : the problem of copying records from a source array into a destination array according to a new ordering . in a typical application ,",
    "one will be given a source data file , a sequence of _ record ids _",
    "( rids ) for that data file , and a destination file .",
    "the task is to copy the source records into the destination file in the order specified by the sequence of rids .",
    "fast record retrieval is the key to faster sorting and faster joins .    a standard approach for data retrieval accesses the records of the source data file directly according to the sequence of the rids .",
    "this implies random access to the main memory .",
    "this , for example , is what was done in alphasort  @xcite and superscalarsort  @xcite , the current record holders for the datamation sorting challenge  @xcite .",
    "however , the cost of such random access has now become the dominant cost in main memory sorting , since the cpu - memory gap has widened still further since the original work on sorting .",
    "( in fact , alphasort and superscalarsort sort data on disk , but the size of the data file , 100  mb , is small enough that the disk access consists solely of reading the source data file from disk , and writing to a destination data file .",
    ")    random access is harmful not just in disk resident databases , but also in main memory resident databases .",
    "current dram technologies , such as ddr ram and rambus ram ( rdram ) , extract a large latency penalty for any non - sequential access to ram .",
    "this is because the memory chips are divided into memory pages of several kilobytes , and there is a latency penalty for switching to a new memory page  @xcite .",
    "random access to ram also harms performance in a second manner .",
    "random access incurs a heavy penalty when large cache blocks are used . on a cache miss , the entire cache block is loaded into memory . if the record size is small compared to the cache block size , then there is a large overhead to load the entire cache block .",
    "for example , for a cache miss on a pentium  4 with ddr-266 ram , approximately 60  ns are spent loading the cache block , and approximately 60  ns are spent waiting on the latency of ddr ram .",
    "the trend is toward larger cache blocks .",
    "the 128  byte l2 cache blocks of the pentium  4 are four times larger than those of the pentium  iii .",
    "the ibm power4 processor goes still further using 512  byte l3 cache blocks .",
    "the solution to avoid these latency penalties in main memory is to access main memory sequentially .",
    "this is similar in spirit to the way in which traditional databases strongly prefer to access disk sequentially . in analogy with operation on disk ,",
    "two - pass algorithms are a key for faster main memory performance .",
    "the dpg - based sorting algorithms immediately yield faster sorting algorithms . both alphasort and superscalarsort sort their data essentially in three phases : extraction of key - pointer pairs ; sorting of the key - pointer pairs ; and copying of the original records into the destination array according to the sorted key - pointer pairs .",
    "the last phase is essentially record retrieval .",
    "a re - implementation of alphasort and superscalarsort on a ibm p690 turbo shows that the record retrieval phase now dominates the running time . with the dpg record retrieval algorithm replacing the standard record retrieval algorithm",
    ", we immediately produce a faster sorting algorithm . in the re - implementation of superscalarsort ,",
    "the versions with dpg as an accelerator are 27% faster .",
    "a direct consequence of faster record retrieval is faster main memory sort - merge joins .",
    "for example , in implementing sort - merge join using superscalarsort , we find that the use of dpg sort instead of superscalarsort results in a 27% faster join algorithm .. the dpg record retrieval phase in isolation is 48% faster than traditional record retrieval algorithm .",
    "finally , we apply dpg algorithm in the context of _ foreign key joins_. in a foreign key join the join key is the same as the foreign key .",
    "we assume that one relation has an secondary index on the join key .",
    "foreign key joins have the advantage that one need only rearrange the records of one of the files .",
    "this is in distinction to sort - merge join and hash join , which both require to rearrange each of the two files into a new file with join key values in sorted order .",
    "foreign key joins require less record retrieval because it is possible to first extract _ join triples _ , ( @xmath0 , rid@xmath1 , rid@xmath2 ) , where @xmath3 and @xmath4 are the two relations and @xmath0 is the join key value .",
    "assume that @xmath3 references a foreign key of  @xmath4 . to construct a join triple ,",
    "do file scan of  @xmath3 , for each record of  @xmath3 , its key  @xmath0 is extracted .",
    "the secondary b - tree index of the join key on  @xmath4 is then used to derive the corresponding record i d , rid@xmath2 , with the key value  @xmath0 .",
    "the standard index lookup is very expensive , we propose a cache efficient b - tree batch lookup to generate the join triples .",
    "join triples reduce foreign key join to record pair retrieval .",
    "the join triples specify the record pairs , ( rid@xmath1 , rid@xmath2 ) , to be retrieved .",
    "one can re - order the records of  @xmath4 to match the ordering of rid@xmath1 in the sequence of record pairs . recall that ,",
    "we do file scan for  @xmath3 , so rid@xmath1s in the join triples are in sorted order .",
    "alternatively , one can sort the join triples according to rid@xmath2 , and re - order the records of  @xmath3 to match the ordering of rid@xmath2 in the sorted rid pairs . in either situation ,",
    "there are fewer record retrievals , and so foreign key join is faster than a general join .",
    "the ideas of faster record retrieval can also be applied to the general case of record pair retrieval .",
    "many algorithms for spatial join  @xcite and temporal join  @xcite produce record pairs .",
    "unlike equijoin , there is no single search key , and so record retrieval is more difficult .",
    "the ideas of this paper are described in terms of foreign key join .",
    "however , it is even simpler to translate the ideas into record pair retrieval , since an initial join triple extraction is not required .",
    "the _ distribute - probe - gather algorithm _ ( dpg ) is a record retrieval algorithm . given a data file of records and a sequence of record ids ( rids ) for the file ,",
    "the goal is to copy the records into a destination file with the property that the ordering of records in the destination file corresponds to the ordering of the rids in the given sequence .",
    "for example , let the source file , # r # , be the array of records with a secondary b+ tree index on the attribute # a#. we want to place the records of # r # in sorted order according to the values of  # a#. the sequence of record ids , # s_rid # , at leaf nodes of the b+ tree is a list of record ids in sorted order according to the value of a. then , the destination file , # d # , below , will contain the corresponding records in sorted order according to the value of  # a#.    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ for each i , d[i ] = r[s_rid[i ] ] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in the case that the sequence of rids is a permutation of the rids for the data file , the sequence of rids acts as a permutation vector .",
    "the destination file is then a permutation of the records in the input file .",
    "note , however , that the dpg algorithm is not limited to permutations of data . in the case of join ,",
    "one record from one relation may match more than one records from another relation .",
    "in such cases portion of the original records must be duplicated .",
    "the dpg algorithm also works for this case .",
    "the input for the algorithm is : a list of rids , # rid_list # , and a data file of records , # input#. the dpg algorithm partitions the rids , # rid_list # , into separate runs .",
    "it also partitions the data records , # input # , into separate runs .",
    "the algorithm makes two passes over the record ids , # rid_list # , and two passes over the records of the data file , # input#.    the ideas are presented in the context of main memory databases .",
    "we assume that neither the sequence of rids , # rid_list # , nor the data file , # input # , fit in cache .",
    "the dpg algorithm applies equally well as an external data retrieval algorithm between disk and main memory .",
    "the spirit of the dpg algorithm is : try to transform arbitrary memory access patterns into sequential memory access patterns ; where arbitrary memory access patterns are unavoidable , we try to divide the data into small partitions that fit into the cache .    for a sequential access pattern ,",
    "it is easy to maintain a buffer in cache . in the dpg algorithm",
    "we need to read many streams simultaneously , and maintain a buffer for each stream .",
    "hence , we want to keep the buffer as small as possible while maintaining reasonable efficiency .",
    "we define a buffer in cache to consist of two cache blocks . when a cache block is full , it is written back to main memory and a new cache block is loaded from main memory into cache .",
    "on pentium  4 , this is done automatically by the hardware prefetch function unit if the access to main memory is sequential . on other architectures without the hardware prefetch function unit , the software instructions , @xmath5 and @xmath6 ,",
    "are needed to maintain the buffers .",
    "[ [ constraints ] ] * constraints : * + + + + + + + + + + + + + +    the data records and rids are split into runs of length  @xmath7 .",
    "the run length  @xmath7 is chosen based on two constraints .",
    "first , the cache must be able to simultaneously hold both one run of data records of length  @xmath7 and one single buffer for the corresponding run of rids .",
    "( this constraint applies in the second phase of dpg . )",
    "second , the cache must simultaneously be able to hold a buffer for each run .",
    "( this constraint applies in the first phase and in the third phase of dpg . )",
    "these constraints are typical of the constraints for two - pass algorithms , such as external sorting .    if the data file has @xmath8  records , then the data file is partitioned into @xmath9 sets of consecutive records .",
    "assuming an rid consists of a page i d and offset on that page , the high order bits of the page number can be used to efficiently identify the particular partition to which the rid belongs .",
    "this assumes that the number of pages in a partition is a power of two , which can be satisfied by appropriate choice of  @xmath7 . for the sake of clarity , we assume the rids values are in the rage of @xmath10 and @xmath8 .    [",
    "[ three - phases ] ] * three phases : * + + + + + + + + + + + + + + +    there are three phases in the dpg algorithm .",
    "the three phases are also illustrated by pseudo - code in figure  [ fig : dpgalgo ] and by the diagram of figure  [ fig : dpg ] .",
    "1 .   * phase i. * the first phase is the _ distribute _ phase .",
    "one _ distributes _ the rids of # rid_list # into appropriate rid runs according to the values of the rids .",
    "the first rid run contains the rid values in the range from @xmath10 to @xmath7 , the second rid run contains the rid values in the range from @xmath7 to @xmath11 , and so on .",
    "both the access to every rid run and the access to # rid_list # are sequential .",
    "therefore , one only needs to maintains a buffer in cache for each rid run and a single buffer in cache for # rid_list # , at the end , we form @xmath9 rid runs and each rid run is a permutation vector .",
    "for example , the @xmath12-th rid run is a permutation vector in the range from @xmath13 and @xmath14 .",
    "* phase ii . *",
    "the second phase is the _ probe _ phase . in this phase ,",
    "we allocate a second , temporary data file , # internal # , in main memory .",
    "the temporary data file has the same size as the original data file , # input # , and is organized into the same number of runs as the original data file .",
    "one then proceeds through each of the runs of rids and each of the runs of # input#. the rids from the @xmath12-th rid run are used to probe the @xmath12-th # input # run and the corresponding records are copied into the @xmath12-th # internal # run .",
    "+ at the end , the @xmath12-th # internal # run contains the same records as the @xmath12-th # input # run , but the order of records in the # internal # run is organized according to the @xmath12-th rid run .",
    "both the @xmath12-th rid run and the @xmath12-th # internal # run are accessed sequentially .",
    "the @xmath12th # input # run is accessed randomly , but it can fit in cache . hence , every time , one loads the @xmath12-th # input # run entirely into cache and maintains two buffers in cache : one for the @xmath12th rid run and the other for the @xmath12-th # internal # run .",
    "* phase iii .",
    "* the third phase is the _ gather _ phase .",
    "this is an inverse of the _ distribute _ phase and is similar to the merge phase of external sorting . in the _ distribute _ phase , the rids are distributed into runs . as a result of the _ probe _ phase ,",
    "the records in a given # internal # run are now in the same order as the rids in the corresponding rid run created in phase i. hence , it suffices to gather ( merge ) the records from the # internal # runs in exactly the same order as the order of the rids in # rid_list#. more precisely , if the @xmath12-th rid was distributed to the @xmath15-th rid run during the _ distribute _ phase , then at the @xmath12-th step of the _ gather _ phase , the next record from the @xmath15-th # internal # run is copied to the destination array .",
    "one maintains several buffers in cache : one single buffer for # rid_list # , one single buffer for the destination array , and a buffer for each # internal # run .",
    "the dpg algorithm is presented more formally in pseudo - code in figure  [ fig : dpgalgo ] .",
    "the input of the algorithm is an array , # rid # , of _ rids _",
    "( record ids ) and a data file , # input_rec # , of records .",
    "it is desired to retrieve the records from # input_rec # in the order corresponding to # rid#. the retrieved records are then written to # output_rec#.    the three phases of the dpg algorithm are illustrated by an example in figure  [ fig : dpg ] .",
    "the input in this example is the leaf nodes of a secondary b+-tree index .",
    "the input contains a sequence of key - rid pairs sorted according to the key values .",
    "the output is a sequence of records sorted according to the key values of the secondary index .",
    "the output will either be stored again on disk or else pipelined to the next stage .",
    "the ability of the dpg algorithm to take advantage of pipelining is an important feature for sorting and joins .",
    "the letters # a # , # b # , # c # , ... are used to indicate the sorted keys on the leaf nodes of the index .",
    "so ( # a # , 5 ) indicates that the record with the rid value of  5 has a key value of # a#. the first two rows are for phase  i , the next three rows for phase  ii , and the following three rows for phase  iii .",
    "the horizontal rectangle of the first row represents a sequence of key - rid pairs sorted according to the key values .",
    "the second row represents the runs of rids into which the first row is partitioned .",
    "similarly , the third row again represents the runs of rids , but now as part of phase  ii .",
    "the fourth row is the partitioned runs of input records , and so on .",
    "there are  12 elements and  3 runs in the example and each run contains  4 elements .    during * phase i * ,",
    "one has a sequence of key - rid pairs sorted according to the key values and will distribute them into appropriate rid runs .",
    "the first rid run will contain rid values from  0 to  3 , the second rid run will contain rid values from  4 to  7 , and the third rid run will contain rid values from  8 to  11 . upon reading the sequence of pairs from the first row ,",
    "one places the rids in their proper runs .",
    "for example , the rid  5 goes to the second rid run , the rid  7 goes to the second rid run , the rid  3 goes to the first rid run , the rid  8 goes to the third rid run , and so on .",
    "the third row in the figure presents the end of phase i. in this phase , we do sequential read on a single stream and sequential writes on multiple streams .    during * phase ii * ,",
    "one copies the original data file , # input # , to a temporary data file , # internal#. the input to this phase is the third row . in the third row , each rid run has rid values that correspond to one contiguous range of the # input # file , an # input # run .",
    "for example , for the first rid run , we will load the first # input # run into the cache .",
    "the first # input # run consists of the first 4 contiguous records .",
    "the first rid in the first rid run is  3 and @xmath16 $ ] is in the cache , so one finds this record , # input[3 ] # , in cache and copies it to the buffer maintained in cache for the first # internal # run , and so on . at the end of phase  ii",
    ", the records in the first # input # run with key values in the sequence of i , l , f , c are reordered as records in the first # internal # run with key values in the sequence of c , f , i , l. the reordering is done according to a permutation specified by the first rid run , 3 , 2 , 0 , 1 .    during * phase iii * , we will use the original rid sequence in the list of key - rid pairs to _ gather _ ( merge ) records from all # internal # run .",
    "for example , upon reading  5 , we go to the second # internal # run to _ gather _ the record ; upon reading  7 , we go to the second # internal # run to _ gather _ the record ; upon reading  3 , we go to the first # internal # run to _ gather _ the record ; upon reading  8 we go to the third # internal # run to _ gather _ the record , and so on . for this phase",
    ", we maintain a buffer for the key - rid list , a buffer for # output # in cache and a buffer for each # internal # run .",
    "all buffers are in cache .",
    "0    .... % $ ( for sake of emacs ) let $ l\\gets$ ( cache_size/2 ) let $ n\\gets$ num_records let num_runs $ \\gets n / l$    \\rm input :   integer \\tt rid[num_rids ] ,      \\rm record \\tt input_rec[num_records ] ; \\rm output : record \\tt output_rec[num_rids ] ; \\rm parameters : \\rm integer \\tt rid_run[num_runs][]\\tt ,          \\rm record \\tt record_run[num_runs ] [ ] ;    //phase i :   { \\it distribute } rid array into runs //           with each run of length $ l$ % for $ i$ = 1 , ... ,",
    "num_runs do %    initialize write buffer of rid_run[$i$ ] for each rid , $ r$ , in rid do \\ {   set { \\it run\\_num } = $ \\lceil{}r / l\\rceil$ ;   append $ r$ to rid_run[{\\it run\\_num } ] \\ }",
    "//phase ii :   { \\it probe } partitions of input_rec % ( conceptually partition input_rec into partitions of length $ l$ and %   for each partition , $ i$ , of input_rec , probe for each rid in rid_run[$i$ ] ) for $ i$ = 1 , ...",
    ", num_runs do \\",
    "{ %    initialize read buffer for rid_run[$i$ ]    read into memory all records from     input_rec[$(i-1)\\!*\\!\\!l\\ ! + \\ !",
    "1 $ ] to input_rec[$i\\!*\\!\\!l$ ]    allocate memory for $ l$ records      to be stored in record_run[i ]    for each rid , $ r$ , in rid_run[$i$ ]      append input_rec[$r$ ] to record_run[$i$ ]    write out record_run[$i$ ] to disk \\ }",
    "//phase iii : { \\it gather } records from record_run [ ] //   into output_rec in same order as rid [ ] % for $ i$ = 1 , ... , num_runs do %    initialize read buffer of record_run[$i$ ] for each rid , $ r$ , in rid do \\",
    "{    set { \\it run\\_num } = $ \\lceil{}r / l\\rceil$ ;    read next record from record_run[{\\it run\\_num } ]    append record to output_rec \\ } ....      implicit in the description of the dpg algorithm is that the input sequence of rids is distributed uniformly among the set of all rids of the input data file .",
    "this is always the case when dpg is applied to retrieve records after sorting key - pointer pairs .",
    "in that situation , the key - pointer pairs act as a permutation vector to permute the records in the input data file .",
    "if the input sequence of rids is not uniformly distributed , then some rid runs will be larger than other runs . as a consequence , in phase  ii , when the partition of the temporary data file ( the partition of # record_run # in figure  [ fig : dpgalgo ] )",
    "may be larger than the size of the cache . if only a few of the partitions of the temporary data file are larger than cache then the overall running time is not greatly affected .",
    "if there is a great deal of data skew and many of the temporary partitions # record_run # are larger than cache , then the @xmath9 partitions of the input sequence of rids must be chosen on some other basis than the high order bits of the page number . in such cases , one can invoke the data skew handling techniques of dewitt et  al .  @xcite .",
    "their solution , reformulated in our context , is to sample the rids from the rid sequence .",
    "the sampled set of rids is then sorted , and partitions of the rids are chosen so as to evenly partition the sampled set .",
    "as discussed in the introduction , dpg acts as an accelerator for many main memory sorting algorithms .",
    "recall that main memory sorts typically proceed in three phases :    1 .",
    "extraction of key - pointer ; 2 .",
    "sorting of the key - pointer pairs ; and 3 .",
    "copying of the original records into the destination array according to the sorted key - pointer pairs .",
    "alphasort  @xcite and superscalarsort  @xcite are examples of this three - phase sorting paradigm .",
    "both sorting algorithms can be considered as main memory sorting algorithms .    in principle , the sorting algorithms are single - pass disk - based sorting algorithms .",
    "both sorting algorithms were introduced as an answer to the datamation sorting challenge  @xcite .",
    "the datamation challenge dictates that one is given one million records of 100  bytes .",
    "each record has a 10  byte key .",
    "the keys are uniformly distributed . at the time of the datamation challenge ,",
    "external sorting algorithms were required . on today s computers , the data file of 100  mb easily fits in main memory .",
    "hence , the only disk - related portion of the datamation challenge is to overlap disk  i / o with cpu operation .",
    "disk striping has the potential to provide very fast disk  i / o .",
    "this occurs because the disks are accessed in parallel .",
    "in this situation , main memory data retrieval becomes the bottleneck .",
    "the dpg algorithm pushes back this main memory bottleneck . by using dpg for data movement",
    ", the largest cost of main memory sorting is reduced .",
    "we have reimplemented the main memory portion of superscalarsort , both with and without dpg .",
    "we use the ideas of dpg to present three new join algorithms : 1.c , 2 and  3 .",
    "algorithms 1.a , 1.b and  4 , will be included in the experimental section  [ sec : joinexperiments ] for completeness .    1 .",
    "sort - merge join 1 .",
    "sort - merge join with alphasort ( sort based on  @xcite ) 2 .",
    "sort - merge join with superscalarsort ( sort based on  @xcite ) 3 .",
    "sort - merge join with dpg sort ( sort based on dpg ; see  [ sec : sortmergejoin ] ) 2 .",
    "dpg - sort join ( see section  [ sec : foreignkeyjoin ] ) 3 .",
    "dpg - move join ( see section  [ sec : foreignkeyjoin ] ) 4 .",
    "radix join ( from  @xcite )      the well - known sort - merge join was introduced by blasgen and eswaran  @xcite .",
    "there are two steps in sort - merge joins : sort two relations on the join key and scan the sorted relations to do a merge on the join key .",
    "applying dpg sort at the first step provides a new faster sort - merge join method , sort - merge join with dpg sort . in sections  [ sec : sortmergejoinexperiments ] and",
    "[ sec : joinexperiments ] , we experimentally compare different versions of sort - merge join , according to the sorting methods used .",
    "specifically , we consider using dpg sort , alphasort and superscalarsort for the sorting step .",
    "we next consider joins in which the join key is a foreign key , and it has an index .",
    "we denote by  @xmath3 a non - indexed relation .",
    "we denote by  @xmath4 an indexed relation .",
    "the notation is motivated by the example of a foreign key join . in a foreign key join , the join key is the same as the foreign key .",
    "so , the join key is a set of attributes in the relation  @xmath3 that refers to a foreign key from relation  @xmath4 .",
    "a _ join triple _ is a triple ( @xmath0 , rid@xmath1 , rid@xmath2 ) , such that @xmath0 is a key value , rid@xmath1 is the rid of a record from  @xmath3 with key  @xmath0 , and rid@xmath2 the rid of a record from  @xmath4 with key  @xmath0 .",
    "there are three steps in a foreign key join algorithm with dpg .",
    "the first step is to construct join triples .",
    "the second step is to use the join triples to copy one of the two relations into a temporary file according to an order derived from the join triples .",
    "the third step is to join the temporary file with the remaining relation .",
    "we describe the second and third steps initially in section  [ sec : foreignkeyjoin ] .",
    "we then return to the more technical problem of efficiently constructing join triples in sections  [ sec : jointriples ] and  [ sec : indexlookup ] .",
    "this section describes two dpg join algorithms .",
    "it assumes that one has already constructed the join triples . some algorithms for constructing the join triples",
    "are described later in sections  [ sec : jointriples ] and  [ sec : indexlookup ] .",
    "assume that one has generated the join triples ( @xmath0 , rid@xmath1 , rid@xmath2 ) .",
    "it is now possible to ignore the key  @xmath0 , and deal directly with the rid pairs ( rid@xmath1 , rid@xmath2 ) .",
    "we wish to satisfy one of two goals :    1 .",
    "[ item : movef ] * dpg - move join : * move the records of  @xmath4 into a temporary file according to the ordering of the records of  @xmath3 .",
    "[ item : mover ] * dpg - sort join : * move the records of  @xmath3 into a temporary file according to the ordering of the records of  @xmath4 .",
    "so , the rid pairs ( rid@xmath1 , rid@xmath2 ) will be sorted according to rid@xmath2 .",
    "first consider dpg - move join .",
    "we will see how to generate the join triples in the order of rid@xmath1 .",
    "this is done by scanning the records of the relation  @xmath3 in file order ( in order of increasing rid@xmath1 ) .",
    "therefore the rid pairs can be used directly as part of a dpg algorithm .",
    "the second component of the pair , rid@xmath2 , is the sequence of rids according to which we want to move the records of  @xmath4 .",
    "this algorithm does not require any sorting or hashing .",
    "hence , we call it dpg - move join .",
    "next consider dpg - sort join . in this version ,",
    "we first sort the rid pairs ( rid@xmath1 , rid@xmath2 ) according to the order of rid@xmath2 .",
    "this is done , for example , with superscalarsort and dpg .",
    "the algorithm then reduces to record movement in which we wish to move the records of  @xmath3 according to the ordering of  rid@xmath2 in the sorted sequence ( rid@xmath1 , rid@xmath2 ) .",
    "note that dpg - move join is preferred when the relation  @xmath4 is smaller .",
    "dpg - sort join is preferred when the relation  @xmath3 is smaller .",
    "the simplest solution for a foreign key join is to do a file scan of  @xmath3 , and for each record of  @xmath3 to extract the join key and do an index lookup in the index of  @xmath4 .",
    "one can then join the record of  @xmath3 with the corresponding record of  @xmath4 .",
    "this involves random access , and is economical only if the join produces very few records . in particular",
    ", this will be the case only if the number of records of  @xmath3 is small .",
    "a better solution is to do a file scan of  @xmath3 , and to use the index on  @xmath4 to create join triples . to construct the join triples ,",
    "one scans the relation  @xmath3 . for each record of  @xmath3",
    ", one extracts the corresponding rid and associated join key  @xmath0 .",
    "one then looks up the key  @xmath0 in the index of  @xmath4 .",
    "the index lookup yields the final element of the triple , rid@xmath2 .",
    "note that the join triple is constructed at the cost of a file scan of  @xmath3 and an index lookup in the index of  @xmath4 for each record of  @xmath3 .",
    "usually an index on a data file is much smaller than the full data file .",
    "if the index fits entirely in cache , then the index lookup will be significantly cheaper than the file scan .",
    "unfortunately , the indexes in many main memory databases generally do not fit in cache . in such cases ,",
    "the index lookup in the index of  @xmath4 will dominate the costs .",
    "for example , in a b+  tree indexing @xmath8  records , if an internal node has @xmath17  children , then @xmath18 nodes of the b+  tree must be accessed .",
    "each such access will be a random access in main memory .",
    "most of the random accesses imply a cache miss .",
    "the cost of so many random accesses makes a naive index lookup uneconomical .",
    "even if the index is a hash index , at least one random access in memory will be required .",
    "luckily , it is possible to execute the index lookup faster than the above analysis would indicate .",
    "this is because the construction of the join triples requires many index lookups , with no intervening record accesses . for purposes of join triple construction , _ batch lookup _ of keys in an index suffices . by batch lookup",
    ", we assume that an array of join keys is first extracted by scanning the data file of  @xmath3 .",
    "the batch lookup then produces an array of rids for  @xmath4 through the use of the index on  @xmath4 .",
    "we show that the index lookups can be reorganized into a two - pass algorithm .",
    "two such two - pass algorithms are demonstrated : one for b+ tree indexes , and one for hash indexes .",
    "note that batch lookup of rids in an index can be substantially faster than individual lookup .",
    "rao and ross had previously discussed cache conscious indexes for main memory  @xcite . there",
    "they present css - trees , which have better cache behavior than either b+  trees or hash indexes .",
    "however , they only consider individual lookup of keys in an index , one at a time . in their scenario , a second key",
    "is not looked up until the index lookup of the first key has been resolved .",
    "[ [ batch - lookup - in - b - tree - indexes ] ] * batch lookup in b+ tree indexes * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for simplicity , we describe the two - pass lookup for an enhanced b+  tree .",
    "the notion of _ enhanced b+  tree _ was introduced by rao and ross  @xcite .",
    "the idea is that all slots of a b+  tree node are used .",
    "this is similar to compact b - trees  @xcite or to the isam method introduced by ibm  @xcite . in the context of a general b+  tree",
    "this can be accomplished by maintaining updates to the b+  tree in a separate index , and then doing a batch update by reorganizing the b+  tree . for brevity",
    ", we will sometimes refer to b+  tree , although in all cases , an enhanced b+  tree is intended .",
    "assume that we are executing a file scan of  @xmath3 with the purpose of constructing the join triples .",
    "we collect a sequence of keys from the relation  @xmath3 , and we wish to carry out a batch lookup of rids in the enhanced b+-tree .",
    "the rids will be used to retrieve records from the foreign relation  @xmath4 .",
    "we assume that the b+  tree does not fit in cache .",
    "our goal is a two - pass algorithm which will efficiently accomplish batch lookup .",
    "assume that the b+  tree has @xmath17  entries per node .",
    "assume that the b+  tree indexes @xmath8  records .",
    "then there are @xmath18 levels .",
    "assume further that the first @xmath19 levels ( the top half of the b+  tree ) fit in cache .",
    "for @xmath20 , the top half of the tree has approximately @xmath21 slots .",
    "for example , if there are @xmath22 records , then there are 32,000 slots , which clearly fit inside cache .",
    "the strategy is a two - pass strategy . in the first pass ,",
    "one performs a lookup of each key , but only using the top half of the b+  tree .",
    "as shown in figure  [ fig : btree ] , each leaf of the subtree comprising this upper half can be considered as the root of a second subtree comprising nodes in the lower half of the b+  tree .",
    "thus , at the end of this first pass , a key can be associated with a leaf of the upper subtree , which is also a root of one of the lower subtrees .",
    "after the first pass , one can associate each key with a subtree within the lower half of the b+  tree .",
    "so , in the second pass , one loads a subtree from the lower half .",
    "one then continues the lookup for all keys associated with the root of the subtree in the lower half . at the end ,",
    "one then has a sequence of keys and rids .",
    "if one wishes to have the keys in the same order as the order of the original rids , then this can also be arranged . in this case , one extends the previous scenario to use the dpg algorithm .",
    "the first phase of the dpg algorithm is to _ distribute _ the keys into runs . in the initial lookup of a key in the first half",
    ", it was associated with a root of a subtree in the first half .",
    "the particular root of a subtree identifies the run into which the key is copied .",
    "the second phase of the dpg algorithm is to use the key to _ probe _ the index , in order to find the rid .",
    "one completes the lookup of all keys in a run associated with a particular subtree of the b+  tree , before proceeding to the next subtree in the lower half .",
    "the resulting rids are stored in a temporary partition or run .",
    "this is exactly what was described earlier .",
    "finally , the third phase of the dpg algorithm _ gathers _ the rids into a destination array in the same order as that of the original keys .",
    "hence , we have completed a batch lookup of the keys , and returned an array of rids in the same order as that of the original keys .",
    "[ [ batch - lookup - in - hash - indexes ] ] * batch lookup in hash indexes * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    batch lookup of hash indexes also proceeds in two passes .",
    "we assume that the hash array of the hash index stores at each hash entry one key - rid pair . a second hash array associated with the index stores pointers to overflow key - rid pairs that would have collided with an occupied slot in the first hash array .",
    "the two - pass lookup for hash indexes proceeds in a very simple manner .",
    "we extract the sequence of keys from  @xmath3 .",
    "as the keys are extracted , the hash values are computed .",
    "those key - hash value pairs are saved in an array in an order corresponding to the rid order of  @xmath3 .",
    "it now suffices to apply the dpg algorithm .",
    "the hash array is partitioned into sets of @xmath7  hash slots . in the distribute phase ,",
    "the hash value acts as an index into the hash array .",
    "hence , this becomes the permutation vector of the dpg algorithm .",
    "the key and hash value are then written into separate runs according to the partition of the hash array .",
    "there is one run of key - hash values for each partition of the hash array .    in the probe phase , a run of hash values",
    "is loaded into cache along with the corresponding partition of the hash array . as part of the probe phase ,",
    "the key and hash values from the run are used to look up the the corresponding rid in the partition of the hash array .",
    "the rids are then saved in a temporary partition , in the same order as the order in which the key - hash values of the original partition are stored .",
    "finally , in the gather phase , the ordering of the key - hash value pairs are used to gather the rids from the temporary partition . as in section",
    "[ sec : dpg ] , the rids are gathered into a destination array in an order corresponding the ordering of the original key - hash value pairs .",
    "figure  [ fig : sorting ] demonstrates the acceleration achieved by superscalarsort when dpg is used .",
    "the results are demonstrated on the ibm pseries 690 turbo .",
    "the ibm  p690 has an l3  cache of size 128  mb .",
    "hence , in order to realistically demonstrate dpg , we were forced to increase the size of the database .",
    "we chose to implement superscalarsort for a data file of size 512  mb .",
    "the record size was treated as a variable , to illustrate the influence of record size . as in the original datamation challenge ,",
    "the key is 10  bytes .",
    "note that the additional speed of superscalarsort with dpg is most pronounced for smaller record sizes . for record sizes of 256  bytes and higher",
    ", dpg provides only a small advantage .",
    "this is because the ibm p690 has an l3  cache block of size 512  bytes .",
    "so , for record sizes below 256  bytes , a cache miss incurs significant overhead in loading a 512  byte cache block .",
    "there was some variability in the results because the data was taken on a time - shared , shared memory machine . on the ibm  p690 ,",
    "the l2  cache is shared among two cpus , and the l3  cache is shared among eight cpus .",
    "our experiments were run on a single cpu .",
    "hence another process on a neighboring cpu could consume some of our cache , thereby affecting the timings .",
    "the reported experimental results are the averages of three runs each .",
    "we implement two sort - merge join methods : sort - merge join with dpg sort and sort - merge join with superscalarsort .",
    "as defined in section  [ sec : sortmergejoin ] , sort - merge join with dpg sort applies the dpg sort for the sorting phase and sort - merge join with superscalarsort applies superscalarsort for the sorting phase .",
    "as expected , the acceleration in the speed of sort - merge join in figure  [ fig : sortmerge ] follows the same pattern as that of figure  [ fig : sorting ] for sorting . in this case , we illustrate our results on a database of size 128  mb on the ibm p690 .",
    "the ibm p690 has an l2  cache of size 1.4  mb .",
    "so , in this case , the l3  cache is acting as the main memory , while l2  cache is acting as the `` cache '' .      in figures  [ fig : join_nonuniform_1 ] through  [ fig : join_dup_3 ] , we now experimentally compare the six join methods originally presented at the begining of section  [ sec : joinalgodpg ] .",
    "the three join algorithms labelled sort - merge join with dpg sort , dpg - sort join , and dpg - move join are all new .",
    "the remaining algorithms , sort - merge join with alphasort , sort - merge join with superscalarsort , and radix join , are all based on sorting or join algorithms from the literature .",
    "as explained earlier , we denote by  @xmath4 an indexed relation and  @xmath3 a relation that has foreign key on the indexed attribute of  @xmath4 .",
    "we consider both uniform and non - uniform distribution of foreign key values .",
    "[ [ the - non - uniform - distribution - of - join - key - values . ] ] * the non - uniform distribution of join key values . * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    sort - merge join with alphasort and dpg - sort are the only two of the previously discussed join methods that operate correctly for a non - uniform distribution of join key values .    in the following we use count bucket sort for bucket sort .",
    "the count bucket sort is as follows :    1 .",
    "count the number of elements destined for each bucket .",
    "2 .   set bucket boundaries according to the statics computed and distribute elements to buckets .",
    "alphasort works for non - uniformly distributed data , because it uses quicksort to sort each run and uses replacement - selection to merge the runs .",
    "dpg - sort join works for non - uniformly distributed data too , because we use count bucket sort to sort rids .",
    "dpg - sort join sorts the rids according to the lowest   @xmath23 bits is enough , @xmath8 is the number of records . in the simulation",
    ", we assign the rid values in the range @xmath24 $ ] , the lowest @xmath23 bits is sufficient for sorting . for example , for @xmath25 sorting rids according to the lowest 20 bits",
    "is enough .",
    "this could be done in two steps with count bucket sort : first do count bucket sort according to the lower 10 bits , then do count bucket sort according to the higher 10 bits .    using the unix @xmath26 and @xmath27 functions we generate an exponential distribution of the data as @xmath28 ( @xmath29 is a constant and in our experiments we assign c with @xmath30 ) .",
    "a comparison of sort - merge join with alphasort and dpg - sort join on three different computer architectures is provided in the figures  [ fig : join_nonuniform_1 ] ,  [ fig : join_nonuniform_2 ] , and  [ fig : join_nonuniform_3 ] .",
    "the three different architectures are the ibm power4 pseries 690 turbo , the 3.06 ghz pentium 4 with rambus pc-1200 ram , and the 2.6 ghz pentium 4 with ddr-266 ram , from the comparison , we can see that dpg - sort join is much faster than sort - merge join with alphasort .",
    "[ [ the - uniform - distribution - of - join - key - values . ] ] * the uniform distribution of join key values . * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    first we will show how all algorithms work for uniformly distributed join key values .",
    "superscalarsort is a key - prefix - sort explained further in section  [ sec : intro ] .",
    "it assumes that data is uniformly distributed according to the highest  7 bits of the key .",
    "this kind of distribution can be applied to all dpg algorithms , because a unform distribution of the join key values is the only constraint of sort - merge join with dpg and dpg - move join .",
    "we also implement the radix join of manegold et al .",
    "they describe a variation of hash join for main memory .",
    "radix join also requires a uniform distribution of the join key values .",
    "otherwise , some of their partitions will be too large to fit into the l2 cache and how to set the boundaries is unknown .",
    "we produce uniformly distributed foreign key values using the unix @xmath26 function . a comparison of the different join methods on three different computer architectures as before is provided in the figures .",
    "figure  [ fig : join_no_dup ] reflects data with no duplicate join key values in the relation  @xmath3 .",
    "figures  [ fig : join_dup_1 ] ,  [ fig : join_dup_2 ] , and  [ fig : join_dup_3 ] , show the same information in which duplicate join key values are allowed . from the comparison , we can see that dpg - move join and radix join are the fastest .",
    "dpg - move is better for large records and radix join is better for small records .",
    "the use of dpg in the sorting provides an accelerator for existing sorting algorithms . especially for the smaller record sizes , such as 32  bytes and 64  bytes , the performance improvements are really impressive .    for the more common case of non - uniform distribution of join key values , dpg - sort join works better than sort - merge join with alphasort across all the tested platforms . for smaller records sizes , such as , 32 , 64",
    ", dpg - sort join is much better than sort - merge join with alphasort . more impressively , on the newer platform",
    ", rambus pc-1200 ram , dpg - sort works better than on pc with ddr-266 ram and even works better for larger record sizes , for example 512  bytes .    for special case of uniform distribution of",
    "join key values , dpg - move join and radix join are the best .",
    "the remaining dpg algorithms are also competitive with older algorithms although with a smaller improvement .",
    "the dpg algorithm can be easily generalized to multiple passes",
    ". this can be useful when there is a very small cache in relation to the size of main memory .",
    "however , we do not encounter this scenario in our current experiments .",
    "we would like to thank betty salzberg and donghui zhang for extensive conversations and insights into additional situations where distribute - probe - gather can be beneficial .",
    "we also gratefully acknowledge the use of the support for the computations on the ibm p690 by the scientific computing and visualization ( scv ) group at boston university .",
    "a. ailamaki , d.j .",
    "dewitt , m.d .",
    "hill , d.a .",
    "wood , `` dbmss on a modern processor : where does time go ? '' , _",
    "vldb99 , proceedings of 25th international conference on very large data bases _ , 1999 , pp .  266 - 277 .",
    "l.  arge , o.  procopiuc , s.  ramaswamy , t.  suel and j.s .",
    "vitter , `` scalable sweeping - based spatial join '' , _",
    "vldb 1998 , proceedings of 24th international conference on very large databases _ , 1998 , pp .",
    "570581 .",
    "dittrich , b.  seeger , d.s .",
    "taylor and p.  widmayer , `` progressive merge join : a generic and non - blocking sort - based join algorithm '' , _",
    "vldb 2002 , proceedings of 28th international conference on very _ , 2002",
    ".        web site : `` latency vs. bandwidth , a performance analysis '' , http://www.lostcircuits.com/memory/latency/2.shtml ; `` inside the eddr chip : combining dram storage and sram speed '' , http://www.lostcircuits.com/memory/eddr/ , nov .",
    "27 , 2000 ; and `` high performance ddr dimms '' , http://www.lostcircuits.com/memory/ddr2/ , july  17 , 2001 .",
    "k.  keeton , d.a .",
    "patterson , y.q .",
    "raphael and w.e .",
    "baker `` performance characterization of a quad pentium pro smp using oltp workloads '' _ porc . of the int .",
    "syp . on computer architecture _",
    ", p0p .  1526 , barcelona , spain , 1998 .",
    "s.  manegold , p.a .",
    "boncz and m.l .",
    "kersten , `` what happens during a join ? dissecting cpu and memory optimization effects '' , _ vldb 2000 , proceedings of 26th international conference on very large data bases , september 10 - 14 , 2000 , cairo , egypt _ , 2000 , pp .",
    "339350 .",
    "p. trancoso j.l .",
    "larriba - pey , z.  zhang and j.  torellas , `` the memory performance of dss commercial workloads in shared - memory multiprocessors '' , _ int . symp . on high performance computer architecture _ , san antonio , tx , usa 1997 ."
  ],
  "abstract_text": [
    "<S> retrieval of records on disk is well - known to be at the heart of many database problems . </S>",
    "<S> we show that the corresponding movement of records in main memory has now become a severe bottleneck for many database operations . </S>",
    "<S> this is due to the stagnating latency of main memory , even while cpu speed , main memory bandwidth , and disk speed all continue to improve . as a result </S>",
    "<S> , record movement has become the dominant cost in main memory sorting .    </S>",
    "<S> we present a new algorithm for fast record retrieval , _ distribute - probe - gather _ , or dpg . </S>",
    "<S> dpg has important applications both in sorting and in joins . </S>",
    "<S> current main memory sorting algorithms split their work into three phases : extraction of key - pointer pairs ; sorting of the key - pointer pairs ; and copying of the original records into the destination array according the sorted key - pointer pairs . </S>",
    "<S> the copying in the last phase dominates today s sorting time . </S>",
    "<S> hence , the use of dpg in the third phase provides an accelerator for existing sorting algorithms .    </S>",
    "<S> dpg also provides two new join methods for foreign key joins : dpg - move join and dpg - sort join . </S>",
    "<S> the resulting join methods with dpg are faster because dpg join is cache - efficient and at the same time dpg join avoids the need for sorting or for hashing . </S>",
    "<S> the ideas presented for foreign key join can also be extended to faster record pair retrieval for spatial and temporal databases . </S>"
  ]
}