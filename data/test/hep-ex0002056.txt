{
  "article_text": [
    "the combination in quadrature of uncertainties due to systematic effects has become quite standard practice in physics .",
    "it is also common practice to add these uncertainties in quadrature to those from random effects .",
    "usually the two kinds of uncertainties are given separately , and the systematic - effect uncertainties are listed individually ( at least for the most relevant ones ) in order to show the potential of further measurements made with the same apparatus .",
    "this combination rule has arisen as a kind of pragmatic procedure  @xcite , in analogy to the combination of standard deviations in probability theory , although can not justifiably be termed within ` conventional ' ( i.e. non - bayesian ) statistics .",
    "the same is true for the use of the covariance matrix to handle correlated uncertainties .",
    "there is less agreement when the uncertainties due to systematic effects are asymmetric and/or they produce asymmetric shifts in the final quantity of interest , due to nonlinear propagation of uncertainty .",
    "fits if the @xmath0 around the minimum is not symmetric . in this paper",
    "we focus only on asymmetries deriving from systematic effects or non - linearity . ] as a numerical example of the latter case , take a quantity @xmath1 depending on three ` influence parameters ' @xmath2 , @xmath3 and @xmath4 , which could be calibration constants , environment quantities or theoretical parameters .",
    "suppose that , for the reference values of the @xmath5 s , the analysis procedure gives ( in arbitrary units ) @xmath6 , where the uncertainty associated with the result is that due to random effects .",
    "consider now that by ` varying reasonably the parameters @xmath7 ' ( the expression is intentionally left vague for the moment ) the following deviations from the central values occur : @xmath8 , @xmath9 , and @xmath10 .",
    "an often - used practice is to combine in quadrature separately positive and negative deviations , obtaining the following result : @xmath11 .",
    "now we are faced with the problem that the result of this _ ad hoc _ procedure has no theoretical justification .",
    "hence the uncertainty content of the statement ( i.e. its probabilistic meaning ) is unclear and , as a consequence , it is not obvious how to make use of this information in further analyses , even in the simple case in which the data points are uncorrelated . as a matter of fact , most people remove the asymmetry in further analysis of the results , using something equivalent to the standard deviations to be used in @xmath0 fits .",
    "this ` standard deviation ' is evaluated either by taking the largest value between @xmath12 and @xmath13 , or by averaging the two values ( some use the arithmetic , others the geometric average ) .",
    "the result is that in both procedures the uncertainty is symmetrized and the result is considered as if it were described , for all practical purposes , by a gaussian model around the published best estimate . and",
    "@xmath14 for a measurement @xmath15 , the error that we use for that measurement in making an average or a fit with other measurements is a continuous function of these three quantities . when the resultant average or fit @xmath16 is less than @xmath17 ,",
    "we use @xmath14 ; when it is greater than @xmath18 , we use @xmath19 . in between",
    ", the error we use is a linear function of @xmath15 .",
    "since the errors we use are functions of the result , we iterate to get the final result .",
    "asymmetric output errors are determined from the input errors assuming a linear relation between the input and the output quantities . ''",
    "_ this rule does not seem to be applied by others then the pdg . as examples of other ad hoc procedures , see refs",
    ".  @xcite . ]",
    "our main worry is not that the combined uncertainties will be incorrect ( we anticipate that the arithmetic average of @xmath12 and @xmath13 gives indeed the correct uncertainty in most cases of practical interest ) , but rather that the result itself can be biased with respect to what one could get using consistently the best knowledge concerning the input quantities , as will be shown in this paper .",
    "the purpose of this paper is to review the issue of uncertainty propagation , starting from general considerations and deducing approximate formulae for practical applications .",
    "the issue will be analysed in the framework of the so - called bayesian inference , though bayes theorem will never appear in this paper .",
    "this just means that , following physics intuition  @xcite , we consider it natural to talk about probability of true values . as a consequence , for this kind of application probability can only have the meaning of degree of belief .",
    "we will show that the rule of combining in quadrature symmetric uncertainties is a natural consequence of the probabilistic approach we follow , assuming that the uncertainties are conceptually properly defined ( although the overall result will not depend on their precise values ) .",
    "formulae to take into account correlations and nonlinearity effects will also be provided .",
    "the paper is structured as follows .",
    "first , in section [ sec : prob ] we illustrate briefly what we mean by probabilistic treatment of measurement uncertainties and why this is meaningful only within the bayesian approach . in this approach , the most general and logically consistent way to include all kinds of uncertainties is just a straightforward application of probability calculus .",
    "however , the application of the general propagation formula ( the derivation of which is given in appendix a ) requires the evaluation of integrals which can rapidly become complicated in real - life problems .",
    "therefore , approximate formulae are derived based on linear and quadratic expansion of the output quantity on the input quantities .",
    "this is done in sections [ sec : linear ] and [ sec : quadratic ] , respectively .",
    "several numerical examples are given , the main ones being discussed in section [ sec : examples ] .",
    "section [ sec : parabolic ] shows that our approximate formulae can also handle the case in which @xmath20 variations on an input quantity produce a shift in the same direction on the output quantity .",
    "correlations are also considered .",
    "we describe in the text only the linear case ( section [ sec : linear ] ) and refer to appendix b for the more complicated formulae which take into account second - order effects .",
    "the important issue of how to model uncertainties due to systematic effects is discussed in section [ sec : typeb ] . for practical purposes the probability density function ( p.d.f . ) of the output quantity can be considered approximately gaussian also in the non - linear cases and also if correlations are present , thanks to the combinatorial effects analogous to those which make the central limit theorem work . in case of important non - gaussian contributions in the input quantities , or strong non - linearity effects in the propagation , a detailed evaluation of the p.d.f .",
    "is needed , usually done using monte carlo methods .",
    "however , deviations from normality can be checked from skewness and kurtosis , and we give approximate formulae for these quantities in appendix b. finally , we show in appendix c how it is possible , in principle , to get a rough evaluation of the final p.d.f . , if this does not differ much from a gaussian ; ` in principle ' because we understand that the method described in appendix c is perhaps more an academic exercise than a real help to practitioners , who most likely will find it more convenient to solve the problem by monte carlo integration . concluding remarks are given in section [ sec : conclusions ] .",
    "in the bayesian approach , probability is associated with uncertainty , whether we are interested in the yet to be observed outcome of a measurement , or in the numerical value of the physics quantity . as a result of the experiment , there will be a p.d.f . @xmath21",
    "associated with the numerical value of the true value ( generically called @xmath22 ) , conditioned by the observed data and by the status of information ( @xmath23 ) concerning measurement and measurand ( the conditions @xmath24 and @xmath23 will usually be considered implicit ) .",
    "although we maintain that the proper way of learning from data is to make use of bayes theorem , it is easy to show that in most routine ( or , at least , non critical ) measurements the usual methods of analysis can be considered as approximations of bayesian inference ( see also section 2.9 of ref .",
    "when these kinds of conditions hold , also the gaussian approximation is usually rather good .",
    "therefore , hereafter we will consider a result of the kind @xmath25 , where @xmath26 is only due to random effects , equivalent to a gaussian p.d.f .",
    "of @xmath22 , as usually perceived by physicists  @xcite , i.e. @xmath27 where the symbol @xmath28 is to remind us that only uncertainties due to random effects are considered in eq .",
    "( [ eq : equivalence ] ) . on the other hand ,",
    "if one sticks strictly to frequentistic ideas , one gets ` results ' which have neither a meaning of certain statements about true values , neither the meaning of probabilistic statements . as a consequence ,",
    "it is not clear what they mean , neither how they should be combined or propagated in a logically consistent way ( see more extended discussion in refs.@xcite and @xcite ) .    in the probabilistic framework in which we are moving , the uncertainties due to systematic effects can be easily and consistently included ( at least conceptually , although the numerical implementation can present some technical problems ) .",
    "indeed , there are several ways to proceed , all leading to the same result , though each way can be more or less intuitive or suitable for a particular application ( see section 2.10.3 of ref .",
    "the closest one to the spirit of probabilistic inference consists in writing explicitly @xmath23 to depend on other physics quantities , which could be calibration constants , influence parameters ( temperature , pressure , etc ) , theoretical quantities , and so on , plus other pieces of general knowledge not easy to model ( @xmath29 ) and which lead the researchers to behave in a given way and to make reasonable assumptions in the many steps of the experimental work .",
    "let us indicate by @xmath29 this general knowledge .",
    "the physical quantities on which the result can depend will be called _ influence quantities _ ( or parameters ) and will be indicated by @xmath30 .",
    "the entire set of influence quantities will be indicated by @xmath31 . in general , the result ( [ eq : equivalence ] ) , which takes into account only random effects , is obtained using the set of best estimates of the parameters ( @xmath32 ) , i.e. @xmath33 the most general inference on @xmath22 will depend , instead , on all possible values of @xmath34 , and the resulting p.d.f . will be @xmath35 .",
    "probability theory teaches us how to get rid of the uncertainty about the exact value of the influence parameters . describing the uncertainty about the influence parameters with the joint p.d.f .",
    "@xmath36 , we obtain that the probabilistic result which takes into account systematic uncertainties is given by @xmath37 ( we use the symbol @xmath38 for all p.d.f.s , and implicitly consider the integrals done over the range of definition of the variables . )",
    "if the influence parameters are perfectly known , i.e. @xmath39 , we reobtain eq .",
    "( [ eq : inf_cond ] ) , and hence eq .",
    "( [ eq : equivalence ] ) , i.e. the uncertainty is that due to the random effects alone .",
    "hereafter we shall consider implicit the general condition @xmath29 .",
    "as an example , let us consider the result of a single measurement yielding the observed value @xmath40 , and in which the most relevant systematic effect is a not exactly known offset @xmath41 , the uncertainty about which is described by a gaussian p.d.f . around zero and standard deviation @xmath42 .",
    "we have ( see ref .",
    "@xcite for further details ) : @xmath43 the p.d.f . which describes @xmath22 is still centred around the observed value @xmath15 , but with a standard deviation which is the quadratic combination of @xmath26 and @xmath42 .",
    "the commonly used combination rule is recovered , but now as a theorem with well - defined conditions , instead of just a ` prescription ' .",
    "an alternative way of including systematic effects , very convenient for deriving approximate formulae , consists in considering a function @xmath44 which relates the true value @xmath22 to @xmath28 and of the influence factors , i.e. @xmath45 therefore the uncertainty about @xmath22 is obtained from the propagation of uncertainties about @xmath28 and @xmath34 ( see appendix a ) : @xmath46 this formula also has a simple interpretation which makes it convenient for monte carlo evaluation :  @xcite , or the parameters of the quark mixing matrix  @xcite : beliefs on the input quantities ( experimental and theoretical quantities ) are propagated into the beliefs on @xmath47 , or on @xmath48 and @xmath49 , respectively .",
    "the result has a clear probabilistic meaning and is , as we shall see , rather insensitive to the exact shape of the input p.d.f.s . instead , the so - called ` scanning '  @xcite or other _ ad hoc _ procedures ( see e.g. ref .",
    "@xcite ) do not have such an intuitive interpretation and can be misleading , especially when the very conservative ` regions of confidence ' produced by these methods are improperly called 95% c.l . regions . ]",
    "the infinitesimal probability element @xmath50 depends on ` how many ' elements @xmath51 contribute to it , each element weighted with the p.d.f .",
    "calculated in @xmath52 .    at this point",
    ", an interesting observation is that @xmath28 and @xmath30 have a symmetric role in the propagation of uncertainty , and therefore there is no real need to keep them separate in the formalism .",
    "therefore , following the iso _ guide _",
    "@xcite , we prefer to speak , generically , of _ input quantities _ , and to indicate them all by @xmath7 .",
    "we indicate the _ output quantity _ by @xmath1 . in many problems of interest",
    "also the output quantities might be more than one .",
    "their values are evaluated using the common data or ( which is conceptually equivalent ) making use of the same instrumentation .",
    "in such a case we have to consider correlations among the output quantities even if the input quantities were uncorrelated .",
    "hereafter we will indicate the generic functions @xmath53 with the same symbol as the output variables , and speak about @xmath54 .",
    "having illustrated the general solution to the problem , it is now interesting to obtain approximate formulae which , in many practical cases , save us from making complicated integrals .",
    "the case in which the dependence of @xmath56 on @xmath7 is approximately linear in a range of several standard deviations around their expected value is well known , and leads to the standard propagation formula of variances and covariances . what is less well known is that the use of these formulae is justified only if the numerical values of the physics quantities are associated with random numbers ( or uncertain numbers ) , and the probability is meant as degree of belief  @xcite .",
    "the first - order expansion of @xmath57 around the expected values of @xmath7 gives @xmath58 )            + \\sum_i\\left .",
    "\\frac{\\partial y_j }                        { \\partial x_i }                   \\right|_{\\mbox{\\small e}[\\mathbf{x } ] }                               ( x_i-\\mbox{e}[x_i ] ) \\label{eq : linear1 } \\\\",
    "& \\approx & k            + \\sum_i\\left.\\frac{\\partial y_j}{\\partial x_i }                    \\right|_{\\mbox{\\small e}[\\mathbf{x } ] } x_i\\ , , \\label{eq : linear2}\\end{aligned}\\ ] ] where @xmath59 $ ] stands for expected value and the derivatives are evaluated for @xmath60 $ ] ( this will be implicit hereafter ) .",
    "the second formula is very convenient to calculate the variance , having put in @xmath61 all terms which do not contain @xmath7 . evaluating the expected values from eq .",
    "( [ eq : linear1 ] ) , and variances and covariances from eq .",
    "( [ eq : linear2 ] ) , we get ( we have replaced the symbol ` @xmath62 ' by ` @xmath63 ' to indicate that there are no further approximations than linearization ) : @xmath64 & = & y_j(\\mbox{e}[\\mathbf{x } ] ) \\ , , \\label{eq : ey } \\\\",
    "\\sigma^2(y_j ) & = & \\sum_i\\left(\\frac{\\partial y_j }       { \\partial x_i}\\right)^2\\sigma^2_i + \\left\\{2\\,\\sum_{l < m } \\left(\\frac{\\partial y_j }       { \\partial x_l}\\right ) \\left(\\frac{\\partial y_j }       { \\partial x_m}\\right)\\,\\rho_{lm}\\,\\sigma_l\\,\\sigma_m \\right\\}\\ , ,   \\label{eq : vary } \\\\ \\mbox{cov}(y_j , y_k ) & = & \\sum_i\\left(\\frac{\\partial y_j }       { \\partial x_i}\\right ) \\left(\\frac{\\partial y_k }   { \\partial x_i}\\right)\\sigma^2_i + \\left\\{2\\,\\sum_{l < m } \\left(\\frac{\\partial y_j }       { \\partial x_l}\\right ) \\left(\\frac{\\partial y_k }       { \\partial x_m}\\right)\\,\\rho_{lm}\\,\\sigma_l\\,\\sigma_m \\right\\ } \\ , ,   \\label{eq : covy}\\end{aligned}\\ ] ] where @xmath65 are shorthand for @xmath66 and @xmath67 are the correlation coefficients , such that @xmath68 .",
    "the terms within @xmath69 vanish if the input quantities are uncorrelated , as it often the case when relevant systematic effects are considered .",
    "however , sometimes this is not the case , as when several calibration constants are simultaneously obtained from a fit . equations ( [ eq : vary])([eq : covy ] ) can be written in the more compact form of covariance matrix transformation . however , for the purpose of this paper , we prefer not to use the matrix formalism , in order to separate the contributions due to variances and covariances .    equations ( [ eq : ey])([eq : covy ] ) give only some limited information about the joint p.d.f .",
    "of @xmath70 , namely only 1st and 2nd moments",
    ". however the central limit theorem plays the important role of making the p.d.f . of each @xmath56",
    "practically gaussian in most of the cases of interest ( see e.g. examples and words of caution in ref .",
    "@xcite , and discussion in ref .",
    "@xcite ) . the joint p.d.f . can be considered for practical purposes a multivariate gaussian .",
    "anyway , in case of doubt , it is good practice to check the shape of each marginal p.d.f .",
    "( see appendix c ) .    in complex real - life cases",
    "the derivatives are not performed analytically . instead ,",
    "the effects of the input values on the output values are evaluated numerically , often by monte carlo techniques . in these cases",
    "the derivatives can be estimated numerically by @xmath71 variations around the expected values . calling @xmath72+\\sigma_x ) - y(\\mbox{e}[x])$ ] and @xmath73)-y(\\mbox{e}[x]-\\sigma_x ) $ ] .",
    "therefore , for monotonic functions around @xmath74 $ ] the increments @xmath12 and @xmath13 have the same sign.[fn : delta ] ] the variation of @xmath56 due to a variation of @xmath7 of @xmath75 around @xmath76 $ ] , linearity implies that @xmath77 since in the linear approximation @xmath78 and @xmath79 are practically equal , we call @xmath80 either of them ( taking the average of the two if there are small differences ; the case of large differences , hint of non - linear effects , will be discussed below ) .",
    "we get , finally , the following practical formulae for the elements of the covariance matrix : @xmath81 in the simple case of independent input quantities , eqs .",
    "( [ eq : vary1])([eq : covy1 ] ) reduce to @xmath82 where @xmath83 stands for the contribution to the covariance from the @xmath84th input quantity , and @xmath85 indicate the product of the signs of the absolute increments of @xmath56 and @xmath86 for a variation of @xmath7 ( @xmath87 have the meaning of standard uncertainty of @xmath56 due to @xmath7 alone ) .    at this point",
    ", we have to remember that @xmath28 defined in sec .",
    "[ sec : prob ] is considered as one of the input quantities , and that in the most general case there will be many @xmath88 , each associated with one and only one output quantity @xmath56 .",
    "the resulting covariance matrix will be equal to the sum of the covariance matrix of the @xmath88 ( they can be correlated as they could come from fitting procedures , unfolding , or other statistical techniques ) and the covariance matrix due to the systematic effects .",
    "let us write down , as an easy and practical example , the formulae for the case when we have @xmath89 values @xmath88 and the influence quantities are uncorrelated : @xmath90 where we have taken into account that the @xmath80 associated with @xmath91 are given by @xmath92 , where @xmath93 is kronecker symbol .",
    "in fact , the derivatives of @xmath56 with respect to @xmath91 , evaluated at the point of best estimate of @xmath94 , are equal to 1 if @xmath95 , and equal to 0 otherwise .",
    "at this point it is important to define somewhat better how the several ingredients appearing in the previous formulae should be evaluated .",
    "in fact , the results of the above formulae have a defined probabilistic meaning only if the various @xmath96 s are obtained as variations of the output quantities for @xmath97 variations of the input quantities , and not , generically , as reasonable variations , or , prudentially , as ` conservative variations ' .",
    "now we are confronted with the problem that in the evaluation of uncertainties due to imperfect knowledge of systematic effects , the case in which the input uncertainties are evaluated from standard statistical procedures which provide standard deviations in an automatic way is rare .",
    "these latter cases would be those in which we feel comfortable . more often , _",
    "`` for estimate @xmath98 of an input quantity @xmath7 that has not been obtained from repeated observations , the  standard uncertainty ",
    "is evaluated by scientific judgement based on all the available information on the possible variability of @xmath7 .",
    "the pool of information may include : previous data ; experience with or general knowledge of the behaviour and properties of relevant materials and instruments ; manufacturer s specifications ; data provided in calibration and other certificates ; uncertainties assigned to reference data taken from handbooks . '' _ ( iso guide  @xcite ) .",
    "this is along the spirit that _ `` the evaluation of uncertainty is neither a routine task nor a purely mathematical one ; it depends on detailed knowledge of the nature of the measurand and of the measurement ''",
    "_  @xcite .    following the recommendation of the bipm recommendations  @xcite",
    ", the iso guide calls this kind of uncertainty type b , in contrast to type - a uncertainties obtained , to say it shortly , by the dispersion of readings ( see also section 6.1.2 of ref .",
    "the evaluation of type - b uncertainties implies the adoption of the _ `` viewpoint  that probability is a measure of the degree of belief that an event will occur '' _   @xcite . in practice",
    "it requires a realistic and honest modelling of the case .",
    "the most common models are discussed in the iso guide itself : for example , if one is practically sure that an input value is in a certain interval , and all values inside the interval appear similarly likely , the proper model for the uncertainty is a uniform distribution .",
    "other times the edges of the interval seem still to be really extreme values for the quantity ; but one tends to believe more in central values , and the belief decreases roughly linearly from the centre to the edges . in this case",
    ", a more suitable distribution is a symmetric triangular distribution . alternatively ,",
    "if the belief decreases towards the edges , but the maximum belief does not coincide with ( approximately ) the centre of the interval , it is preferable to use an asymmetric triangular distribution . finally , if the interval seems simply to be just a highly probable one ( e.g. 90% , 95% or 99% ) , but also far away values are believed to be possible , one can use a gaussian model with a standard deviation which is a suitable fraction of the uncertainty interval .",
    "figure  [ fig : pdfsys ] shows the most common models to handle type - b uncertainties , together with their most interesting statistical parameters .       [ the integral ( [ eq : integrale ] ) has been solved with _ mathematica _ ] . for comparison",
    "the dotted curves show the estimations of p.d.f.s obtained by monte carlo .",
    "the agreement as it can been judged by eye is excellent . however , since the method is approximate , there are slight problems of normalization and positiveness .",
    "but these problems affect the tails of the distribution and are not really relevant if one is interested in having an idea of the shape under the assumptions of the approximation .",
    "note also the divergent term in eq .",
    "( [ eq : integrale ] ) for @xmath99 .",
    "but in practical cases the kurtosis is never much larger than this value .",
    "in fact one starts usually from distributions which have @xmath100 ( see fig .  [",
    "fig : pdfsys ] ) and , thanks to the central limit theorem , there is a natural tendency to have @xmath101 .",
    "therefore , in case of values of kurtosis slightly larger that @xmath102 , a good approximation is to limit it at 3 .",
    "this approximation has been indeed applied to the ` interpretation 2 ' of example of table [ tab : compare ] , and the resulting p.d.f .",
    "is still in excellent agreement with the monte carlo evaluation ( see right hand plot of fig .  [",
    "fig : out3 ] ) .",
    "ref99 g. dagostini , _ bayesian reasoning versus conventional statistics in high energy physics _ , proc .",
    "xviii international workshop on maximum entropy and bayesian methods , garching , germany , july 1998 , eds .",
    "v. dose , w. von der linden , r. fischer , and r. preuss , ( kluwer academic publishers , dordrecht , 1999 ) , pp .",
    "157170 , physics/9811046 .",
    "p. astone and g. dagostini , _ inferring the intensity of poisson processes at the limit of detector sensitivity ( with a case study on gravitational wave burst search ) _ , cern ",
    "ep/99126 , august 1999 , hep - ex/9909047 .",
    "g. dagostini , _ overcoming priors anxiety _ , to be published in the monographic issue of the revista de la real academia de ciencias on bayesian methods in the sciences , ed . j.m .",
    "bernardo , physics/9906048 , june 1999 .",
    "g. dagostini , _ confidence limits : what is the problem ? is there _ the _ solution ? _ , contribution to the workshop on `` confidence limits '' , cern 1718/1/2000 , hep - ex/0002055 g. dagostini , _ quantum mechanics and interpretation of probability ( with comments on confidence intervals ) _ , contribution to the workshop on `` confidence limits '' , cern 1718/1/2000 , paper in preparation . s. bertolini , j.o .",
    "eeg , m. fabbrichesi and e.i .",
    "@xmath47 at the @xmath105 in the chiral expansion _ , _ nucl .",
    "_ * b514 * ( 1998 ) 93 ; + a.j .",
    "buras , m. gorbahn , s. jger , m. jamin , m.e .",
    "lautenbacher and l. silvestrini , _ standard model confronting new results for @xmath47 _ , tum - hep-347/99 , hep - ph/9904408 ; + t. hambye , g.o .",
    "kohler , e.a .",
    "paschos and p.h .",
    "soldanet , _ analysis of @xmath47 in the @xmath106 expansion _ , do ",
    "th9910 , lnf99/016(p ) , june 1999 , hep - ph/9906434 ; + a.a .",
    "belkov , g. bohm , a.v .",
    "lanyov and a.a .",
    "moshkin , _ phenomenological analysis of @xmath47 within an effective chiral lagrangian approach at @xmath107 _ , jinr e299236 , july 1999 , hep - ph/9907335 .",
    "m. ciuchini , e. franco , l. giusti , v. lubicz and g. martinelli , _ combined analysis of the unitarity triangle and cp violation in the standard model _ , buhep9924 , rm3th/999 and rome 99/1267 , october 1999 , hep - ph/9910236 . f. parodi , p. roudeau and a. stocchi , _",
    "constraints on the parameters of the ckm matrix by end 1998 _ , lal 99 - 03 , march 1999 , hep - ex/9903063 s. plaszczynski and m .- h .",
    "schune , _ overall determination of the ckm matrix _ , lal 99 - 03 , november 1999 , hep - ph/9911280 .",
    "international organization for standardization ( iso ) , _ guide to the expression of uncertainty in measurement _ , geneva , switzerland , 1993 ."
  ],
  "abstract_text": [
    "<S> starting from considerations about meaning and subsequent use of asymmetric uncertainty intervals of experimental results , we review the issue of uncertainty propagation . </S>",
    "<S> we show that , using a probabilistic approach ( the so - called bayesian approach ) , all sources of uncertainty can be included in a logically consistent way . </S>",
    "<S> practical formulae for the first moments of the probability distribution are derived up to second - order approximations . </S>"
  ]
}